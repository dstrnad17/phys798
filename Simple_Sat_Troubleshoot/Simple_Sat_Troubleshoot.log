Training iteration loss = 0.016180433

Training iteration loss = 0.012741964

Training iteration loss = 0.011732523

Training iteration loss = 0.009449061

Training iteration loss = 0.01033885

Training iteration loss = 0.0074877106

Training iteration loss = 0.016442562

Training iteration loss = 0.00676251

Training iteration loss = 0.008333645

Training iteration loss = 0.008157925

Training iteration loss = 0.007529384

Training iteration loss = 0.0067118853

Training iteration loss = 0.007038051

Training iteration loss = 0.007355833

Training iteration loss = 0.00758501

Training iteration loss = 0.008710778

Training iteration loss = 0.007980004

Training iteration loss = 0.007462839

Training iteration loss = 0.0060254037

Training iteration loss = 0.0046780403

Training iteration loss = 0.005904406

Training iteration loss = 0.005364478

Training iteration loss = 0.0055578067

Training iteration loss = 0.01095542

Training iteration loss = 0.004683026

Training iteration loss = 0.0054623783

Training iteration loss = 0.0060213474

Training iteration loss = 0.007157637

Training iteration loss = 0.005268372

Training iteration loss = 0.00583737

Training iteration loss = 0.0048961057

Training iteration loss = 0.0042284722

Training iteration loss = 0.006202673

Training iteration loss = 0.0048182886

Training iteration loss = 0.0042338003

Training iteration loss = 0.0038382637

Training iteration loss = 0.0044646175

Training iteration loss = 0.005134784

Training iteration loss = 0.0050546993

Training iteration loss = 0.004336897

Training iteration loss = 0.0058489605

Training iteration loss = 0.0043641627

Training iteration loss = 0.0040057953

Training iteration loss = 0.0032211982

Training iteration loss = 0.0033403737

Training iteration loss = 0.0027862333

Training iteration loss = 0.004256562

Training iteration loss = 0.0024605936

Training iteration loss = 0.0028947678

Training iteration loss = 0.0037966834

Training iteration loss = 0.0032150196

Training iteration loss = 0.0033073192

Training iteration loss = 0.0029873122

Training iteration loss = 0.004310151

Training iteration loss = 0.003618148

Training iteration loss = 0.004614838

Training iteration loss = 0.0026631358

Training iteration loss = 0.002999665

Training iteration loss = 0.0024115187

Training iteration loss = 0.0035113695

Training iteration loss = 0.002710594

Training iteration loss = 0.0031634343

Training iteration loss = 0.0028085678

Training iteration loss = 0.0023312217

Training iteration loss = 0.0025392713

Training iteration loss = 0.0034674678

Training iteration loss = 0.0027946446

Training iteration loss = 0.0025774424

Training iteration loss = 0.002755208

Training iteration loss = 0.0025582446

Training iteration loss = 0.0021953445

Training iteration loss = 0.0026084303

Training iteration loss = 0.0022253608

Training iteration loss = 0.002030391

Training iteration loss = 0.001984883

Training iteration loss = 0.0017666859

Training iteration loss = 0.0014269395

Training iteration loss = 0.0023113147

Training iteration loss = 0.002923961

Training iteration loss = 0.002199044

Training iteration loss = 0.002169707

Training iteration loss = 0.0011213998

Training iteration loss = 0.00238502

Training iteration loss = 0.0027266406

Training iteration loss = 0.0013480615

Training iteration loss = 0.0017969925

Training iteration loss = 0.0014004163

Training iteration loss = 0.0013861969

Training iteration loss = 0.0013290676

Training iteration loss = 0.0013850229

Training iteration loss = 0.0020854785

Training iteration loss = 0.0021689252

Training iteration loss = 0.00092682434

Training iteration loss = 0.0011966744

Training iteration loss = 0.00087495503

Training iteration loss = 0.0011696854

Training iteration loss = 0.0013315114

Training iteration loss = 0.0012767276

Training iteration loss = 0.0014233128

Training iteration loss = 0.00075703516

Training iteration loss = 0.0015235721

Training iteration loss = 0.0025269592

Training iteration loss = 0.0013744693

Training iteration loss = 0.0013458999

Training iteration loss = 0.00079503545

Training iteration loss = 0.0009297626

Training iteration loss = 0.00088812265

Training iteration loss = 0.0010923481

Training iteration loss = 0.000736891

Training iteration loss = 0.00055516436

Training iteration loss = 0.0008130734

Training iteration loss = 0.0006897905

Training iteration loss = 0.00062949467

Training iteration loss = 0.0014284378

Training iteration loss = 0.00077463686

Training iteration loss = 0.0012055604

Training iteration loss = 0.00065256166

Training iteration loss = 0.0006304706

Training iteration loss = 0.0007526761

Training iteration loss = 0.0010732849

Training iteration loss = 0.00095586054

Training iteration loss = 0.0006206516

Training iteration loss = 0.0005871383

Training iteration loss = 0.0008141237

Training iteration loss = 0.00041941367

Training iteration loss = 0.00043494595

Training iteration loss = 0.0003806244

Training iteration loss = 0.0007027993

Training iteration loss = 0.0005748983

Training iteration loss = 0.0005705811

Training iteration loss = 0.0003957546

Training iteration loss = 0.0003317586

Training iteration loss = 0.00048136627

Training iteration loss = 0.00026903782

Training iteration loss = 0.0003694682

Training iteration loss = 0.0003176978

Training iteration loss = 0.00037674056

Training iteration loss = 0.00043991895

Training iteration loss = 0.00050684373

Training iteration loss = 0.0008323803

Training iteration loss = 0.00047739677

Training iteration loss = 0.0004178671

Training iteration loss = 0.00031682503

Training iteration loss = 0.0003473611

Training iteration loss = 0.0003246958

Training iteration loss = 0.00072793785

Training iteration loss = 0.00036388126

Training iteration loss = 0.00042651067

Training iteration loss = 0.00024111483

Training iteration loss = 0.00042681932

Training iteration loss = 0.0010028629

Training iteration loss = 0.00031659254

Training iteration loss = 0.00041989237

Training iteration loss = 0.00038716602

Training iteration loss = 0.00023788546

Training iteration loss = 0.00037948936

Training iteration loss = 0.00036689363

Training iteration loss = 0.00027516016

Training iteration loss = 0.00021806693

Training iteration loss = 0.00037399554

Training iteration loss = 0.0003459342

Training iteration loss = 0.00027438186

Training iteration loss = 0.0006934334

Training iteration loss = 0.00048744446

Training iteration loss = 0.00029193578

Training iteration loss = 0.00030735793

Training iteration loss = 0.00027016507

Training iteration loss = 0.00047286577

Training iteration loss = 0.00022955505

Training iteration loss = 0.00026419654

Training iteration loss = 0.00021202948

Training iteration loss = 0.00017025735

Training iteration loss = 0.0001325301

Training iteration loss = 0.00026297796

Training iteration loss = 0.00018442333

Training iteration loss = 0.00013200633

Training iteration loss = 0.00025454586

Training iteration loss = 0.00020143965

Training iteration loss = 0.0001619625

Training iteration loss = 0.0001434914

Training iteration loss = 0.00021351675

Training iteration loss = 0.00015675042

Training iteration loss = 0.000225158

Training iteration loss = 0.00031771307

Training iteration loss = 0.00042409546

Training iteration loss = 0.00015038085

Training iteration loss = 0.000160422

Training iteration loss = 0.00011536615

Training iteration loss = 9.328222e-05

Training iteration loss = 9.7929995e-05

Training iteration loss = 0.00026748134

Training iteration loss = 9.13977e-05

Training iteration loss = 0.00024700086

Training iteration loss = 0.00017829584

Training iteration loss = 0.0001418128

Training iteration loss = 8.1099024e-05

Training iteration loss = 9.9666715e-05

Training iteration loss = 0.0003797355

Training iteration loss = 9.2208655e-05

Training iteration loss = 0.000104629915

Training iteration loss = 0.0001901788

Training iteration loss = 0.00016081252

Training iteration loss = 8.966258e-05

Training iteration loss = 0.00014164094

Training iteration loss = 0.00023523574

Training iteration loss = 8.167676e-05

Training iteration loss = 0.00045819054

Training iteration loss = 7.460133e-05

Training iteration loss = 0.00011149602

Training iteration loss = 0.00013833247

Training iteration loss = 6.8453315e-05

Training iteration loss = 4.6508834e-05

Training iteration loss = 8.125272e-05

Training iteration loss = 4.5118446e-05

Training iteration loss = 9.364714e-05

Training iteration loss = 0.00014471258

Training iteration loss = 0.00014451069

Training iteration loss = 7.333842e-05

Training iteration loss = 8.36954e-05

Training iteration loss = 3.9162154e-05

Training iteration loss = 4.463064e-05

Training iteration loss = 3.7183363e-05

Training iteration loss = 5.3796364e-05

Training iteration loss = 0.00029258328

Training iteration loss = 5.184377e-05

Training iteration loss = 4.7660888e-05

Training iteration loss = 5.6427743e-05

Training iteration loss = 5.288472e-05

Training iteration loss = 5.741367e-05

Training iteration loss = 5.6193105e-05

Training iteration loss = 3.7552007e-05

Training iteration loss = 2.944617e-05

Training iteration loss = 8.600795e-05

Training iteration loss = 4.3168042e-05

Training iteration loss = 3.858448e-05

Training iteration loss = 3.7306007e-05

Training iteration loss = 5.0518458e-05

Training iteration loss = 6.0583247e-05

Training iteration loss = 6.171821e-05

Training iteration loss = 4.4911725e-05

Training iteration loss = 8.949977e-05

Training iteration loss = 2.638747e-05

Training iteration loss = 1.9050913e-05

Training iteration loss = 2.181172e-05

Training iteration loss = 2.4273648e-05

Training iteration loss = 2.5758229e-05

Training iteration loss = 4.123809e-05

Training iteration loss = 1.8008326e-05

Training iteration loss = 2.2486842e-05

Training iteration loss = 5.8821668e-05

Training iteration loss = 2.8846522e-05

Training iteration loss = 4.4463275e-05

Training iteration loss = 3.6149435e-05

Training iteration loss = 5.772804e-05

Training iteration loss = 3.7186208e-05

Training iteration loss = 0.000104273546

Training iteration loss = 1.9445584e-05

Training iteration loss = 1.5064611e-05

Training iteration loss = 1.6237822e-05

Training iteration loss = 4.239478e-05

Training iteration loss = 1.4770067e-05

Training iteration loss = 3.3907094e-05

Training iteration loss = 2.3959963e-05

Training iteration loss = 1.5589392e-05

Training iteration loss = 2.081166e-05

Training iteration loss = 3.7844682e-05

Training iteration loss = 3.413043e-05

Training iteration loss = 1.6018423e-05

Training iteration loss = 2.2366206e-05

Training iteration loss = 3.7577483e-05

Training iteration loss = 1.777978e-05

Training iteration loss = 2.620468e-05

Training iteration loss = 1.5631993e-05

Training iteration loss = 1.4478331e-05

Training iteration loss = 1.2452917e-05

Training iteration loss = 1.9450352e-05

Training iteration loss = 5.5690703e-06

Training iteration loss = 2.1389591e-05

Training iteration loss = 5.035379e-05

Training iteration loss = 1.6888302e-05

Training iteration loss = 6.203147e-05

Training iteration loss = 5.8984338e-06

Training iteration loss = 2.4866924e-05

Training iteration loss = 2.3398365e-05

Training iteration loss = 8.458353e-06

Training iteration loss = 1.2228127e-05

Training iteration loss = 6.381268e-06

Training iteration loss = 7.334806e-06

Training iteration loss = 6.42128e-06

Training iteration loss = 9.655751e-06

Training iteration loss = 4.414238e-05

Training iteration loss = 9.408348e-05

Training iteration loss = 3.9771285e-06

Training iteration loss = 6.974546e-06

Training iteration loss = 3.9396423e-06

Training iteration loss = 6.317357e-06

Training iteration loss = 8.057761e-06

Training iteration loss = 7.714002e-06

Training iteration loss = 1.4874367e-05

Training iteration loss = 4.2529955e-06

Training iteration loss = 1.2864177e-05

Training iteration loss = 0.00035100602

Training iteration loss = 3.233823e-05

Training iteration loss = 1.27689245e-05

Training iteration loss = 6.793906e-06

Training iteration loss = 4.8357456e-06

Training iteration loss = 1.11973395e-05

Training iteration loss = 7.253943e-06

Training iteration loss = 3.9739884e-06

Training iteration loss = 3.577312e-06

Training iteration loss = 5.8348924e-06

Training iteration loss = 3.635076e-05

Training iteration loss = 6.4950914e-06

Training iteration loss = 1.5888103e-05

Training iteration loss = 4.5231923e-06

Training iteration loss = 8.717472e-06

Training iteration loss = 3.6758308e-06

Training iteration loss = 5.589826e-06

Training iteration loss = 6.7020806e-06

Training iteration loss = 2.570112e-05

Training iteration loss = 1.0014099e-05

Training iteration loss = 3.5363776e-06

Training iteration loss = 3.2885275e-06

Training iteration loss = 8.869831e-05

Training iteration loss = 2.8446686e-06

Training iteration loss = 2.504495e-06

Training iteration loss = 2.787767e-06

Training iteration loss = 3.58093e-06

Training iteration loss = 3.8946673e-06

Training iteration loss = 4.0771465e-06

Training iteration loss = 2.6043028e-06

Training iteration loss = 5.6476506e-06

Training iteration loss = 1.0455554e-05

Training iteration loss = 1.8754687e-06

Training iteration loss = 3.3164445e-06

Training iteration loss = 2.1837652e-06

Training iteration loss = 2.5073957e-06

Training iteration loss = 3.2847972e-06

Training iteration loss = 3.0049293e-06

Training iteration loss = 1.35841865e-05

Training iteration loss = 5.118556e-06

Training iteration loss = 1.25616325e-05

Training iteration loss = 1.953933e-06

Training iteration loss = 8.826397e-06

Training iteration loss = 1.95606e-06

Training iteration loss = 0.00012282199

Training iteration loss = 6.46791e-06

Training iteration loss = 2.5217555e-06

Training iteration loss = 2.224386e-06

Training iteration loss = 3.2856879e-06

Training iteration loss = 0.00031770207

Training iteration loss = 3.8919793e-06

Training iteration loss = 4.0493146e-06

Training iteration loss = 3.3555204e-06

Training iteration loss = 2.7917265e-06

Training iteration loss = 3.5777366e-06

Training iteration loss = 3.943142e-06

Training iteration loss = 2.3315376e-06

Training iteration loss = 2.8334705e-06

Training iteration loss = 4.0469163e-06

Training iteration loss = 1.1894978e-05

Training iteration loss = 1.3303143e-05

Training iteration loss = 0.00030699655

Training iteration loss = 7.017627e-06

Training iteration loss = 5.271715e-06

Training iteration loss = 4.4554818e-06

Training iteration loss = 3.574811e-05

Training iteration loss = 9.032498e-06

Training iteration loss = 3.384146e-06

Training iteration loss = 7.032117e-06

Training iteration loss = 4.944597e-06

Training iteration loss = 5.5093037e-06

Training iteration loss = 5.364114e-06

Training iteration loss = 4.6382806e-06

Training iteration loss = 5.2579376e-06

Training iteration loss = 3.853044e-06

Training iteration loss = 4.2729457e-06

Training iteration loss = 3.3986778e-06

Training iteration loss = 2.629636e-06

Training iteration loss = 2.859151e-06

Training iteration loss = 3.4775967e-06

Training iteration loss = 2.4850488e-06

Training iteration loss = 2.6012692e-06

Training iteration loss = 9.978749e-06

Training iteration loss = 1.8485878e-05

Training iteration loss = 1.8866317e-06

Training iteration loss = 2.8648385e-06

Training iteration loss = 2.8211919e-06

Training iteration loss = 2.579016e-06

Training iteration loss = 2.0489483e-06

Training iteration loss = 4.74105e-06

Training iteration loss = 2.2535862e-06

Training iteration loss = 5.940383e-06

Training iteration loss = 1.3236141e-05

Training iteration loss = 4.338466e-06

Training iteration loss = 1.406558e-06

Training iteration loss = 1.7993498e-06

Training iteration loss = 2.3810877e-05

Training iteration loss = 1.0267111e-05

Training iteration loss = 1.6460338e-06

Training iteration loss = 3.598164e-06

Training iteration loss = 1.6753916e-06

Training iteration loss = 1.7906601e-06

Training iteration loss = 1.6684647e-06

Training iteration loss = 7.3106276e-06

Training iteration loss = 8.3488834e-07

Training iteration loss = 0.00026447096

Training iteration loss = 1.0800467e-06

Training iteration loss = 1.6902064e-06

Training iteration loss = 3.9414435e-06

Training iteration loss = 1.2059198e-06

Training iteration loss = 1.5305101e-06

Training iteration loss = 1.5440415e-06

Training iteration loss = 1.3706355e-06

Training iteration loss = 2.2403149e-06

Training iteration loss = 1.4130023e-05

Training iteration loss = 7.5490134e-06

Training iteration loss = 4.088876e-06

Training iteration loss = 2.0541258e-06

Training iteration loss = 1.3672176e-06

Training iteration loss = 1.6996469e-06

Training iteration loss = 1.1763045e-06

Training iteration loss = 1.6635782e-06

Training iteration loss = 0.00020896287

Training iteration loss = 1.4324905e-06

Training iteration loss = 1.6334119e-06

Training iteration loss = 1.8105056e-06

Training iteration loss = 6.8934933e-06

Training iteration loss = 1.6387736e-06

Training iteration loss = 2.1319854e-06

Training iteration loss = 2.184963e-06

Training iteration loss = 1.3016796e-06

Training iteration loss = 1.912218e-05

Training iteration loss = 2.5189895e-06

Training iteration loss = 2.3034656e-06

Training iteration loss = 1.6261071e-06

Training iteration loss = 2.8300444e-06

Training iteration loss = 1.8709728e-06

Training iteration loss = 3.933737e-06

Training iteration loss = 1.469909e-06

Training iteration loss = 4.1063463e-06

Training iteration loss = 2.0181824e-06

Training iteration loss = 1.7217516e-06

Training iteration loss = 1.5217174e-06

Training iteration loss = 1.5793821e-06

Training iteration loss = 9.4367607e-07

Training iteration loss = 7.2462176e-06

Training iteration loss = 9.089684e-07

Training iteration loss = 9.2411955e-07

Training iteration loss = 9.604439e-06

Training iteration loss = 1.1295081e-06

Training iteration loss = 1.9642953e-06

Training iteration loss = 2.933318e-06

Training iteration loss = 1.8012384e-05

Training iteration loss = 1.7546143e-06

Training iteration loss = 4.653737e-05

Training iteration loss = 1.2252035e-06

Training iteration loss = 1.2054927e-06

Training iteration loss = 6.9861903e-07

Training iteration loss = 2.9241753e-06

Training iteration loss = 1.2629204e-06

Training iteration loss = 5.2504734e-06

Training iteration loss = 1.9169468e-06

Training iteration loss = 1.3967982e-06

Training iteration loss = 1.6733749e-06

Training iteration loss = 4.1281196e-06

Training iteration loss = 2.9572766e-06

Training iteration loss = 3.2605833e-06

Training iteration loss = 1.9391662e-06

Training iteration loss = 1.7201004e-05

Training iteration loss = 1.6988843e-06

Training iteration loss = 1.5908108e-05

Training iteration loss = 1.657831e-06

Training iteration loss = 1.3196468e-06

Training iteration loss = 2.4360609e-06

Training iteration loss = 5.2633495e-06

Training iteration loss = 1.086608e-06

Training iteration loss = 1.994175e-06

Training iteration loss = 2.5945114e-05

Training iteration loss = 2.5519603e-06

Training iteration loss = 3.893583e-05

Training iteration loss = 9.854122e-07

Training iteration loss = 4.677252e-06

Training iteration loss = 8.0578175e-06

Training iteration loss = 2.5765464e-06

Training iteration loss = 1.7947615e-06

Training iteration loss = 1.7052531e-06

Training iteration loss = 1.0850309e-06

Training iteration loss = 1.3656181e-06

Training iteration loss = 2.012505e-06

Training iteration loss = 2.7131457e-05

Training iteration loss = 7.787189e-05

Training iteration loss = 1.3345725e-06

Training iteration loss = 1.4613917e-06

Training iteration loss = 1.6591599e-06

Training iteration loss = 1.5627597e-06

Training iteration loss = 2.6843666e-06

Training iteration loss = 1.937315e-06

Training iteration loss = 4.05333e-06

Training iteration loss = 1.7358825e-06

Training iteration loss = 2.8414613e-06

Training iteration loss = 0.0002982745

Training iteration loss = 2.0115318e-05

Training iteration loss = 4.196562e-06

Training iteration loss = 3.7715224e-06

Training iteration loss = 2.7498147e-06

Training iteration loss = 5.7218126e-06

Training iteration loss = 3.2925575e-06

Training iteration loss = 2.3670973e-06

Training iteration loss = 4.056377e-06

Training iteration loss = 3.614696e-06

Training iteration loss = 2.9494833e-05

Training iteration loss = 5.1638303e-06

Training iteration loss = 7.292565e-06

Training iteration loss = 3.9551555e-06

Training iteration loss = 4.44253e-06

Training iteration loss = 3.173367e-06

Training iteration loss = 4.484354e-06

Training iteration loss = 4.4986605e-06

Training iteration loss = 2.1454345e-05

Training iteration loss = 6.243606e-06

Training iteration loss = 2.8923712e-06

Training iteration loss = 2.1260619e-06

Training iteration loss = 7.6603515e-05

Training iteration loss = 3.1519885e-06

Training iteration loss = 2.2251486e-06

Training iteration loss = 2.8403858e-06

Training iteration loss = 2.5063e-06

Training iteration loss = 2.86874e-06

Training iteration loss = 3.2099372e-06

Training iteration loss = 2.5801594e-06

Training iteration loss = 5.255541e-06

Training iteration loss = 8.306531e-06

Training iteration loss = 1.7629101e-06

Training iteration loss = 2.5335883e-06

Training iteration loss = 1.7774695e-06

Training iteration loss = 2.2536328e-06

Training iteration loss = 2.0476762e-06

Training iteration loss = 1.8917809e-06

Training iteration loss = 9.859167e-06

Training iteration loss = 3.8979642e-06

Training iteration loss = 1.1691954e-05

Training iteration loss = 1.7285583e-06

Training iteration loss = 7.1198615e-06

Training iteration loss = 1.2459813e-06

Training iteration loss = 0.00010978172

Training iteration loss = 5.61325e-06

Training iteration loss = 1.9128388e-06

Training iteration loss = 2.083176e-06

Training iteration loss = 2.1592289e-06

Training iteration loss = 0.00029049657

Training iteration loss = 3.0318106e-06

Training iteration loss = 3.2955588e-06

Training iteration loss = 2.5485708e-06

Training iteration loss = 2.681021e-06

Training iteration loss = 3.2522264e-06

Training iteration loss = 3.4466302e-06

Training iteration loss = 2.1096946e-06

Training iteration loss = 2.6385922e-06

Training iteration loss = 3.0780682e-06

Training iteration loss = 9.805018e-06

Training iteration loss = 1.1016401e-05

Training iteration loss = 0.00027555114

Training iteration loss = 5.85509e-06

Training iteration loss = 5.3616823e-06

Training iteration loss = 4.34527e-06

Training iteration loss = 3.078188e-05

Training iteration loss = 7.89231e-06

Training iteration loss = 3.3008619e-06

Training iteration loss = 7.1907634e-06

Training iteration loss = 5.471515e-06

Training iteration loss = 5.671594e-06

Training iteration loss = 5.4668913e-06

Training iteration loss = 4.4713693e-06

Training iteration loss = 5.316803e-06

Training iteration loss = 3.8893622e-06

Training iteration loss = 4.226121e-06

Training iteration loss = 3.1034972e-06

Training iteration loss = 2.2995023e-06

Training iteration loss = 2.89779e-06

Training iteration loss = 3.458993e-06

Training iteration loss = 2.1448466e-06

Training iteration loss = 1.9987644e-06

Training iteration loss = 8.483694e-06

Training iteration loss = 1.576064e-05

Training iteration loss = 1.859134e-06

Training iteration loss = 2.6569612e-06

Training iteration loss = 2.6567022e-06

Training iteration loss = 2.2222857e-06

Training iteration loss = 1.6334524e-06

Training iteration loss = 4.087729e-06

Training iteration loss = 1.990719e-06

Training iteration loss = 5.337309e-06

Training iteration loss = 1.2305155e-05

Training iteration loss = 3.883731e-06

Training iteration loss = 1.183873e-06

Training iteration loss = 1.5275697e-06

Training iteration loss = 2.2328437e-05

Training iteration loss = 9.46375e-06

Training iteration loss = 1.1774231e-06

Single layer neural network training data error = 1.1774231e-06

Single layer neural network test data error = 1.8599482e-06
