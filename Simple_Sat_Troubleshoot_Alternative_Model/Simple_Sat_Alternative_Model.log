Training iteration loss = 0.016665297

Training iteration loss = 0.009209136

Training iteration loss = 0.009516745

Training iteration loss = 0.0070179533

Training iteration loss = 0.008231265

Training iteration loss = 0.0058379564

Training iteration loss = 0.0127347885

Training iteration loss = 0.0060745603

Training iteration loss = 0.008482379

Training iteration loss = 0.008143304

Training iteration loss = 0.005362743

Training iteration loss = 0.0048921267

Training iteration loss = 0.005021162

Training iteration loss = 0.005135019

Training iteration loss = 0.0054382687

Training iteration loss = 0.006854883

Training iteration loss = 0.007070117

Training iteration loss = 0.0058678477

Training iteration loss = 0.0055688247

Training iteration loss = 0.0043207146

Training iteration loss = 0.005191127

Training iteration loss = 0.004573776

Training iteration loss = 0.0048593637

Training iteration loss = 0.011086802

Training iteration loss = 0.0042729345

Training iteration loss = 0.0047202245

Training iteration loss = 0.0053815213

Training iteration loss = 0.0072445036

Training iteration loss = 0.005216953

Training iteration loss = 0.0055971234

Training iteration loss = 0.004884575

Training iteration loss = 0.0033264535

Training iteration loss = 0.008100578

Training iteration loss = 0.005076357

Training iteration loss = 0.0049733236

Training iteration loss = 0.004121778

Training iteration loss = 0.0052134767

Training iteration loss = 0.0059005544

Training iteration loss = 0.0063730963

Training iteration loss = 0.0057947133

Training iteration loss = 0.0069752424

Training iteration loss = 0.0054251966

Training iteration loss = 0.0047768014

Training iteration loss = 0.0039206524

Training iteration loss = 0.004232771

Training iteration loss = 0.0040336377

Training iteration loss = 0.0060734716

Training iteration loss = 0.0030899022

Training iteration loss = 0.004220811

Training iteration loss = 0.005524985

Training iteration loss = 0.0050738584

Training iteration loss = 0.005200623

Training iteration loss = 0.0047515873

Training iteration loss = 0.006742693

Training iteration loss = 0.0062128208

Training iteration loss = 0.008557471

Training iteration loss = 0.0045913043

Training iteration loss = 0.0054071634

Training iteration loss = 0.004557539

Training iteration loss = 0.0060218326

Training iteration loss = 0.0051031346

Training iteration loss = 0.005842646

Training iteration loss = 0.0054078563

Training iteration loss = 0.004711271

Training iteration loss = 0.0051720636

Training iteration loss = 0.0076368307

Training iteration loss = 0.0050158305

Training iteration loss = 0.006062032

Training iteration loss = 0.0058421823

Training iteration loss = 0.0060887295

Training iteration loss = 0.0048224363

Training iteration loss = 0.006997604

Training iteration loss = 0.0053541684

Training iteration loss = 0.004732575

Training iteration loss = 0.005402211

Training iteration loss = 0.004465386

Training iteration loss = 0.0040185126

Training iteration loss = 0.006382715

Training iteration loss = 0.009281932

Training iteration loss = 0.0059324936

Training iteration loss = 0.0071882517

Training iteration loss = 0.003535446

Training iteration loss = 0.007997689

Training iteration loss = 0.0093608545

Training iteration loss = 0.0045044227

Training iteration loss = 0.0060518063

Training iteration loss = 0.005036484

Training iteration loss = 0.005408658

Training iteration loss = 0.0050388193

Training iteration loss = 0.005254219

Training iteration loss = 0.007714553

Training iteration loss = 0.010107298

Training iteration loss = 0.00358418

Training iteration loss = 0.004907815

Training iteration loss = 0.0041271686

Training iteration loss = 0.0051505375

Training iteration loss = 0.0057930183

Training iteration loss = 0.005082187

Training iteration loss = 0.0065084584

Training iteration loss = 0.003650401

Training iteration loss = 0.0072503197

Training iteration loss = 0.011648654

Training iteration loss = 0.007162817

Training iteration loss = 0.0057554333

Training iteration loss = 0.0051224274

Training iteration loss = 0.005962307

Training iteration loss = 0.004233871

Training iteration loss = 0.0056520305

Training iteration loss = 0.003923524

Training iteration loss = 0.003868393

Training iteration loss = 0.004363498

Training iteration loss = 0.0063482136

Training iteration loss = 0.0046872227

Training iteration loss = 0.0063338354

Training iteration loss = 0.005237758

Training iteration loss = 0.0076443483

Training iteration loss = 0.0045784116

Training iteration loss = 0.0049617053

Training iteration loss = 0.0054342956

Training iteration loss = 0.010288458

Training iteration loss = 0.0078492435

Training iteration loss = 0.005355332

Training iteration loss = 0.004426329

Training iteration loss = 0.008962539

Training iteration loss = 0.0039694794

Training iteration loss = 0.0035852662

Training iteration loss = 0.004073717

Training iteration loss = 0.0052862386

Training iteration loss = 0.0047266716

Training iteration loss = 0.006545262

Training iteration loss = 0.005047677

Training iteration loss = 0.004068366

Training iteration loss = 0.0053660353

Training iteration loss = 0.0034327516

Training iteration loss = 0.0045586093

Training iteration loss = 0.0037155394

Training iteration loss = 0.0042434107

Training iteration loss = 0.005341871

Training iteration loss = 0.0057030967

Training iteration loss = 0.0069812336

Training iteration loss = 0.0061136354

Training iteration loss = 0.0069690454

Training iteration loss = 0.0030937807

Training iteration loss = 0.005578067

Training iteration loss = 0.004005523

Training iteration loss = 0.009409233

Training iteration loss = 0.0069401884

Training iteration loss = 0.004314565

Training iteration loss = 0.0041142707

Training iteration loss = 0.005827356

Training iteration loss = 0.0130499005

Training iteration loss = 0.0048642023

Training iteration loss = 0.0051968056

Training iteration loss = 0.0050602686

Training iteration loss = 0.003643744

Training iteration loss = 0.005109206

Training iteration loss = 0.005208073

Training iteration loss = 0.003970049

Training iteration loss = 0.0040102997

Training iteration loss = 0.0050152563

Training iteration loss = 0.005911334

Training iteration loss = 0.0053677983

Training iteration loss = 0.010164552

Training iteration loss = 0.00812907

Training iteration loss = 0.0045576175

Training iteration loss = 0.0049390164

Training iteration loss = 0.0075011044

Training iteration loss = 0.007198682

Training iteration loss = 0.004367874

Training iteration loss = 0.0058250357

Training iteration loss = 0.005218908

Training iteration loss = 0.0044550532

Training iteration loss = 0.0039641955

Training iteration loss = 0.0053414335

Training iteration loss = 0.0046729236

Training iteration loss = 0.0035355866

Training iteration loss = 0.0048228935

Training iteration loss = 0.003140213

Training iteration loss = 0.0030086644

Training iteration loss = 0.003103987

Training iteration loss = 0.0047689457

Training iteration loss = 0.0030984394

Training iteration loss = 0.004406286

Training iteration loss = 0.0059882156

Training iteration loss = 0.010106567

Training iteration loss = 0.004073912

Training iteration loss = 0.0040922333

Training iteration loss = 0.004159286

Training iteration loss = 0.0045080986

Training iteration loss = 0.0037222572

Training iteration loss = 0.005718928

Training iteration loss = 0.0043809563

Training iteration loss = 0.0063384287

Training iteration loss = 0.007307621

Training iteration loss = 0.005392621

Training iteration loss = 0.0028138596

Training iteration loss = 0.0035386337

Training iteration loss = 0.010103279

Training iteration loss = 0.0057588834

Training iteration loss = 0.0033590826

Training iteration loss = 0.0067037884

Training iteration loss = 0.0047592013

Training iteration loss = 0.005254833

Training iteration loss = 0.0049599865

Training iteration loss = 0.005667714

Training iteration loss = 0.003410502

Training iteration loss = 0.010204184

Training iteration loss = 0.003851867

Training iteration loss = 0.0046766796

Training iteration loss = 0.0054716733

Training iteration loss = 0.0037046878

Training iteration loss = 0.003385817

Training iteration loss = 0.0036111474

Training iteration loss = 0.0034796374

Training iteration loss = 0.004578288

Training iteration loss = 0.0053171455

Training iteration loss = 0.005624602

Training iteration loss = 0.004291992

Training iteration loss = 0.0044696056

Training iteration loss = 0.0030677952

Training iteration loss = 0.0034094236

Training iteration loss = 0.003462996

Training iteration loss = 0.003888937

Training iteration loss = 0.009393338

Training iteration loss = 0.0030847976

Training iteration loss = 0.0039342246

Training iteration loss = 0.004228119

Training iteration loss = 0.0055761603

Training iteration loss = 0.0043781204

Training iteration loss = 0.0045675435

Training iteration loss = 0.0038703072

Training iteration loss = 0.00260345

Training iteration loss = 0.0067864284

Training iteration loss = 0.004180202

Training iteration loss = 0.0038740467

Training iteration loss = 0.0031186715

Training iteration loss = 0.0042810384

Training iteration loss = 0.0052323234

Training iteration loss = 0.005328663

Training iteration loss = 0.0044354755

Training iteration loss = 0.006144061

Training iteration loss = 0.004480732

Training iteration loss = 0.0037180998

Training iteration loss = 0.0028467055

Training iteration loss = 0.003075875

Training iteration loss = 0.0028381504

Training iteration loss = 0.0051389816

Training iteration loss = 0.0023439017

Training iteration loss = 0.0032652759

Training iteration loss = 0.0045710546

Training iteration loss = 0.004108325

Training iteration loss = 0.0044638272

Training iteration loss = 0.0038833308

Training iteration loss = 0.005626904

Training iteration loss = 0.0052505396

Training iteration loss = 0.007283425

Training iteration loss = 0.0038702711

Training iteration loss = 0.004384214

Training iteration loss = 0.0035196056

Training iteration loss = 0.0053720362

Training iteration loss = 0.0044115954

Training iteration loss = 0.00525666

Training iteration loss = 0.0046707797

Training iteration loss = 0.003854284

Training iteration loss = 0.004476246

Training iteration loss = 0.0069960076

Training iteration loss = 0.00441888

Training iteration loss = 0.005056675

Training iteration loss = 0.005124874

Training iteration loss = 0.0049757943

Training iteration loss = 0.0036489505

Training iteration loss = 0.006009419

Training iteration loss = 0.004937551

Training iteration loss = 0.004148573

Training iteration loss = 0.004778072

Training iteration loss = 0.0037538998

Training iteration loss = 0.0033554651

Training iteration loss = 0.005979961

Training iteration loss = 0.008211064

Training iteration loss = 0.0052291076

Training iteration loss = 0.006542479

Training iteration loss = 0.0028097157

Training iteration loss = 0.0074446425

Training iteration loss = 0.008170911

Training iteration loss = 0.0038874063

Training iteration loss = 0.0057403888

Training iteration loss = 0.0042108973

Training iteration loss = 0.004228273

Training iteration loss = 0.004476264

Training iteration loss = 0.0045180996

Training iteration loss = 0.006860318

Training iteration loss = 0.009114624

Training iteration loss = 0.0029852723

Training iteration loss = 0.0041738474

Training iteration loss = 0.0032981634

Training iteration loss = 0.00435208

Training iteration loss = 0.0051205456

Training iteration loss = 0.004286901

Training iteration loss = 0.005784471

Training iteration loss = 0.0032111106

Training iteration loss = 0.006364856

Training iteration loss = 0.010810918

Training iteration loss = 0.006710129

Training iteration loss = 0.005276037

Training iteration loss = 0.0043452336

Training iteration loss = 0.0052730064

Training iteration loss = 0.003644772

Training iteration loss = 0.005233073

Training iteration loss = 0.0033378673

Training iteration loss = 0.0033046564

Training iteration loss = 0.0037752597

Training iteration loss = 0.005339045

Training iteration loss = 0.004099132

Training iteration loss = 0.0058388505

Training iteration loss = 0.0044080317

Training iteration loss = 0.007085591

Training iteration loss = 0.0040205023

Training iteration loss = 0.004241156

Training iteration loss = 0.0046335305

Training iteration loss = 0.00950637

Training iteration loss = 0.0070405807

Training iteration loss = 0.0047964747

Training iteration loss = 0.0038003018

Training iteration loss = 0.008075095

Training iteration loss = 0.003305223

Training iteration loss = 0.003255235

Training iteration loss = 0.0037719284

Training iteration loss = 0.004807516

Training iteration loss = 0.003809958

Training iteration loss = 0.005746445

Training iteration loss = 0.004628614

Training iteration loss = 0.0038122265

Training iteration loss = 0.0048918105

Training iteration loss = 0.0028655638

Training iteration loss = 0.003578347

Training iteration loss = 0.0030417189

Training iteration loss = 0.0039531123

Training iteration loss = 0.0050741774

Training iteration loss = 0.0051936023

Training iteration loss = 0.006202735

Training iteration loss = 0.005180832

Training iteration loss = 0.006293059

Training iteration loss = 0.0029506155

Training iteration loss = 0.004957723

Training iteration loss = 0.0033867976

Training iteration loss = 0.00859662

Training iteration loss = 0.0063046976

Training iteration loss = 0.004171535

Training iteration loss = 0.0036576905

Training iteration loss = 0.005104339

Training iteration loss = 0.012341299

Training iteration loss = 0.0040684473

Training iteration loss = 0.0047550215

Training iteration loss = 0.004677221

Training iteration loss = 0.0034786193

Training iteration loss = 0.0047405753

Training iteration loss = 0.0047163735

Training iteration loss = 0.00334958

Training iteration loss = 0.0036557096

Training iteration loss = 0.0046978593

Training iteration loss = 0.0053326446

Training iteration loss = 0.00480957

Training iteration loss = 0.009265321

Training iteration loss = 0.00745897

Training iteration loss = 0.0041474574

Training iteration loss = 0.004269951

Training iteration loss = 0.007156987

Training iteration loss = 0.006704459

Training iteration loss = 0.0039270134

Training iteration loss = 0.00539564

Training iteration loss = 0.004942138

Training iteration loss = 0.0038561318

Training iteration loss = 0.0034851674

Training iteration loss = 0.00488695

Training iteration loss = 0.004225263

Training iteration loss = 0.0032492147

Training iteration loss = 0.004264219

Training iteration loss = 0.0029567415

Training iteration loss = 0.0027626723

Training iteration loss = 0.0027469816

Training iteration loss = 0.004233033

Training iteration loss = 0.0026168602

Training iteration loss = 0.004041606

Training iteration loss = 0.0056839525

Training iteration loss = 0.009496526

Training iteration loss = 0.0038361165

Training iteration loss = 0.0036784278

Training iteration loss = 0.0036585752

Training iteration loss = 0.0042077187

Training iteration loss = 0.0032636004

Training iteration loss = 0.005121232

Training iteration loss = 0.0041283336

Training iteration loss = 0.006135659

Training iteration loss = 0.006336612

Training iteration loss = 0.004971921

Training iteration loss = 0.0026745042

Training iteration loss = 0.0031626113

Training iteration loss = 0.00955578

Training iteration loss = 0.00528176

Training iteration loss = 0.0027904606

Training iteration loss = 0.0059270184

Training iteration loss = 0.0045544314

Training iteration loss = 0.004884538

Training iteration loss = 0.0046045524

Training iteration loss = 0.0053354646

Training iteration loss = 0.0031301351

Training iteration loss = 0.009450962

Training iteration loss = 0.003646478

Training iteration loss = 0.0044744485

Training iteration loss = 0.0049741813

Training iteration loss = 0.0034604613

Training iteration loss = 0.0031763755

Training iteration loss = 0.0032344202

Training iteration loss = 0.0029937017

Training iteration loss = 0.0046028825

Training iteration loss = 0.004979027

Training iteration loss = 0.005332586

Training iteration loss = 0.004003024

Training iteration loss = 0.0042179446

Training iteration loss = 0.0027284308

Training iteration loss = 0.0031355713

Training iteration loss = 0.0032641485

Training iteration loss = 0.0036875478

Training iteration loss = 0.00876741

Training iteration loss = 0.0026437405

Training iteration loss = 0.0036318165

Training iteration loss = 0.00381581

Training iteration loss = 0.005157806

Training iteration loss = 0.0041478863

Training iteration loss = 0.004116705

Training iteration loss = 0.0036128936

Training iteration loss = 0.0024077173

Training iteration loss = 0.006503114

Training iteration loss = 0.0038166922

Training iteration loss = 0.0034550643

Training iteration loss = 0.0027983545

Training iteration loss = 0.004169148

Training iteration loss = 0.005008895

Training iteration loss = 0.0048505836

Training iteration loss = 0.0039216536

Training iteration loss = 0.00577278

Training iteration loss = 0.0040132347

Training iteration loss = 0.0033247967

Training iteration loss = 0.00252859

Training iteration loss = 0.0028326532

Training iteration loss = 0.002539586

Training iteration loss = 0.004811386

Training iteration loss = 0.0021685252

Training iteration loss = 0.0029689604

Training iteration loss = 0.004345693

Training iteration loss = 0.003861557

Training iteration loss = 0.004268698

Training iteration loss = 0.0035839642

Training iteration loss = 0.0052613956

Training iteration loss = 0.0050042327

Training iteration loss = 0.0068151243

Training iteration loss = 0.0035067343

Training iteration loss = 0.003936048

Training iteration loss = 0.003306648

Training iteration loss = 0.0050037173

Training iteration loss = 0.0042099063

Training iteration loss = 0.0050093723

Training iteration loss = 0.0042904695

Training iteration loss = 0.0035565326

Training iteration loss = 0.0042168074

Training iteration loss = 0.0068008057

Training iteration loss = 0.0042437385

Training iteration loss = 0.0047326847

Training iteration loss = 0.0047539757

Training iteration loss = 0.0046032122

Training iteration loss = 0.003320024

Training iteration loss = 0.005487514

Training iteration loss = 0.00462714

Training iteration loss = 0.0039493823

Training iteration loss = 0.0043907375

Training iteration loss = 0.0035168128

Training iteration loss = 0.003056239

Training iteration loss = 0.0057916753

Training iteration loss = 0.0077968515

Training iteration loss = 0.005002379

Training iteration loss = 0.006294653

Training iteration loss = 0.0025927427

Training iteration loss = 0.0069717453

Training iteration loss = 0.007632091

Training iteration loss = 0.0037521783

Training iteration loss = 0.005467552

Training iteration loss = 0.0039244913

Training iteration loss = 0.0036759924

Training iteration loss = 0.0041273586

Training iteration loss = 0.0042569335

Training iteration loss = 0.0064858478

Training iteration loss = 0.008669444

Training iteration loss = 0.0028395457

Training iteration loss = 0.0038377119

Training iteration loss = 0.002972223

Training iteration loss = 0.0040418073

Training iteration loss = 0.004736625

Training iteration loss = 0.0040661637

Training iteration loss = 0.005457764

Training iteration loss = 0.0029585853

Training iteration loss = 0.0059201606

Training iteration loss = 0.010434368

Training iteration loss = 0.006393924

Training iteration loss = 0.005031618

Training iteration loss = 0.0041392287

Training iteration loss = 0.0047417334

Training iteration loss = 0.003519632

Training iteration loss = 0.0052099046

Training iteration loss = 0.0031641077

Training iteration loss = 0.0031994658

Training iteration loss = 0.0037182395

Training iteration loss = 0.004953994

Training iteration loss = 0.003912406

Training iteration loss = 0.0057362267

Training iteration loss = 0.004155872

Training iteration loss = 0.0068716686

Training iteration loss = 0.0038572622

Training iteration loss = 0.0039543477

Training iteration loss = 0.004349482

Training iteration loss = 0.009125003

Training iteration loss = 0.0065439274

Training iteration loss = 0.0045372318

Training iteration loss = 0.0037023583

Training iteration loss = 0.007730846

Training iteration loss = 0.0031728018

Training iteration loss = 0.0030921984

Training iteration loss = 0.0036204394

Training iteration loss = 0.004596294

Training iteration loss = 0.0034424374

Training iteration loss = 0.0054305866

Training iteration loss = 0.004444936

Training iteration loss = 0.0037724704

Training iteration loss = 0.004577537

Training iteration loss = 0.0026280053

Training iteration loss = 0.0032578614

Training iteration loss = 0.0030531075

Training iteration loss = 0.0036429558

Training iteration loss = 0.005010656

Training iteration loss = 0.0048616864

Training iteration loss = 0.006015565

Training iteration loss = 0.0048496746

Training iteration loss = 0.0060210973

Training iteration loss = 0.0028562818

Training iteration loss = 0.0044637457

Training iteration loss = 0.0032290872

Training iteration loss = 0.008294248

Training iteration loss = 0.0059753354

Training iteration loss = 0.003967963

Training iteration loss = 0.0033163324

Training iteration loss = 0.0048827673

Training iteration loss = 0.011947151

Training iteration loss = 0.003917996

Training iteration loss = 0.0045384085

Training iteration loss = 0.004583353

Training iteration loss = 0.0032252595

Training iteration loss = 0.0045494824

Training iteration loss = 0.004542966

Training iteration loss = 0.0032257922

Training iteration loss = 0.0034919789

Training iteration loss = 0.0044064936

Training iteration loss = 0.005095402

Training iteration loss = 0.004551153

Training iteration loss = 0.008921807

Training iteration loss = 0.0071017295

Training iteration loss = 0.0040145605

Training iteration loss = 0.00411646

Training iteration loss = 0.0068176263

Training iteration loss = 0.006484371

Training iteration loss = 0.003704842

Training iteration loss = 0.0049867104

Training iteration loss = 0.0045813234

Training iteration loss = 0.0036217596

Training iteration loss = 0.003350975

Training iteration loss = 0.0046221903

Training iteration loss = 0.004085208

Training iteration loss = 0.0032578912

Training iteration loss = 0.004219081

Training iteration loss = 0.002930986

Training iteration loss = 0.0026954694

Training iteration loss = 0.0026098138

Training iteration loss = 0.0040583247

Training iteration loss = 0.002640348

Training iteration loss = 0.003911088

Training iteration loss = 0.005543158

Training iteration loss = 0.009254309

Training iteration loss = 0.0036358896

Training iteration loss = 0.003485309

Training iteration loss = 0.003490344

Training iteration loss = 0.0040269303

Training iteration loss = 0.0030809566

Training iteration loss = 0.004980623

Training iteration loss = 0.003919002

Training iteration loss = 0.005991623

Training iteration loss = 0.0059791915

Training iteration loss = 0.0048222854

Training iteration loss = 0.0025609394

Training iteration loss = 0.0030183622

Training iteration loss = 0.00939003

Training iteration loss = 0.0049456074

Training iteration loss = 0.0025514057

Training iteration loss = 0.0057376693

Training iteration loss = 0.004382374

Training iteration loss = 0.0046631056

Training iteration loss = 0.004442429

Training iteration loss = 0.0051553366

Training iteration loss = 0.0030441266

Training iteration loss = 0.009119474

Training iteration loss = 0.0036060642

Training iteration loss = 0.0043493705

Training iteration loss = 0.004721446

Training iteration loss = 0.0033850612

Training iteration loss = 0.0030285788

Training iteration loss = 0.0030884135

Training iteration loss = 0.0029323185

Training iteration loss = 0.0045012096

Training iteration loss = 0.004825304

Training iteration loss = 0.0051832977

Training iteration loss = 0.003934773

Training iteration loss = 0.004103105

Training iteration loss = 0.0026622235

Training iteration loss = 0.0030850794

Training iteration loss = 0.0032017892

Training iteration loss = 0.0035690104

Training iteration loss = 0.008642692

Training iteration loss = 0.0025423856

Training iteration loss = 0.0035494377

Training iteration loss = 0.0037072746

Training iteration loss = 0.0050420878

Training iteration loss = 0.004079322

Training iteration loss = 0.004001023

Training iteration loss = 0.0035520904

Training iteration loss = 0.002356431

Training iteration loss = 0.006352985

Training iteration loss = 0.0037023127

Training iteration loss = 0.003242383

Training iteration loss = 0.0027325694

Training iteration loss = 0.004064583

Training iteration loss = 0.0049441527

Training iteration loss = 0.004697325

Training iteration loss = 0.003743659

Training iteration loss = 0.0056312424

Training iteration loss = 0.0038037088

Training iteration loss = 0.0032107895

Training iteration loss = 0.002419857

Training iteration loss = 0.0027493387

Training iteration loss = 0.0024654968

Training iteration loss = 0.004740931

Training iteration loss = 0.0021159917

Training iteration loss = 0.002897051

Training iteration loss = 0.0043354128

Training iteration loss = 0.0038414604

Training iteration loss = 0.0041597486

Training iteration loss = 0.0034924631

Training iteration loss = 0.005151512

Training iteration loss = 0.004911534

Training iteration loss = 0.00661875

Training iteration loss = 0.0033711817

Training iteration loss = 0.0037918899

Training iteration loss = 0.00325768

Training iteration loss = 0.0048730006

Training iteration loss = 0.0041645854

Training iteration loss = 0.004886958

Training iteration loss = 0.0041565765

Training iteration loss = 0.0034323002

Training iteration loss = 0.0041225455

Training iteration loss = 0.006733745

Training iteration loss = 0.0041833296

Training iteration loss = 0.004692456

Training iteration loss = 0.0046140207

Training iteration loss = 0.0045331516

Training iteration loss = 0.0032463397

Training iteration loss = 0.005281273

Training iteration loss = 0.0045608976

Training iteration loss = 0.003899623

Training iteration loss = 0.0042037517

Training iteration loss = 0.0034175871

Training iteration loss = 0.0029312174

Training iteration loss = 0.0057528927

Training iteration loss = 0.007602859

Training iteration loss = 0.0049359244

Training iteration loss = 0.0061632046

Training iteration loss = 0.002556037

Training iteration loss = 0.006762449

Training iteration loss = 0.0074579194

Training iteration loss = 0.0036855054

Training iteration loss = 0.005304705

Training iteration loss = 0.0038319232

Training iteration loss = 0.0034227797

Training iteration loss = 0.003961226

Training iteration loss = 0.0041687363

Training iteration loss = 0.006343279

Training iteration loss = 0.008505334

Training iteration loss = 0.0027948439

Training iteration loss = 0.003706462

Training iteration loss = 0.0028864553

Training iteration loss = 0.0039888243

Training iteration loss = 0.004597748

Training iteration loss = 0.00393775

Training iteration loss = 0.005323652

Training iteration loss = 0.0029154327

Training iteration loss = 0.0057539083

Training iteration loss = 0.010293713

Training iteration loss = 0.0062232893

Training iteration loss = 0.0048867078

Training iteration loss = 0.0040086587

Training iteration loss = 0.0045624706

Training iteration loss = 0.0034064886

Training iteration loss = 0.0050896555

Training iteration loss = 0.0031455373

Training iteration loss = 0.0031020574

Training iteration loss = 0.0036375215

Training iteration loss = 0.0048317737

Training iteration loss = 0.0038296639

Training iteration loss = 0.005634504

Training iteration loss = 0.0041342876

Training iteration loss = 0.006750139

Training iteration loss = 0.0037914459

Training iteration loss = 0.0038501183

Training iteration loss = 0.004238788

Training iteration loss = 0.008978265

Training iteration loss = 0.0064121555

Training iteration loss = 0.004435044

Training iteration loss = 0.0036384172

Training iteration loss = 0.007636776

Training iteration loss = 0.0030699298

Training iteration loss = 0.003016554

Training iteration loss = 0.0035569456

Training iteration loss = 0.0045398986

Training iteration loss = 0.0033564027

Training iteration loss = 0.0052838344

Training iteration loss = 0.004359348

Training iteration loss = 0.003713519

Training iteration loss = 0.0045219203

Training iteration loss = 0.0025479898

Training iteration loss = 0.003204068

Training iteration loss = 0.003041295

Training iteration loss = 0.0036025234

Training iteration loss = 0.004939101

Training iteration loss = 0.0047539375

Training iteration loss = 0.005997524

Training iteration loss = 0.004666452

Training iteration loss = 0.005912076

Training iteration loss = 0.0028571496

Training iteration loss = 0.0043219593

Training iteration loss = 0.0031860683

Training iteration loss = 0.008133751

Training iteration loss = 0.0058043706

Training iteration loss = 0.0038759876

Training iteration loss = 0.00327259

Training iteration loss = 0.004770149

Training iteration loss = 0.0117412945

Training iteration loss = 0.0038333014

Training iteration loss = 0.0044517736

Training iteration loss = 0.004520834

Training iteration loss = 0.0030946133

Training iteration loss = 0.004500966

Training iteration loss = 0.004458548

Training iteration loss = 0.003167428

Training iteration loss = 0.003363912

Training iteration loss = 0.0042628176

Training iteration loss = 0.0050287545

Training iteration loss = 0.004506664

Training iteration loss = 0.008776379

Training iteration loss = 0.006961482

Training iteration loss = 0.0039907056

Training iteration loss = 0.004087755

Training iteration loss = 0.006708344

Training iteration loss = 0.006402358

Training iteration loss = 0.0036138834

Training iteration loss = 0.004828513

Training iteration loss = 0.0044702236

Training iteration loss = 0.0035038095

Training iteration loss = 0.003283567

Training iteration loss = 0.0045229546

Training iteration loss = 0.0039882516

Training iteration loss = 0.0032488795

Training iteration loss = 0.004223385

Training iteration loss = 0.0028954325

Training iteration loss = 0.002625446

Training iteration loss = 0.0025679294

Training iteration loss = 0.003989808

Training iteration loss = 0.0026318089

Training iteration loss = 0.0038594839

Training iteration loss = 0.0055481154

Training iteration loss = 0.009205463

Training iteration loss = 0.0035472324

Training iteration loss = 0.0033814246

Training iteration loss = 0.0034001071

Training iteration loss = 0.0039749225

Training iteration loss = 0.0030716087

Training iteration loss = 0.004928992

Training iteration loss = 0.003821413

Training iteration loss = 0.005918452

Training iteration loss = 0.005916195

Training iteration loss = 0.004740809

Training iteration loss = 0.002515455

Training iteration loss = 0.0029871284

Training iteration loss = 0.009337553

Training iteration loss = 0.0048033367

Training iteration loss = 0.002560092

Training iteration loss = 0.0057455245

Training iteration loss = 0.0043006423

Training iteration loss = 0.004597925

Training iteration loss = 0.0044095484

Training iteration loss = 0.005079013

Training iteration loss = 0.003011235

Training iteration loss = 0.0090534175

Training iteration loss = 0.003549495

Training iteration loss = 0.004329066

Training iteration loss = 0.0046591777

Training iteration loss = 0.003279288

Training iteration loss = 0.0029396333

Training iteration loss = 0.0030501245

Training iteration loss = 0.0029524209

Training iteration loss = 0.0043418906

Training iteration loss = 0.0047481935

Training iteration loss = 0.005133863

Training iteration loss = 0.0038950008

Training iteration loss = 0.0040597655

Training iteration loss = 0.0027027298

Training iteration loss = 0.0030283693

Training iteration loss = 0.0031564496

Training iteration loss = 0.003530341

Training iteration loss = 0.008555598

Training iteration loss = 0.0024980388

Training iteration loss = 0.0035284802

Training iteration loss = 0.0036533717

Training iteration loss = 0.0049924185

Training iteration loss = 0.004049944

Training iteration loss = 0.0039493325

Training iteration loss = 0.0035150144

Training iteration loss = 0.002335698

Training iteration loss = 0.0062683714

Training iteration loss = 0.0036578898

Training iteration loss = 0.0031462836

Training iteration loss = 0.0027214333

Training iteration loss = 0.0040064114

Training iteration loss = 0.0049279504

Training iteration loss = 0.0046516983

Training iteration loss = 0.0036610363

Training iteration loss = 0.0055583636

Training iteration loss = 0.003724911

Training iteration loss = 0.0031924788

Training iteration loss = 0.0024152764

Training iteration loss = 0.002727161

Training iteration loss = 0.0024253328

Training iteration loss = 0.0047073634

Training iteration loss = 0.0020927659

Training iteration loss = 0.002846363

Training iteration loss = 0.004336463

Training iteration loss = 0.0038452155

Training iteration loss = 0.0041194833

Training iteration loss = 0.0034365356

Training iteration loss = 0.005105791

Training iteration loss = 0.0048646

Training iteration loss = 0.00652759

Training iteration loss = 0.0032842944

Training iteration loss = 0.003688677

Training iteration loss = 0.0032387702

Training iteration loss = 0.004836677

Training iteration loss = 0.004176824

Training iteration loss = 0.004822925

Training iteration loss = 0.0040838895

Training iteration loss = 0.0033670394

Training iteration loss = 0.004101061

Training iteration loss = 0.006695625

Training iteration loss = 0.0041147736

Training iteration loss = 0.004666692

Training iteration loss = 0.004581232

Training iteration loss = 0.0045229383

Training iteration loss = 0.0032004993

Training iteration loss = 0.005151111

Training iteration loss = 0.004541327

Training iteration loss = 0.0038757876

Training iteration loss = 0.004153328

Training iteration loss = 0.0033620715

Training iteration loss = 0.0028697632

Training iteration loss = 0.0057285423

Training iteration loss = 0.007494829

Training iteration loss = 0.004906284

Training iteration loss = 0.0060417172

Training iteration loss = 0.0025422287

Training iteration loss = 0.006667674

Training iteration loss = 0.007403847

Training iteration loss = 0.0036523817

Training iteration loss = 0.005150637

Training iteration loss = 0.003750516

Training iteration loss = 0.0033111114

Training iteration loss = 0.0038979657

Training iteration loss = 0.0041059772

Training iteration loss = 0.0062394384

Training iteration loss = 0.008422966

Training iteration loss = 0.0028011396

Training iteration loss = 0.0036302514

Training iteration loss = 0.0028234683

Training iteration loss = 0.00392875

Training iteration loss = 0.004554562

Training iteration loss = 0.0038180992

Training iteration loss = 0.0052537746

Training iteration loss = 0.0028974228

Training iteration loss = 0.0056761582

Training iteration loss = 0.010228938

Training iteration loss = 0.0061547756

Training iteration loss = 0.0047722617

Training iteration loss = 0.00391628

Training iteration loss = 0.0045087556

Training iteration loss = 0.0033278426

Training iteration loss = 0.004944373

Training iteration loss = 0.0031530075

Training iteration loss = 0.0030210458

Training iteration loss = 0.0035407078

Training iteration loss = 0.0047897766

Training iteration loss = 0.0037691884

Training iteration loss = 0.005535996

Training iteration loss = 0.004134919

Training iteration loss = 0.0066650347

Training iteration loss = 0.0037667789

Training iteration loss = 0.003782387

Training iteration loss = 0.0041363356

Training iteration loss = 0.008861984

Training iteration loss = 0.0063561797

Training iteration loss = 0.004378314

Training iteration loss = 0.0035535737

Training iteration loss = 0.0075837784

Training iteration loss = 0.0030272584

Training iteration loss = 0.0029788471

Training iteration loss = 0.0035199292

Training iteration loss = 0.004520602

Training iteration loss = 0.0033290146

Training iteration loss = 0.0051818555

Training iteration loss = 0.0043193325

Training iteration loss = 0.0036500066

Training iteration loss = 0.0044914675

Training iteration loss = 0.0025267191

Training iteration loss = 0.003210107

Training iteration loss = 0.0030480444

Training iteration loss = 0.0036090494

Training iteration loss = 0.004857738

Training iteration loss = 0.0046306127

Training iteration loss = 0.006024863

Training iteration loss = 0.0046295645

Training iteration loss = 0.005878749

Training iteration loss = 0.0028059995

Training iteration loss = 0.004259381

Training iteration loss = 0.0031676318

Training iteration loss = 0.008015028

Training iteration loss = 0.0056552608

Training iteration loss = 0.0038249353

Training iteration loss = 0.0032912977

Training iteration loss = 0.0046878266

Training iteration loss = 0.01158798

Training iteration loss = 0.0037554165

Training iteration loss = 0.0044371285

Training iteration loss = 0.004496867

Training iteration loss = 0.002983282

Training iteration loss = 0.004442356

Training iteration loss = 0.0044189063

Training iteration loss = 0.0031340613

Training iteration loss = 0.00325871

Training iteration loss = 0.004181653

Training iteration loss = 0.0050148815

Training iteration loss = 0.0044851974

Training iteration loss = 0.0086619975

Training iteration loss = 0.0069155297

Training iteration loss = 0.003998606

Training iteration loss = 0.004060701

Training iteration loss = 0.006616941

Training iteration loss = 0.0063494206

Training iteration loss = 0.0036049567

Training iteration loss = 0.0047047273

Training iteration loss = 0.004416797

Training iteration loss = 0.0034204565

Training iteration loss = 0.0032359182

Training iteration loss = 0.0044515827

Training iteration loss = 0.003916355

Training iteration loss = 0.0032057946

Training iteration loss = 0.0042668018

Training iteration loss = 0.0028680929

Training iteration loss = 0.0025147705

Training iteration loss = 0.002516819

Training iteration loss = 0.003959942

Training iteration loss = 0.0026181368

Training iteration loss = 0.0038067307

Training iteration loss = 0.0055690445

Training iteration loss = 0.0091485055

Training iteration loss = 0.0034831706

Training iteration loss = 0.0033286337

Training iteration loss = 0.0033432946

Training iteration loss = 0.0039340663

Training iteration loss = 0.0030843623

Training iteration loss = 0.0049028746

Training iteration loss = 0.0037914452

Training iteration loss = 0.00584003

Training iteration loss = 0.0058924276

Training iteration loss = 0.0047223917

Training iteration loss = 0.002471438

Training iteration loss = 0.002963248

Training iteration loss = 0.009332431

Training iteration loss = 0.00468694

Training iteration loss = 0.0025830837

Training iteration loss = 0.00579764

Training iteration loss = 0.004224528

Training iteration loss = 0.004505958

Training iteration loss = 0.00440264

Training iteration loss = 0.005052761

Training iteration loss = 0.003011319

Training iteration loss = 0.009036354

Training iteration loss = 0.003467192

Training iteration loss = 0.004271588

Training iteration loss = 0.0046320227

Training iteration loss = 0.0032383313

Training iteration loss = 0.0028649291

Training iteration loss = 0.0029852781

Training iteration loss = 0.0029202073

Training iteration loss = 0.0042386698

Training iteration loss = 0.004709407

Training iteration loss = 0.005102146

Training iteration loss = 0.0038286524

Training iteration loss = 0.004044523

Training iteration loss = 0.0027757064

Training iteration loss = 0.0029893285

Training iteration loss = 0.0031056113

Training iteration loss = 0.0035039613

Training iteration loss = 0.008504196

Training iteration loss = 0.0024753402

Training iteration loss = 0.0035413655

Training iteration loss = 0.0036488727

Training iteration loss = 0.0049272967

Training iteration loss = 0.004032064

Training iteration loss = 0.0039219297

Training iteration loss = 0.0035105518

Training iteration loss = 0.0022783547

Training iteration loss = 0.0062070973

Training iteration loss = 0.0036283296

Training iteration loss = 0.0031005729

Training iteration loss = 0.0027419871

Training iteration loss = 0.003982209

Training iteration loss = 0.0049289805

Training iteration loss = 0.00462457

Training iteration loss = 0.0036047294

Training iteration loss = 0.0055067153

Training iteration loss = 0.0036727733

Training iteration loss = 0.0031766628

Training iteration loss = 0.002439229

Training iteration loss = 0.0027334057

Training iteration loss = 0.0024084158

Training iteration loss = 0.004679303

Training iteration loss = 0.002085832

Training iteration loss = 0.002798222

Training iteration loss = 0.004322742

Training iteration loss = 0.0038548384

Training iteration loss = 0.00412774

Training iteration loss = 0.0033916943

Training iteration loss = 0.0050748787

Training iteration loss = 0.0048364117

Training iteration loss = 0.0064850277

Training iteration loss = 0.0032096251

Training iteration loss = 0.0035917892

Training iteration loss = 0.003226266

Training iteration loss = 0.004807256

Training iteration loss = 0.0042040865

Training iteration loss = 0.0047958945

Training iteration loss = 0.0040162015

Training iteration loss = 0.00330951

Training iteration loss = 0.0040948344

Training iteration loss = 0.0067202896

Training iteration loss = 0.004061079

Training iteration loss = 0.004607133

Training iteration loss = 0.004562962

Training iteration loss = 0.004534489

Training iteration loss = 0.0032122422

Training iteration loss = 0.005058253

Training iteration loss = 0.0045208298

Training iteration loss = 0.0038378316

Training iteration loss = 0.0041403607

Training iteration loss = 0.0033593902

Training iteration loss = 0.0028364768

Training iteration loss = 0.0056684525

Training iteration loss = 0.0074279564

Training iteration loss = 0.004900419

Training iteration loss = 0.0059494474

Training iteration loss = 0.0025418964

Training iteration loss = 0.0066327862

Training iteration loss = 0.0073524504

Training iteration loss = 0.0036312665

Training iteration loss = 0.0050345697

Training iteration loss = 0.003688079

Training iteration loss = 0.0032550672

Training iteration loss = 0.003860417

Training iteration loss = 0.004076775

Training iteration loss = 0.006132172

Training iteration loss = 0.008324127

Training iteration loss = 0.0028173693

Training iteration loss = 0.0036089607

Training iteration loss = 0.0027855264

Training iteration loss = 0.0038498212

Training iteration loss = 0.004535584

Training iteration loss = 0.0037446197

Training iteration loss = 0.0051867017

Training iteration loss = 0.0028645492

Training iteration loss = 0.0056466036

Training iteration loss = 0.010134787

Training iteration loss = 0.0060977866

Training iteration loss = 0.0047074393

Training iteration loss = 0.003831909

Training iteration loss = 0.0044482276

Training iteration loss = 0.0032995737

Training iteration loss = 0.004804579

Training iteration loss = 0.0031382972

Training iteration loss = 0.0029893273

Training iteration loss = 0.00347177

Training iteration loss = 0.0047584767

Training iteration loss = 0.0037223175

Training iteration loss = 0.0054749213

Training iteration loss = 0.004108826

Training iteration loss = 0.0065919613

Training iteration loss = 0.0037510071

Training iteration loss = 0.0037459042

Training iteration loss = 0.0040494404

Training iteration loss = 0.008775709

Training iteration loss = 0.006245461

Training iteration loss = 0.0043472364

Training iteration loss = 0.0035094705

Training iteration loss = 0.0075437077

Training iteration loss = 0.0030175187

Training iteration loss = 0.0029144548

Training iteration loss = 0.0034704583

Training iteration loss = 0.004504807

Training iteration loss = 0.0033205866

Training iteration loss = 0.005086226

Training iteration loss = 0.004281725

Training iteration loss = 0.0036019355

Training iteration loss = 0.0044521797

Training iteration loss = 0.002520574

Training iteration loss = 0.003181121

Training iteration loss = 0.0030366292

Training iteration loss = 0.003600467

Training iteration loss = 0.004832491

Training iteration loss = 0.0044731097

Training iteration loss = 0.0059868717

Training iteration loss = 0.004665527

Training iteration loss = 0.00588326

Training iteration loss = 0.0027274138

Training iteration loss = 0.004162504

Training iteration loss = 0.0031324364

Training iteration loss = 0.007945561

Training iteration loss = 0.005554555

Training iteration loss = 0.0037761722

Training iteration loss = 0.0033414774

Training iteration loss = 0.0046387585

Training iteration loss = 0.01144101

Training iteration loss = 0.0037185766

Training iteration loss = 0.0044354782

Training iteration loss = 0.0045437776

Training iteration loss = 0.0028951184

Training iteration loss = 0.0043826527

Training iteration loss = 0.004413867

Training iteration loss = 0.0031320418

Training iteration loss = 0.003177541

Training iteration loss = 0.004102945

Training iteration loss = 0.005019892

Training iteration loss = 0.0044922326

Training iteration loss = 0.008587002

Training iteration loss = 0.006862609

Training iteration loss = 0.004003138

Training iteration loss = 0.0040684254

Training iteration loss = 0.0065083057

Training iteration loss = 0.0062512415

Training iteration loss = 0.0036143025

Training iteration loss = 0.004633567

Training iteration loss = 0.004380058

Training iteration loss = 0.0033469535

Training iteration loss = 0.0031972043

Training iteration loss = 0.004413853

Training iteration loss = 0.0038771166

Training iteration loss = 0.0031335696

Training iteration loss = 0.004279382

Training iteration loss = 0.0028693033

Training iteration loss = 0.0024305366

Training iteration loss = 0.0024626183

Training iteration loss = 0.0039386847

Training iteration loss = 0.0026216467

Training iteration loss = 0.003790087

Training iteration loss = 0.005559797

Training iteration loss = 0.00907624

Training iteration loss = 0.0034393521

Training iteration loss = 0.0033237652

Training iteration loss = 0.0033016813

Training iteration loss = 0.0038937733

Training iteration loss = 0.0030860521

Training iteration loss = 0.004892882

Training iteration loss = 0.0037814642

Training iteration loss = 0.00576579

Training iteration loss = 0.0058790944

Training iteration loss = 0.004753018

Training iteration loss = 0.0024085436

Training iteration loss = 0.0029206807

Training iteration loss = 0.009340854

Training iteration loss = 0.0046115723

Training iteration loss = 0.0025775526

Training iteration loss = 0.0058070924

Training iteration loss = 0.004186158

Training iteration loss = 0.0044103

Training iteration loss = 0.0043928945

Training iteration loss = 0.00503616

Training iteration loss = 0.0030234375

Training iteration loss = 0.008996026

Training iteration loss = 0.0034252724

Training iteration loss = 0.0042037102

Training iteration loss = 0.0045608934

Training iteration loss = 0.0032359126

Training iteration loss = 0.0028621505

Training iteration loss = 0.0029476758

Training iteration loss = 0.0028235123

Training iteration loss = 0.0041850205

Training iteration loss = 0.004697869

Training iteration loss = 0.0050701895

Training iteration loss = 0.003771505

Training iteration loss = 0.004011209

Training iteration loss = 0.0028271198

Training iteration loss = 0.0029649066

Training iteration loss = 0.0030679181

Training iteration loss = 0.00347176

Training iteration loss = 0.008469681

Training iteration loss = 0.0024228673

Training iteration loss = 0.0035183309

Training iteration loss = 0.0036735719

Training iteration loss = 0.004874876

Training iteration loss = 0.0039921715

Training iteration loss = 0.003908709

Training iteration loss = 0.003513627

Training iteration loss = 0.0022413626

Training iteration loss = 0.0062071676

Training iteration loss = 0.0035696272

Training iteration loss = 0.0030684818

Training iteration loss = 0.0027492444

Training iteration loss = 0.003984875

Training iteration loss = 0.004936458

Training iteration loss = 0.00457578

Training iteration loss = 0.003538021

Training iteration loss = 0.0054943

Training iteration loss = 0.0036388387

Training iteration loss = 0.0031715094

Training iteration loss = 0.002467188

Training iteration loss = 0.0027530966

Training iteration loss = 0.0023806666

Training iteration loss = 0.004658679

Training iteration loss = 0.0021023087

Training iteration loss = 0.0027791457

Training iteration loss = 0.004292422

Training iteration loss = 0.003829101

Training iteration loss = 0.004145809

Training iteration loss = 0.0033683637

Training iteration loss = 0.0050360314

Training iteration loss = 0.0047914325

Training iteration loss = 0.006437127

Training iteration loss = 0.0031624583

Training iteration loss = 0.003527188

Training iteration loss = 0.0032198865

Training iteration loss = 0.0047297557

Training iteration loss = 0.0041974573

Training iteration loss = 0.004800006

Training iteration loss = 0.0039672838

Training iteration loss = 0.0032438512

Training iteration loss = 0.004048855

Training iteration loss = 0.006752137

Training iteration loss = 0.004059549

Training iteration loss = 0.00456165

Training iteration loss = 0.004512236

Training iteration loss = 0.0044996305

Training iteration loss = 0.0032511714

Training iteration loss = 0.00503315

Training iteration loss = 0.004508583

Training iteration loss = 0.0037745852

Training iteration loss = 0.004116452

Training iteration loss = 0.003363559

Training iteration loss = 0.0028190706

Training iteration loss = 0.0056144595

Training iteration loss = 0.007381109

Training iteration loss = 0.00488417

Training iteration loss = 0.005883176

Training iteration loss = 0.0025747665

Training iteration loss = 0.0066270796

Training iteration loss = 0.0072876294

Training iteration loss = 0.0035830736

Training iteration loss = 0.0049652974

Training iteration loss = 0.0036689413

Training iteration loss = 0.003247883

Training iteration loss = 0.003814041

Training iteration loss = 0.0040516504

Training iteration loss = 0.006073954

Training iteration loss = 0.008272604

Training iteration loss = 0.0028415285

Training iteration loss = 0.0036045592

Training iteration loss = 0.0027996877

Training iteration loss = 0.0037872111

Training iteration loss = 0.0045200386

Training iteration loss = 0.003729834

Training iteration loss = 0.0051157787

Training iteration loss = 0.0028458405

Training iteration loss = 0.0056384862

Training iteration loss = 0.010026802

Training iteration loss = 0.006051635

Training iteration loss = 0.0046712393

Training iteration loss = 0.0037552018

Training iteration loss = 0.004379259

Training iteration loss = 0.003278672

Training iteration loss = 0.0047088745

Training iteration loss = 0.0031113604

Training iteration loss = 0.0029621134

Training iteration loss = 0.0034326538

Training iteration loss = 0.004737846

Training iteration loss = 0.0036742345

Training iteration loss = 0.005403453

Training iteration loss = 0.004087919

Training iteration loss = 0.0065532196

Training iteration loss = 0.0037345162

Training iteration loss = 0.003728289

Training iteration loss = 0.0040028803

Training iteration loss = 0.008725621

Training iteration loss = 0.006180877

Training iteration loss = 0.0043251417

Training iteration loss = 0.003474341

Training iteration loss = 0.007523442

Training iteration loss = 0.0030152835

Training iteration loss = 0.0028380118

Training iteration loss = 0.0034109124

Training iteration loss = 0.0044650524

Training iteration loss = 0.0033437368

Training iteration loss = 0.0050050416

Training iteration loss = 0.0042450572

Training iteration loss = 0.0035394991

Training iteration loss = 0.004416006

Training iteration loss = 0.0025357187

Training iteration loss = 0.0031666372

Training iteration loss = 0.0030021544

Training iteration loss = 0.003570608

Training iteration loss = 0.0048389737

Training iteration loss = 0.0043768776

Training iteration loss = 0.005910941

Training iteration loss = 0.0046676826

Training iteration loss = 0.0058857067

Training iteration loss = 0.0026851278

Training iteration loss = 0.0040649422

Training iteration loss = 0.0030762265

Training iteration loss = 0.007904248

Training iteration loss = 0.0054939124

Training iteration loss = 0.00372436

Training iteration loss = 0.0033432574

Training iteration loss = 0.004626297

Training iteration loss = 0.011308511

Training iteration loss = 0.0036968251

Training iteration loss = 0.0044124904

Training iteration loss = 0.004603986

Training iteration loss = 0.0028444591

Training iteration loss = 0.004319864

Training iteration loss = 0.004388001

Training iteration loss = 0.0031405091

Training iteration loss = 0.003139263

Training iteration loss = 0.004024916

Training iteration loss = 0.0050252685

Training iteration loss = 0.004505249

Training iteration loss = 0.008558478

Training iteration loss = 0.0068074022

Training iteration loss = 0.0039656027

Training iteration loss = 0.0040799906

Training iteration loss = 0.006439092

Training iteration loss = 0.0061569116

Training iteration loss = 0.0035837146

Training iteration loss = 0.004606445

Training iteration loss = 0.0043847286

Training iteration loss = 0.003273462

Training iteration loss = 0.0031289048

Training iteration loss = 0.0044002705

Training iteration loss = 0.0038688313

Training iteration loss = 0.003048527

Training iteration loss = 0.004253167

Training iteration loss = 0.0028817032

Training iteration loss = 0.0023900922

Training iteration loss = 0.0024189453

Training iteration loss = 0.003915077

Training iteration loss = 0.002620252

Training iteration loss = 0.0037836016

Training iteration loss = 0.0055290814

Training iteration loss = 0.008989047

Training iteration loss = 0.003393742

Training iteration loss = 0.0033287366

Training iteration loss = 0.0032752817

Training iteration loss = 0.0038450938

Training iteration loss = 0.0030480751

Training iteration loss = 0.004890844

Training iteration loss = 0.0037930154

Training iteration loss = 0.005703931

Training iteration loss = 0.005854524

Training iteration loss = 0.0047763004

Training iteration loss = 0.002363494

Training iteration loss = 0.0028585864

Training iteration loss = 0.00929489

Training iteration loss = 0.00457957

Training iteration loss = 0.0025624766

Training iteration loss = 0.005761417

Training iteration loss = 0.0041374876

Training iteration loss = 0.004355892

Training iteration loss = 0.004364634

Training iteration loss = 0.005036524

Training iteration loss = 0.003034358

Training iteration loss = 0.008907274

Training iteration loss = 0.0034122465

Training iteration loss = 0.004185317

Training iteration loss = 0.0044786306

Training iteration loss = 0.0032191335

Training iteration loss = 0.0028822243

Training iteration loss = 0.0029692876

Training iteration loss = 0.0027330993

Training iteration loss = 0.004138442

Training iteration loss = 0.0046731923

Training iteration loss = 0.0050470307

Training iteration loss = 0.003757841

Training iteration loss = 0.0039567505

Training iteration loss = 0.0028190904

Training iteration loss = 0.0029604367

Training iteration loss = 0.0030429133

Training iteration loss = 0.0034291751

Training iteration loss = 0.008457366

Training iteration loss = 0.0023525753

Training iteration loss = 0.0034576356

Training iteration loss = 0.003676161

Training iteration loss = 0.0048783524

Training iteration loss = 0.003965472

Training iteration loss = 0.0038983647

Training iteration loss = 0.0034924627

Training iteration loss = 0.002230731

Training iteration loss = 0.006231681

Training iteration loss = 0.0035177653

Training iteration loss = 0.003040674

Training iteration loss = 0.0027029493

Training iteration loss = 0.0039801137

Training iteration loss = 0.0049321554

Training iteration loss = 0.004527224

Training iteration loss = 0.0034799536

Training iteration loss = 0.0055044307

Training iteration loss = 0.003604235

Training iteration loss = 0.0031622725

Training iteration loss = 0.002488034

Training iteration loss = 0.0027622075

Training iteration loss = 0.0023376287

Training iteration loss = 0.0046409373

Training iteration loss = 0.0021000388

Training iteration loss = 0.0027690514

Training iteration loss = 0.004280287

Training iteration loss = 0.0037891374

Training iteration loss = 0.0041291043

Training iteration loss = 0.00335344

Training iteration loss = 0.005023591

Training iteration loss = 0.004754025

Training iteration loss = 0.0063636084

Training iteration loss = 0.0031160293

Training iteration loss = 0.0035061862

Training iteration loss = 0.003240695

Training iteration loss = 0.0046475767

Training iteration loss = 0.004152104

Training iteration loss = 0.004802084

Training iteration loss = 0.00394474

Training iteration loss = 0.00320875

Training iteration loss = 0.004002655

Training iteration loss = 0.0067367605

Training iteration loss = 0.0040636114

Training iteration loss = 0.004544377

Training iteration loss = 0.004471879

Training iteration loss = 0.0044418373

Training iteration loss = 0.0032535046

Training iteration loss = 0.005029051

Training iteration loss = 0.0045021274

Training iteration loss = 0.0037138208

Training iteration loss = 0.0040831426

Training iteration loss = 0.0033491666

Training iteration loss = 0.0027925335

Training iteration loss = 0.005601939

Training iteration loss = 0.0073460327

Training iteration loss = 0.004858182

Training iteration loss = 0.0058344225

Training iteration loss = 0.002607014

Training iteration loss = 0.006583601

Training iteration loss = 0.007252539

Training iteration loss = 0.003548798

Training iteration loss = 0.004916915

Training iteration loss = 0.0036525235

Training iteration loss = 0.003243555

Training iteration loss = 0.0037934107

Training iteration loss = 0.0040401802

Training iteration loss = 0.0060457108

Training iteration loss = 0.008262533

Training iteration loss = 0.0028660416

Training iteration loss = 0.0035881186

Training iteration loss = 0.0028302397

Training iteration loss = 0.0037553154

Training iteration loss = 0.004495894

Training iteration loss = 0.0037341465

Training iteration loss = 0.0050707054

Training iteration loss = 0.0028288204

Training iteration loss = 0.0056286524

Training iteration loss = 0.009956733

Training iteration loss = 0.006030766

Training iteration loss = 0.004634851

Training iteration loss = 0.0037194483

Training iteration loss = 0.0043260176

Training iteration loss = 0.0032600404

Training iteration loss = 0.0046651834

Training iteration loss = 0.0030898207

Training iteration loss = 0.002952775

Training iteration loss = 0.003409081

Training iteration loss = 0.0047127926

Training iteration loss = 0.0036485486

Training iteration loss = 0.0053430945

Training iteration loss = 0.0040675607

Training iteration loss = 0.006534025

Training iteration loss = 0.0037268435

Training iteration loss = 0.0037228733

Training iteration loss = 0.003957943

Training iteration loss = 0.008678467

Training iteration loss = 0.0061407215

Training iteration loss = 0.004301062

Training iteration loss = 0.0034283623

Training iteration loss = 0.007500171

Training iteration loss = 0.003004401

Training iteration loss = 0.0027879644

Training iteration loss = 0.0033669313

Training iteration loss = 0.0044060214

Training iteration loss = 0.0033609457

Training iteration loss = 0.0049606697

Training iteration loss = 0.004218427

Training iteration loss = 0.003480113

Training iteration loss = 0.0044016824

Training iteration loss = 0.0025546078

Training iteration loss = 0.0031628169

Training iteration loss = 0.002964341

Training iteration loss = 0.0035302474

Training iteration loss = 0.004842294

Training iteration loss = 0.0043093567

Training iteration loss = 0.0058428063

Training iteration loss = 0.00463326

Training iteration loss = 0.0058714743

Training iteration loss = 0.002673543

Training iteration loss = 0.00399881

Training iteration loss = 0.0030115552

Training iteration loss = 0.007878093

Training iteration loss = 0.0054468364

Training iteration loss = 0.003688825

Training iteration loss = 0.0033098368

Training iteration loss = 0.004637174

Training iteration loss = 0.011236574

Training iteration loss = 0.003677673

Training iteration loss = 0.0043706573

Training iteration loss = 0.0046227737

Training iteration loss = 0.0028366037

Training iteration loss = 0.0042875954

Training iteration loss = 0.0043479563

Training iteration loss = 0.0031348888

Training iteration loss = 0.0031337177

Training iteration loss = 0.003978798

Training iteration loss = 0.005029105

Training iteration loss = 0.004504395

Training iteration loss = 0.00854517

Training iteration loss = 0.0067761745

Training iteration loss = 0.0039176308

Training iteration loss = 0.0040715626

Training iteration loss = 0.0064013614

Training iteration loss = 0.0061148913

Training iteration loss = 0.003551346

Training iteration loss = 0.0045683365

Training iteration loss = 0.00438849

Training iteration loss = 0.0032261582

Training iteration loss = 0.0030654084

Training iteration loss = 0.0043916907

Training iteration loss = 0.003873275

Training iteration loss = 0.0029673046

Training iteration loss = 0.0042193467

Training iteration loss = 0.0028922455

Training iteration loss = 0.0023770616

Training iteration loss = 0.0023744234

Training iteration loss = 0.003882934

Training iteration loss = 0.0026047754

Training iteration loss = 0.0037673612

Training iteration loss = 0.005497705

Training iteration loss = 0.008901102

Training iteration loss = 0.00335165

Training iteration loss = 0.0033229683

Training iteration loss = 0.0032573252

Training iteration loss = 0.0038139606

Training iteration loss = 0.003003719

Training iteration loss = 0.004863652

Training iteration loss = 0.003806998

Training iteration loss = 0.0056698066

Training iteration loss = 0.0058130324

Training iteration loss = 0.004775354

Training iteration loss = 0.002330831

Training iteration loss = 0.0027983189

Training iteration loss = 0.009217813

Training iteration loss = 0.0045636906

Training iteration loss = 0.002543935

Training iteration loss = 0.0056935176

Training iteration loss = 0.0040971157

Training iteration loss = 0.004338093

Training iteration loss = 0.0043170615

Training iteration loss = 0.0050430736

Training iteration loss = 0.00305276

Training iteration loss = 0.008812013

Training iteration loss = 0.0034005253

Training iteration loss = 0.0041929367

Training iteration loss = 0.004426293

Training iteration loss = 0.0032031087

Training iteration loss = 0.0028852846

Training iteration loss = 0.003007489

Training iteration loss = 0.0026848791

Training iteration loss = 0.004114634

Training iteration loss = 0.0046271347

Training iteration loss = 0.005026883

Training iteration loss = 0.0037727077

Training iteration loss = 0.0039007163

Training iteration loss = 0.0027749666

Training iteration loss = 0.0029671786

Training iteration loss = 0.0030252084

Training iteration loss = 0.003397742

Training iteration loss = 0.008449447

Training iteration loss = 0.0022907485

Training iteration loss = 0.0034055496

Training iteration loss = 0.0036539442

Training iteration loss = 0.004897355

Training iteration loss = 0.003949371

Training iteration loss = 0.003884191

Training iteration loss = 0.0034655028

Training iteration loss = 0.002231965

Training iteration loss = 0.0062411465

Training iteration loss = 0.0034800312

Training iteration loss = 0.003030204

Training iteration loss = 0.0026497992

Training iteration loss = 0.0039704232

Training iteration loss = 0.0048997486

Training iteration loss = 0.004496882

Training iteration loss = 0.0034603607

Training iteration loss = 0.005515434

Training iteration loss = 0.0035738552

Training iteration loss = 0.00314184

Training iteration loss = 0.0025024198

Training iteration loss = 0.0027682835

Training iteration loss = 0.0023081962

Training iteration loss = 0.004635566

Training iteration loss = 0.00208575

Training iteration loss = 0.0027578801

Training iteration loss = 0.0042808983

Training iteration loss = 0.0037726627

Training iteration loss = 0.004107972

Training iteration loss = 0.0033375507

Training iteration loss = 0.00501968

Training iteration loss = 0.0047392873

Training iteration loss = 0.0063036387

Training iteration loss = 0.0030674718

Training iteration loss = 0.0034997652

Training iteration loss = 0.0032674782

Training iteration loss = 0.004592626

Training iteration loss = 0.0041108173

Training iteration loss = 0.0047981148

Training iteration loss = 0.003931549

Training iteration loss = 0.0031973652

Training iteration loss = 0.003979675

Training iteration loss = 0.006718945

Training iteration loss = 0.0040552747

Training iteration loss = 0.0045267395

Training iteration loss = 0.0044432227

Training iteration loss = 0.004403651

Training iteration loss = 0.0032432012

Training iteration loss = 0.0050177085

Training iteration loss = 0.0044903294

Training iteration loss = 0.0036674237

Training iteration loss = 0.0040491116

Training iteration loss = 0.0033311741

Training iteration loss = 0.0027783888

Training iteration loss = 0.0056134933

Training iteration loss = 0.007317454

Training iteration loss = 0.0048123254

Training iteration loss = 0.0058039925

Training iteration loss = 0.0026450453

Training iteration loss = 0.0065157698

Training iteration loss = 0.007224668

Training iteration loss = 0.0035322655

Training iteration loss = 0.004890104

Training iteration loss = 0.003635429

Training iteration loss = 0.0032201968

Training iteration loss = 0.003790342

Training iteration loss = 0.0040457626

Training iteration loss = 0.0060263574

Training iteration loss = 0.008263876

Training iteration loss = 0.0028792191

Training iteration loss = 0.0035572748

Training iteration loss = 0.0028470235

Training iteration loss = 0.0037482549

Training iteration loss = 0.0044706375

Training iteration loss = 0.0037324484

Training iteration loss = 0.0050329454

Training iteration loss = 0.0028134994

Training iteration loss = 0.0056113657

Training iteration loss = 0.009934385

Training iteration loss = 0.006018195

Training iteration loss = 0.0046041203

Training iteration loss = 0.0037166337

Training iteration loss = 0.0042951484

Training iteration loss = 0.0032490194

Training iteration loss = 0.0046486794

Training iteration loss = 0.003076411

Training iteration loss = 0.0029553256

Training iteration loss = 0.0033993141

Training iteration loss = 0.004696533

Training iteration loss = 0.0036342395

Training iteration loss = 0.0052866344

Training iteration loss = 0.0040549366

Training iteration loss = 0.0065108817

Training iteration loss = 0.0037239438

Training iteration loss = 0.003720897

Training iteration loss = 0.00390879

Training iteration loss = 0.008635661

Training iteration loss = 0.0060873665

Training iteration loss = 0.0042811492

Training iteration loss = 0.0033820588

Training iteration loss = 0.0074779945

Training iteration loss = 0.0029969756

Training iteration loss = 0.0027479157

Training iteration loss = 0.003320315

Training iteration loss = 0.004348514

Training iteration loss = 0.0033766609

Training iteration loss = 0.0049354676

Training iteration loss = 0.0041938685

Training iteration loss = 0.0034240216

Training iteration loss = 0.0043896604

Training iteration loss = 0.0025737118

Training iteration loss = 0.0031597444

Training iteration loss = 0.0029247983

Training iteration loss = 0.0034790512

Training iteration loss = 0.004837492

Training iteration loss = 0.0042572697

Training iteration loss = 0.005796294

Training iteration loss = 0.00459496

Training iteration loss = 0.0058357776

Training iteration loss = 0.0026747466

Training iteration loss = 0.003961894

Training iteration loss = 0.002959637

Training iteration loss = 0.007861082

Training iteration loss = 0.0054041133

Training iteration loss = 0.003665736

Training iteration loss = 0.0032720484

Training iteration loss = 0.0046482794

Training iteration loss = 0.01120676

Training iteration loss = 0.0036627885

Training iteration loss = 0.004328757

Training iteration loss = 0.0046040835

Training iteration loss = 0.002832248

Training iteration loss = 0.00427715

Training iteration loss = 0.0043198005

Training iteration loss = 0.0031290103

Training iteration loss = 0.0031381797

Training iteration loss = 0.0039443797

Training iteration loss = 0.005027794

Training iteration loss = 0.004497314

Training iteration loss = 0.008539831

Training iteration loss = 0.0067655295

Training iteration loss = 0.0038712511

Training iteration loss = 0.00405363

Training iteration loss = 0.0063720974

Training iteration loss = 0.0061057676

Training iteration loss = 0.003535209

Training iteration loss = 0.0045115757

Training iteration loss = 0.0043737255

Training iteration loss = 0.0031915864

Training iteration loss = 0.0030147813

Training iteration loss = 0.004388314

Training iteration loss = 0.0038885707

Training iteration loss = 0.0028842713

Training iteration loss = 0.0041698343

Training iteration loss = 0.0028881996

Training iteration loss = 0.0023769392

Training iteration loss = 0.0023357917

Training iteration loss = 0.0038441417

Training iteration loss = 0.0025769984

Training iteration loss = 0.0037430685

Training iteration loss = 0.005459841

Training iteration loss = 0.008826959

Training iteration loss = 0.0033240898

Training iteration loss = 0.0033163466

Training iteration loss = 0.0032280565

Training iteration loss = 0.0037912084

Training iteration loss = 0.002972367

Training iteration loss = 0.004824444

Training iteration loss = 0.0038052488

Training iteration loss = 0.0056526414

Training iteration loss = 0.0057622516

Training iteration loss = 0.004760751

Training iteration loss = 0.0023118283

Training iteration loss = 0.0027493304

Training iteration loss = 0.009129526

Training iteration loss = 0.0045506745

Training iteration loss = 0.0025373718

Training iteration loss = 0.005623597

Training iteration loss = 0.0040593785

Training iteration loss = 0.004337718

Training iteration loss = 0.004269703

Training iteration loss = 0.005050579

Training iteration loss = 0.0030707065

Training iteration loss = 0.008747673

Training iteration loss = 0.0033930934

Training iteration loss = 0.0042084656

Training iteration loss = 0.004402258

Training iteration loss = 0.003201878

Training iteration loss = 0.0028776405

Training iteration loss = 0.0030306869

Training iteration loss = 0.0026640669

Training iteration loss = 0.0041144057

Training iteration loss = 0.0045826733

Training iteration loss = 0.005017181

Training iteration loss = 0.0037905036

Training iteration loss = 0.0038490489

Training iteration loss = 0.0027163771

Training iteration loss = 0.0029726485

Training iteration loss = 0.0030131396

Training iteration loss = 0.0033848528

Training iteration loss = 0.008427753

Training iteration loss = 0.0022429805

Training iteration loss = 0.0033761289

Training iteration loss = 0.0036233652

Training iteration loss = 0.004915031

Training iteration loss = 0.003932237

Training iteration loss = 0.0038631165

Training iteration loss = 0.0034394169

Training iteration loss = 0.002233147

Training iteration loss = 0.006239854

Training iteration loss = 0.003451055

Training iteration loss = 0.0030267488

Training iteration loss = 0.002613889

Training iteration loss = 0.0039675008

Training iteration loss = 0.004853283

Training iteration loss = 0.0044780816

Training iteration loss = 0.0034570685

Training iteration loss = 0.0055243266

Training iteration loss = 0.0035591798

Training iteration loss = 0.003114638

Training iteration loss = 0.002506832

Training iteration loss = 0.0027800258

Training iteration loss = 0.002295514

Training iteration loss = 0.0046338825

Training iteration loss = 0.002072702

Training iteration loss = 0.0027551102

Training iteration loss = 0.004282081

Training iteration loss = 0.0037652468

Training iteration loss = 0.0040977844

Training iteration loss = 0.0033293918

Training iteration loss = 0.005009517

Training iteration loss = 0.004738367

Training iteration loss = 0.0062659862

Training iteration loss = 0.003021774

Training iteration loss = 0.0034929148

Training iteration loss = 0.0032874013

Training iteration loss = 0.004558937

Training iteration loss = 0.0040864614

Training iteration loss = 0.0047878395

Training iteration loss = 0.003919372

Training iteration loss = 0.0031987957

Training iteration loss = 0.0039710538

Training iteration loss = 0.0067004287

Training iteration loss = 0.004039423

Training iteration loss = 0.0045099948

Training iteration loss = 0.004415039

Training iteration loss = 0.0043699737

Training iteration loss = 0.0032290749

Training iteration loss = 0.005001417

Training iteration loss = 0.0044668936

Training iteration loss = 0.003629027

Training iteration loss = 0.0040204027

Training iteration loss = 0.0033098087

Training iteration loss = 0.002772092

Training iteration loss = 0.005628184

Training iteration loss = 0.0073059364

Training iteration loss = 0.0047452073

Training iteration loss = 0.005773743

Training iteration loss = 0.002677979

Training iteration loss = 0.0064483644

Training iteration loss = 0.0071923654

Training iteration loss = 0.0035197928

Training iteration loss = 0.00488619

Training iteration loss = 0.0036237023

Training iteration loss = 0.003182222

Training iteration loss = 0.003791838

Training iteration loss = 0.0040603527

Training iteration loss = 0.0060108113

Training iteration loss = 0.008267839

Training iteration loss = 0.0028820394

Training iteration loss = 0.0035195227

Training iteration loss = 0.0028383571

Training iteration loss = 0.003757682

Training iteration loss = 0.004459483

Training iteration loss = 0.0037234265

Training iteration loss = 0.0049934383

Training iteration loss = 0.0028000341

Training iteration loss = 0.005591625

Training iteration loss = 0.009952809

Training iteration loss = 0.0060073845

Training iteration loss = 0.0045814402

Training iteration loss = 0.0037276102

Training iteration loss = 0.0042820624

Training iteration loss = 0.0032429963

Training iteration loss = 0.004632399

Training iteration loss = 0.0030725647

Training iteration loss = 0.0029607627

Training iteration loss = 0.0033936535

Training iteration loss = 0.0047016283

Training iteration loss = 0.0036221922

Training iteration loss = 0.005227

Training iteration loss = 0.004045962

Training iteration loss = 0.0064857122

Training iteration loss = 0.003732499

Training iteration loss = 0.003723152

Training iteration loss = 0.0038677042

Training iteration loss = 0.008600503

Training iteration loss = 0.0060192957

Training iteration loss = 0.004271401

Training iteration loss = 0.0033398385

Training iteration loss = 0.0074563953

Training iteration loss = 0.0029958338

Training iteration loss = 0.0027137361

Training iteration loss = 0.0032699099

Training iteration loss = 0.0042834333

Training iteration loss = 0.0033844467

Training iteration loss = 0.004918407

Training iteration loss = 0.004172825

Training iteration loss = 0.0033734925

Training iteration loss = 0.0043736603

Training iteration loss = 0.0025827268

Training iteration loss = 0.0031595004

Training iteration loss = 0.0028914681

Training iteration loss = 0.0034276412

Training iteration loss = 0.0048146783

Training iteration loss = 0.004213805

Training iteration loss = 0.0057684854

Training iteration loss = 0.0045543495

Training iteration loss = 0.0057883393

Training iteration loss = 0.002680565

Training iteration loss = 0.003939268

Training iteration loss = 0.002920409

Training iteration loss = 0.00785203

Training iteration loss = 0.0053680777

Training iteration loss = 0.003643209

Training iteration loss = 0.0032247577

Training iteration loss = 0.004649519

Training iteration loss = 0.0112001635

Training iteration loss = 0.003656094

Training iteration loss = 0.004297807

Training iteration loss = 0.0045627183

Training iteration loss = 0.0028104633

Training iteration loss = 0.0042680744

Training iteration loss = 0.0043046055

Training iteration loss = 0.0031325035

Training iteration loss = 0.003149633

Training iteration loss = 0.0039144633

Training iteration loss = 0.0050141956

Training iteration loss = 0.0044769137

Training iteration loss = 0.008537925

Training iteration loss = 0.006769488

Training iteration loss = 0.0038345426

Training iteration loss = 0.004031453

Training iteration loss = 0.0063311798

Training iteration loss = 0.0061043445

Training iteration loss = 0.0035334714

Training iteration loss = 0.0044536623

Training iteration loss = 0.0043468405

Training iteration loss = 0.0031652898

Training iteration loss = 0.0029652787

Training iteration loss = 0.0043803984

Training iteration loss = 0.0039075967

Training iteration loss = 0.0028112726

Training iteration loss = 0.0041084844

Training iteration loss = 0.0028586683

Training iteration loss = 0.002378988

Training iteration loss = 0.0023123452

Training iteration loss = 0.003805112

Training iteration loss = 0.0025481463

Training iteration loss = 0.003716318

Training iteration loss = 0.005412882

Training iteration loss = 0.008776251

Training iteration loss = 0.0033097335

Training iteration loss = 0.0033202637

Training iteration loss = 0.0031912776

Training iteration loss = 0.0037633888

Training iteration loss = 0.0029477885

Training iteration loss = 0.004791155

Training iteration loss = 0.0037881613

Training iteration loss = 0.0056467243

Training iteration loss = 0.0057224445

Training iteration loss = 0.004732781

Training iteration loss = 0.0023037118

Training iteration loss = 0.002716081

Training iteration loss = 0.009047373

Training iteration loss = 0.004537556

Training iteration loss = 0.0025408482

Single layer neural network training data error = 0.0025408482

Single layer neural network test data error = 0.0034649842
