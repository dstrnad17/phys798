Training iteration loss = 0.045221712

Training iteration loss = 0.030970665

Training iteration loss = 0.017165821

Training iteration loss = 0.012297087

Training iteration loss = 0.009505562

Training iteration loss = 0.006213806

Training iteration loss = 0.015096472

Training iteration loss = 0.00932826

Training iteration loss = 0.010767513

Training iteration loss = 0.010988454

Training iteration loss = 0.009395673

Training iteration loss = 0.008829206

Training iteration loss = 0.0071868957

Training iteration loss = 0.0067656417

Training iteration loss = 0.006461156

Training iteration loss = 0.0064055338

Training iteration loss = 0.007173396

Training iteration loss = 0.0056982324

Training iteration loss = 0.006100682

Training iteration loss = 0.0049859504

Training iteration loss = 0.0063893087

Training iteration loss = 0.005897417

Training iteration loss = 0.006705426

Training iteration loss = 0.010225103

Training iteration loss = 0.0047183726

Training iteration loss = 0.004718126

Training iteration loss = 0.005147844

Training iteration loss = 0.0074127004

Training iteration loss = 0.0050973343

Training iteration loss = 0.005801301

Training iteration loss = 0.004757439

Training iteration loss = 0.0036075627

Training iteration loss = 0.009242031

Training iteration loss = 0.0053522196

Training iteration loss = 0.0050833584

Training iteration loss = 0.0044348924

Training iteration loss = 0.0051551713

Training iteration loss = 0.0061271437

Training iteration loss = 0.006585485

Training iteration loss = 0.005416088

Training iteration loss = 0.007131234

Training iteration loss = 0.0055369823

Training iteration loss = 0.004642849

Training iteration loss = 0.003951168

Training iteration loss = 0.0042500603

Training iteration loss = 0.0040297043

Training iteration loss = 0.0062254015

Training iteration loss = 0.0032250034

Training iteration loss = 0.004324258

Training iteration loss = 0.005287211

Training iteration loss = 0.0048376834

Training iteration loss = 0.005066797

Training iteration loss = 0.0046028933

Training iteration loss = 0.006511899

Training iteration loss = 0.00601487

Training iteration loss = 0.007972768

Training iteration loss = 0.0045956443

Training iteration loss = 0.005169272

Training iteration loss = 0.0044162106

Training iteration loss = 0.0062702782

Training iteration loss = 0.005067812

Training iteration loss = 0.006244685

Training iteration loss = 0.005162397

Training iteration loss = 0.004442173

Training iteration loss = 0.005290266

Training iteration loss = 0.0072151027

Training iteration loss = 0.005164935

Training iteration loss = 0.0058286157

Training iteration loss = 0.005616423

Training iteration loss = 0.006013661

Training iteration loss = 0.005193859

Training iteration loss = 0.0074842316

Training iteration loss = 0.0058204345

Training iteration loss = 0.0051263315

Training iteration loss = 0.005230611

Training iteration loss = 0.0048274514

Training iteration loss = 0.0040399986

Training iteration loss = 0.0062826523

Training iteration loss = 0.009077717

Training iteration loss = 0.0062636286

Training iteration loss = 0.0060084113

Training iteration loss = 0.0036200136

Training iteration loss = 0.0074809506

Training iteration loss = 0.009144861

Training iteration loss = 0.005067026

Training iteration loss = 0.0060310797

Training iteration loss = 0.004949699

Training iteration loss = 0.00563826

Training iteration loss = 0.005398972

Training iteration loss = 0.005157294

Training iteration loss = 0.008124629

Training iteration loss = 0.010953079

Training iteration loss = 0.0037327742

Training iteration loss = 0.0055121738

Training iteration loss = 0.0044945865

Training iteration loss = 0.0052037886

Training iteration loss = 0.006627392

Training iteration loss = 0.0052562305

Training iteration loss = 0.00613486

Training iteration loss = 0.0038972066

Training iteration loss = 0.0069118175

Training iteration loss = 0.01100734

Training iteration loss = 0.0070940293

Training iteration loss = 0.005979474

Training iteration loss = 0.0054254406

Training iteration loss = 0.0063596754

Training iteration loss = 0.004418492

Training iteration loss = 0.0055075088

Training iteration loss = 0.0046909363

Training iteration loss = 0.0044592153

Training iteration loss = 0.0047291694

Training iteration loss = 0.0074709556

Training iteration loss = 0.0049789697

Training iteration loss = 0.0067182877

Training iteration loss = 0.0056529385

Training iteration loss = 0.007668048

Training iteration loss = 0.0049948934

Training iteration loss = 0.0054394803

Training iteration loss = 0.005440746

Training iteration loss = 0.010324702

Training iteration loss = 0.008810227

Training iteration loss = 0.0055072266

Training iteration loss = 0.004306457

Training iteration loss = 0.008788065

Training iteration loss = 0.0045542284

Training iteration loss = 0.0036210914

Training iteration loss = 0.004204272

Training iteration loss = 0.0052266563

Training iteration loss = 0.004767176

Training iteration loss = 0.006634926

Training iteration loss = 0.005274805

Training iteration loss = 0.0040371376

Training iteration loss = 0.006297989

Training iteration loss = 0.0037856188

Training iteration loss = 0.0048094667

Training iteration loss = 0.003937221

Training iteration loss = 0.004831713

Training iteration loss = 0.0055216453

Training iteration loss = 0.005834136

Training iteration loss = 0.0075529725

Training iteration loss = 0.0061669834

Training iteration loss = 0.007190447

Training iteration loss = 0.0034486698

Training iteration loss = 0.0059265215

Training iteration loss = 0.004205452

Training iteration loss = 0.009190544

Training iteration loss = 0.006590666

Training iteration loss = 0.004782352

Training iteration loss = 0.004409892

Training iteration loss = 0.0060504093

Training iteration loss = 0.01225447

Training iteration loss = 0.0045174086

Training iteration loss = 0.005671426

Training iteration loss = 0.005323536

Training iteration loss = 0.0043331077

Training iteration loss = 0.005696952

Training iteration loss = 0.00572402

Training iteration loss = 0.0043642945

Training iteration loss = 0.004626768

Training iteration loss = 0.0056689666

Training iteration loss = 0.006541397

Training iteration loss = 0.005739229

Training iteration loss = 0.009310649

Training iteration loss = 0.008659972

Training iteration loss = 0.0047615874

Training iteration loss = 0.0056408145

Training iteration loss = 0.0072545274

Training iteration loss = 0.008355602

Training iteration loss = 0.004602859

Training iteration loss = 0.0066841315

Training iteration loss = 0.0056278016

Training iteration loss = 0.00484561

Training iteration loss = 0.004195846

Training iteration loss = 0.0054927305

Training iteration loss = 0.0053835195

Training iteration loss = 0.004170069

Training iteration loss = 0.005124532

Training iteration loss = 0.0035182314

Training iteration loss = 0.0032689737

Training iteration loss = 0.0037801962

Training iteration loss = 0.005089523

Training iteration loss = 0.0036442399

Training iteration loss = 0.0045947167

Training iteration loss = 0.005698632

Training iteration loss = 0.01066321

Training iteration loss = 0.004059238

Training iteration loss = 0.0041508605

Training iteration loss = 0.004429971

Training iteration loss = 0.0051257615

Training iteration loss = 0.0037746208

Training iteration loss = 0.005818521

Training iteration loss = 0.0048658024

Training iteration loss = 0.0068050935

Training iteration loss = 0.0076327757

Training iteration loss = 0.0057022036

Training iteration loss = 0.0030506544

Training iteration loss = 0.0035648781

Training iteration loss = 0.009864905

Training iteration loss = 0.006774731

Training iteration loss = 0.0037935094

Training iteration loss = 0.006976481

Training iteration loss = 0.0049029673

Training iteration loss = 0.00561706

Training iteration loss = 0.005607452

Training iteration loss = 0.006462963

Training iteration loss = 0.003978804

Training iteration loss = 0.010704939

Training iteration loss = 0.004717819

Training iteration loss = 0.0051859966

Training iteration loss = 0.0060970825

Training iteration loss = 0.00423642

Training iteration loss = 0.0038114106

Training iteration loss = 0.0039483686

Training iteration loss = 0.0042209947

Training iteration loss = 0.004947347

Training iteration loss = 0.0050731525

Training iteration loss = 0.0059182704

Training iteration loss = 0.004639339

Training iteration loss = 0.004712101

Training iteration loss = 0.0034506675

Training iteration loss = 0.004095567

Training iteration loss = 0.0040234015

Training iteration loss = 0.0043406417

Training iteration loss = 0.008807392

Training iteration loss = 0.0037240386

Training iteration loss = 0.0041378355

Training iteration loss = 0.004676038

Training iteration loss = 0.0066619627

Training iteration loss = 0.0046870676

Training iteration loss = 0.00511159

Training iteration loss = 0.0041925986

Training iteration loss = 0.0029936254

Training iteration loss = 0.0077704736

Training iteration loss = 0.004572728

Training iteration loss = 0.0043074326

Training iteration loss = 0.0041961535

Training iteration loss = 0.0048364974

Training iteration loss = 0.005705867

Training iteration loss = 0.0062630256

Training iteration loss = 0.0051984345

Training iteration loss = 0.0066174474

Training iteration loss = 0.0051026284

Training iteration loss = 0.0043213763

Training iteration loss = 0.0032308854

Training iteration loss = 0.0037920775

Training iteration loss = 0.003787405

Training iteration loss = 0.0059961877

Training iteration loss = 0.0029668903

Training iteration loss = 0.003875263

Training iteration loss = 0.0051452494

Training iteration loss = 0.0047805533

Training iteration loss = 0.004977037

Training iteration loss = 0.0042261914

Training iteration loss = 0.0060651735

Training iteration loss = 0.0058741258

Training iteration loss = 0.007583519

Training iteration loss = 0.0042977543

Training iteration loss = 0.0048026727

Training iteration loss = 0.0041266787

Training iteration loss = 0.0059408597

Training iteration loss = 0.004993979

Training iteration loss = 0.0059785913

Training iteration loss = 0.004709931

Training iteration loss = 0.004201947

Training iteration loss = 0.0050811446

Training iteration loss = 0.007195337

Training iteration loss = 0.004920086

Training iteration loss = 0.0054084654

Training iteration loss = 0.005322577

Training iteration loss = 0.005640656

Training iteration loss = 0.004770662

Training iteration loss = 0.007110448

Training iteration loss = 0.0054712705

Training iteration loss = 0.004696371

Training iteration loss = 0.004948838

Training iteration loss = 0.0044805766

Training iteration loss = 0.0037638403

Training iteration loss = 0.006099433

Training iteration loss = 0.0084696645

Training iteration loss = 0.005760802

Training iteration loss = 0.0055613634

Training iteration loss = 0.0033234023

Training iteration loss = 0.0071685165

Training iteration loss = 0.008586823

Training iteration loss = 0.004616632

Training iteration loss = 0.005620017

Training iteration loss = 0.004479739

Training iteration loss = 0.00520502

Training iteration loss = 0.0050275414

Training iteration loss = 0.004767341

Training iteration loss = 0.0075678085

Training iteration loss = 0.0103550255

Training iteration loss = 0.003442132

Training iteration loss = 0.0051005757

Training iteration loss = 0.003967209

Training iteration loss = 0.004790652

Training iteration loss = 0.0062552937

Training iteration loss = 0.0047579734

Training iteration loss = 0.0058670994

Training iteration loss = 0.0034482314

Training iteration loss = 0.006469741

Training iteration loss = 0.010586883

Training iteration loss = 0.006648633

Training iteration loss = 0.0056138653

Training iteration loss = 0.004968545

Training iteration loss = 0.005871585

Training iteration loss = 0.003982863

Training iteration loss = 0.005096429

Training iteration loss = 0.0041169515

Training iteration loss = 0.004140056

Training iteration loss = 0.0042835358

Training iteration loss = 0.0067757354

Training iteration loss = 0.004479956

Training iteration loss = 0.006205365

Training iteration loss = 0.005191384

Training iteration loss = 0.0073314407

Training iteration loss = 0.0045199064

Training iteration loss = 0.004986811

Training iteration loss = 0.0049219276

Training iteration loss = 0.010009977

Training iteration loss = 0.008410355

Training iteration loss = 0.0050116684

Training iteration loss = 0.003929499

Training iteration loss = 0.0083226655

Training iteration loss = 0.0040733726

Training iteration loss = 0.0032593918

Training iteration loss = 0.0037368704

Training iteration loss = 0.0049697277

Training iteration loss = 0.004428853

Training iteration loss = 0.006204313

Training iteration loss = 0.0049356506

Training iteration loss = 0.0035592054

Training iteration loss = 0.0055716424

Training iteration loss = 0.0034758055

Training iteration loss = 0.004428162

Training iteration loss = 0.0036064128

Training iteration loss = 0.004075828

Training iteration loss = 0.005011792

Training iteration loss = 0.0055929977

Training iteration loss = 0.007308535

Training iteration loss = 0.005721785

Training iteration loss = 0.0066764182

Training iteration loss = 0.0030932624

Training iteration loss = 0.0053110425

Training iteration loss = 0.0038117033

Training iteration loss = 0.0087733045

Training iteration loss = 0.0060031726

Training iteration loss = 0.0043785633

Training iteration loss = 0.004020497

Training iteration loss = 0.005509451

Training iteration loss = 0.011750989

Training iteration loss = 0.0039567016

Training iteration loss = 0.005305408

Training iteration loss = 0.0048083053

Training iteration loss = 0.0037830358

Training iteration loss = 0.005291806

Training iteration loss = 0.005430793

Training iteration loss = 0.004073327

Training iteration loss = 0.004100115

Training iteration loss = 0.0052889474

Training iteration loss = 0.005951286

Training iteration loss = 0.005067972

Training iteration loss = 0.0086375745

Training iteration loss = 0.008212225

Training iteration loss = 0.004265909

Training iteration loss = 0.005223671

Training iteration loss = 0.006754949

Training iteration loss = 0.007668761

Training iteration loss = 0.0042395154

Training iteration loss = 0.0061450433

Training iteration loss = 0.0052317414

Training iteration loss = 0.0043513393

Training iteration loss = 0.0037813412

Training iteration loss = 0.0051585785

Training iteration loss = 0.004858105

Training iteration loss = 0.0036332149

Training iteration loss = 0.0046773874

Training iteration loss = 0.0030787995

Training iteration loss = 0.0028856702

Training iteration loss = 0.0031867325

Training iteration loss = 0.004658683

Training iteration loss = 0.0031450142

Training iteration loss = 0.004054554

Training iteration loss = 0.005482512

Training iteration loss = 0.010233529

Training iteration loss = 0.0038347915

Training iteration loss = 0.003796498

Training iteration loss = 0.0038775206

Training iteration loss = 0.004696057

Training iteration loss = 0.0033436697

Training iteration loss = 0.0056694094

Training iteration loss = 0.0044319727

Training iteration loss = 0.006403284

Training iteration loss = 0.00731179

Training iteration loss = 0.005272919

Training iteration loss = 0.0027649896

Training iteration loss = 0.0032128182

Training iteration loss = 0.00941418

Training iteration loss = 0.006036813

Training iteration loss = 0.003337293

Training iteration loss = 0.006334483

Training iteration loss = 0.004631778

Training iteration loss = 0.00499272

Training iteration loss = 0.005136332

Training iteration loss = 0.0059019937

Training iteration loss = 0.0035869505

Training iteration loss = 0.009948634

Training iteration loss = 0.0043297154

Training iteration loss = 0.004790678

Training iteration loss = 0.0057743513

Training iteration loss = 0.0037622887

Training iteration loss = 0.0034714255

Training iteration loss = 0.0034585006

Training iteration loss = 0.0036988163

Training iteration loss = 0.0046602082

Training iteration loss = 0.0046402924

Training iteration loss = 0.0053738444

Training iteration loss = 0.004221355

Training iteration loss = 0.004545115

Training iteration loss = 0.0031340262

Training iteration loss = 0.003449711

Training iteration loss = 0.003642875

Training iteration loss = 0.0039591794

Training iteration loss = 0.0081358235

Training iteration loss = 0.0031679505

Training iteration loss = 0.0037684466

Training iteration loss = 0.0041814237

Training iteration loss = 0.0061117127

Training iteration loss = 0.0042925375

Training iteration loss = 0.0044974685

Training iteration loss = 0.0038200654

Training iteration loss = 0.0025738503

Training iteration loss = 0.0072852634

Training iteration loss = 0.004115281

Training iteration loss = 0.0038939377

Training iteration loss = 0.00369393

Training iteration loss = 0.004302737

Training iteration loss = 0.0053195707

Training iteration loss = 0.0056548435

Training iteration loss = 0.0044197123

Training iteration loss = 0.0060028653

Training iteration loss = 0.004661858

Training iteration loss = 0.0038285174

Training iteration loss = 0.0028498091

Training iteration loss = 0.0033713423

Training iteration loss = 0.0031312667

Training iteration loss = 0.005444203

Training iteration loss = 0.002579967

Training iteration loss = 0.0034114018

Training iteration loss = 0.0047800634

Training iteration loss = 0.004194032

Training iteration loss = 0.0044609136

Training iteration loss = 0.0037488192

Training iteration loss = 0.0055791344

Training iteration loss = 0.0055244863

Training iteration loss = 0.0067654797

Training iteration loss = 0.0037968075

Training iteration loss = 0.004193405

Training iteration loss = 0.0036874723

Training iteration loss = 0.0054025277

Training iteration loss = 0.0045427033

Training iteration loss = 0.0055721737

Training iteration loss = 0.004342258

Training iteration loss = 0.003827027

Training iteration loss = 0.004754769

Training iteration loss = 0.0068066097

Training iteration loss = 0.004576269

Training iteration loss = 0.0047951913

Training iteration loss = 0.0048117037

Training iteration loss = 0.005046294

Training iteration loss = 0.004226169

Training iteration loss = 0.00669194

Training iteration loss = 0.0051843715

Training iteration loss = 0.004264415

Training iteration loss = 0.004510263

Training iteration loss = 0.003989984

Training iteration loss = 0.0033140006

Training iteration loss = 0.0059796553

Training iteration loss = 0.007790481

Training iteration loss = 0.005166855

Training iteration loss = 0.0050567393

Training iteration loss = 0.0030988737

Training iteration loss = 0.006766721

Training iteration loss = 0.007867734

Training iteration loss = 0.0042123487

Training iteration loss = 0.005389163

Training iteration loss = 0.004093696

Training iteration loss = 0.004545733

Training iteration loss = 0.004661396

Training iteration loss = 0.0043531065

Training iteration loss = 0.007086067

Training iteration loss = 0.009793526

Training iteration loss = 0.0031462729

Training iteration loss = 0.004683812

Training iteration loss = 0.0036198106

Training iteration loss = 0.004216039

Training iteration loss = 0.0058535277

Training iteration loss = 0.004327147

Training iteration loss = 0.005647531

Training iteration loss = 0.0031564673

Training iteration loss = 0.006025938

Training iteration loss = 0.010222293

Training iteration loss = 0.006303882

Training iteration loss = 0.0053394944

Training iteration loss = 0.0044926624

Training iteration loss = 0.0054005943

Training iteration loss = 0.0035999853

Training iteration loss = 0.0048295707

Training iteration loss = 0.0036228553

Training iteration loss = 0.0037580945

Training iteration loss = 0.0038364169

Training iteration loss = 0.006176295

Training iteration loss = 0.0040815156

Training iteration loss = 0.0058552534

Training iteration loss = 0.0047980584

Training iteration loss = 0.0070060515

Training iteration loss = 0.004148754

Training iteration loss = 0.0044795168

Training iteration loss = 0.0044218316

Training iteration loss = 0.009636168

Training iteration loss = 0.008034894

Training iteration loss = 0.0045866678

Training iteration loss = 0.0035729

Training iteration loss = 0.007837135

Training iteration loss = 0.003631102

Training iteration loss = 0.0030687032

Training iteration loss = 0.0035291065

Training iteration loss = 0.004815051

Training iteration loss = 0.0042193807

Training iteration loss = 0.005828517

Training iteration loss = 0.0046262564

Training iteration loss = 0.0033647653

Training iteration loss = 0.0051105414

Training iteration loss = 0.0032011718

Training iteration loss = 0.003864872

Training iteration loss = 0.003259444

Training iteration loss = 0.003618887

Training iteration loss = 0.004872497

Training iteration loss = 0.005506199

Training iteration loss = 0.0068396046

Training iteration loss = 0.005274529

Training iteration loss = 0.0063950513

Training iteration loss = 0.0028778918

Training iteration loss = 0.0048635593

Training iteration loss = 0.0035388658

Training iteration loss = 0.008460857

Training iteration loss = 0.0054905065

Training iteration loss = 0.004273272

Training iteration loss = 0.0037321374

Training iteration loss = 0.005119428

Training iteration loss = 0.011298996

Training iteration loss = 0.0035679415

Training iteration loss = 0.0049395775

Training iteration loss = 0.0045550535

Training iteration loss = 0.0035003575

Training iteration loss = 0.004995151

Training iteration loss = 0.005173758

Training iteration loss = 0.0038605777

Training iteration loss = 0.0037018394

Training iteration loss = 0.004981693

Training iteration loss = 0.005452864

Training iteration loss = 0.0048087654

Training iteration loss = 0.008145581

Training iteration loss = 0.007819322

Training iteration loss = 0.0039482363

Training iteration loss = 0.0048956634

Training iteration loss = 0.0064755124

Training iteration loss = 0.007225364

Training iteration loss = 0.0039595836

Training iteration loss = 0.005644784

Training iteration loss = 0.0050502545

Training iteration loss = 0.0040437956

Training iteration loss = 0.003475859

Training iteration loss = 0.0048769373

Training iteration loss = 0.004419698

Training iteration loss = 0.003321761

Training iteration loss = 0.004410283

Training iteration loss = 0.00285007

Training iteration loss = 0.0026574172

Training iteration loss = 0.0029341222

Training iteration loss = 0.004425856

Training iteration loss = 0.0029142138

Training iteration loss = 0.0038146165

Training iteration loss = 0.0052457233

Training iteration loss = 0.009812817

Training iteration loss = 0.0035876308

Training iteration loss = 0.00352043

Training iteration loss = 0.0035976134

Training iteration loss = 0.004592356

Training iteration loss = 0.0030234654

Training iteration loss = 0.005542224

Training iteration loss = 0.0042313705

Training iteration loss = 0.006141512

Training iteration loss = 0.0069514825

Training iteration loss = 0.0049325405

Training iteration loss = 0.0026263094

Training iteration loss = 0.0029995677

Training iteration loss = 0.009214635

Training iteration loss = 0.0055477344

Training iteration loss = 0.0029739672

Training iteration loss = 0.0059584915

Training iteration loss = 0.0044242707

Training iteration loss = 0.0046436517

Training iteration loss = 0.0049536363

Training iteration loss = 0.005536772

Training iteration loss = 0.0033286635

Training iteration loss = 0.009475241

Training iteration loss = 0.0039996607

Training iteration loss = 0.004528791

Training iteration loss = 0.0054260287

Training iteration loss = 0.0034739103

Training iteration loss = 0.0032058458

Training iteration loss = 0.003261478

Training iteration loss = 0.0034451124

Training iteration loss = 0.004463256

Training iteration loss = 0.004436254

Training iteration loss = 0.005117601

Training iteration loss = 0.0039070826

Training iteration loss = 0.004372299

Training iteration loss = 0.0029403428

Training iteration loss = 0.0032110338

Training iteration loss = 0.0034666061

Training iteration loss = 0.003796647

Training iteration loss = 0.0076422854

Training iteration loss = 0.0028748016

Training iteration loss = 0.0034502698

Training iteration loss = 0.0039238925

Training iteration loss = 0.005728031

Training iteration loss = 0.0039981487

Training iteration loss = 0.0042219996

Training iteration loss = 0.0035945906

Training iteration loss = 0.0023483

Training iteration loss = 0.0070675947

Training iteration loss = 0.0038942012

Training iteration loss = 0.0036739334

Training iteration loss = 0.0033228945

Training iteration loss = 0.00401859

Training iteration loss = 0.0050547305

Training iteration loss = 0.0052410737

Training iteration loss = 0.003948107

Training iteration loss = 0.005633256

Training iteration loss = 0.0043116747

Training iteration loss = 0.0035001289

Training iteration loss = 0.002618298

Training iteration loss = 0.00308247

Training iteration loss = 0.002835313

Training iteration loss = 0.0052137002

Training iteration loss = 0.0024022234

Training iteration loss = 0.003114865

Training iteration loss = 0.0045188502

Training iteration loss = 0.003903935

Training iteration loss = 0.004362623

Training iteration loss = 0.0035691045

Training iteration loss = 0.0053065424

Training iteration loss = 0.0053147282

Training iteration loss = 0.0063585006

Training iteration loss = 0.0034305982

Training iteration loss = 0.0038832815

Training iteration loss = 0.0035298925

Training iteration loss = 0.0050016916

Training iteration loss = 0.0043039573

Training iteration loss = 0.0053408244

Training iteration loss = 0.0040352885

Training iteration loss = 0.0035020069

Training iteration loss = 0.0045330217

Training iteration loss = 0.006580228

Training iteration loss = 0.004350916

Training iteration loss = 0.004548076

Training iteration loss = 0.0044994936

Training iteration loss = 0.004676829

Training iteration loss = 0.003899483

Training iteration loss = 0.0062642046

Training iteration loss = 0.0049607325

Training iteration loss = 0.0039883866

Training iteration loss = 0.004257607

Training iteration loss = 0.0038411692

Training iteration loss = 0.0031112593

Training iteration loss = 0.005860997

Training iteration loss = 0.0072954595

Training iteration loss = 0.0048967265

Training iteration loss = 0.004774636

Training iteration loss = 0.0028393313

Training iteration loss = 0.006487545

Training iteration loss = 0.007405568

Training iteration loss = 0.004107773

Training iteration loss = 0.005175379

Training iteration loss = 0.003950507

Training iteration loss = 0.0041390867

Training iteration loss = 0.004374743

Training iteration loss = 0.004088009

Training iteration loss = 0.0067187673

Training iteration loss = 0.009362248

Training iteration loss = 0.0030041656

Training iteration loss = 0.004394955

Training iteration loss = 0.0033590486

Training iteration loss = 0.0038292746

Training iteration loss = 0.0055447095

Training iteration loss = 0.004131972

Training iteration loss = 0.0052962936

Training iteration loss = 0.0029894577

Training iteration loss = 0.005721064

Training iteration loss = 0.0099404985

Training iteration loss = 0.0061246506

Training iteration loss = 0.005140994

Training iteration loss = 0.004162342

Training iteration loss = 0.005110134

Training iteration loss = 0.0033636084

Training iteration loss = 0.0046435464

Training iteration loss = 0.0033270882

Training iteration loss = 0.0034611912

Training iteration loss = 0.0035833865

Training iteration loss = 0.005841547

Training iteration loss = 0.0037879283

Training iteration loss = 0.005627289

Training iteration loss = 0.0045628934

Training iteration loss = 0.006690351

Training iteration loss = 0.003950953

Training iteration loss = 0.004095559

Training iteration loss = 0.0041110683

Training iteration loss = 0.0092019485

Training iteration loss = 0.0076355874

Training iteration loss = 0.0042847297

Training iteration loss = 0.0033408322

Training iteration loss = 0.007476658

Training iteration loss = 0.0034238936

Training iteration loss = 0.0029439507

Training iteration loss = 0.0034219178

Training iteration loss = 0.004560027

Training iteration loss = 0.0039865784

Training iteration loss = 0.0055618645

Training iteration loss = 0.004455599

Training iteration loss = 0.0032101965

Training iteration loss = 0.0047454806

Training iteration loss = 0.0029529498

Training iteration loss = 0.003490351

Training iteration loss = 0.0031989024

Training iteration loss = 0.0034773636

Training iteration loss = 0.0046822303

Training iteration loss = 0.005196705

Training iteration loss = 0.0063844416

Training iteration loss = 0.0050290306

Training iteration loss = 0.006247332

Training iteration loss = 0.0027583176

Training iteration loss = 0.0045005563

Training iteration loss = 0.0033628577

Training iteration loss = 0.008265256

Training iteration loss = 0.0052077062

Training iteration loss = 0.0041454677

Training iteration loss = 0.0034553055

Training iteration loss = 0.0048680287

Training iteration loss = 0.010840184

Training iteration loss = 0.0033976396

Training iteration loss = 0.004686371

Training iteration loss = 0.0044537596

Training iteration loss = 0.0033221515

Training iteration loss = 0.0048085656

Training iteration loss = 0.0049403124

Training iteration loss = 0.0035793458

Training iteration loss = 0.003445728

Training iteration loss = 0.004631815

Training iteration loss = 0.0052522556

Training iteration loss = 0.0045978497

Training iteration loss = 0.0077777454

Training iteration loss = 0.0074344296

Training iteration loss = 0.003713808

Training iteration loss = 0.004616029

Training iteration loss = 0.0062857135

Training iteration loss = 0.006910631

Training iteration loss = 0.0037966808

Training iteration loss = 0.005238667

Training iteration loss = 0.0048083854

Training iteration loss = 0.0037875094

Training iteration loss = 0.003235683

Training iteration loss = 0.004665801

Training iteration loss = 0.0040873447

Training iteration loss = 0.0031463408

Training iteration loss = 0.004217187

Training iteration loss = 0.0027650434

Training iteration loss = 0.0024827116

Training iteration loss = 0.002786415

Training iteration loss = 0.0041939714

Training iteration loss = 0.0027846228

Training iteration loss = 0.0035961622

Training iteration loss = 0.004969987

Training iteration loss = 0.00925724

Training iteration loss = 0.0033530642

Training iteration loss = 0.0033659514

Training iteration loss = 0.0033806749

Training iteration loss = 0.0043629035

Training iteration loss = 0.002853821

Training iteration loss = 0.0052692206

Training iteration loss = 0.0039945734

Training iteration loss = 0.0058556623

Training iteration loss = 0.0066027227

Training iteration loss = 0.004647512

Training iteration loss = 0.002518528

Training iteration loss = 0.0027941603

Training iteration loss = 0.008985174

Training iteration loss = 0.0051059998

Training iteration loss = 0.0025537931

Training iteration loss = 0.0056295176

Training iteration loss = 0.0042155925

Training iteration loss = 0.004361801

Training iteration loss = 0.00477602

Training iteration loss = 0.0052376944

Training iteration loss = 0.003094659

Training iteration loss = 0.009112292

Training iteration loss = 0.0037034063

Training iteration loss = 0.0042796643

Training iteration loss = 0.0050714053

Training iteration loss = 0.0032606681

Training iteration loss = 0.002960025

Training iteration loss = 0.0030620312

Training iteration loss = 0.003129266

Training iteration loss = 0.004248692

Training iteration loss = 0.004194763

Training iteration loss = 0.004825942

Training iteration loss = 0.003657888

Training iteration loss = 0.0041283704

Training iteration loss = 0.0027933707

Training iteration loss = 0.0030080017

Training iteration loss = 0.0032294216

Training iteration loss = 0.0036161935

Training iteration loss = 0.007190749

Training iteration loss = 0.0026521657

Training iteration loss = 0.0032828033

Training iteration loss = 0.0037448232

Training iteration loss = 0.0053951335

Training iteration loss = 0.0037331544

Training iteration loss = 0.0039433176

Training iteration loss = 0.003402122

Training iteration loss = 0.0022528928

Training iteration loss = 0.006974431

Training iteration loss = 0.003661125

Training iteration loss = 0.0033825694

Training iteration loss = 0.0029792238

Training iteration loss = 0.0039018097

Training iteration loss = 0.004786654

Training iteration loss = 0.004947905

Training iteration loss = 0.0036146145

Training iteration loss = 0.0054499595

Training iteration loss = 0.0040174513

Training iteration loss = 0.0032361865

Training iteration loss = 0.002436931

Training iteration loss = 0.0029038654

Training iteration loss = 0.0026433077

Training iteration loss = 0.0050274404

Training iteration loss = 0.0022556249

Training iteration loss = 0.00281976

Training iteration loss = 0.004248803

Training iteration loss = 0.0037151296

Training iteration loss = 0.004227294

Training iteration loss = 0.003407224

Training iteration loss = 0.0050645643

Training iteration loss = 0.0050657582

Training iteration loss = 0.005954653

Training iteration loss = 0.0031074092

Training iteration loss = 0.0037048429

Training iteration loss = 0.0033278188

Training iteration loss = 0.004697476

Training iteration loss = 0.0040707807

Training iteration loss = 0.005195469

Training iteration loss = 0.00379835

Training iteration loss = 0.003237446

Training iteration loss = 0.0042668716

Training iteration loss = 0.0063296203

Training iteration loss = 0.0041480823

Training iteration loss = 0.0041996003

Training iteration loss = 0.004223203

Training iteration loss = 0.0043489183

Training iteration loss = 0.0035986735

Training iteration loss = 0.005678091

Training iteration loss = 0.0046294555

Training iteration loss = 0.0037693752

Training iteration loss = 0.0039556823

Training iteration loss = 0.0036708114

Training iteration loss = 0.0028807416

Training iteration loss = 0.0055919555

Training iteration loss = 0.006601056

Training iteration loss = 0.004714111

Training iteration loss = 0.004493524

Training iteration loss = 0.002576326

Training iteration loss = 0.00611596

Training iteration loss = 0.0069268844

Training iteration loss = 0.0038569793

Training iteration loss = 0.004836842

Training iteration loss = 0.00367989

Training iteration loss = 0.0037835715

Training iteration loss = 0.004033012

Training iteration loss = 0.003808164

Training iteration loss = 0.00632274

Training iteration loss = 0.008876608

Training iteration loss = 0.0028857419

Training iteration loss = 0.004028589

Training iteration loss = 0.0029777882

Training iteration loss = 0.0035037566

Training iteration loss = 0.005141602

Training iteration loss = 0.0038683778

Training iteration loss = 0.004877385

Training iteration loss = 0.002791031

Training iteration loss = 0.0052943374

Training iteration loss = 0.009562883

Training iteration loss = 0.0057748794

Training iteration loss = 0.004898379

Training iteration loss = 0.0038691054

Training iteration loss = 0.0046521304

Training iteration loss = 0.0031675193

Training iteration loss = 0.0043630083

Training iteration loss = 0.0030789261

Training iteration loss = 0.0031795676

Training iteration loss = 0.003397565

Training iteration loss = 0.005493605

Training iteration loss = 0.0035030553

Training iteration loss = 0.0053357263

Training iteration loss = 0.004262148

Training iteration loss = 0.0062518087

Training iteration loss = 0.0037715072

Training iteration loss = 0.0037508693

Training iteration loss = 0.003825944

Training iteration loss = 0.008692377

Training iteration loss = 0.007033804

Training iteration loss = 0.003980424

Training iteration loss = 0.0031980232

Training iteration loss = 0.007028151

Training iteration loss = 0.0031303086

Training iteration loss = 0.002749719

Training iteration loss = 0.0032404184

Training iteration loss = 0.004258756

Training iteration loss = 0.0037206085

Training iteration loss = 0.0051578972

Training iteration loss = 0.004149212

Training iteration loss = 0.0029291415

Training iteration loss = 0.0043198224

Training iteration loss = 0.0026924752

Training iteration loss = 0.0032355143

Training iteration loss = 0.002976817

Training iteration loss = 0.0033115689

Training iteration loss = 0.0043728254

Training iteration loss = 0.004754162

Training iteration loss = 0.0059288

Training iteration loss = 0.004615109

Training iteration loss = 0.005836628

Training iteration loss = 0.00263033

Training iteration loss = 0.0041420893

Training iteration loss = 0.00322231

Training iteration loss = 0.007839665

Training iteration loss = 0.004824924

Training iteration loss = 0.0037502355

Training iteration loss = 0.0032255866

Training iteration loss = 0.0045706932

Training iteration loss = 0.010233403

Training iteration loss = 0.0030493683

Training iteration loss = 0.004410128

Training iteration loss = 0.0042963703

Training iteration loss = 0.003102324

Training iteration loss = 0.0044964165

Training iteration loss = 0.0045743645

Training iteration loss = 0.0032587333

Training iteration loss = 0.0031965815

Training iteration loss = 0.004263378

Training iteration loss = 0.00489817

Training iteration loss = 0.004397943

Training iteration loss = 0.0072538294

Training iteration loss = 0.007012811

Training iteration loss = 0.0035274504

Training iteration loss = 0.0043325615

Training iteration loss = 0.0061692647

Training iteration loss = 0.0065306653

Training iteration loss = 0.0035402626

Training iteration loss = 0.0048491512

Training iteration loss = 0.004576431

Training iteration loss = 0.003400578

Training iteration loss = 0.0028789842

Training iteration loss = 0.004445282

Training iteration loss = 0.003673171

Training iteration loss = 0.0029988813

Training iteration loss = 0.0039981664

Training iteration loss = 0.0027100847

Training iteration loss = 0.0023444435

Training iteration loss = 0.002580912

Training iteration loss = 0.004009797

Training iteration loss = 0.0026446052

Training iteration loss = 0.0032824874

Training iteration loss = 0.004740727

Training iteration loss = 0.008532714

Training iteration loss = 0.0031124195

Training iteration loss = 0.0031854836

Training iteration loss = 0.0030832633

Training iteration loss = 0.004004115

Training iteration loss = 0.0027949836

Training iteration loss = 0.004889375

Training iteration loss = 0.003683924

Training iteration loss = 0.0055796006

Training iteration loss = 0.0061002984

Training iteration loss = 0.0042460538

Training iteration loss = 0.0023358185

Training iteration loss = 0.00258747

Training iteration loss = 0.008745412

Training iteration loss = 0.004617285

Training iteration loss = 0.002081178

Training iteration loss = 0.0053712106

Training iteration loss = 0.004062423

Training iteration loss = 0.0040617916

Training iteration loss = 0.0043673846

Training iteration loss = 0.0049079168

Training iteration loss = 0.002869877

Training iteration loss = 0.008658878

Training iteration loss = 0.0034199965

Training iteration loss = 0.004059876

Training iteration loss = 0.004821841

Training iteration loss = 0.002919704

Training iteration loss = 0.0027246077

Training iteration loss = 0.0028357531

Training iteration loss = 0.0027900164

Training iteration loss = 0.0040233606

Training iteration loss = 0.0039008216

Training iteration loss = 0.0045470805

Training iteration loss = 0.0035312735

Training iteration loss = 0.0037134085

Training iteration loss = 0.0025362049

Training iteration loss = 0.0026849473

Training iteration loss = 0.0029450543

Training iteration loss = 0.0034001044

Training iteration loss = 0.0066954163

Training iteration loss = 0.0024279354

Training iteration loss = 0.003136702

Training iteration loss = 0.003480985

Training iteration loss = 0.0049865493

Training iteration loss = 0.0034835201

Training iteration loss = 0.0037150895

Training iteration loss = 0.003314582

Training iteration loss = 0.002129779

Training iteration loss = 0.0068222717

Training iteration loss = 0.003470538

Training iteration loss = 0.0030066755

Training iteration loss = 0.0026492632

Training iteration loss = 0.0038002767

Training iteration loss = 0.004422409

Training iteration loss = 0.0046391063

Training iteration loss = 0.0033196665

Training iteration loss = 0.0053255646

Training iteration loss = 0.0037301092

Training iteration loss = 0.0029782492

Training iteration loss = 0.0023184062

Training iteration loss = 0.0027941444

Training iteration loss = 0.0024820557

Training iteration loss = 0.004745267

Training iteration loss = 0.002102414

Training iteration loss = 0.0025087334

Training iteration loss = 0.003969026

Training iteration loss = 0.0035622753

Training iteration loss = 0.00395189

Training iteration loss = 0.0032129197

Training iteration loss = 0.004810161

Training iteration loss = 0.004795561

Training iteration loss = 0.0055848532

Training iteration loss = 0.0027537283

Training iteration loss = 0.0035800394

Training iteration loss = 0.0030756842

Training iteration loss = 0.004377378

Training iteration loss = 0.0038927144

Training iteration loss = 0.0051539796

Training iteration loss = 0.003570145

Training iteration loss = 0.0029769375

Training iteration loss = 0.003998568

Training iteration loss = 0.0060457042

Training iteration loss = 0.0039592325

Training iteration loss = 0.0038550878

Training iteration loss = 0.004016666

Training iteration loss = 0.004104588

Training iteration loss = 0.0033315576

Training iteration loss = 0.0049841334

Training iteration loss = 0.0043955385

Training iteration loss = 0.0035483614

Training iteration loss = 0.0036058456

Training iteration loss = 0.003446615

Training iteration loss = 0.0026894587

Training iteration loss = 0.0053185294

Training iteration loss = 0.005895329

Training iteration loss = 0.004521987

Training iteration loss = 0.0042284015

Training iteration loss = 0.002449276

Training iteration loss = 0.005654423

Training iteration loss = 0.0064232456

Training iteration loss = 0.0035098095

Training iteration loss = 0.0044127833

Training iteration loss = 0.0033835918

Training iteration loss = 0.003434121

Training iteration loss = 0.0036705697

Training iteration loss = 0.0034232643

Training iteration loss = 0.005961575

Training iteration loss = 0.0082347775

Training iteration loss = 0.0028014919

Training iteration loss = 0.003576849

Training iteration loss = 0.00266455

Training iteration loss = 0.003227025

Training iteration loss = 0.0046665794

Training iteration loss = 0.0036174015

Training iteration loss = 0.0045635058

Training iteration loss = 0.0026174495

Training iteration loss = 0.0047662114

Training iteration loss = 0.009108309

Training iteration loss = 0.005452979

Training iteration loss = 0.0046032346

Training iteration loss = 0.003623999

Training iteration loss = 0.0041855453

Training iteration loss = 0.002981182

Training iteration loss = 0.004057239

Training iteration loss = 0.0028428969

Training iteration loss = 0.0030184856

Training iteration loss = 0.0032779872

Training iteration loss = 0.0049993023

Training iteration loss = 0.0031934828

Training iteration loss = 0.0050512725

Training iteration loss = 0.004037784

Training iteration loss = 0.005910861

Training iteration loss = 0.0036203687

Training iteration loss = 0.0034731922

Training iteration loss = 0.0035782394

Training iteration loss = 0.008251427

Training iteration loss = 0.0064332834

Training iteration loss = 0.0037478497

Training iteration loss = 0.0030851883

Training iteration loss = 0.0065016504

Training iteration loss = 0.0028498657

Training iteration loss = 0.002693683

Training iteration loss = 0.003080409

Training iteration loss = 0.0040806034

Training iteration loss = 0.003451567

Training iteration loss = 0.0047571617

Training iteration loss = 0.00399788

Training iteration loss = 0.00271569

Training iteration loss = 0.003946897

Training iteration loss = 0.0024202673

Training iteration loss = 0.0030532533

Training iteration loss = 0.0027320532

Training iteration loss = 0.0033045348

Training iteration loss = 0.004106886

Training iteration loss = 0.004385616

Training iteration loss = 0.0055351406

Training iteration loss = 0.0042163623

Training iteration loss = 0.0054505803

Training iteration loss = 0.002576333

Training iteration loss = 0.0038595737

Training iteration loss = 0.0030254067

Training iteration loss = 0.0072246958

Training iteration loss = 0.0045061647

Training iteration loss = 0.003452342

Training iteration loss = 0.003120925

Training iteration loss = 0.0042475965

Training iteration loss = 0.009594038

Training iteration loss = 0.0027110928

Training iteration loss = 0.0042447345

Training iteration loss = 0.0041592903

Training iteration loss = 0.002805202

Training iteration loss = 0.004215649

Training iteration loss = 0.0042754896

Training iteration loss = 0.0030963586

Training iteration loss = 0.0029279937

Training iteration loss = 0.003917595

Training iteration loss = 0.0044813873

Training iteration loss = 0.0042160414

Training iteration loss = 0.006651511

Training iteration loss = 0.0065773036

Training iteration loss = 0.003399816

Training iteration loss = 0.0041673263

Training iteration loss = 0.0060218293

Training iteration loss = 0.0060471743

Training iteration loss = 0.0033138674

Training iteration loss = 0.004526266

Training iteration loss = 0.0043638614

Training iteration loss = 0.0030416877

Training iteration loss = 0.0025879585

Training iteration loss = 0.0042854887

Training iteration loss = 0.0032969248

Training iteration loss = 0.0028042018

Training iteration loss = 0.0037282754

Training iteration loss = 0.002620862

Training iteration loss = 0.0022667053

Training iteration loss = 0.0023382045

Training iteration loss = 0.003866368

Training iteration loss = 0.0024466785

Training iteration loss = 0.0029544604

Training iteration loss = 0.004500454

Training iteration loss = 0.007870932

Training iteration loss = 0.0029474671

Training iteration loss = 0.0030504772

Training iteration loss = 0.0027947351

Training iteration loss = 0.0036778226

Training iteration loss = 0.002739735

Training iteration loss = 0.0046399212

Training iteration loss = 0.003453456

Training iteration loss = 0.005380904

Training iteration loss = 0.005582852

Training iteration loss = 0.0039257687

Training iteration loss = 0.0021985353

Training iteration loss = 0.002432002

Training iteration loss = 0.008657234

Training iteration loss = 0.004224867

Training iteration loss = 0.0017615333

Training iteration loss = 0.0052100793

Training iteration loss = 0.0040448178

Training iteration loss = 0.00388447

Training iteration loss = 0.003768104

Training iteration loss = 0.0045991405

Training iteration loss = 0.0026546658

Training iteration loss = 0.008143303

Training iteration loss = 0.003229877

Training iteration loss = 0.0038765839

Training iteration loss = 0.004593305

Training iteration loss = 0.002583138

Training iteration loss = 0.0025431775

Training iteration loss = 0.0027357328

Training iteration loss = 0.0025467149

Training iteration loss = 0.003849689

Training iteration loss = 0.003666967

Training iteration loss = 0.0043488215

Training iteration loss = 0.0035099213

Training iteration loss = 0.0033422762

Training iteration loss = 0.0023944648

Training iteration loss = 0.0025036565

Training iteration loss = 0.0027319056

Training iteration loss = 0.0032252362

Training iteration loss = 0.006339083

Training iteration loss = 0.002250314

Training iteration loss = 0.0030214507

Training iteration loss = 0.0033036105

Training iteration loss = 0.004612

Training iteration loss = 0.0032961126

Training iteration loss = 0.0036245391

Training iteration loss = 0.0032344481

Training iteration loss = 0.0020132004

Training iteration loss = 0.0067121745

Training iteration loss = 0.0033986114

Training iteration loss = 0.002757923

Training iteration loss = 0.0023507606

Training iteration loss = 0.003732376

Training iteration loss = 0.004103806

Training iteration loss = 0.0044294377

Training iteration loss = 0.0031271456

Training iteration loss = 0.005354813

Training iteration loss = 0.0035642453

Training iteration loss = 0.0028341739

Training iteration loss = 0.0022180018

Training iteration loss = 0.0027086653

Training iteration loss = 0.002327035

Training iteration loss = 0.004399215

Training iteration loss = 0.0019989414

Training iteration loss = 0.0023328653

Training iteration loss = 0.0038288475

Training iteration loss = 0.0034126912

Training iteration loss = 0.0036457425

Training iteration loss = 0.003007969

Training iteration loss = 0.0046488843

Training iteration loss = 0.004594926

Training iteration loss = 0.005306561

Training iteration loss = 0.0024828545

Training iteration loss = 0.0034421927

Training iteration loss = 0.0028518785

Training iteration loss = 0.004136325

Training iteration loss = 0.0037738455

Training iteration loss = 0.0051217284

Training iteration loss = 0.0033842644

Training iteration loss = 0.002773009

Training iteration loss = 0.0038182198

Training iteration loss = 0.0057408195

Training iteration loss = 0.0037736604

Training iteration loss = 0.0035941873

Training iteration loss = 0.003933665

Training iteration loss = 0.0039959713

Training iteration loss = 0.0031026916

Training iteration loss = 0.0043696105

Training iteration loss = 0.0042300653

Training iteration loss = 0.0033866286

Training iteration loss = 0.0034272652

Training iteration loss = 0.0032921962

Training iteration loss = 0.002553818

Training iteration loss = 0.0050952104

Training iteration loss = 0.0053835106

Training iteration loss = 0.004413321

Training iteration loss = 0.0039932844

Training iteration loss = 0.0024346216

Training iteration loss = 0.00535368

Training iteration loss = 0.006160803

Training iteration loss = 0.0032163549

Training iteration loss = 0.0039827838

Training iteration loss = 0.0031298154

Training iteration loss = 0.0031937214

Training iteration loss = 0.0033609113

Training iteration loss = 0.0031298066

Training iteration loss = 0.0057751504

Training iteration loss = 0.007666726

Training iteration loss = 0.0027492766

Training iteration loss = 0.0032505675

Training iteration loss = 0.0024786813

Training iteration loss = 0.0030470148

Training iteration loss = 0.0043114745

Training iteration loss = 0.0034801734

Training iteration loss = 0.0044218632

Training iteration loss = 0.002533946

Training iteration loss = 0.00438772

Training iteration loss = 0.008678149

Training iteration loss = 0.005261691

Training iteration loss = 0.0043879673

Training iteration loss = 0.0034582308

Training iteration loss = 0.0039824406

Training iteration loss = 0.0028451227

Training iteration loss = 0.0038530193

Training iteration loss = 0.0026137717

Training iteration loss = 0.002912093

Training iteration loss = 0.0031692665

Training iteration loss = 0.004543284

Training iteration loss = 0.0028690055

Training iteration loss = 0.0048525804

Training iteration loss = 0.0039024763

Training iteration loss = 0.0057339747

Training iteration loss = 0.003511994

Training iteration loss = 0.0033582815

Training iteration loss = 0.0034795816

Training iteration loss = 0.007970224

Training iteration loss = 0.005958898

Training iteration loss = 0.0035787392

Training iteration loss = 0.0029300803

Training iteration loss = 0.006118346

Training iteration loss = 0.0026780488

Training iteration loss = 0.0026499163

Training iteration loss = 0.002957788

Training iteration loss = 0.0039085443

Training iteration loss = 0.003309138

Training iteration loss = 0.0045028497

Training iteration loss = 0.0040012593

Training iteration loss = 0.0024941585

Training iteration loss = 0.0035948313

Training iteration loss = 0.0021863952

Training iteration loss = 0.0029836104

Training iteration loss = 0.0025768403

Training iteration loss = 0.0032924728

Training iteration loss = 0.0039004155

Training iteration loss = 0.0040948237

Training iteration loss = 0.005275557

Training iteration loss = 0.0040906514

Training iteration loss = 0.0052151107

Training iteration loss = 0.0025228916

Training iteration loss = 0.0036471179

Training iteration loss = 0.0028120785

Training iteration loss = 0.0068607335

Training iteration loss = 0.004299159

Training iteration loss = 0.0032814394

Training iteration loss = 0.0030246654

Training iteration loss = 0.0040004672

Training iteration loss = 0.009148843

Training iteration loss = 0.0025653054

Training iteration loss = 0.004140396

Training iteration loss = 0.004049378

Training iteration loss = 0.0026458728

Training iteration loss = 0.0040818998

Training iteration loss = 0.004093792

Training iteration loss = 0.0030103999

Training iteration loss = 0.0027706437

Training iteration loss = 0.0037612377

Training iteration loss = 0.004289975

Training iteration loss = 0.0040528947

Training iteration loss = 0.006103148

Training iteration loss = 0.0062517785

Training iteration loss = 0.0033435535

Training iteration loss = 0.0040951236

Training iteration loss = 0.00584683

Training iteration loss = 0.0056923237

Training iteration loss = 0.0032283983

Training iteration loss = 0.0043281335

Training iteration loss = 0.004242327

Training iteration loss = 0.0028753665

Training iteration loss = 0.002459699

Training iteration loss = 0.004116429

Training iteration loss = 0.003021608

Training iteration loss = 0.0027181115

Training iteration loss = 0.0036029108

Training iteration loss = 0.0025547722

Training iteration loss = 0.0021864332

Training iteration loss = 0.002186258

Training iteration loss = 0.00373739

Training iteration loss = 0.002306042

Training iteration loss = 0.0027561358

Training iteration loss = 0.004381433

Training iteration loss = 0.00730823

Training iteration loss = 0.0028266667

Training iteration loss = 0.0029563552

Training iteration loss = 0.0026276552

Training iteration loss = 0.0034491923

Training iteration loss = 0.0026564302

Training iteration loss = 0.0045081405

Training iteration loss = 0.0033487817

Training iteration loss = 0.005287142

Training iteration loss = 0.005172759

Training iteration loss = 0.0036801866

Training iteration loss = 0.0021056312

Training iteration loss = 0.0023002827

Training iteration loss = 0.008678399

Training iteration loss = 0.0039696353

Training iteration loss = 0.001670943

Training iteration loss = 0.0051110885

Training iteration loss = 0.0040135807

Training iteration loss = 0.0038136241

Training iteration loss = 0.003398652

Training iteration loss = 0.0044289664

Training iteration loss = 0.0025223806

Training iteration loss = 0.0077633304

Training iteration loss = 0.0030358464

Training iteration loss = 0.003730891

Training iteration loss = 0.004443426

Training iteration loss = 0.002417317

Training iteration loss = 0.0024380356

Training iteration loss = 0.0026814304

Training iteration loss = 0.0023471096

Training iteration loss = 0.0037264265

Training iteration loss = 0.0035203139

Training iteration loss = 0.0042275894

Training iteration loss = 0.0034983093

Training iteration loss = 0.003145823

Training iteration loss = 0.0023496307

Training iteration loss = 0.0024123366

Training iteration loss = 0.0025791642

Training iteration loss = 0.0031181127

Training iteration loss = 0.0060853213

Training iteration loss = 0.0021640717

Training iteration loss = 0.0029993271

Training iteration loss = 0.0032093201

Training iteration loss = 0.0042890585

Training iteration loss = 0.0032111418

Training iteration loss = 0.003594247

Training iteration loss = 0.0031676274

Training iteration loss = 0.0019504302

Training iteration loss = 0.0066114585

Training iteration loss = 0.003356959

Training iteration loss = 0.0026421903

Training iteration loss = 0.0021542984

Training iteration loss = 0.003693255

Training iteration loss = 0.00393769

Training iteration loss = 0.00429282

Training iteration loss = 0.003047217

Training iteration loss = 0.0054609384

Training iteration loss = 0.003480924

Training iteration loss = 0.0027445292

Training iteration loss = 0.0021401152

Training iteration loss = 0.002645544

Training iteration loss = 0.002253177

Training iteration loss = 0.0041330955

Training iteration loss = 0.0019437633

Training iteration loss = 0.002234173

Training iteration loss = 0.0037956575

Training iteration loss = 0.0033377225

Training iteration loss = 0.003552199

Training iteration loss = 0.002919778

Training iteration loss = 0.0045792945

Training iteration loss = 0.0044821477

Training iteration loss = 0.005097894

Training iteration loss = 0.002356486

Training iteration loss = 0.003338476

Training iteration loss = 0.0027273055

Training iteration loss = 0.004021252

Training iteration loss = 0.003703108

Training iteration loss = 0.0050833225

Training iteration loss = 0.003284659

Training iteration loss = 0.002664401

Training iteration loss = 0.003703363

Training iteration loss = 0.0055620377

Training iteration loss = 0.0036529228

Training iteration loss = 0.0034170805

Training iteration loss = 0.0038745229

Training iteration loss = 0.003915068

Training iteration loss = 0.0029207852

Training iteration loss = 0.003951834

Training iteration loss = 0.004121739

Training iteration loss = 0.0033049155

Training iteration loss = 0.0033673088

Training iteration loss = 0.0032037792

Training iteration loss = 0.0024914904

Training iteration loss = 0.004992794

Training iteration loss = 0.005113579

Training iteration loss = 0.004344141

Training iteration loss = 0.0038535234

Training iteration loss = 0.0024213984

Training iteration loss = 0.0051635895

Training iteration loss = 0.006086298

Training iteration loss = 0.00306504

Training iteration loss = 0.0037882708

Training iteration loss = 0.0029218553

Training iteration loss = 0.0030767173

Training iteration loss = 0.0031951044

Training iteration loss = 0.002999177

Training iteration loss = 0.0056741163

Training iteration loss = 0.0072867484

Training iteration loss = 0.0026951486

Training iteration loss = 0.0031376218

Training iteration loss = 0.0023847793

Training iteration loss = 0.0029328528

Training iteration loss = 0.004075314

Training iteration loss = 0.0034408474

Training iteration loss = 0.0043455735

Training iteration loss = 0.0025009771

Training iteration loss = 0.004237726

Training iteration loss = 0.008360415

Training iteration loss = 0.0052035796

Training iteration loss = 0.0042867176

Training iteration loss = 0.0033769791

Training iteration loss = 0.0039169258

Training iteration loss = 0.0027957668

Training iteration loss = 0.0037480623

Training iteration loss = 0.0024905019

Training iteration loss = 0.0028700132

Training iteration loss = 0.0030986734

Training iteration loss = 0.0042015514

Training iteration loss = 0.00267179

Training iteration loss = 0.0047324905

Training iteration loss = 0.0038259383

Training iteration loss = 0.005670575

Training iteration loss = 0.0034755648

Training iteration loss = 0.003371816

Training iteration loss = 0.0034527534

Training iteration loss = 0.007810915

Training iteration loss = 0.005567651

Training iteration loss = 0.00351125

Training iteration loss = 0.0028494375

Training iteration loss = 0.0059306785

Training iteration loss = 0.0025907198

Training iteration loss = 0.002573105

Training iteration loss = 0.0029090848

Training iteration loss = 0.0038142384

Training iteration loss = 0.0032751213

Training iteration loss = 0.004359664

Training iteration loss = 0.0040295143

Training iteration loss = 0.0023517853

Training iteration loss = 0.003364567

Training iteration loss = 0.002084666

Training iteration loss = 0.002957507

Training iteration loss = 0.0024951263

Training iteration loss = 0.003210852

Training iteration loss = 0.003807515

Training iteration loss = 0.003903848

Training iteration loss = 0.0051407

Training iteration loss = 0.0041137496

Training iteration loss = 0.00507455

Training iteration loss = 0.0024462969

Training iteration loss = 0.0035157967

Training iteration loss = 0.002697407

Training iteration loss = 0.0067242016

Training iteration loss = 0.0041846875

Training iteration loss = 0.0032007631

Training iteration loss = 0.0029619168

Training iteration loss = 0.003870142

Training iteration loss = 0.0089081

Training iteration loss = 0.0024976705

Training iteration loss = 0.0040740888

Training iteration loss = 0.003981152

Training iteration loss = 0.0026059411

Training iteration loss = 0.004023933

Training iteration loss = 0.004012672

Training iteration loss = 0.0029738992

Training iteration loss = 0.0027126877

Training iteration loss = 0.0036966654

Training iteration loss = 0.004218219

Training iteration loss = 0.003957316

Training iteration loss = 0.0057644583

Training iteration loss = 0.006021176

Training iteration loss = 0.0032918416

Training iteration loss = 0.004058971

Training iteration loss = 0.0056659454

Training iteration loss = 0.005474917

Training iteration loss = 0.0031786512

Training iteration loss = 0.0042342446

Training iteration loss = 0.004201271

Training iteration loss = 0.00282176

Training iteration loss = 0.002400159

Training iteration loss = 0.0039910884

Training iteration loss = 0.0028453215

Training iteration loss = 0.0026629681

Training iteration loss = 0.0035437334

Training iteration loss = 0.0025056272

Training iteration loss = 0.0021459272

Training iteration loss = 0.0021210222

Training iteration loss = 0.0036211356

Training iteration loss = 0.0022432858

Training iteration loss = 0.002655716

Training iteration loss = 0.004304584

Training iteration loss = 0.006905744

Training iteration loss = 0.0027740255

Training iteration loss = 0.0029278344

Training iteration loss = 0.0025738527

Training iteration loss = 0.0032721907

Training iteration loss = 0.0025701488

Training iteration loss = 0.0044624875

Training iteration loss = 0.003355792

Training iteration loss = 0.005225754

Training iteration loss = 0.0049586026

Training iteration loss = 0.0034861537

Training iteration loss = 0.0020830377

Training iteration loss = 0.002245676

Training iteration loss = 0.008710361

Training iteration loss = 0.0038181406

Training iteration loss = 0.0017033871

Training iteration loss = 0.00501583

Training iteration loss = 0.0039863735

Training iteration loss = 0.0038184293

Training iteration loss = 0.0032369383

Training iteration loss = 0.004365925

Training iteration loss = 0.0024945606

Training iteration loss = 0.007559307

Training iteration loss = 0.0029006943

Training iteration loss = 0.003637595

Training iteration loss = 0.004381895

Training iteration loss = 0.002374724

Training iteration loss = 0.0023881935

Training iteration loss = 0.0026468337

Training iteration loss = 0.0022302337

Training iteration loss = 0.0036738806

Training iteration loss = 0.0034515606

Training iteration loss = 0.0041832956

Training iteration loss = 0.003463005

Training iteration loss = 0.003063036

Training iteration loss = 0.0023249371

Training iteration loss = 0.0023777164

Training iteration loss = 0.0025139174

Training iteration loss = 0.0030675589

Training iteration loss = 0.0059007914

Training iteration loss = 0.0021230543

Training iteration loss = 0.0030049777

Training iteration loss = 0.003182306

Training iteration loss = 0.0041170768

Training iteration loss = 0.0031625591

Training iteration loss = 0.0035611847

Training iteration loss = 0.0031379166

Training iteration loss = 0.0019288603

Training iteration loss = 0.006545922

Training iteration loss = 0.0033225243

Training iteration loss = 0.002592364

Training iteration loss = 0.0020499297

Training iteration loss = 0.0036928346

Training iteration loss = 0.0038727166

Training iteration loss = 0.004212395

Training iteration loss = 0.002997639

Training iteration loss = 0.0055560432

Training iteration loss = 0.0034481212

Training iteration loss = 0.0026903858

Training iteration loss = 0.0021075462

Training iteration loss = 0.0025959392

Training iteration loss = 0.002233185

Training iteration loss = 0.0039694044

Training iteration loss = 0.0019409334

Training iteration loss = 0.0021727278

Training iteration loss = 0.0037785077

Training iteration loss = 0.0033137584

Training iteration loss = 0.0035848229

Training iteration loss = 0.002881677

Training iteration loss = 0.00451494

Training iteration loss = 0.0044285436

Training iteration loss = 0.0049679666

Training iteration loss = 0.0023022343

Training iteration loss = 0.0032732857

Training iteration loss = 0.0026584242

Training iteration loss = 0.0039740964

Training iteration loss = 0.0036945306

Training iteration loss = 0.00507192

Training iteration loss = 0.0032223861

Training iteration loss = 0.002601507

Training iteration loss = 0.0036001317

Training iteration loss = 0.005476191

Training iteration loss = 0.0035833567

Training iteration loss = 0.0032995802

Training iteration loss = 0.0037925777

Training iteration loss = 0.003834447

Training iteration loss = 0.0028038556

Training iteration loss = 0.0036942093

Training iteration loss = 0.0040679364

Training iteration loss = 0.0032501838

Training iteration loss = 0.0033459167

Training iteration loss = 0.0031494515

Training iteration loss = 0.0024695848

Training iteration loss = 0.0049591986

Training iteration loss = 0.0049602496

Training iteration loss = 0.004259344

Training iteration loss = 0.0037622212

Training iteration loss = 0.0024174403

Training iteration loss = 0.0050616334

Training iteration loss = 0.006042738

Training iteration loss = 0.002980245

Training iteration loss = 0.0037087605

Training iteration loss = 0.0027846703

Training iteration loss = 0.0030301644

Training iteration loss = 0.0031145753

Training iteration loss = 0.0029434785

Training iteration loss = 0.0056136274

Training iteration loss = 0.00706479

Training iteration loss = 0.0026750534

Training iteration loss = 0.0031320034

Training iteration loss = 0.0023346029

Training iteration loss = 0.002847652

Training iteration loss = 0.003950263

Training iteration loss = 0.0034399293

Training iteration loss = 0.0042831716

Training iteration loss = 0.0024781886

Training iteration loss = 0.004163004

Training iteration loss = 0.008164969

Training iteration loss = 0.00520179

Training iteration loss = 0.0042445282

Training iteration loss = 0.0033306081

Training iteration loss = 0.0038910534

Training iteration loss = 0.002780684

Training iteration loss = 0.003693276

Training iteration loss = 0.002430286

Training iteration loss = 0.0028481204

Training iteration loss = 0.0030414145

Training iteration loss = 0.0039629075

Training iteration loss = 0.002561765

Training iteration loss = 0.0046702432

Training iteration loss = 0.0037874803

Training iteration loss = 0.0056408825

Training iteration loss = 0.0034528945

Training iteration loss = 0.003398619

Training iteration loss = 0.0034343507

Training iteration loss = 0.0077309744

Training iteration loss = 0.0052913125

Training iteration loss = 0.0034878755

Training iteration loss = 0.002809

Training iteration loss = 0.005831866

Training iteration loss = 0.0025423227

Training iteration loss = 0.0025242828

Training iteration loss = 0.0028988777

Training iteration loss = 0.0037706334

Training iteration loss = 0.0032495784

Training iteration loss = 0.0042669973

Training iteration loss = 0.0040350542

Training iteration loss = 0.002274829

Training iteration loss = 0.003221078

Training iteration loss = 0.0020304807

Training iteration loss = 0.0029188879

Training iteration loss = 0.0024490869

Training iteration loss = 0.0031181565

Training iteration loss = 0.0037609984

Training iteration loss = 0.003784474

Training iteration loss = 0.005057324

Training iteration loss = 0.004153193

Training iteration loss = 0.0049964045

Training iteration loss = 0.0023821713

Training iteration loss = 0.00343958

Training iteration loss = 0.0026293437

Training iteration loss = 0.0066543804

Training iteration loss = 0.004117768

Training iteration loss = 0.0031668062

Training iteration loss = 0.0029542695

Training iteration loss = 0.003802215

Training iteration loss = 0.0087530585

Training iteration loss = 0.0024582818

Training iteration loss = 0.004046682

Training iteration loss = 0.003953149

Training iteration loss = 0.0025829922

Training iteration loss = 0.003969484

Training iteration loss = 0.0039809267

Training iteration loss = 0.0029642426

Training iteration loss = 0.0026821308

Training iteration loss = 0.003656012

Training iteration loss = 0.00419734

Training iteration loss = 0.0039086808

Training iteration loss = 0.0055572037

Training iteration loss = 0.005837754

Training iteration loss = 0.0032706354

Training iteration loss = 0.0040478436

Training iteration loss = 0.0055049737

Training iteration loss = 0.0053297076

Training iteration loss = 0.0031476803

Training iteration loss = 0.0041799545

Training iteration loss = 0.004181676

Training iteration loss = 0.0028094258

Training iteration loss = 0.0023680935

Training iteration loss = 0.0038986441

Training iteration loss = 0.0027377624

Training iteration loss = 0.0026055072

Training iteration loss = 0.0035105713

Training iteration loss = 0.0024676865

Training iteration loss = 0.0021156757

Training iteration loss = 0.0020919049

Training iteration loss = 0.0035225742

Training iteration loss = 0.0022213547

Training iteration loss = 0.0026071833

Training iteration loss = 0.004256007

Training iteration loss = 0.006647443

Training iteration loss = 0.0027485576

Training iteration loss = 0.0029152678

Training iteration loss = 0.0025583447

Training iteration loss = 0.0031529756

Training iteration loss = 0.0025030312

Training iteration loss = 0.0044445875

Training iteration loss = 0.0033810006

Training iteration loss = 0.005164781

Training iteration loss = 0.0048538432

Training iteration loss = 0.0033574344

Training iteration loss = 0.002080649

Training iteration loss = 0.0022177163

Training iteration loss = 0.00872673

Training iteration loss = 0.0037193985

Training iteration loss = 0.0017492478

Training iteration loss = 0.0049279877

Training iteration loss = 0.0039605317

Training iteration loss = 0.0038274655

Training iteration loss = 0.003171075

Training iteration loss = 0.004331784

Training iteration loss = 0.0025048945

Training iteration loss = 0.0074650026

Training iteration loss = 0.0028182585

Training iteration loss = 0.0035650423

Training iteration loss = 0.004338882

Training iteration loss = 0.002362187

Training iteration loss = 0.0023621526

Training iteration loss = 0.0026349917

Training iteration loss = 0.0021519705

Training iteration loss = 0.0036514795

Training iteration loss = 0.0034192551

Training iteration loss = 0.0041691083

Training iteration loss = 0.003411411

Training iteration loss = 0.0030217217

Training iteration loss = 0.0023028005

Training iteration loss = 0.002372984

Training iteration loss = 0.0024878539

Training iteration loss = 0.0030490796

Training iteration loss = 0.0057895803

Training iteration loss = 0.0020999608

Training iteration loss = 0.003012854

Training iteration loss = 0.003180013

Training iteration loss = 0.0040407325

Training iteration loss = 0.0031279463

Training iteration loss = 0.0035286027

Training iteration loss = 0.0031220845

Training iteration loss = 0.0019232814

Training iteration loss = 0.006526359

Training iteration loss = 0.0032884323

Training iteration loss = 0.0025571014

Training iteration loss = 0.0019946375

Training iteration loss = 0.0037095528

Training iteration loss = 0.003850133

Training iteration loss = 0.0041602887

Training iteration loss = 0.0029412229

Training iteration loss = 0.0056078634

Training iteration loss = 0.0034426025

Training iteration loss = 0.0026632957

Training iteration loss = 0.0020981699

Training iteration loss = 0.002551093

Training iteration loss = 0.0022123137

Training iteration loss = 0.003871927

Training iteration loss = 0.0019642634

Training iteration loss = 0.002132633

Training iteration loss = 0.0037472062

Training iteration loss = 0.0032839973

Training iteration loss = 0.003624018

Training iteration loss = 0.002856007

Training iteration loss = 0.0044434005

Training iteration loss = 0.0043730526

Training iteration loss = 0.004869888

Training iteration loss = 0.0022684953

Training iteration loss = 0.0032147074

Training iteration loss = 0.0026055074

Training iteration loss = 0.003943682

Training iteration loss = 0.0036870127

Training iteration loss = 0.005068621

Training iteration loss = 0.0031814568

Training iteration loss = 0.002559124

Training iteration loss = 0.0034977666

Training iteration loss = 0.005418204

Training iteration loss = 0.0035409129

Training iteration loss = 0.003220915

Training iteration loss = 0.0037159708

Training iteration loss = 0.0037508234

Training iteration loss = 0.0027303544

Training iteration loss = 0.0035422079

Training iteration loss = 0.004041916

Training iteration loss = 0.0032057995

Training iteration loss = 0.0033355223

Training iteration loss = 0.0031017277

Training iteration loss = 0.0024558373

Training iteration loss = 0.004939442

Training iteration loss = 0.0048696543

Training iteration loss = 0.004174125

Training iteration loss = 0.0036929694

Training iteration loss = 0.0024153774

Training iteration loss = 0.0050147064

Training iteration loss = 0.005994543

Training iteration loss = 0.0029133726

Training iteration loss = 0.0036625534

Training iteration loss = 0.0027055473

Training iteration loss = 0.0030124753

Training iteration loss = 0.0030559103

Training iteration loss = 0.0029068405

Training iteration loss = 0.0055785906

Training iteration loss = 0.006930904

Training iteration loss = 0.0026689845

Training iteration loss = 0.0031421648

Training iteration loss = 0.002310251

Training iteration loss = 0.0027939521

Training iteration loss = 0.0038785962

Training iteration loss = 0.003442656

Training iteration loss = 0.0042325906

Training iteration loss = 0.0024674672

Training iteration loss = 0.0041115857

Training iteration loss = 0.008041817

Training iteration loss = 0.005206535

Training iteration loss = 0.0042208903

Training iteration loss = 0.00328362

Training iteration loss = 0.003859808

Training iteration loss = 0.002774313

Training iteration loss = 0.0036590158

Training iteration loss = 0.00238729

Training iteration loss = 0.0028230145

Training iteration loss = 0.0029920528

Training iteration loss = 0.0038163047

Training iteration loss = 0.0024877796

Training iteration loss = 0.0046218024

Training iteration loss = 0.0037556067

Training iteration loss = 0.005621093

Training iteration loss = 0.0034282599

Training iteration loss = 0.0034145156

Training iteration loss = 0.0034254063

Training iteration loss = 0.007687571

Training iteration loss = 0.005118435

Training iteration loss = 0.0034780884

Training iteration loss = 0.002779697

Training iteration loss = 0.005762885

Training iteration loss = 0.002505916

Training iteration loss = 0.0024913698

Training iteration loss = 0.002895214

Training iteration loss = 0.0037450332

Training iteration loss = 0.003226761

Training iteration loss = 0.004197847

Training iteration loss = 0.004017063

Training iteration loss = 0.002228214

Training iteration loss = 0.003136134

Training iteration loss = 0.0020019058

Training iteration loss = 0.0028748577

Training iteration loss = 0.002413924

Training iteration loss = 0.003034325

Training iteration loss = 0.003732072

Training iteration loss = 0.003704412

Training iteration loss = 0.00499749

Training iteration loss = 0.004182168

Training iteration loss = 0.0049460866

Training iteration loss = 0.0023363975

Training iteration loss = 0.0033972424

Training iteration loss = 0.002586404

Training iteration loss = 0.0066121332

Training iteration loss = 0.0040731938

Training iteration loss = 0.0031486347

Training iteration loss = 0.0029750885

Training iteration loss = 0.0037600182

Training iteration loss = 0.00863107

Training iteration loss = 0.0024343997

Training iteration loss = 0.0040370473

Training iteration loss = 0.0039530774

Training iteration loss = 0.0025570008

Training iteration loss = 0.0039113727

Training iteration loss = 0.003969471

Training iteration loss = 0.00296255

Training iteration loss = 0.0026556477

Training iteration loss = 0.0036159214

Training iteration loss = 0.004197362

Training iteration loss = 0.003887181

Training iteration loss = 0.0054234155

Training iteration loss = 0.0056938916

Training iteration loss = 0.0032695069

Training iteration loss = 0.0040454296

Training iteration loss = 0.0053637177

Training iteration loss = 0.0052230447

Training iteration loss = 0.0031256115

Training iteration loss = 0.0041461536

Training iteration loss = 0.0041662715

Training iteration loss = 0.0027956509

Training iteration loss = 0.0023503487

Training iteration loss = 0.0038308033

Training iteration loss = 0.002678078

Training iteration loss = 0.0025538346

Training iteration loss = 0.0034949647

Training iteration loss = 0.0024396062

Training iteration loss = 0.00208289

Training iteration loss = 0.00207138

Training iteration loss = 0.0034440227

Training iteration loss = 0.0022193918

Training iteration loss = 0.0025867254

Training iteration loss = 0.0042241467

Training iteration loss = 0.006480346

Training iteration loss = 0.002734693

Training iteration loss = 0.0029052412

Training iteration loss = 0.0025521324

Training iteration loss = 0.0030770174

Training iteration loss = 0.002447787

Training iteration loss = 0.0044256016

Training iteration loss = 0.0033997467

Training iteration loss = 0.0051133977

Training iteration loss = 0.0047985464

Training iteration loss = 0.0032768166

Training iteration loss = 0.0020752281

Training iteration loss = 0.0022005776

Training iteration loss = 0.008730422

Training iteration loss = 0.0036479544

Training iteration loss = 0.0017778602

Training iteration loss = 0.004848988

Training iteration loss = 0.003931983

Training iteration loss = 0.003822621

Training iteration loss = 0.0031490081

Training iteration loss = 0.004304154

Training iteration loss = 0.0025128375

Training iteration loss = 0.0074128783

Training iteration loss = 0.0027670574

Training iteration loss = 0.0035072498

Training iteration loss = 0.0042947545

Training iteration loss = 0.0023470134

Training iteration loss = 0.002346831

Training iteration loss = 0.0026361905

Training iteration loss = 0.002087774

Training iteration loss = 0.0036336507

Training iteration loss = 0.0033959989

Training iteration loss = 0.0041690185

Training iteration loss = 0.0033631977

Training iteration loss = 0.0029894628

Training iteration loss = 0.002281463

Training iteration loss = 0.0023725268

Training iteration loss = 0.0024763148

Training iteration loss = 0.0030472642

Training iteration loss = 0.0057160053

Training iteration loss = 0.0020829914

Training iteration loss = 0.00301701

Training iteration loss = 0.003176375

Training iteration loss = 0.004003941

Training iteration loss = 0.0031041864

Training iteration loss = 0.0035005456

Training iteration loss = 0.003105509

Training iteration loss = 0.0019185279

Training iteration loss = 0.0065281806

Training iteration loss = 0.0032622209

Training iteration loss = 0.0025355618

Training iteration loss = 0.001954854

Training iteration loss = 0.0037133836

Training iteration loss = 0.0038454358

Training iteration loss = 0.004133558

Training iteration loss = 0.0028740524

Training iteration loss = 0.0056306724

Training iteration loss = 0.0034399389

Training iteration loss = 0.0026557825

Training iteration loss = 0.00210383

Training iteration loss = 0.0025178513

Training iteration loss = 0.0021791446

Training iteration loss = 0.003805556

Training iteration loss = 0.001991479

Training iteration loss = 0.0021127549

Training iteration loss = 0.0037103647

Training iteration loss = 0.0032378277

Training iteration loss = 0.0036371583

Training iteration loss = 0.002835459

Training iteration loss = 0.0043813386

Training iteration loss = 0.004312891

Training iteration loss = 0.0047901203

Training iteration loss = 0.0022407046

Training iteration loss = 0.0031665151

Training iteration loss = 0.0025661958

Training iteration loss = 0.003919635

Training iteration loss = 0.003662187

Training iteration loss = 0.0050601284

Training iteration loss = 0.0031533928

Training iteration loss = 0.0025340384

Training iteration loss = 0.00340565

Training iteration loss = 0.005370124

Training iteration loss = 0.0035115825

Training iteration loss = 0.003165081

Training iteration loss = 0.003658787

Training iteration loss = 0.003680135

Training iteration loss = 0.0026835764

Training iteration loss = 0.0034476249

Training iteration loss = 0.0040234015

Training iteration loss = 0.0031753343

Training iteration loss = 0.0033315385

Training iteration loss = 0.0030576733

Training iteration loss = 0.0024407615

Training iteration loss = 0.0049252165

Training iteration loss = 0.004812419

Training iteration loss = 0.00409976

Training iteration loss = 0.003642535

Training iteration loss = 0.002409338

Training iteration loss = 0.0049895905

Training iteration loss = 0.0059481026

Training iteration loss = 0.0028567675

Training iteration loss = 0.0036275482

Training iteration loss = 0.0026586826

Training iteration loss = 0.0030028466

Training iteration loss = 0.0030066594

Training iteration loss = 0.0028754238

Training iteration loss = 0.005555604

Training iteration loss = 0.0068439636

Training iteration loss = 0.0026651742

Training iteration loss = 0.0031434672

Training iteration loss = 0.002297034

Training iteration loss = 0.0027648613

Training iteration loss = 0.0038305025

Training iteration loss = 0.003440067

Training iteration loss = 0.0041915383

Training iteration loss = 0.0024625957

Training iteration loss = 0.0040773717

Training iteration loss = 0.007955658

Training iteration loss = 0.005201315

Training iteration loss = 0.004200836

Training iteration loss = 0.0032377318

Training iteration loss = 0.0038166847

Training iteration loss = 0.0027644404

Training iteration loss = 0.0036360153

Training iteration loss = 0.0023534228

Training iteration loss = 0.002797417

Training iteration loss = 0.0029477582

Training iteration loss = 0.0037259518

Training iteration loss = 0.0024337515

Training iteration loss = 0.0045785317

Training iteration loss = 0.0037197536

Training iteration loss = 0.0056101573

Training iteration loss = 0.0034076988

Training iteration loss = 0.0034249888

Training iteration loss = 0.0034268433

Training iteration loss = 0.0076555493

Training iteration loss = 0.0050082305

Training iteration loss = 0.0034770584

Training iteration loss = 0.0027499015

Training iteration loss = 0.0057092793

Training iteration loss = 0.0024756626

Training iteration loss = 0.0024646602

Training iteration loss = 0.0028940167

Training iteration loss = 0.0037284542

Training iteration loss = 0.0032085774

Training iteration loss = 0.0041474104

Training iteration loss = 0.003987024

Training iteration loss = 0.0021972358

Training iteration loss = 0.0030853248

Training iteration loss = 0.0019922226

Training iteration loss = 0.0028288483

Training iteration loss = 0.0023742977

Training iteration loss = 0.0029630896

Training iteration loss = 0.00371629

Training iteration loss = 0.003649351

Training iteration loss = 0.00494518

Training iteration loss = 0.0041961693

Training iteration loss = 0.0049035493

Training iteration loss = 0.0023021065

Training iteration loss = 0.003370379

Training iteration loss = 0.0025530343

Training iteration loss = 0.0065879244

Training iteration loss = 0.004039426

Training iteration loss = 0.0031254983

Training iteration loss = 0.002997658

Training iteration loss = 0.0037337672

Training iteration loss = 0.008521189

Training iteration loss = 0.0024176661

Training iteration loss = 0.0040291958

Training iteration loss = 0.003967418

Training iteration loss = 0.0025319424

Training iteration loss = 0.003850748

Training iteration loss = 0.0039607217

Training iteration loss = 0.0029624172

Training iteration loss = 0.0026298228

Training iteration loss = 0.0035701066

Training iteration loss = 0.0042018197

Training iteration loss = 0.003883091

Training iteration loss = 0.0053325756

Training iteration loss = 0.0055714604

Training iteration loss = 0.003269614

Training iteration loss = 0.0040457263

Training iteration loss = 0.0052461424

Training iteration loss = 0.005133961

Training iteration loss = 0.003102037

Training iteration loss = 0.004123854

Training iteration loss = 0.0041532163

Training iteration loss = 0.0027725159

Training iteration loss = 0.0023408837

Training iteration loss = 0.0037828411

Training iteration loss = 0.0026482362

Training iteration loss = 0.002511449

Training iteration loss = 0.0034845185

Training iteration loss = 0.0024229607

Training iteration loss = 0.0020521723

Training iteration loss = 0.0020496058

Training iteration loss = 0.0033801503

Training iteration loss = 0.00222476

Training iteration loss = 0.0025826693

Training iteration loss = 0.004200953

Training iteration loss = 0.006356118

Training iteration loss = 0.0027221076

Training iteration loss = 0.002897882

Training iteration loss = 0.0025480909

Training iteration loss = 0.0030267567

Training iteration loss = 0.0024015717

Training iteration loss = 0.004403124

Training iteration loss = 0.0034114232

Training iteration loss = 0.0050744503

Training iteration loss = 0.004768147

Training iteration loss = 0.003223259

Training iteration loss = 0.0020632937

Training iteration loss = 0.0021887168

Training iteration loss = 0.00872182

Training iteration loss = 0.0035967994

Training iteration loss = 0.0017915126

Training iteration loss = 0.004779146

Training iteration loss = 0.0039047182

Training iteration loss = 0.003812507

Training iteration loss = 0.00314553

Training iteration loss = 0.004279326

Training iteration loss = 0.00251121

Training iteration loss = 0.007374776

Training iteration loss = 0.0027350013

Training iteration loss = 0.0034647908

Training iteration loss = 0.004251066

Training iteration loss = 0.002327103

Training iteration loss = 0.002336236

Training iteration loss = 0.0026414583

Training iteration loss = 0.002035028

Training iteration loss = 0.0036174636

Training iteration loss = 0.0033706704

Training iteration loss = 0.004170596

Training iteration loss = 0.0033267227

Training iteration loss = 0.0029623955

Training iteration loss = 0.0022603504

Training iteration loss = 0.0023644373

Training iteration loss = 0.0024698868

Training iteration loss = 0.00305174

Training iteration loss = 0.005658313

Training iteration loss = 0.002067785

Training iteration loss = 0.0030162204

Training iteration loss = 0.0031659051

Training iteration loss = 0.003978251

Training iteration loss = 0.0030882123

Training iteration loss = 0.0034815464

Training iteration loss = 0.003088632

Training iteration loss = 0.0019101565

Training iteration loss = 0.00652406

Training iteration loss = 0.0032454326

Training iteration loss = 0.0025305331

Training iteration loss = 0.0019209954

Training iteration loss = 0.0036947047

Training iteration loss = 0.003844173

Training iteration loss = 0.0041276226

Training iteration loss = 0.002809286

Training iteration loss = 0.0056432895

Training iteration loss = 0.0034284042

Training iteration loss = 0.0026544181

Training iteration loss = 0.0021172208

Training iteration loss = 0.0025007287

Training iteration loss = 0.0021386943

Training iteration loss = 0.0037518234

Training iteration loss = 0.0020102656

Training iteration loss = 0.0021094163

Training iteration loss = 0.003678575

Training iteration loss = 0.003186349

Training iteration loss = 0.003628127

Training iteration loss = 0.0028160308

Training iteration loss = 0.0043393034

Training iteration loss = 0.004260658

Training iteration loss = 0.004727144

Training iteration loss = 0.002217648

Training iteration loss = 0.0031301964

Training iteration loss = 0.0025385362

Training iteration loss = 0.0039001552

Training iteration loss = 0.0036320055

Training iteration loss = 0.0050462377

Training iteration loss = 0.0031298802

Training iteration loss = 0.0025203037

Training iteration loss = 0.0033332931

Training iteration loss = 0.005333481

Training iteration loss = 0.0034905216

Training iteration loss = 0.0031198307

Training iteration loss = 0.003618556

Training iteration loss = 0.0036301396

Training iteration loss = 0.0026592528

Training iteration loss = 0.0033797708

Training iteration loss = 0.0040011676

Training iteration loss = 0.003157167

Training iteration loss = 0.003334176

Training iteration loss = 0.0030218707

Training iteration loss = 0.0024229216

Training iteration loss = 0.004912893

Training iteration loss = 0.0047687585

Training iteration loss = 0.004039109

Training iteration loss = 0.0036058764

Training iteration loss = 0.0023992828

Training iteration loss = 0.0049716905

Training iteration loss = 0.0059076822

Training iteration loss = 0.0028092582

Training iteration loss = 0.0035966747

Training iteration loss = 0.0026279045

Training iteration loss = 0.002995882

Training iteration loss = 0.002963863

Training iteration loss = 0.0028461507

Training iteration loss = 0.0055365283

Training iteration loss = 0.0067815795

Training iteration loss = 0.0026615316

Training iteration loss = 0.003133379

Training iteration loss = 0.0022855373

Training iteration loss = 0.0027513665

Training iteration loss = 0.0037965917

Training iteration loss = 0.0034353845

Training iteration loss = 0.0041563953

Training iteration loss = 0.0024558865

Training iteration loss = 0.004056998

Training iteration loss = 0.007889022

Training iteration loss = 0.0051868465

Training iteration loss = 0.0041783317

Training iteration loss = 0.0031987738

Training iteration loss = 0.0037684639

Training iteration loss = 0.0027479285

Training iteration loss = 0.0036192026

Training iteration loss = 0.0023285532

Training iteration loss = 0.0027778747

Training iteration loss = 0.0029065178

Training iteration loss = 0.0036552679

Training iteration loss = 0.0023936413

Training iteration loss = 0.0045437175

Training iteration loss = 0.0036813943

Training iteration loss = 0.005605811

Training iteration loss = 0.0033917318

Training iteration loss = 0.003433606

Training iteration loss = 0.0034366145

Training iteration loss = 0.0076225065

Training iteration loss = 0.0049256017

Training iteration loss = 0.0034821676

Training iteration loss = 0.0027195774

Training iteration loss = 0.005667222

Training iteration loss = 0.0024518303

Training iteration loss = 0.0024433965

Training iteration loss = 0.0028944798

Training iteration loss = 0.003718085

Training iteration loss = 0.0031914732

Training iteration loss = 0.004116146

Training iteration loss = 0.003953897

Training iteration loss = 0.0021723462

Training iteration loss = 0.003045372

Training iteration loss = 0.0019928578

Training iteration loss = 0.0027858596

Training iteration loss = 0.0023284275

Training iteration loss = 0.0028995683

Training iteration loss = 0.003703758

Training iteration loss = 0.003613998

Training iteration loss = 0.0048983213

Training iteration loss = 0.0041939947

Training iteration loss = 0.0048583546

Training iteration loss = 0.0022780078

Training iteration loss = 0.0033508402

Training iteration loss = 0.0025189605

Training iteration loss = 0.006574637

Training iteration loss = 0.004014742

Training iteration loss = 0.0030935165

Training iteration loss = 0.003003791

Training iteration loss = 0.003719377

Training iteration loss = 0.008428198

Training iteration loss = 0.0024069638

Training iteration loss = 0.0040142685

Training iteration loss = 0.0039776904

Training iteration loss = 0.0025135728

Training iteration loss = 0.0037948654

Training iteration loss = 0.0039472287

Training iteration loss = 0.002957767

Training iteration loss = 0.0026086736

Training iteration loss = 0.0035246916

Training iteration loss = 0.004199514

Training iteration loss = 0.0038860645

Training iteration loss = 0.0052708755

Training iteration loss = 0.005463609

Training iteration loss = 0.003261106

Training iteration loss = 0.004042053

Training iteration loss = 0.005156892

Training iteration loss = 0.0050614523

Training iteration loss = 0.0030755165

Training iteration loss = 0.004102758

Training iteration loss = 0.004142749

Training iteration loss = 0.0027474456

Training iteration loss = 0.0023363768

Training iteration loss = 0.0037491943

Training iteration loss = 0.0026353009

Training iteration loss = 0.0024764652

Training iteration loss = 0.003472835

Training iteration loss = 0.0024156647

Training iteration loss = 0.0020272692

Training iteration loss = 0.002025522

Training iteration loss = 0.0033289988

Training iteration loss = 0.0022274756

Training iteration loss = 0.002584854

Training iteration loss = 0.004184479

Training iteration loss = 0.0062502683

Training iteration loss = 0.0027051978

Training iteration loss = 0.0028917177

Training iteration loss = 0.0025462725

Training iteration loss = 0.0029907983

Training iteration loss = 0.0023635707

Training iteration loss = 0.0043808413

Training iteration loss = 0.0034203322

Training iteration loss = 0.0050443863

Training iteration loss = 0.0047473744

Training iteration loss = 0.0031829278

Training iteration loss = 0.0020503209

Training iteration loss = 0.002178386

Training iteration loss = 0.008703539

Training iteration loss = 0.0035611324

Training iteration loss = 0.0018017143

Training iteration loss = 0.0047161826

Training iteration loss = 0.0038805278

Training iteration loss = 0.00380444

Training iteration loss = 0.0031478994

Training iteration loss = 0.004256469

Training iteration loss = 0.0025014794

Training iteration loss = 0.0073396526

Training iteration loss = 0.002716758

Training iteration loss = 0.0034359007

Training iteration loss = 0.0042117406

Training iteration loss = 0.0023063526

Training iteration loss = 0.002329033

Training iteration loss = 0.002645801

Training iteration loss = 0.0019920783

Training iteration loss = 0.0036037809

Training iteration loss = 0.003345913

Training iteration loss = 0.004170755

Training iteration loss = 0.0032997532

Training iteration loss = 0.0029405246

Training iteration loss = 0.0022413442

Training iteration loss = 0.0023529609

Training iteration loss = 0.0024656078

Training iteration loss = 0.003055968

Training iteration loss = 0.0056079365

Training iteration loss = 0.002054445

Training iteration loss = 0.003014871

Training iteration loss = 0.0031523702

Training iteration loss = 0.0039533204

Training iteration loss = 0.0030772993

Training iteration loss = 0.0034703983

Training iteration loss = 0.0030763168

Training iteration loss = 0.0019011385

Training iteration loss = 0.0065065455

Training iteration loss = 0.0032338651

Training iteration loss = 0.0025402822

Training iteration loss = 0.0018970844

Training iteration loss = 0.0036608651

Training iteration loss = 0.0038389636

Training iteration loss = 0.0041320133

Training iteration loss = 0.0027580159

Training iteration loss = 0.005657719

Training iteration loss = 0.0034085212

Training iteration loss = 0.0026503224

Training iteration loss = 0.002132293

Training iteration loss = 0.0024993669

Training iteration loss = 0.0020998183

Training iteration loss = 0.0037050995

Training iteration loss = 0.0020184277

Training iteration loss = 0.0021175225

Training iteration loss = 0.0036565668

Training iteration loss = 0.0031402174

Training iteration loss = 0.0036089912

Training iteration loss = 0.0027980106

Training iteration loss = 0.0043175085

Training iteration loss = 0.0042217025

Training iteration loss = 0.004678115

Training iteration loss = 0.0022010787

Training iteration loss = 0.0031044951

Training iteration loss = 0.0025191405

Training iteration loss = 0.0038808268

Training iteration loss = 0.0036052826

Training iteration loss = 0.0050330316

Training iteration loss = 0.0031091345

Training iteration loss = 0.002511483

Training iteration loss = 0.0032801533

Training iteration loss = 0.005306741

Training iteration loss = 0.0034776342

Training iteration loss = 0.0030813173

Training iteration loss = 0.0035872506

Training iteration loss = 0.0035934653

Training iteration loss = 0.0026516914

Training iteration loss = 0.003326352

Training iteration loss = 0.0039717397

Training iteration loss = 0.0031416703

Training iteration loss = 0.0033395821

Training iteration loss = 0.002997677

Training iteration loss = 0.0024051957

Training iteration loss = 0.0048939153

Training iteration loss = 0.00472752

Training iteration loss = 0.003992003

Training iteration loss = 0.003578324

Training iteration loss = 0.0023864415

Training iteration loss = 0.004951741

Training iteration loss = 0.005873824

Training iteration loss = 0.0027704637

Training iteration loss = 0.003565992

Training iteration loss = 0.0026027

Training iteration loss = 0.0029903676

Training iteration loss = 0.0029290905

Training iteration loss = 0.0028170971

Training iteration loss = 0.005513927

Training iteration loss = 0.0067304224

Training iteration loss = 0.0026602885

Training iteration loss = 0.0031166535

Training iteration loss = 0.0022737577

Training iteration loss = 0.0027458947

Training iteration loss = 0.0037722802

Training iteration loss = 0.003434214

Training iteration loss = 0.0041250717

Training iteration loss = 0.0024408347

Training iteration loss = 0.0040449803

Training iteration loss = 0.007834257

Training iteration loss = 0.005168131

Training iteration loss = 0.0041495636

Training iteration loss = 0.0031697024

Training iteration loss = 0.0037228533

Training iteration loss = 0.0027267227

Training iteration loss = 0.0036051183

Training iteration loss = 0.0023114746

Training iteration loss = 0.002767375

Training iteration loss = 0.0028702412

Training iteration loss = 0.0035841574

Training iteration loss = 0.0023623542

Training iteration loss = 0.004521165

Training iteration loss = 0.0036465062

Training iteration loss = 0.0056051905

Training iteration loss = 0.0033778287

Training iteration loss = 0.003439531

Training iteration loss = 0.0034508638

Training iteration loss = 0.007586151

Training iteration loss = 0.004853318

Training iteration loss = 0.003488023

Training iteration loss = 0.0026932422

Training iteration loss = 0.005633931

Training iteration loss = 0.00243385

Training iteration loss = 0.0024314534

Training iteration loss = 0.0028956037

Training iteration loss = 0.0037124502

Training iteration loss = 0.003170536

Training iteration loss = 0.004101354

Training iteration loss = 0.0039211637

Training iteration loss = 0.0021503333

Training iteration loss = 0.0030037186

Training iteration loss = 0.0019938324

Training iteration loss = 0.002748823

Training iteration loss = 0.002282923

Training iteration loss = 0.0028423527

Training iteration loss = 0.0036849289

Training iteration loss = 0.0035917219

Training iteration loss = 0.0048600603

Training iteration loss = 0.004180894

Training iteration loss = 0.00480796

Training iteration loss = 0.0022640263

Training iteration loss = 0.0033379544

Training iteration loss = 0.0024855735

Training iteration loss = 0.006565862

Training iteration loss = 0.003998609

Training iteration loss = 0.0030626869

Training iteration loss = 0.002993174

Training iteration loss = 0.0037105018

Training iteration loss = 0.008358534

Training iteration loss = 0.0024029014

Training iteration loss = 0.00399506

Training iteration loss = 0.003971917

Training iteration loss = 0.0025005531

Training iteration loss = 0.0037515534

Training iteration loss = 0.003932523

Training iteration loss = 0.0029468776

Training iteration loss = 0.0025930773

Training iteration loss = 0.0034877881

Training iteration loss = 0.004188512

Training iteration loss = 0.003888582

Training iteration loss = 0.0052285376

Training iteration loss = 0.0053738193

Training iteration loss = 0.0032463667

Training iteration loss = 0.0040311175

Training iteration loss = 0.0050914474

Training iteration loss = 0.005007717

Training iteration loss = 0.0030508793

Training iteration loss = 0.0040770597

Training iteration loss = 0.004130909

Training iteration loss = 0.002725647

Training iteration loss = 0.0023351437

Training iteration loss = 0.003724941

Training iteration loss = 0.0026298538

Training iteration loss = 0.0024440598

Training iteration loss = 0.0034586703

Training iteration loss = 0.00241347

Training iteration loss = 0.0020084148

Training iteration loss = 0.001999843

Training iteration loss = 0.003290212

Training iteration loss = 0.0022233855

Training iteration loss = 0.0025853333

Training iteration loss = 0.004172932

Training iteration loss = 0.0061556934

Training iteration loss = 0.0026853054

Training iteration loss = 0.0028847556

Training iteration loss = 0.002545555

Training iteration loss = 0.0029620954

Training iteration loss = 0.0023339714

Training iteration loss = 0.0043611513

Training iteration loss = 0.0034282561

Training iteration loss = 0.005018306

Training iteration loss = 0.0047240104

Training iteration loss = 0.003150072

Training iteration loss = 0.0020413306

Training iteration loss = 0.0021688926

Training iteration loss = 0.008679376

Training iteration loss = 0.003531931

Training iteration loss = 0.0018146767

Training iteration loss = 0.004658616

Training iteration loss = 0.0038587612

Training iteration loss = 0.0037962429

Training iteration loss = 0.003149826

Training iteration loss = 0.004235625

Training iteration loss = 0.0024860145

Training iteration loss = 0.0073019364

Training iteration loss = 0.0027071408

Training iteration loss = 0.0034181357

Training iteration loss = 0.0041790926

Training iteration loss = 0.0022859538

Training iteration loss = 0.0023239674

Training iteration loss = 0.0026478225

Training iteration loss = 0.0019552258

Training iteration loss = 0.0035900883

Training iteration loss = 0.0033246137

Training iteration loss = 0.004173584

Training iteration loss = 0.0032792874

Training iteration loss = 0.0029214604

Training iteration loss = 0.0022262014

Training iteration loss = 0.0023425731

Training iteration loss = 0.002463822

Training iteration loss = 0.0030596715

Training iteration loss = 0.0055588675

Training iteration loss = 0.0020415352

Training iteration loss = 0.0030160903

Training iteration loss = 0.0031410072

Training iteration loss = 0.0039242962

Training iteration loss = 0.0030675617

Training iteration loss = 0.0034627405

Training iteration loss = 0.0030713046

Training iteration loss = 0.0018962356

Training iteration loss = 0.0064801066

Training iteration loss = 0.003220944

Training iteration loss = 0.002558666

Training iteration loss = 0.0018870578

Training iteration loss = 0.003622087

Training iteration loss = 0.0038286212

Training iteration loss = 0.0041350587

Training iteration loss = 0.0027219558

Training iteration loss = 0.005679687

Training iteration loss = 0.0033849755

Training iteration loss = 0.002639155

Training iteration loss = 0.0021449958

Training iteration loss = 0.0025110438

Training iteration loss = 0.0020683606

Training iteration loss = 0.0036634973

Training iteration loss = 0.002016852

Training iteration loss = 0.0021324991

Training iteration loss = 0.0036458913

Training iteration loss = 0.003103364

Training iteration loss = 0.0035869845

Training iteration loss = 0.0027817797

Training iteration loss = 0.0043115406

Training iteration loss = 0.0041967495

Training iteration loss = 0.004637178

Training iteration loss = 0.0021890728

Training iteration loss = 0.0030870186

Training iteration loss = 0.0025074913

Training iteration loss = 0.003859328

Training iteration loss = 0.0035812736

Training iteration loss = 0.0050231274

Training iteration loss = 0.003092989

Training iteration loss = 0.0025058314

Training iteration loss = 0.0032411602

Training iteration loss = 0.0052818656

Training iteration loss = 0.0034714418

Training iteration loss = 0.0030509683

Training iteration loss = 0.003559713

Training iteration loss = 0.0035578785

Training iteration loss = 0.0026492004

Training iteration loss = 0.003284121

Training iteration loss = 0.0039383634

Training iteration loss = 0.0031202275

Training iteration loss = 0.0033406361

Training iteration loss = 0.0029841748

Training iteration loss = 0.002392325

Training iteration loss = 0.0048631337

Training iteration loss = 0.0046811085

Training iteration loss = 0.0039559533

Training iteration loss = 0.003560729

Training iteration loss = 0.0023727813

Training iteration loss = 0.0049208407

Training iteration loss = 0.0058438717

Training iteration loss = 0.0027414393

Training iteration loss = 0.0035371997

Training iteration loss = 0.0025764778

Training iteration loss = 0.0029803645

Training iteration loss = 0.0029048205

Training iteration loss = 0.0027901065

Training iteration loss = 0.0054850094

Training iteration loss = 0.006681271

Training iteration loss = 0.0026610617

Training iteration loss = 0.0031007298

Training iteration loss = 0.0022650003

Training iteration loss = 0.0027425084

Training iteration loss = 0.0037514044

Training iteration loss = 0.0034367852

Training iteration loss = 0.0040982757

Training iteration loss = 0.0024152622

Training iteration loss = 0.0040337737

Training iteration loss = 0.0077924784

Training iteration loss = 0.0051496304

Training iteration loss = 0.004114919

Training iteration loss = 0.0031503476

Training iteration loss = 0.0036845952

Training iteration loss = 0.0027066765

Training iteration loss = 0.0035933666

Training iteration loss = 0.0022993567

Training iteration loss = 0.0027638355

Training iteration loss = 0.0028417232

Training iteration loss = 0.0035102125

Training iteration loss = 0.0023353824

Training iteration loss = 0.004511954

Training iteration loss = 0.0036181298

Training iteration loss = 0.0056047183

Training iteration loss = 0.0033643171

Training iteration loss = 0.0034395328

Training iteration loss = 0.0034596808

Training iteration loss = 0.0075497017

Training iteration loss = 0.0047865487

Training iteration loss = 0.00348837

Training iteration loss = 0.0026734027

Training iteration loss = 0.005605431

Training iteration loss = 0.002421159

Training iteration loss = 0.0024300693

Training iteration loss = 0.0028940171

Training iteration loss = 0.003708125

Training iteration loss = 0.0031453937

Training iteration loss = 0.004096602

Training iteration loss = 0.0038874291

Training iteration loss = 0.0021300458

Training iteration loss = 0.0029585892

Training iteration loss = 0.0019899386

Training iteration loss = 0.0027161494

Training iteration loss = 0.0022424008

Training iteration loss = 0.0027934667

Training iteration loss = 0.003660513

Training iteration loss = 0.0035752403

Training iteration loss = 0.0048303814

Training iteration loss = 0.0041675153

Training iteration loss = 0.0047570565

Training iteration loss = 0.0022568095

Training iteration loss = 0.0033306915

Training iteration loss = 0.0024615687

Training iteration loss = 0.006560614

Training iteration loss = 0.0039874944

Training iteration loss = 0.003040958

Training iteration loss = 0.002976748

Training iteration loss = 0.0037027309

Training iteration loss = 0.008305953

Training iteration loss = 0.0024037831

Training iteration loss = 0.0039789495

Training iteration loss = 0.003951906

Training iteration loss = 0.002488215

Training iteration loss = 0.003720634

Training iteration loss = 0.003921846

Training iteration loss = 0.0029347707

Training iteration loss = 0.002580628

Training iteration loss = 0.0034598466

Training iteration loss = 0.004171515

Training iteration loss = 0.003890014

Training iteration loss = 0.005198294

Training iteration loss = 0.005301697

Training iteration loss = 0.0032309117

Training iteration loss = 0.0040146676

Training iteration loss = 0.0050410894

Training iteration loss = 0.004967976

Training iteration loss = 0.003030848

Training iteration loss = 0.0040475656

Training iteration loss = 0.0041157682

Training iteration loss = 0.0027064488

Training iteration loss = 0.0023345284

Training iteration loss = 0.003707282

Training iteration loss = 0.0026282268

Training iteration loss = 0.0024119124

Training iteration loss = 0.0034406483

Training iteration loss = 0.0024121173

Training iteration loss = 0.0019950196

Training iteration loss = 0.001974054

Training iteration loss = 0.0032625457

Training iteration loss = 0.002213192

Training iteration loss = 0.0025809645

Training iteration loss = 0.004164171

Training iteration loss = 0.0060717463

Training iteration loss = 0.0026654394

Training iteration loss = 0.0028768473

Training iteration loss = 0.0025446285

Training iteration loss = 0.0029366612

Training iteration loss = 0.0023115985

Training iteration loss = 0.004344948

Training iteration loss = 0.0034352934

Training iteration loss = 0.0049942713

Training iteration loss = 0.004690815

Training iteration loss = 0.0031221171

Training iteration loss = 0.0020377599

Training iteration loss = 0.0021616742

Training iteration loss = 0.008652615

Training iteration loss = 0.003501039

Training iteration loss = 0.0018290062

Training iteration loss = 0.0046073315

Training iteration loss = 0.0038393403

Training iteration loss = 0.003783636

Training iteration loss = 0.0031491416

Training iteration loss = 0.00421754

Training iteration loss = 0.0024677187

Training iteration loss = 0.00726188

Training iteration loss = 0.0027006827

Training iteration loss = 0.0034090849

Training iteration loss = 0.0041543436

Training iteration loss = 0.0022662608

Training iteration loss = 0.0023186083

Training iteration loss = 0.00264721

Training iteration loss = 0.0019229698

Training iteration loss = 0.0035746687

Training iteration loss = 0.0033060908

Training iteration loss = 0.0041816314

Training iteration loss = 0.003263469

Training iteration loss = 0.0029044568

Training iteration loss = 0.0022153065

Training iteration loss = 0.00233081

Training iteration loss = 0.0024636195

Training iteration loss = 0.0030654755

Training iteration loss = 0.0055086347

Training iteration loss = 0.0020258317

Training iteration loss = 0.0030167822

Training iteration loss = 0.0031342532

Training iteration loss = 0.0038919256

Training iteration loss = 0.0030564496

Training iteration loss = 0.0034539162

Training iteration loss = 0.0030705358

Training iteration loss = 0.0018979312

Training iteration loss = 0.006452532

Training iteration loss = 0.0032010619

Training iteration loss = 0.0025762685

Training iteration loss = 0.0018887484

Training iteration loss = 0.0035862967

Training iteration loss = 0.003814795

Training iteration loss = 0.004125967

Training iteration loss = 0.0026958203

Training iteration loss = 0.005709535

Training iteration loss = 0.0033626708

Training iteration loss = 0.0026181063

Training iteration loss = 0.002150022

Training iteration loss = 0.0025291357

Training iteration loss = 0.0020478333

Training iteration loss = 0.0036265198

Training iteration loss = 0.002004692

Training iteration loss = 0.0021472594

Training iteration loss = 0.0036464625

Training iteration loss = 0.0030772893

Training iteration loss = 0.0035652556

Training iteration loss = 0.0027651219

Training iteration loss = 0.0043127337

Training iteration loss = 0.0041857515

Training iteration loss = 0.004601184

Training iteration loss = 0.002177675

Training iteration loss = 0.0030723696

Training iteration loss = 0.0025026158

Training iteration loss = 0.0038390234

Training iteration loss = 0.0035576608

Training iteration loss = 0.005013984

Training iteration loss = 0.0030811625

Training iteration loss = 0.0025055062

Training iteration loss = 0.0032139865

Training iteration loss = 0.005250947

Training iteration loss = 0.003466042

Training iteration loss = 0.0030289888

Training iteration loss = 0.0035362544

Training iteration loss = 0.0035176568

Training iteration loss = 0.0026387086

Training iteration loss = 0.0032505654

Training iteration loss = 0.00390758

Training iteration loss = 0.0030928783

Training iteration loss = 0.0033317895

Training iteration loss = 0.002975486

Training iteration loss = 0.0023874629

Training iteration loss = 0.00482533

Training iteration loss = 0.0046266974

Training iteration loss = 0.0039250855

Training iteration loss = 0.0035548483

Training iteration loss = 0.0023602652

Training iteration loss = 0.004879099

Training iteration loss = 0.0058138785

Training iteration loss = 0.0027191981

Training iteration loss = 0.0035142303

Training iteration loss = 0.0025498632

Training iteration loss = 0.0029609136

Training iteration loss = 0.0028882008

Training iteration loss = 0.0027665535

Training iteration loss = 0.0054533747

Training iteration loss = 0.0066310097

Training iteration loss = 0.0026592605

Training iteration loss = 0.0030883162

Training iteration loss = 0.0022621902

Training iteration loss = 0.0027392653

Training iteration loss = 0.0037285704

Training iteration loss = 0.0034362634

Training iteration loss = 0.0040758797

Training iteration loss = 0.0023863092

Training iteration loss = 0.004018526

Training iteration loss = 0.007764337

Training iteration loss = 0.005131018

Training iteration loss = 0.004080269

Training iteration loss = 0.0031385664

Training iteration loss = 0.003653583

Training iteration loss = 0.0026918761

Training iteration loss = 0.003584969

Training iteration loss = 0.002290386

Training iteration loss = 0.0027633617

Training iteration loss = 0.0028202375

Training iteration loss = 0.003439557

Training iteration loss = 0.0023109003

Training iteration loss = 0.004512316

Training iteration loss = 0.00359485

Training iteration loss = 0.0055992994

Training iteration loss = 0.0033504944

Training iteration loss = 0.0034328417

Training iteration loss = 0.0034555837

Training iteration loss = 0.007515441

Training iteration loss = 0.004724749

Training iteration loss = 0.0034832105

Training iteration loss = 0.002658276

Training iteration loss = 0.005577124

Training iteration loss = 0.0024123967

Training iteration loss = 0.002434865

Training iteration loss = 0.0028888367

Training iteration loss = 0.0037000934

Training iteration loss = 0.0031190559

Training iteration loss = 0.0040945583

Training iteration loss = 0.0038528943

Training iteration loss = 0.0021104666

Training iteration loss = 0.002911318

Training iteration loss = 0.0019828372

Training iteration loss = 0.0026871485

Training iteration loss = 0.0022075104

Training iteration loss = 0.002753311

Training iteration loss = 0.0036375972

Training iteration loss = 0.0035621703

Training iteration loss = 0.0048066373

Training iteration loss = 0.004158667

Training iteration loss = 0.0047110203

Training iteration loss = 0.0022515438

Training iteration loss = 0.0033252481

Training iteration loss = 0.002449367

Training iteration loss = 0.0065583936

Training iteration loss = 0.0039762226

Training iteration loss = 0.0030256463

Training iteration loss = 0.0029597252

Training iteration loss = 0.0036949143

Training iteration loss = 0.008255273

Training iteration loss = 0.0024071396

Training iteration loss = 0.003967048

Training iteration loss = 0.00392362

Training iteration loss = 0.0024751464

Training iteration loss = 0.0036976605

Training iteration loss = 0.003915092

Training iteration loss = 0.0029243545

Training iteration loss = 0.002569968

Training iteration loss = 0.0034377875

Training iteration loss = 0.004150597

Training iteration loss = 0.0038901595

Training iteration loss = 0.005175675

Training iteration loss = 0.005243518

Training iteration loss = 0.0032170822

Training iteration loss = 0.0039922926

Training iteration loss = 0.004999086

Training iteration loss = 0.0049346476

Training iteration loss = 0.003015654

Training iteration loss = 0.004017011

Training iteration loss = 0.0040991665

Training iteration loss = 0.0026874805

Training iteration loss = 0.0023317516

Training iteration loss = 0.0036956836

Training iteration loss = 0.0026278878

Training iteration loss = 0.0023801522

Training iteration loss = 0.0034173874

Training iteration loss = 0.0024079245

Training iteration loss = 0.0019864386

Training iteration loss = 0.001949383

Training iteration loss = 0.0032435004

Training iteration loss = 0.0021992028

Training iteration loss = 0.0025712282

Training iteration loss = 0.004156939

Training iteration loss = 0.005998336

Training iteration loss = 0.0026469578

Training iteration loss = 0.0028690519

Training iteration loss = 0.002544507

Training iteration loss = 0.0029137495

Training iteration loss = 0.0022943986

Training iteration loss = 0.004331567

Training iteration loss = 0.0034411065

Training iteration loss = 0.004973346

Training iteration loss = 0.004646235

Training iteration loss = 0.0030968047

Training iteration loss = 0.0020383259

Training iteration loss = 0.0021581892

Training iteration loss = 0.008627498

Training iteration loss = 0.0034654688

Training iteration loss = 0.0018400276

Training iteration loss = 0.0045640054

Training iteration loss = 0.0038229215

Training iteration loss = 0.0037652876

Training iteration loss = 0.0031455897

Training iteration loss = 0.004202212

Training iteration loss = 0.0024494834

Training iteration loss = 0.007221153

Training iteration loss = 0.0026931178

Training iteration loss = 0.0034052057

Training iteration loss = 0.004137701

Training iteration loss = 0.002248735

Training iteration loss = 0.0023113808

Training iteration loss = 0.0026439086

Training iteration loss = 0.0018952818

Training iteration loss = 0.0035584653

Training iteration loss = 0.003289451

Training iteration loss = 0.004193498

Training iteration loss = 0.0032501416

Training iteration loss = 0.002890261

Training iteration loss = 0.0022084892

Training iteration loss = 0.0023148453

Training iteration loss = 0.002462743

Training iteration loss = 0.0030740583

Training iteration loss = 0.005460679

Training iteration loss = 0.0020072164

Training iteration loss = 0.0030119584

Training iteration loss = 0.003130901

Training iteration loss = 0.0038610057

Training iteration loss = 0.0030450004

Training iteration loss = 0.003442426

Training iteration loss = 0.0030675773

Training iteration loss = 0.0019043563

Training iteration loss = 0.006429257

Training iteration loss = 0.0031755734

Training iteration loss = 0.0025868306

Training iteration loss = 0.0018929263

Training iteration loss = 0.003556759

Training iteration loss = 0.0038006816

Training iteration loss = 0.004099726

Training iteration loss = 0.002671534

Training iteration loss = 0.0057402155

Training iteration loss = 0.0033447098

Training iteration loss = 0.002590751

Training iteration loss = 0.0021443444

Training iteration loss = 0.002545873

Training iteration loss = 0.0020381613

Training iteration loss = 0.0035961836

Training iteration loss = 0.0019841248

Training iteration loss = 0.0021538313

Training iteration loss = 0.003651687

Training iteration loss = 0.003062401

Training iteration loss = 0.0035459753

Training iteration loss = 0.0027452465

Training iteration loss = 0.0043104147

Training iteration loss = 0.004184634

Training iteration loss = 0.0045723203

Training iteration loss = 0.002165647

Training iteration loss = 0.0030543727

Training iteration loss = 0.0024994975

Training iteration loss = 0.0038259795

Training iteration loss = 0.0035362206

Training iteration loss = 0.0050022393

Training iteration loss = 0.0030682494

Training iteration loss = 0.002510001

Training iteration loss = 0.0031972646

Training iteration loss = 0.0052138013

Training iteration loss = 0.003455352

Training iteration loss = 0.0030111035

Training iteration loss = 0.0035187758

Training iteration loss = 0.0034763794

Training iteration loss = 0.0026152993

Training iteration loss = 0.0032201263

Training iteration loss = 0.00388313

Training iteration loss = 0.0030675381

Training iteration loss = 0.0033160795

Training iteration loss = 0.0029651383

Training iteration loss = 0.002388513

Training iteration loss = 0.004790388

Training iteration loss = 0.0045708404

Training iteration loss = 0.0038955703

Training iteration loss = 0.0035595417

Training iteration loss = 0.0023473613

Training iteration loss = 0.004835948

Training iteration loss = 0.0057823895

Training iteration loss = 0.0026977435

Training iteration loss = 0.0034966662

Training iteration loss = 0.0025265694

Training iteration loss = 0.0029338368

Training iteration loss = 0.002874492

Training iteration loss = 0.0027437273

Training iteration loss = 0.00542374

Training iteration loss = 0.0065811393

Training iteration loss = 0.0026529587

Training iteration loss = 0.0030774698

Training iteration loss = 0.002263482

Training iteration loss = 0.0027371414

Training iteration loss = 0.0037051598

Training iteration loss = 0.00342823

Training iteration loss = 0.0040551084

Training iteration loss = 0.0023623446

Training iteration loss = 0.0040007513

Training iteration loss = 0.007752016

Training iteration loss = 0.00510899

Training iteration loss = 0.004049459

Training iteration loss = 0.0031312043

Training iteration loss = 0.0036280414

Training iteration loss = 0.0026821159

Training iteration loss = 0.003578265

Training iteration loss = 0.00228263

Training iteration loss = 0.0027639985

Training iteration loss = 0.0028032316

Training iteration loss = 0.0033752397

Training iteration loss = 0.0022874756

Training iteration loss = 0.0045157834

Training iteration loss = 0.003575818

Training iteration loss = 0.0055862316

Training iteration loss = 0.0033348587

Training iteration loss = 0.0034209972

Training iteration loss = 0.0034442476

Training iteration loss = 0.007482219

Training iteration loss = 0.0046659796

Training iteration loss = 0.0034759075

Training iteration loss = 0.0026443973

Training iteration loss = 0.0055478592

Training iteration loss = 0.0024050337

Training iteration loss = 0.0024391937

Training iteration loss = 0.002883723

Training iteration loss = 0.0036875962

Training iteration loss = 0.0030920506

Training iteration loss = 0.004089106

Training iteration loss = 0.003819526

Training iteration loss = 0.0020919086

Training iteration loss = 0.0028638544

Training iteration loss = 0.0019739938

Training iteration loss = 0.0026619465

Training iteration loss = 0.0021773

Training iteration loss = 0.002720978

Training iteration loss = 0.0036183645

Training iteration loss = 0.0035512291

Training iteration loss = 0.004785886

Training iteration loss = 0.004150744

Training iteration loss = 0.0046703345

Training iteration loss = 0.0022458017

Training iteration loss = 0.0033191459

Training iteration loss = 0.0024437339

Training iteration loss = 0.0065590986

Training iteration loss = 0.0039633526

Training iteration loss = 0.0030124336

Training iteration loss = 0.0029424753

Training iteration loss = 0.0036873787

Training iteration loss = 0.008211233

Training iteration loss = 0.0024113243

Training iteration loss = 0.003956607

Training iteration loss = 0.0038891956

Training iteration loss = 0.0024607128

Training iteration loss = 0.0036767877

Training iteration loss = 0.003908347

Training iteration loss = 0.0029112045

Training iteration loss = 0.0025605618

Training iteration loss = 0.0034179613

Training iteration loss = 0.0041248235

Training iteration loss = 0.0038869006

Training iteration loss = 0.005156394

Training iteration loss = 0.005196991

Training iteration loss = 0.0032061136

Training iteration loss = 0.003966239

Training iteration loss = 0.004964

Training iteration loss = 0.0049093454

Training iteration loss = 0.0030038625

Training iteration loss = 0.003987072

Training iteration loss = 0.004080706

Training iteration loss = 0.0026707975

Training iteration loss = 0.0023257236

Training iteration loss = 0.0036859568

Training iteration loss = 0.0026296638

Training iteration loss = 0.0023480859

Training iteration loss = 0.0033920922

Training iteration loss = 0.0024010623

Training iteration loss = 0.0019809855

Training iteration loss = 0.0019267186

Training iteration loss = 0.0032294837

Training iteration loss = 0.0021820243

Training iteration loss = 0.0025565291

Training iteration loss = 0.0041507245

Training iteration loss = 0.005934547

Training iteration loss = 0.0026303856

Training iteration loss = 0.0028609252

Training iteration loss = 0.0025444871

Training iteration loss = 0.0028911515

Training iteration loss = 0.0022810588

Training iteration loss = 0.0043188953

Training iteration loss = 0.0034451846

Training iteration loss = 0.0049575907

Training iteration loss = 0.004594588

Training iteration loss = 0.003071256

Training iteration loss = 0.002040354

Training iteration loss = 0.0021592276

Training iteration loss = 0.008603232

Training iteration loss = 0.0034252687

Training iteration loss = 0.0018476987

Training iteration loss = 0.0045276103

Training iteration loss = 0.003811002

Training iteration loss = 0.0037435929

Training iteration loss = 0.0031410113

Training iteration loss = 0.004189876

Training iteration loss = 0.002433534

Training iteration loss = 0.0071824007

Training iteration loss = 0.002682165

Training iteration loss = 0.0034030445

Training iteration loss = 0.004126242

Training iteration loss = 0.0022353728

Training iteration loss = 0.00230322

Training iteration loss = 0.0026390434

Training iteration loss = 0.0018711084

Training iteration loss = 0.003542588

Training iteration loss = 0.003275662

Training iteration loss = 0.00420778

Training iteration loss = 0.0032369324

Training iteration loss = 0.0028791751

Training iteration loss = 0.002204154

Training iteration loss = 0.002296996

Training iteration loss = 0.0024586474

Training iteration loss = 0.0030821676

Training iteration loss = 0.005415416

Training iteration loss = 0.00198855

Training iteration loss = 0.003002141

Training iteration loss = 0.0031267416

Training iteration loss = 0.0038332331

Training iteration loss = 0.0030373784

Training iteration loss = 0.0034300264

Training iteration loss = 0.0030577902

Training iteration loss = 0.0019106922

Training iteration loss = 0.0064148325

Training iteration loss = 0.0031499898

Training iteration loss = 0.0025910356

Training iteration loss = 0.0018941178

Training iteration loss = 0.0035332313

Training iteration loss = 0.0037893679

Training iteration loss = 0.004063587

Training iteration loss = 0.0026449838

Training iteration loss = 0.0057645966

Training iteration loss = 0.0033309646

Training iteration loss = 0.0025630984

Training iteration loss = 0.0021297128

Training iteration loss = 0.0025537526

Training iteration loss = 0.0020348912

Training iteration loss = 0.0035723562

Training iteration loss = 0.001961866

Training iteration loss = 0.0021507097

Training iteration loss = 0.0036570774

Training iteration loss = 0.003054803

Training iteration loss = 0.0035342763

Training iteration loss = 0.0027258804

Training iteration loss = 0.004298341

Training iteration loss = 0.0041868114

Training iteration loss = 0.0045520454

Training iteration loss = 0.0021553154

Training iteration loss = 0.0030321078

Training iteration loss = 0.0024930409

Training iteration loss = 0.0038193718

Training iteration loss = 0.003519933

Training iteration loss = 0.0049887905

Training iteration loss = 0.0030533725

Training iteration loss = 0.0025168613

Training iteration loss = 0.0031885533

Training iteration loss = 0.005178246

Training iteration loss = 0.003439827

Training iteration loss = 0.0029922181

Training iteration loss = 0.003506236

Training iteration loss = 0.0034434712

Training iteration loss = 0.0025882714

Training iteration loss = 0.0031898106

Training iteration loss = 0.0038641447

Training iteration loss = 0.0030499955

Training iteration loss = 0.0033015169

Training iteration loss = 0.0029532143

Training iteration loss = 0.0023916026

Training iteration loss = 0.004761443

Training iteration loss = 0.004518406

Training iteration loss = 0.0038694057

Training iteration loss = 0.003569046

Training iteration loss = 0.0023318883

Training iteration loss = 0.004800771

Training iteration loss = 0.0057532187

Training iteration loss = 0.0026760427

Training iteration loss = 0.0034834817

Training iteration loss = 0.0025073064

Training iteration loss = 0.0029050934

Training iteration loss = 0.0028620681

Training iteration loss = 0.0027215627

Training iteration loss = 0.0053957454

Training iteration loss = 0.0065342

Training iteration loss = 0.0026446914

Training iteration loss = 0.0030666387

Training iteration loss = 0.0022648287

Training iteration loss = 0.0027344197

Training iteration loss = 0.003683604

Training iteration loss = 0.003416089

Training iteration loss = 0.0040338854

Training iteration loss = 0.0023452525

Training iteration loss = 0.0039821374

Training iteration loss = 0.007744296

Training iteration loss = 0.0050830934

Training iteration loss = 0.004022676

Training iteration loss = 0.0031247188

Training iteration loss = 0.0036052775

Training iteration loss = 0.0026760942

Training iteration loss = 0.0035729574

Training iteration loss = 0.00227498

Training iteration loss = 0.0027650443

Training iteration loss = 0.0027903682

Training iteration loss = 0.0033172583

Training iteration loss = 0.0022650172

Training iteration loss = 0.004517265

Training iteration loss = 0.003560974

Training iteration loss = 0.0055688857

Training iteration loss = 0.0033180339

Training iteration loss = 0.0034063577

Training iteration loss = 0.0034328923

Training iteration loss = 0.007449282

Training iteration loss = 0.0046089864

Training iteration loss = 0.0034680404

Training iteration loss = 0.0026310878

Training iteration loss = 0.005521839

Training iteration loss = 0.002398046

Training iteration loss = 0.0024409266

Training iteration loss = 0.0028798312

Training iteration loss = 0.003672404

Training iteration loss = 0.0030651025

Training iteration loss = 0.0040785535

Training iteration loss = 0.0037887634

Training iteration loss = 0.0020762046

Training iteration loss = 0.0028181141

Training iteration loss = 0.0019639884

Training iteration loss = 0.0026412315

Training iteration loss = 0.0021530532

Training iteration loss = 0.0026961656

Training iteration loss = 0.0036008868

Training iteration loss = 0.0035414149

Training iteration loss = 0.004767018

Training iteration loss = 0.004141461

Training iteration loss = 0.0046349796

Training iteration loss = 0.0022396466

Training iteration loss = 0.0033115929

Training iteration loss = 0.0024403897

Training iteration loss = 0.0065548816

Training iteration loss = 0.003946002

Training iteration loss = 0.0030006748

Training iteration loss = 0.002925521

Training iteration loss = 0.003681327

Training iteration loss = 0.008162028

Training iteration loss = 0.0024129986

Training iteration loss = 0.0039463663

Training iteration loss = 0.0038529274

Training iteration loss = 0.0024480657

Training iteration loss = 0.0036612272

Training iteration loss = 0.003902335

Training iteration loss = 0.0028973569

Training iteration loss = 0.002552957

Training iteration loss = 0.003403469

Training iteration loss = 0.0041018655

Training iteration loss = 0.0038810195

Training iteration loss = 0.0051378584

Training iteration loss = 0.0051623383

Training iteration loss = 0.0031996965

Training iteration loss = 0.0039371704

Training iteration loss = 0.004931439

Training iteration loss = 0.004885347

Training iteration loss = 0.0029965956

Training iteration loss = 0.003959372

Training iteration loss = 0.0040638745

Training iteration loss = 0.0026535795

Training iteration loss = 0.002315651

Training iteration loss = 0.003679581

Training iteration loss = 0.002628765

Training iteration loss = 0.0023180686

Training iteration loss = 0.0033637893

Training iteration loss = 0.002389481

Training iteration loss = 0.0019787217

Training iteration loss = 0.0019075334

Training iteration loss = 0.003217121

Training iteration loss = 0.0021650742

Training iteration loss = 0.002539431

Training iteration loss = 0.0041452656

Training iteration loss = 0.0058779814

Training iteration loss = 0.0026151864

Training iteration loss = 0.002853471

Training iteration loss = 0.0025464834

Training iteration loss = 0.002872779

Training iteration loss = 0.0022703302

Training iteration loss = 0.0043062307

Training iteration loss = 0.0034474032

Training iteration loss = 0.004947513

Training iteration loss = 0.004539885

Training iteration loss = 0.0030467196

Training iteration loss = 0.0020417687

Training iteration loss = 0.002162731

Training iteration loss = 0.008584757

Training iteration loss = 0.003386559

Training iteration loss = 0.0018491497

Training iteration loss = 0.004498447

Training iteration loss = 0.003802677

Training iteration loss = 0.0037215676

Training iteration loss = 0.003136385

Training iteration loss = 0.004178618

Training iteration loss = 0.0024203092

Training iteration loss = 0.007148135

Training iteration loss = 0.0026691156

Training iteration loss = 0.0034005034

Training iteration loss = 0.0041178144

Training iteration loss = 0.0022270489

Training iteration loss = 0.0022960843

Training iteration loss = 0.0026344953

Training iteration loss = 0.0018499346

Training iteration loss = 0.0035285533

Training iteration loss = 0.003265483

Training iteration loss = 0.004222589

Training iteration loss = 0.0032240527

Training iteration loss = 0.0028716384

Training iteration loss = 0.002201696

Training iteration loss = 0.002281273

Training iteration loss = 0.0024535507

Training iteration loss = 0.0030886338

Training iteration loss = 0.0053752996

Training iteration loss = 0.0019731896

Training iteration loss = 0.002990476

Training iteration loss = 0.003121142

Training iteration loss = 0.003809097

Training iteration loss = 0.0030350273

Training iteration loss = 0.003419439

Training iteration loss = 0.0030429305

Training iteration loss = 0.0019146766

Training iteration loss = 0.006405454

Training iteration loss = 0.003129353

Training iteration loss = 0.0025937953

Training iteration loss = 0.0018911568

Training iteration loss = 0.0035130454

Training iteration loss = 0.0037806353

Training iteration loss = 0.0040253755

Training iteration loss = 0.0026182309

Training iteration loss = 0.005780427

Training iteration loss = 0.0033190332

Training iteration loss = 0.00253997

Training iteration loss = 0.002112456

Training iteration loss = 0.0025556283

Training iteration loss = 0.0020337163

Training iteration loss = 0.0035532897

Training iteration loss = 0.0019430402

Training iteration loss = 0.002142161

Training iteration loss = 0.0036584276

Training iteration loss = 0.003050208

Training iteration loss = 0.0035283433

Training iteration loss = 0.0027094635

Training iteration loss = 0.0042801835

Training iteration loss = 0.004187889

Training iteration loss = 0.004539986

Training iteration loss = 0.0021476496

Training iteration loss = 0.0030087754

Training iteration loss = 0.0024839065

Training iteration loss = 0.003816709

Training iteration loss = 0.0035086144

Training iteration loss = 0.0049746237

Training iteration loss = 0.00303653

Training iteration loss = 0.002522778

Training iteration loss = 0.0031828173

Training iteration loss = 0.005147875

Training iteration loss = 0.0034233087

Training iteration loss = 0.0029730403

Training iteration loss = 0.003496319

Training iteration loss = 0.0034191571

Training iteration loss = 0.002563928

Training iteration loss = 0.003159579

Training iteration loss = 0.0038498947

Training iteration loss = 0.0030392613

Training iteration loss = 0.0032919582

Training iteration loss = 0.0029410552

Training iteration loss = 0.0023952082

Training iteration loss = 0.004737597

Training iteration loss = 0.0044744457

Training iteration loss = 0.0038486393

Training iteration loss = 0.003582512

Training iteration loss = 0.0023155678

Training iteration loss = 0.0047734813

Training iteration loss = 0.0057267975

Training iteration loss = 0.002655056

Training iteration loss = 0.0034741322

Training iteration loss = 0.0024912874

Training iteration loss = 0.002874945

Training iteration loss = 0.0028507493

Training iteration loss = 0.0027017817

Training iteration loss = 0.0053702085

Training iteration loss = 0.0064895577

Training iteration loss = 0.0026361838

Training iteration loss = 0.0030562088

Training iteration loss = 0.0022664592

Training iteration loss = 0.0027302883

Training iteration loss = 0.003664896

Training iteration loss = 0.0034043603

Training iteration loss = 0.0040143416

Training iteration loss = 0.0023322527

Training iteration loss = 0.0039635515

Training iteration loss = 0.007738029

Training iteration loss = 0.005056486

Training iteration loss = 0.0039997366

Training iteration loss = 0.0031179811

Training iteration loss = 0.0035840396

Training iteration loss = 0.002672495

Training iteration loss = 0.0035693932

Training iteration loss = 0.002267199

Training iteration loss = 0.002765092

Training iteration loss = 0.0027805082

Training iteration loss = 0.0032654062

Training iteration loss = 0.0022442772

Training iteration loss = 0.004515587

Training iteration loss = 0.0035493094

Training iteration loss = 0.00555056

Training iteration loss = 0.0033011828

Training iteration loss = 0.0033904107

Training iteration loss = 0.0034239225

Training iteration loss = 0.007416554

Training iteration loss = 0.0045545273

Training iteration loss = 0.0034590878

Training iteration loss = 0.0026182702

Training iteration loss = 0.005500171

Training iteration loss = 0.002391822

Training iteration loss = 0.0024400493

Training iteration loss = 0.0028763935

Training iteration loss = 0.0036563494

Training iteration loss = 0.003038479

Training iteration loss = 0.004063157

Training iteration loss = 0.0037608724

Training iteration loss = 0.0020629445

Training iteration loss = 0.0027766305

Training iteration loss = 0.0019527607

Training iteration loss = 0.0026232207

Training iteration loss = 0.0021332894

Training iteration loss = 0.002677819

Training iteration loss = 0.0035839074

Training iteration loss = 0.003530711

Training iteration loss = 0.0047483705

Training iteration loss = 0.0041316897

Training iteration loss = 0.0046049263

Training iteration loss = 0.002233869

Training iteration loss = 0.0033032252

Training iteration loss = 0.0024387997

Training iteration loss = 0.006548638

Training iteration loss = 0.0039274055

Training iteration loss = 0.0029916156

Training iteration loss = 0.0029120578

Training iteration loss = 0.0036771744

Training iteration loss = 0.0081191985

Training iteration loss = 0.002412523

Training iteration loss = 0.0039371136

Training iteration loss = 0.00381865

Training iteration loss = 0.0024359745

Training iteration loss = 0.0036475693

Training iteration loss = 0.003896334

Training iteration loss = 0.0028834154

Training iteration loss = 0.0025469626

Training iteration loss = 0.003390719

Training iteration loss = 0.0040809666

Training iteration loss = 0.0038740216

Training iteration loss = 0.005117761

Training iteration loss = 0.00513796

Training iteration loss = 0.0031966018

Training iteration loss = 0.003910977

Training iteration loss = 0.0049035386

Training iteration loss = 0.0048672925

Training iteration loss = 0.002991502

Training iteration loss = 0.0039340206

Training iteration loss = 0.004047384

Training iteration loss = 0.0026399754

Training iteration loss = 0.0023041496

Training iteration loss = 0.0036728524

Training iteration loss = 0.0026285024

Training iteration loss = 0.0022917066

Training iteration loss = 0.0033368403

Training iteration loss = 0.0023775822

Training iteration loss = 0.0019778477

Training iteration loss = 0.0018925518

Training iteration loss = 0.0032061862

Training iteration loss = 0.0021484904

Training iteration loss = 0.0025204278

Training iteration loss = 0.0041404855

Training iteration loss = 0.005828632

Training iteration loss = 0.0026023916

Training iteration loss = 0.002846336

Training iteration loss = 0.00254799

Training iteration loss = 0.002856728

Training iteration loss = 0.0022614559

Training iteration loss = 0.004294056

Training iteration loss = 0.003449573

Training iteration loss = 0.004941248

Training iteration loss = 0.0044878023

Training iteration loss = 0.0030232586

Training iteration loss = 0.0020434945

Training iteration loss = 0.0021686633

Training iteration loss = 0.0085686045

Training iteration loss = 0.00335079

Training iteration loss = 0.0018515574

Training iteration loss = 0.0044725235

Training iteration loss = 0.0037981907

Training iteration loss = 0.003701851

Training iteration loss = 0.0031331033

Training iteration loss = 0.0041690334

Training iteration loss = 0.0024097075

Training iteration loss = 0.0071171005

Training iteration loss = 0.0026547555

Training iteration loss = 0.0033968084

Training iteration loss = 0.004109128

Training iteration loss = 0.0022225042

Training iteration loss = 0.0022905937

Training iteration loss = 0.002632316

Training iteration loss = 0.0018310308

Training iteration loss = 0.0035157956

Training iteration loss = 0.0032584069

Training iteration loss = 0.0042382465

Training iteration loss = 0.0032115977

Training iteration loss = 0.0028666763

Training iteration loss = 0.00219965

Training iteration loss = 0.0022704327

Training iteration loss = 0.0024480906

Training iteration loss = 0.0030931074

Training iteration loss = 0.005336026

Training iteration loss = 0.0019609076

Training iteration loss = 0.0029806234

Training iteration loss = 0.0031138838

Training iteration loss = 0.0037863774

Training iteration loss = 0.0030373735

Training iteration loss = 0.0034112714

Training iteration loss = 0.0030257944

Training iteration loss = 0.0019157241

Training iteration loss = 0.006401682

Training iteration loss = 0.0031140435

Training iteration loss = 0.0025972193

Training iteration loss = 0.0018867761

Training iteration loss = 0.0034959847

Training iteration loss = 0.0037742276

Training iteration loss = 0.0039899363

Training iteration loss = 0.0025936163

Training iteration loss = 0.0057872646

Training iteration loss = 0.0033065453

Training iteration loss = 0.002518684

Training iteration loss = 0.0020945005

Training iteration loss = 0.0025506762

Training iteration loss = 0.0020322534

Training iteration loss = 0.0035349198

Training iteration loss = 0.0019286914

Training iteration loss = 0.00213278

Training iteration loss = 0.003661435

Training iteration loss = 0.003045142

Training iteration loss = 0.0035285486

Training iteration loss = 0.0026985158

Training iteration loss = 0.0042637717

Training iteration loss = 0.0041880016

Training iteration loss = 0.0045296117

Training iteration loss = 0.0021433474

Training iteration loss = 0.0029886875

Training iteration loss = 0.0024750482

Training iteration loss = 0.0038149285

Training iteration loss = 0.0035001107

Training iteration loss = 0.0049641277

Training iteration loss = 0.0030237508

Training iteration loss = 0.002528416

Training iteration loss = 0.003181204

Training iteration loss = 0.005125623

Training iteration loss = 0.0034078564

Training iteration loss = 0.002954289

Training iteration loss = 0.0034884943

Training iteration loss = 0.0034058525

Training iteration loss = 0.0025500853

Training iteration loss = 0.003134247

Training iteration loss = 0.0038371915

Training iteration loss = 0.0030330003

Training iteration loss = 0.0032860024

Training iteration loss = 0.002931187

Training iteration loss = 0.0023997657

Training iteration loss = 0.004717589

Training iteration loss = 0.0044422974

Training iteration loss = 0.0038326571

Training iteration loss = 0.003598907

Training iteration loss = 0.0023017616

Training iteration loss = 0.004754226

Training iteration loss = 0.005704854

Training iteration loss = 0.0026380883

Training iteration loss = 0.0034708788

Training iteration loss = 0.0024785334

Training iteration loss = 0.0028472415

Training iteration loss = 0.002840347

Training iteration loss = 0.0026879727

Training iteration loss = 0.005346218

Training iteration loss = 0.0064512156

Training iteration loss = 0.0026295707

Training iteration loss = 0.0030450288

Training iteration loss = 0.0022681816

Training iteration loss = 0.0027230948

Training iteration loss = 0.0036460415

Training iteration loss = 0.0033942524

Training iteration loss = 0.003995918

Training iteration loss = 0.0023227762

Training iteration loss = 0.0039450787

Training iteration loss = 0.00771671

Training iteration loss = 0.0050307284

Training iteration loss = 0.003981855

Training iteration loss = 0.0031115592

Training iteration loss = 0.0035647054

Training iteration loss = 0.002671139

Training iteration loss = 0.0035695268

Training iteration loss = 0.002261371

Training iteration loss = 0.002764685

Training iteration loss = 0.0027742304

Training iteration loss = 0.0032218844

Training iteration loss = 0.0022275026

Training iteration loss = 0.0045107813

Training iteration loss = 0.0035388947

Training iteration loss = 0.0055346754

Training iteration loss = 0.0032881058

Training iteration loss = 0.0033770641

Training iteration loss = 0.003412814

Training iteration loss = 0.007386511

Training iteration loss = 0.0045053107

Training iteration loss = 0.0034507718

Training iteration loss = 0.0026080597

Training iteration loss = 0.0054863766

Training iteration loss = 0.0023867816

Training iteration loss = 0.002438001

Training iteration loss = 0.0028725388

Training iteration loss = 0.0036408668

Training iteration loss = 0.0030158872

Training iteration loss = 0.004046394

Training iteration loss = 0.003737281

Training iteration loss = 0.002054465

Training iteration loss = 0.0027402584

Training iteration loss = 0.0019434717

Training iteration loss = 0.0026091405

Training iteration loss = 0.0021194795

Training iteration loss = 0.002664312

Training iteration loss = 0.003568464

Training iteration loss = 0.0035210736

Training iteration loss = 0.0047318474

Training iteration loss = 0.004122181

Training iteration loss = 0.0045802905

Training iteration loss = 0.0022288703

Training iteration loss = 0.0032940859

Training iteration loss = 0.0024376686

Training iteration loss = 0.0065274425

Training iteration loss = 0.003902111

Training iteration loss = 0.0029847894

Training iteration loss = 0.0029007494

Training iteration loss = 0.0036768902

Training iteration loss = 0.00804031

Training iteration loss = 0.002405661

Training iteration loss = 0.0039279154

Training iteration loss = 0.003795318

Training iteration loss = 0.0024346034

Training iteration loss = 0.003649476

Training iteration loss = 0.003894448

Training iteration loss = 0.0028771784

Training iteration loss = 0.0025439647

Training iteration loss = 0.0033895879

Training iteration loss = 0.0040781093

Training iteration loss = 0.003867434

Training iteration loss = 0.005091127

Training iteration loss = 0.0051202257

Training iteration loss = 0.0031986665

Training iteration loss = 0.0038791317

Training iteration loss = 0.0048700594

Training iteration loss = 0.0048357677

Training iteration loss = 0.0029918419

Training iteration loss = 0.003909257

Training iteration loss = 0.004037264

Training iteration loss = 0.0026189971

Training iteration loss = 0.0022918447

Training iteration loss = 0.0036789523

Training iteration loss = 0.0026129282

Training iteration loss = 0.0022739682

Training iteration loss = 0.003304228

Training iteration loss = 0.0023629942

Training iteration loss = 0.0019822961

Training iteration loss = 0.0018808305

Training iteration loss = 0.0031940911

Training iteration loss = 0.0021392156

Training iteration loss = 0.0025038142

Training iteration loss = 0.0041376534

Training iteration loss = 0.0057783164

Training iteration loss = 0.0025888016

Training iteration loss = 0.0028435362

Training iteration loss = 0.0025589566

Training iteration loss = 0.002855038

Training iteration loss = 0.0022552067

Training iteration loss = 0.0042868834

Training iteration loss = 0.0034532973

Training iteration loss = 0.0049408465

Training iteration loss = 0.004438902

Training iteration loss = 0.0030067686

Training iteration loss = 0.0020442202

Training iteration loss = 0.0021727877

Training iteration loss = 0.008559425

Training iteration loss = 0.0033249175

Training iteration loss = 0.0018461562

Training iteration loss = 0.0044531343

Training iteration loss = 0.0037958806

Training iteration loss = 0.0036831973

Training iteration loss = 0.003128199

Training iteration loss = 0.004156292

Training iteration loss = 0.0023991468

Training iteration loss = 0.007084349

Training iteration loss = 0.0026403994

Training iteration loss = 0.0033943886

Training iteration loss = 0.004102331

Training iteration loss = 0.002220562

Training iteration loss = 0.0022875366

Training iteration loss = 0.0026312387

Training iteration loss = 0.0018154072

Training iteration loss = 0.003503966

Training iteration loss = 0.0032519635

Training iteration loss = 0.004250912

Training iteration loss = 0.0032009704

Training iteration loss = 0.0028653257

Training iteration loss = 0.002199341

Training iteration loss = 0.0022622384

Training iteration loss = 0.0024451816

Training iteration loss = 0.0030984674

Training iteration loss = 0.0052991956

Training iteration loss = 0.0019526755

Training iteration loss = 0.0029704918

Training iteration loss = 0.0031062234

Training iteration loss = 0.0037640186

Training iteration loss = 0.00304314

Training iteration loss = 0.0034049265

Training iteration loss = 0.0030082436

Training iteration loss = 0.001916349

Training iteration loss = 0.00639998

Training iteration loss = 0.003101309

Training iteration loss = 0.002599479

Training iteration loss = 0.0018847479

Training iteration loss = 0.0034842566

Training iteration loss = 0.0037698941

Training iteration loss = 0.003959585

Training iteration loss = 0.0025763947

Training iteration loss = 0.005793793

Training iteration loss = 0.003297951

Training iteration loss = 0.00250352

Training iteration loss = 0.002078828

Training iteration loss = 0.0025447833

Training iteration loss = 0.002030194

Training iteration loss = 0.0035197397

Training iteration loss = 0.0019180287

Training iteration loss = 0.002122419

Training iteration loss = 0.0036576937

Training iteration loss = 0.0030412078

Training iteration loss = 0.0035323908

Training iteration loss = 0.0026929593

Training iteration loss = 0.0042403797

Training iteration loss = 0.004186276

Training iteration loss = 0.004529893

Training iteration loss = 0.002139034

Training iteration loss = 0.0029707009

Training iteration loss = 0.0024664912

Training iteration loss = 0.0038106993

Training iteration loss = 0.003496019

Training iteration loss = 0.004950453

Training iteration loss = 0.0030080136

Training iteration loss = 0.0025303538

Training iteration loss = 0.0031757012

Training iteration loss = 0.005103869

Training iteration loss = 0.0033950189

Training iteration loss = 0.002939687

Training iteration loss = 0.0034808668

Training iteration loss = 0.0033953332

Training iteration loss = 0.002534902

Training iteration loss = 0.003105348

Training iteration loss = 0.0038313137

Training iteration loss = 0.0030289933

Training iteration loss = 0.0032851973

Training iteration loss = 0.0029205151

Training iteration loss = 0.002402482

Training iteration loss = 0.0046997513

Training iteration loss = 0.0044105756

Training iteration loss = 0.0038231306

Training iteration loss = 0.0036126121

Training iteration loss = 0.002290277

Training iteration loss = 0.0047369394

Training iteration loss = 0.0056856363

Training iteration loss = 0.002620372

Training iteration loss = 0.0034660539

Training iteration loss = 0.0024684542

Training iteration loss = 0.002817693

Training iteration loss = 0.0028300646

Training iteration loss = 0.0026755696

Training iteration loss = 0.0053273723

Training iteration loss = 0.0064127226

Training iteration loss = 0.0026213846

Training iteration loss = 0.0030350953

Training iteration loss = 0.0022708757

Training iteration loss = 0.0027156884

Training iteration loss = 0.0036307282

Training iteration loss = 0.0033871813

Training iteration loss = 0.003982072

Training iteration loss = 0.00231437

Training iteration loss = 0.003926325

Training iteration loss = 0.0077045285

Training iteration loss = 0.0050089094

Training iteration loss = 0.003967349

Training iteration loss = 0.0031041084

Training iteration loss = 0.003548579

Training iteration loss = 0.0026688736

Training iteration loss = 0.0035670586

Training iteration loss = 0.0022532747

Training iteration loss = 0.0027607938

Training iteration loss = 0.0027671729

Training iteration loss = 0.0031810661

Training iteration loss = 0.002212392

Training iteration loss = 0.004505582

Training iteration loss = 0.0035310872

Training iteration loss = 0.005520379

Training iteration loss = 0.0032719774

Training iteration loss = 0.0033615837

Training iteration loss = 0.003409336

Training iteration loss = 0.0073554926

Training iteration loss = 0.004461149

Training iteration loss = 0.0034414732

Training iteration loss = 0.0025975676

Training iteration loss = 0.0054713185

Training iteration loss = 0.0023823013

Training iteration loss = 0.0024345035

Training iteration loss = 0.0028682007

Training iteration loss = 0.0036266178

Training iteration loss = 0.002993564

Training iteration loss = 0.0040283906

Training iteration loss = 0.0037174115

Training iteration loss = 0.002043362

Training iteration loss = 0.002710568

Training iteration loss = 0.001933125

Training iteration loss = 0.0025944961

Training iteration loss = 0.002106708

Training iteration loss = 0.0026533229

Training iteration loss = 0.003551738

Training iteration loss = 0.0035110526

Training iteration loss = 0.0047135535

Training iteration loss = 0.0041151643

Training iteration loss = 0.0045605847

Training iteration loss = 0.0022246707

Training iteration loss = 0.0032850134

Training iteration loss = 0.0024370935

Training iteration loss = 0.0065199784

Training iteration loss = 0.0038871225

Training iteration loss = 0.002980007

Training iteration loss = 0.0028920276

Training iteration loss = 0.0036735714

Training iteration loss = 0.008022358

Training iteration loss = 0.0024041224

Training iteration loss = 0.0039207907

Training iteration loss = 0.003766836

Training iteration loss = 0.0024196415

Training iteration loss = 0.0036319

Training iteration loss = 0.0038864787

Training iteration loss = 0.0028650172

Training iteration loss = 0.0025405118

Training iteration loss = 0.0033759472

Training iteration loss = 0.0040570586

Training iteration loss = 0.0038588548

Training iteration loss = 0.0050696186

Training iteration loss = 0.0051106396

Training iteration loss = 0.0031963047

Training iteration loss = 0.0038646956

Training iteration loss = 0.004848423

Training iteration loss = 0.0048322286

Training iteration loss = 0.0029891236

Training iteration loss = 0.0038920979

Training iteration loss = 0.004021768

Training iteration loss = 0.002616123

Training iteration loss = 0.0022829985

Training iteration loss = 0.0036662545

Training iteration loss = 0.002615454

Training iteration loss = 0.0022559434

Training iteration loss = 0.003285969

Training iteration loss = 0.002355371

Training iteration loss = 0.0019805783

Training iteration loss = 0.0018741069

Training iteration loss = 0.0031869148

Training iteration loss = 0.0021254881

Training iteration loss = 0.0024851223

Training iteration loss = 0.004134081

Training iteration loss = 0.005750412

Training iteration loss = 0.002581807

Training iteration loss = 0.0028402908

Training iteration loss = 0.0025577913

Training iteration loss = 0.0028429043

Training iteration loss = 0.0022476737

Training iteration loss = 0.0042730216

Training iteration loss = 0.0034561271

Training iteration loss = 0.0049346904

Training iteration loss = 0.004395325

Training iteration loss = 0.0029882065

Training iteration loss = 0.0020462458

Training iteration loss = 0.0021800138

Training iteration loss = 0.008549748

Training iteration loss = 0.0032964705

Training iteration loss = 0.0018523321

Training iteration loss = 0.0044312007

Training iteration loss = 0.0037950054

Training iteration loss = 0.003665667

Training iteration loss = 0.0031278916

Training iteration loss = 0.004150432

Training iteration loss = 0.0023924184

Training iteration loss = 0.0070541413

Training iteration loss = 0.0026271325

Training iteration loss = 0.00338806

Training iteration loss = 0.004091255

Training iteration loss = 0.002219543

Training iteration loss = 0.002284688

Training iteration loss = 0.0026334785

Training iteration loss = 0.0018027312

Training iteration loss = 0.0034958487

Training iteration loss = 0.0032457486

Training iteration loss = 0.0042583086

Training iteration loss = 0.003191557

Training iteration loss = 0.0028609845

Training iteration loss = 0.0021970565

Training iteration loss = 0.0022545797

Training iteration loss = 0.0024425343

Training iteration loss = 0.0031026807

Training iteration loss = 0.005270938

Training iteration loss = 0.0019470663

Training iteration loss = 0.0029602144

Training iteration loss = 0.003101334

Training iteration loss = 0.0037424404

Training iteration loss = 0.0030441012

Training iteration loss = 0.0034026525

Training iteration loss = 0.0029897925

Training iteration loss = 0.0019138643

Training iteration loss = 0.006388031

Training iteration loss = 0.0030942168

Training iteration loss = 0.002602448

Training iteration loss = 0.001875346

Training iteration loss = 0.0034702716

Training iteration loss = 0.003760941

Training iteration loss = 0.00392855

Training iteration loss = 0.0025593187

Training iteration loss = 0.0057911575

Training iteration loss = 0.0032855114

Training iteration loss = 0.0024902388

Training iteration loss = 0.0020661638

Training iteration loss = 0.0025434715

Training iteration loss = 0.0020277845

Training iteration loss = 0.003507143

Training iteration loss = 0.0019095057

Training iteration loss = 0.0021120992

Training iteration loss = 0.0036451372

Training iteration loss = 0.003036771

Training iteration loss = 0.003525585

Training iteration loss = 0.0026852477

Training iteration loss = 0.004228219

Training iteration loss = 0.00418333

Training iteration loss = 0.0045359773

Training iteration loss = 0.002137386

Training iteration loss = 0.002956386

Training iteration loss = 0.0024575402

Training iteration loss = 0.003809905

Training iteration loss = 0.003493781

Training iteration loss = 0.0049396995

Training iteration loss = 0.0029895771

Training iteration loss = 0.0025269764

Training iteration loss = 0.0031689482

Training iteration loss = 0.005084029

Training iteration loss = 0.0033837382

Training iteration loss = 0.0029279

Training iteration loss = 0.0034737706

Training iteration loss = 0.0033845159

Training iteration loss = 0.0025222476

Training iteration loss = 0.0030761745

Training iteration loss = 0.0038278245

Training iteration loss = 0.0030267623

Training iteration loss = 0.003287116

Training iteration loss = 0.0029086962

Training iteration loss = 0.0024035543

Training iteration loss = 0.0046864357

Training iteration loss = 0.0043951315

Training iteration loss = 0.0038176298

Training iteration loss = 0.0036297801

Training iteration loss = 0.0022819212

Training iteration loss = 0.004723692

Training iteration loss = 0.005667483

Training iteration loss = 0.0026041511

Training iteration loss = 0.0034634226

Training iteration loss = 0.0024625063

Training iteration loss = 0.002788097

Training iteration loss = 0.002820111

Training iteration loss = 0.0026668946

Training iteration loss = 0.005313959

Training iteration loss = 0.006377891

Training iteration loss = 0.00261377

Training iteration loss = 0.003024738

Training iteration loss = 0.0022740243

Training iteration loss = 0.0027089354

Training iteration loss = 0.0036165367

Training iteration loss = 0.0033813715

Training iteration loss = 0.0039707604

Training iteration loss = 0.0023071899

Training iteration loss = 0.0039094184

Training iteration loss = 0.007691584

Training iteration loss = 0.004990672

Training iteration loss = 0.0039556925

Training iteration loss = 0.0030970601

Training iteration loss = 0.0035354632

Training iteration loss = 0.002666936

Training iteration loss = 0.0035640423

Training iteration loss = 0.002245135

Training iteration loss = 0.002755724

Training iteration loss = 0.0027587258

Training iteration loss = 0.0031441422

Training iteration loss = 0.002198612

Training iteration loss = 0.004498959

Training iteration loss = 0.0035217276

Training iteration loss = 0.005508181

Training iteration loss = 0.0032583515

Training iteration loss = 0.003348518

Training iteration loss = 0.0034038427

Training iteration loss = 0.007327354

Training iteration loss = 0.00442387

Training iteration loss = 0.0034337633

Training iteration loss = 0.0025879696

Training iteration loss = 0.005458089

Training iteration loss = 0.002378406

Training iteration loss = 0.0024305442

Training iteration loss = 0.0028641366

Training iteration loss = 0.003614717

Training iteration loss = 0.0029756625

Training iteration loss = 0.0040129013

Training iteration loss = 0.003701234

Training iteration loss = 0.0020334767

Training iteration loss = 0.0026876803

Training iteration loss = 0.0019241258

Training iteration loss = 0.002580651

Training iteration loss = 0.00209474

Training iteration loss = 0.0026425645

Training iteration loss = 0.003536991

Training iteration loss = 0.003500695

Training iteration loss = 0.004696194

Training iteration loss = 0.0041106325

Training iteration loss = 0.0045435573

Training iteration loss = 0.0022207394

Training iteration loss = 0.0032758715

Training iteration loss = 0.0024346667

Training iteration loss = 0.0065054446

Training iteration loss = 0.0038699058

Training iteration loss = 0.0029771943

Training iteration loss = 0.0028847225

Training iteration loss = 0.0036728121

Training iteration loss = 0.007989132

Training iteration loss = 0.0024002844

Training iteration loss = 0.003914296

Training iteration loss = 0.003745713

Training iteration loss = 0.002410179

Training iteration loss = 0.0036225102

Training iteration loss = 0.003882386

Training iteration loss = 0.0028565659

Training iteration loss = 0.0025390435

Training iteration loss = 0.0033671083

Training iteration loss = 0.0040448667

Training iteration loss = 0.0038503623

Training iteration loss = 0.005044011

Training iteration loss = 0.005105412

Training iteration loss = 0.00319706

Training iteration loss = 0.0038486815

Training iteration loss = 0.004824287

Training iteration loss = 0.004821748

Training iteration loss = 0.0029860295

Training iteration loss = 0.0038749517

Training iteration loss = 0.0040086014

Training iteration loss = 0.0026117505

Training iteration loss = 0.0022737393

Training iteration loss = 0.003659581

Training iteration loss = 0.0026135265

Training iteration loss = 0.0022440017

Training iteration loss = 0.0032674894

Training iteration loss = 0.0023484712

Training iteration loss = 0.0019812633

Training iteration loss = 0.0018682369

Training iteration loss = 0.0031804414

Training iteration loss = 0.0021153772

Training iteration loss = 0.0024674132

Training iteration loss = 0.00413416

Training iteration loss = 0.005724057

Training iteration loss = 0.0025757959

Training iteration loss = 0.0028375173

Training iteration loss = 0.0025596803

Training iteration loss = 0.0028375604

Training iteration loss = 0.0022419214

Training iteration loss = 0.0042652157

Training iteration loss = 0.0034608052

Training iteration loss = 0.0049323174

Training iteration loss = 0.0043586125

Training iteration loss = 0.0029744285

Training iteration loss = 0.0020488787

Training iteration loss = 0.0021874874

Training iteration loss = 0.0085430555

Training iteration loss = 0.0032724764

Training iteration loss = 0.0018578689

Training iteration loss = 0.004412229

Training iteration loss = 0.0037974261

Training iteration loss = 0.0036498883

Training iteration loss = 0.0031270462

Training iteration loss = 0.0041442104

Training iteration loss = 0.0023870326

Training iteration loss = 0.0070317746

Training iteration loss = 0.0026148406

Training iteration loss = 0.0033832814

Training iteration loss = 0.004081628

Training iteration loss = 0.0022192488

Training iteration loss = 0.0022818944

Training iteration loss = 0.0026357127

Training iteration loss = 0.0017902927

Training iteration loss = 0.003485556

Training iteration loss = 0.00324189

Training iteration loss = 0.0042685303

Training iteration loss = 0.0031830948

Training iteration loss = 0.0028600376

Training iteration loss = 0.0021973767

Training iteration loss = 0.0022525194

Training iteration loss = 0.0024378952

Training iteration loss = 0.003105847

Training iteration loss = 0.0052309246

Training iteration loss = 0.0019408996

Training iteration loss = 0.002956054

Training iteration loss = 0.0030946482

Training iteration loss = 0.0037206726

Training iteration loss = 0.0030478388

Training iteration loss = 0.0033992168

Training iteration loss = 0.0029751684

Training iteration loss = 0.0019105492

Training iteration loss = 0.006394924

Training iteration loss = 0.0030867716

Training iteration loss = 0.0026041083

Training iteration loss = 0.001872716

Training iteration loss = 0.003463722

Training iteration loss = 0.003757309

Training iteration loss = 0.0039058318

Training iteration loss = 0.0025456462

Training iteration loss = 0.005787022

Training iteration loss = 0.0032742436

Training iteration loss = 0.002473616

Training iteration loss = 0.0020532303

Training iteration loss = 0.0025319143

Training iteration loss = 0.0020239532

Training iteration loss = 0.0034898473

Training iteration loss = 0.0019019224

Training iteration loss = 0.0021051965

Training iteration loss = 0.0036462068

Training iteration loss = 0.0030319926

Training iteration loss = 0.00352964

Training iteration loss = 0.0026826558

Training iteration loss = 0.004218561

Training iteration loss = 0.0041825734

Training iteration loss = 0.004533382

Training iteration loss = 0.0021352246

Training iteration loss = 0.0029467242

Training iteration loss = 0.0024548094

Training iteration loss = 0.0038062818

Training iteration loss = 0.0034897253

Training iteration loss = 0.004933409

Training iteration loss = 0.0029848216

Training iteration loss = 0.0025292358

Training iteration loss = 0.0031678753

Training iteration loss = 0.0050736475

Training iteration loss = 0.003376907

Training iteration loss = 0.002916687

Training iteration loss = 0.0034678613

Training iteration loss = 0.0033845135

Training iteration loss = 0.0025235421

Training iteration loss = 0.0030553946

Training iteration loss = 0.0038201099

Training iteration loss = 0.0030260955

Training iteration loss = 0.0032879289

Training iteration loss = 0.002903852

Training iteration loss = 0.0024055606

Training iteration loss = 0.0046731182

Training iteration loss = 0.0043786285

Training iteration loss = 0.003813417

Training iteration loss = 0.0036423374

Training iteration loss = 0.0022759407

Training iteration loss = 0.004714062

Training iteration loss = 0.0056551043

Training iteration loss = 0.0025935962

Training iteration loss = 0.003463152

Training iteration loss = 0.0024577756

Training iteration loss = 0.0027694397

Training iteration loss = 0.0028112766

Training iteration loss = 0.0026614268

Training iteration loss = 0.005299321

Training iteration loss = 0.0063524884

Training iteration loss = 0.0026093067

Training iteration loss = 0.0030134919

Training iteration loss = 0.0022748096

Training iteration loss = 0.0027001232

Training iteration loss = 0.0036006283

Training iteration loss = 0.0033766518

Training iteration loss = 0.0039569307

Training iteration loss = 0.0023027624

Training iteration loss = 0.0038925305

Training iteration loss = 0.0076585044

Training iteration loss = 0.0049733757

Training iteration loss = 0.0039472827

Training iteration loss = 0.0030918159

Training iteration loss = 0.0035257128

Training iteration loss = 0.002665717

Training iteration loss = 0.003562388

Training iteration loss = 0.0022400504

Training iteration loss = 0.0027519807

Training iteration loss = 0.0027542002

Training iteration loss = 0.003114533

Training iteration loss = 0.0021890488

Training iteration loss = 0.0044930973

Training iteration loss = 0.0035135068

Training iteration loss = 0.005501321

Training iteration loss = 0.0032487912

Training iteration loss = 0.003339649

Training iteration loss = 0.0033983178

Training iteration loss = 0.0073024877

Training iteration loss = 0.004393763

Training iteration loss = 0.0034290086

Training iteration loss = 0.0025827785

Training iteration loss = 0.005450384

Training iteration loss = 0.0023745834

Training iteration loss = 0.0024298378

Training iteration loss = 0.0028599023

Training iteration loss = 0.0036052894

Training iteration loss = 0.0029632573

Training iteration loss = 0.0040027257

Training iteration loss = 0.0036886425

Training iteration loss = 0.0020283659

Training iteration loss = 0.002667971

Training iteration loss = 0.0019196514

Training iteration loss = 0.0025718568

Training iteration loss = 0.0020896483

Training iteration loss = 0.0026338238

Training iteration loss = 0.0035243612

Training iteration loss = 0.0034954946

Training iteration loss = 0.0046832873

Training iteration loss = 0.0041041025

Training iteration loss = 0.004529404

Training iteration loss = 0.0022179587

Training iteration loss = 0.0032677054

Training iteration loss = 0.002431126

Training iteration loss = 0.0064760842

Training iteration loss = 0.0038487576

Training iteration loss = 0.0029750278

Training iteration loss = 0.0028765372

Training iteration loss = 0.0036727644

Training iteration loss = 0.007925111

Training iteration loss = 0.0023932296

Training iteration loss = 0.003907693

Training iteration loss = 0.0037330242

Training iteration loss = 0.0024091874

Training iteration loss = 0.0036225794

Training iteration loss = 0.0038771725

Training iteration loss = 0.0028512918

Training iteration loss = 0.0025395353

Training iteration loss = 0.003368599

Training iteration loss = 0.004044241

Training iteration loss = 0.003842721

Training iteration loss = 0.005016849

Training iteration loss = 0.0050994

Training iteration loss = 0.003199443

Training iteration loss = 0.003826485

Training iteration loss = 0.0047952854

Training iteration loss = 0.004805488

Training iteration loss = 0.0029889503

Training iteration loss = 0.0038597395

Training iteration loss = 0.0040013553

Training iteration loss = 0.0025997686

Training iteration loss = 0.0022663872

Training iteration loss = 0.0036622444

Training iteration loss = 0.0025980668

Training iteration loss = 0.0022359048

Training iteration loss = 0.0032469553

Training iteration loss = 0.0023413447

Training iteration loss = 0.0019845502

Training iteration loss = 0.0018635573

Training iteration loss = 0.0031712241

Training iteration loss = 0.0021104573

Training iteration loss = 0.0024550194

Training iteration loss = 0.0041337204

Training iteration loss = 0.0056984164

Training iteration loss = 0.0025682675

Training iteration loss = 0.0028391446

Training iteration loss = 0.0025676687

Training iteration loss = 0.0028420177

Training iteration loss = 0.0022368825

Training iteration loss = 0.0042548957

Training iteration loss = 0.0034632867

Training iteration loss = 0.004930271

Training iteration loss = 0.00432289

Training iteration loss = 0.0029680382

Training iteration loss = 0.002048476

Training iteration loss = 0.0021902425

Training iteration loss = 0.008547538

Training iteration loss = 0.0032563743

Training iteration loss = 0.0018553355

Training iteration loss = 0.0043982305

Training iteration loss = 0.0037965775

Training iteration loss = 0.003633673

Training iteration loss = 0.0031248445

Training iteration loss = 0.0041354466

Training iteration loss = 0.002380844

Training iteration loss = 0.0069946

Training iteration loss = 0.002605443

Training iteration loss = 0.0033798972

Training iteration loss = 0.0040721763

Training iteration loss = 0.0022191124

Training iteration loss = 0.0022800525

Training iteration loss = 0.002638113

Training iteration loss = 0.0017828164

Training iteration loss = 0.0034799643

Training iteration loss = 0.0032351613

Training iteration loss = 0.004267337

Training iteration loss = 0.0031757967

Training iteration loss = 0.0028588409

Training iteration loss = 0.0021973073

Training iteration loss = 0.0022472076

Training iteration loss = 0.0024373718

Training iteration loss = 0.0031094349

Training iteration loss = 0.005207881

Training iteration loss = 0.0019398909

Training iteration loss = 0.0029484937

Training iteration loss = 0.0030899756

Training iteration loss = 0.0037011504

Training iteration loss = 0.003048049

Training iteration loss = 0.0033972126

Training iteration loss = 0.0029596991

Training iteration loss = 0.0019090343

Training iteration loss = 0.006379995

Training iteration loss = 0.0030806381

Training iteration loss = 0.0026042871

Training iteration loss = 0.0018664483

Training iteration loss = 0.0034576468

Training iteration loss = 0.0037497394

Training iteration loss = 0.0038837434

Training iteration loss = 0.0025377127

Training iteration loss = 0.0057861716

Training iteration loss = 0.003265999

Training iteration loss = 0.0024660293

Training iteration loss = 0.0020444447

Training iteration loss = 0.002529939

Training iteration loss = 0.00202184

Training iteration loss = 0.0034790225

Training iteration loss = 0.0018969012

Training iteration loss = 0.0020973296

Training iteration loss = 0.003634517

Training iteration loss = 0.0030277008

Training iteration loss = 0.0035239432

Training iteration loss = 0.0026795391

Training iteration loss = 0.0042060395

Training iteration loss = 0.004178937

Training iteration loss = 0.0045444015

Training iteration loss = 0.0021336016

Training iteration loss = 0.002937022

Training iteration loss = 0.0024475416

Training iteration loss = 0.0038042897

Training iteration loss = 0.0034885865

Training iteration loss = 0.0049244463

Training iteration loss = 0.0029687649

Training iteration loss = 0.0025234018

Training iteration loss = 0.003159973

Training iteration loss = 0.005055512

Training iteration loss = 0.0033699814

Training iteration loss = 0.0029077937

Training iteration loss = 0.003461235

Training iteration loss = 0.00337781

Training iteration loss = 0.0025140666

Training iteration loss = 0.0030274682

Training iteration loss = 0.0038196808

Training iteration loss = 0.0030250328

Training iteration loss = 0.0032912884

Training iteration loss = 0.002893176

Training iteration loss = 0.0024028642

Training iteration loss = 0.0046634194

Training iteration loss = 0.0043698666

Training iteration loss = 0.003812995

Training iteration loss = 0.0036562884

Training iteration loss = 0.0022715183

Training iteration loss = 0.004703921

Training iteration loss = 0.0056422413

Training iteration loss = 0.002579646

Training iteration loss = 0.0034584792

Training iteration loss = 0.0024560606

Training iteration loss = 0.002745935

Training iteration loss = 0.0028024137

Training iteration loss = 0.0026562375

Training iteration loss = 0.005288034

Training iteration loss = 0.00632159

Training iteration loss = 0.0026028184

Training iteration loss = 0.0030024897

Training iteration loss = 0.0022766825

Training iteration loss = 0.0026943795

Training iteration loss = 0.003587516

Training iteration loss = 0.0033723318

Training iteration loss = 0.0039464124

Training iteration loss = 0.002297778

Training iteration loss = 0.0038770342

Training iteration loss = 0.007641064

Training iteration loss = 0.0049597644

Training iteration loss = 0.0039380575

Training iteration loss = 0.0030856123

Training iteration loss = 0.0035191262

Training iteration loss = 0.0026637753

Training iteration loss = 0.0035564296

Training iteration loss = 0.0022318666

Training iteration loss = 0.0027467816

Training iteration loss = 0.0027460968

Training iteration loss = 0.0030827206

Training iteration loss = 0.0021784252

Training iteration loss = 0.0044869063

Training iteration loss = 0.0035052842

Training iteration loss = 0.0054938165

Training iteration loss = 0.003237041

Training iteration loss = 0.0033290114

Training iteration loss = 0.0033933802

Training iteration loss = 0.007277859

Training iteration loss = 0.004365138

Training iteration loss = 0.0034233087

Training iteration loss = 0.0025760692

Training iteration loss = 0.0054398435

Training iteration loss = 0.0023709286

Training iteration loss = 0.002427791

Training iteration loss = 0.0028570062

Training iteration loss = 0.003597495

Training iteration loss = 0.002951468

Training iteration loss = 0.003993646

Training iteration loss = 0.0036780804

Training iteration loss = 0.0020188706

Training iteration loss = 0.0026523487

Training iteration loss = 0.0019143098

Training iteration loss = 0.0025609923

Training iteration loss = 0.0020816715

Training iteration loss = 0.0026235075

Training iteration loss = 0.00351186

Training iteration loss = 0.0034886089

Training iteration loss = 0.00466881

Training iteration loss = 0.0041017705

Training iteration loss = 0.0045161205

Training iteration loss = 0.002214643

Training iteration loss = 0.003259279

Training iteration loss = 0.002426505

Training iteration loss = 0.006459451

Training iteration loss = 0.00383392

Training iteration loss = 0.0029729654

Training iteration loss = 0.0028700267

Training iteration loss = 0.0036706894

Training iteration loss = 0.007897046

Training iteration loss = 0.0023882238

Training iteration loss = 0.0039031089

Training iteration loss = 0.0037177939

Training iteration loss = 0.0024005848

Training iteration loss = 0.003611704

Training iteration loss = 0.0038714625

Training iteration loss = 0.0028435986

Training iteration loss = 0.002539763

Training iteration loss = 0.0033627602

Training iteration loss = 0.0040338067

Training iteration loss = 0.0038339829

Training iteration loss = 0.004989105

Training iteration loss = 0.0050961585

Training iteration loss = 0.0031992572

Training iteration loss = 0.0038173841

Training iteration loss = 0.0047712396

Training iteration loss = 0.0047985627

Training iteration loss = 0.002985588

Training iteration loss = 0.0038497753

Training iteration loss = 0.0039934902

Training iteration loss = 0.0025990396

Training iteration loss = 0.0022593483

Training iteration loss = 0.0036530255

Training iteration loss = 0.0025934398

Training iteration loss = 0.0022286589

Training iteration loss = 0.0032361865

Training iteration loss = 0.0023381216

Training iteration loss = 0.001984983

Training iteration loss = 0.0018610297

Training iteration loss = 0.0031651324

Training iteration loss = 0.0021049997

Training iteration loss = 0.0024411613

Training iteration loss = 0.0041346997

Training iteration loss = 0.0056841895

Training iteration loss = 0.0025641287

Training iteration loss = 0.0028386225

Training iteration loss = 0.0025693765

Training iteration loss = 0.0028407734

Training iteration loss = 0.002232725

Training iteration loss = 0.0042451886

Training iteration loss = 0.0034647302

Training iteration loss = 0.0049276715

Training iteration loss = 0.0042934148

Training iteration loss = 0.0029598677

Training iteration loss = 0.0020484568

Training iteration loss = 0.002193985

Training iteration loss = 0.008545264

Training iteration loss = 0.0032383893

Training iteration loss = 0.0018583459

Training iteration loss = 0.004384582

Training iteration loss = 0.0037982417

Training iteration loss = 0.003618752

Training iteration loss = 0.003124853

Training iteration loss = 0.00413043

Training iteration loss = 0.0023766528

Training iteration loss = 0.006972334

Training iteration loss = 0.0025985138

Training iteration loss = 0.0033763547

Training iteration loss = 0.004062601

Training iteration loss = 0.0022186935

Training iteration loss = 0.0022784518

Training iteration loss = 0.0026404138

Training iteration loss = 0.0017751235

Training iteration loss = 0.003473011

Training iteration loss = 0.0032306977

Training iteration loss = 0.0042683245

Training iteration loss = 0.0031697892

Training iteration loss = 0.0028564453

Training iteration loss = 0.0021987164

Training iteration loss = 0.0022460285

Training iteration loss = 0.0024352458

Training iteration loss = 0.0031107997

Training iteration loss = 0.0051795025

Training iteration loss = 0.0019369904

Training iteration loss = 0.0029463908

Training iteration loss = 0.003087342

Training iteration loss = 0.0036826662

Training iteration loss = 0.003046458

Training iteration loss = 0.003395065

Training iteration loss = 0.0029480264

Training iteration loss = 0.001906014

Training iteration loss = 0.006378984

Training iteration loss = 0.0030756614

Training iteration loss = 0.0026056087

Training iteration loss = 0.001862208

Training iteration loss = 0.0034536866

Training iteration loss = 0.0037445568

Training iteration loss = 0.003866467

Training iteration loss = 0.0025288605

Training iteration loss = 0.005781679

Training iteration loss = 0.003256078

Training iteration loss = 0.0024555821

Training iteration loss = 0.0020374085

Training iteration loss = 0.0025252039

Training iteration loss = 0.002019608

Training iteration loss = 0.0034669098

Training iteration loss = 0.0018920297

Training iteration loss = 0.002092135

Training iteration loss = 0.0036298034

Training iteration loss = 0.003024362

Training iteration loss = 0.0035190692

Training iteration loss = 0.0026749559

Training iteration loss = 0.0042009945

Training iteration loss = 0.004177957

Training iteration loss = 0.004546289

Training iteration loss = 0.002131594

Training iteration loss = 0.0029312437

Training iteration loss = 0.0024447935

Training iteration loss = 0.0038017293

Training iteration loss = 0.0034858023

Training iteration loss = 0.0049178344

Training iteration loss = 0.0029611134

Training iteration loss = 0.0025220457

Training iteration loss = 0.0031563037

Training iteration loss = 0.005042642

Training iteration loss = 0.0033666317

Training iteration loss = 0.0029000377

Training iteration loss = 0.0034551893

Training iteration loss = 0.0033750294

Training iteration loss = 0.0025136794

Training iteration loss = 0.003004835

Training iteration loss = 0.0038138505

Training iteration loss = 0.0030240482

Training iteration loss = 0.003292824

Training iteration loss = 0.0028869763

Training iteration loss = 0.0024022472

Training iteration loss = 0.0046528713

Training iteration loss = 0.0043617883

Training iteration loss = 0.0038119275

Training iteration loss = 0.0036673788

Training iteration loss = 0.0022677355

Training iteration loss = 0.0046955645

Training iteration loss = 0.0056320652

Training iteration loss = 0.0025694922

Training iteration loss = 0.003455343

Training iteration loss = 0.0024546187

Training iteration loss = 0.0027301656

Training iteration loss = 0.0027949258

Training iteration loss = 0.0026523396

Training iteration loss = 0.0052773063

Training iteration loss = 0.0062962933

Training iteration loss = 0.0025988612

Training iteration loss = 0.0029925648

Training iteration loss = 0.002277151

Training iteration loss = 0.0026884961

Training iteration loss = 0.003574035

Training iteration loss = 0.00336864

Training iteration loss = 0.0039343243

Training iteration loss = 0.0022941872

Training iteration loss = 0.0038624583

Training iteration loss = 0.0076169856

Training iteration loss = 0.00494739

Training iteration loss = 0.0039300383

Training iteration loss = 0.003080699

Training iteration loss = 0.0035140868

Training iteration loss = 0.002661872

Training iteration loss = 0.0035511942

Training iteration loss = 0.002225111

Training iteration loss = 0.002742451

Training iteration loss = 0.0027394632

Training iteration loss = 0.0030562782

Training iteration loss = 0.0021692994

Training iteration loss = 0.0044817957

Training iteration loss = 0.0034968995

Training iteration loss = 0.005488995

Training iteration loss = 0.0032290572

Training iteration loss = 0.0033215669

Training iteration loss = 0.0033898933

Training iteration loss = 0.007256282

Training iteration loss = 0.004343344

Training iteration loss = 0.003419811

Training iteration loss = 0.0025717737

Training iteration loss = 0.0054298397

Training iteration loss = 0.0023670162

Training iteration loss = 0.002427086

Training iteration loss = 0.0028540585

Training iteration loss = 0.0035923326

Training iteration loss = 0.0029428406

Training iteration loss = 0.003987821

Training iteration loss = 0.003669386

Training iteration loss = 0.0020127508

Training iteration loss = 0.002639821

Training iteration loss = 0.0019105995

Training iteration loss = 0.0025522897

Training iteration loss = 0.0020761795

Training iteration loss = 0.0026143736

Training iteration loss = 0.0035017033

Training iteration loss = 0.003482814

Training iteration loss = 0.0046570883

Training iteration loss = 0.0040980275

Training iteration loss = 0.004503736

Training iteration loss = 0.0022119621

Training iteration loss = 0.003251969

Training iteration loss = 0.0024211681

Training iteration loss = 0.006436297

Training iteration loss = 0.003818213

Training iteration loss = 0.0029722515

Training iteration loss = 0.0028636772

Training iteration loss = 0.0036702168

Training iteration loss = 0.007853062

Training iteration loss = 0.0023840463

Training iteration loss = 0.0038980946

Training iteration loss = 0.0037076066

Training iteration loss = 0.0023977465

Training iteration loss = 0.0036077409

Training iteration loss = 0.0038665046

Training iteration loss = 0.0028385

Training iteration loss = 0.002541027

Training iteration loss = 0.0033626698

Training iteration loss = 0.004028591

Training iteration loss = 0.0038267237

Training iteration loss = 0.0049650637

Training iteration loss = 0.005090524

Training iteration loss = 0.0032011867

Training iteration loss = 0.0038018676

Training iteration loss = 0.0047486867

Training iteration loss = 0.0047868183

Training iteration loss = 0.0029835133

Training iteration loss = 0.0038376085

Training iteration loss = 0.003987175

Training iteration loss = 0.002594215

Training iteration loss = 0.0022521

Training iteration loss = 0.0036502508

Training iteration loss = 0.002585879

Training iteration loss = 0.0022230938

Training iteration loss = 0.0032213011

Training iteration loss = 0.0023329372

Training iteration loss = 0.001986381

Training iteration loss = 0.0018574746

Training iteration loss = 0.003159437

Training iteration loss = 0.002099144

Training iteration loss = 0.0024300069

Training iteration loss = 0.0041353013

Training iteration loss = 0.0056682196

Training iteration loss = 0.0025603173

Training iteration loss = 0.0028359266

Training iteration loss = 0.0025711479

Training iteration loss = 0.002842767

Training iteration loss = 0.0022294286

Training iteration loss = 0.004239033

Training iteration loss = 0.0034664075

Training iteration loss = 0.0049256324

Training iteration loss = 0.004267066

Training iteration loss = 0.002955295

Training iteration loss = 0.0020484142

Training iteration loss = 0.0021966097

Training iteration loss = 0.00855209

Training iteration loss = 0.0032232553

Training iteration loss = 0.0018594699

Training iteration loss = 0.004371916

Training iteration loss = 0.0038004026

Training iteration loss = 0.0036058307

Training iteration loss = 0.003122542

Training iteration loss = 0.0041238964

Training iteration loss = 0.0023735

Training iteration loss = 0.0069483276

Training iteration loss = 0.0025919916

Training iteration loss = 0.0033744636

Training iteration loss = 0.0040550972

Training iteration loss = 0.0022191664

Training iteration loss = 0.0022762208

Training iteration loss = 0.0026425477

Training iteration loss = 0.0017681319

Training iteration loss = 0.0034655512

Training iteration loss = 0.003227189

Training iteration loss = 0.004270852

Training iteration loss = 0.0031635314

Training iteration loss = 0.0028558273

Training iteration loss = 0.002200085

Training iteration loss = 0.0022460397

Training iteration loss = 0.0024319927

Training iteration loss = 0.0031137995

Training iteration loss = 0.0051454683

Training iteration loss = 0.0019340419

Training iteration loss = 0.002944638

Training iteration loss = 0.0030828796

Training iteration loss = 0.0036644742

Training iteration loss = 0.0030444346

Training iteration loss = 0.003392534

Training iteration loss = 0.0029364163

Training iteration loss = 0.0019033923

Training iteration loss = 0.006376695

Training iteration loss = 0.0030707803

Training iteration loss = 0.0026058678

Training iteration loss = 0.0018569754

Training iteration loss = 0.0034515623

Training iteration loss = 0.00374014

Training iteration loss = 0.0038500486

Training iteration loss = 0.0025218034

Training iteration loss = 0.0057755928

Training iteration loss = 0.0032471952

Training iteration loss = 0.0024450142

Training iteration loss = 0.002029934

Training iteration loss = 0.0025182057

Training iteration loss = 0.0020163

Training iteration loss = 0.0034529597

Training iteration loss = 0.0018869074

Training iteration loss = 0.0020874294

Training iteration loss = 0.0036268162

Training iteration loss = 0.0030188716

Training iteration loss = 0.0035162985

Training iteration loss = 0.0026730045

Training iteration loss = 0.0041932133

Training iteration loss = 0.0041766255

Training iteration loss = 0.004545747

Training iteration loss = 0.0021284532

Training iteration loss = 0.0029265534

Training iteration loss = 0.00244266

Training iteration loss = 0.0037983463

Training iteration loss = 0.003482605

Training iteration loss = 0.004911233

Training iteration loss = 0.0029557608

Training iteration loss = 0.002520766

Training iteration loss = 0.003154217

Training iteration loss = 0.0050310115

Training iteration loss = 0.0033625548

Training iteration loss = 0.0028918274

Training iteration loss = 0.0034496225

Training iteration loss = 0.0033746362

Training iteration loss = 0.0025149626

Training iteration loss = 0.0029848528

Training iteration loss = 0.00380682

Training iteration loss = 0.0030243306

Training iteration loss = 0.0032925394

Training iteration loss = 0.0028816757

Training iteration loss = 0.0024013484

Training iteration loss = 0.0046439194

Training iteration loss = 0.0043573915

Training iteration loss = 0.0038110472

Training iteration loss = 0.0036789665

Training iteration loss = 0.0022646748

Training iteration loss = 0.004687982

Training iteration loss = 0.005624945

Training iteration loss = 0.002561249

Training iteration loss = 0.0034531157

Training iteration loss = 0.002453298

Training iteration loss = 0.0027181336

Training iteration loss = 0.0027885186

Training iteration loss = 0.002649355

Training iteration loss = 0.0052647814

Training iteration loss = 0.0062734648

Training iteration loss = 0.0025964917

Training iteration loss = 0.002981767

Training iteration loss = 0.0022768162

Training iteration loss = 0.0026828998

Training iteration loss = 0.003560169

Training iteration loss = 0.0033645602

Training iteration loss = 0.0039203647

Training iteration loss = 0.0022921336

Training iteration loss = 0.0038476984

Training iteration loss = 0.00758492

Training iteration loss = 0.004935226

Training iteration loss = 0.003923196

Training iteration loss = 0.0030771792

Training iteration loss = 0.0035115967

Training iteration loss = 0.0026609013

Training iteration loss = 0.0035467336

Training iteration loss = 0.0022206418

Training iteration loss = 0.0027406954

Training iteration loss = 0.0027352571

Training iteration loss = 0.0030331158

Training iteration loss = 0.002161756

Training iteration loss = 0.0044774543

Training iteration loss = 0.003488876

Training iteration loss = 0.005487097

Training iteration loss = 0.0032229433

Training iteration loss = 0.0033157552

Training iteration loss = 0.0033826362

Training iteration loss = 0.0072368397

Training iteration loss = 0.004319958

Training iteration loss = 0.0034172991

Training iteration loss = 0.0025699975

Training iteration loss = 0.005423375

Training iteration loss = 0.0023639947

Training iteration loss = 0.0024277032

Training iteration loss = 0.0028519833

Training iteration loss = 0.0035888862

Training iteration loss = 0.0029390838

Training iteration loss = 0.0039866487

Training iteration loss = 0.003661828

Training iteration loss = 0.0020077901

Training iteration loss = 0.0026261986

Training iteration loss = 0.0019112119

Training iteration loss = 0.0025471644

Training iteration loss = 0.0020746503

Training iteration loss = 0.002603792

Training iteration loss = 0.0034940757

Training iteration loss = 0.0034825336

Training iteration loss = 0.004647581

Training iteration loss = 0.0040937806

Training iteration loss = 0.0044921064

Training iteration loss = 0.0022091784

Training iteration loss = 0.0032445

Training iteration loss = 0.0024149285

Training iteration loss = 0.0064089135

Training iteration loss = 0.00380166

Training iteration loss = 0.0029709702

Training iteration loss = 0.0028589012

Training iteration loss = 0.0036682256

Training iteration loss = 0.007801302

Training iteration loss = 0.0023764255

Training iteration loss = 0.00389472

Training iteration loss = 0.0037023313

Training iteration loss = 0.002397171

Training iteration loss = 0.0036032775

Training iteration loss = 0.0038584676

Training iteration loss = 0.002831139

Training iteration loss = 0.00254188

Training iteration loss = 0.0033635397

Training iteration loss = 0.0040257913

Training iteration loss = 0.0038197923

Training iteration loss = 0.0049382388

Training iteration loss = 0.0050811656

Training iteration loss = 0.0032012875

Training iteration loss = 0.003789005

Training iteration loss = 0.004727257

Training iteration loss = 0.0047789686

Training iteration loss = 0.0029836774

Training iteration loss = 0.0038292657

Training iteration loss = 0.003985267

Training iteration loss = 0.0025881426

Training iteration loss = 0.0022476234

Training iteration loss = 0.0036482064

Training iteration loss = 0.00257279

Training iteration loss = 0.002219394

Training iteration loss = 0.0032120554

Training iteration loss = 0.0023308895

Training iteration loss = 0.0019871157

Training iteration loss = 0.0018553965

Training iteration loss = 0.0031517188

Training iteration loss = 0.0020987387

Training iteration loss = 0.0024195823

Training iteration loss = 0.004133125

Training iteration loss = 0.005649779

Training iteration loss = 0.00255601

Training iteration loss = 0.0028376153

Training iteration loss = 0.0025745623

Training iteration loss = 0.0028455628

Training iteration loss = 0.0022262812

Training iteration loss = 0.004229501

Training iteration loss = 0.0034649903

Training iteration loss = 0.0049240864

Training iteration loss = 0.004243138

Training iteration loss = 0.002953314

Training iteration loss = 0.002046749

Training iteration loss = 0.002196485

Training iteration loss = 0.008550501

Training iteration loss = 0.0032089297

Training iteration loss = 0.0018596458

Training iteration loss = 0.0043621543

Training iteration loss = 0.003800037

Training iteration loss = 0.0035922732

Training iteration loss = 0.003121584

Training iteration loss = 0.004117506

Training iteration loss = 0.0023701566

Training iteration loss = 0.006928254

Training iteration loss = 0.002591705

Training iteration loss = 0.00337483

Training iteration loss = 0.0040470515

Training iteration loss = 0.0022184548

Training iteration loss = 0.002274005

Training iteration loss = 0.0026433885

Training iteration loss = 0.0017644987

Training iteration loss = 0.0034609772

Training iteration loss = 0.0032227102

Training iteration loss = 0.004266293

Training iteration loss = 0.0031589593

Training iteration loss = 0.0028543274

Training iteration loss = 0.0022018424

Training iteration loss = 0.0022451023

Training iteration loss = 0.0024321883

Training iteration loss = 0.0031145709

Training iteration loss = 0.0051230104

Training iteration loss = 0.0019320395

Training iteration loss = 0.002944652

Training iteration loss = 0.0030807343

Training iteration loss = 0.0036486331

Training iteration loss = 0.0030414101

Training iteration loss = 0.0033894002

Training iteration loss = 0.0029258945

Training iteration loss = 0.0019016579

Training iteration loss = 0.0063711684

Training iteration loss = 0.003064647

Training iteration loss = 0.0026073793

Training iteration loss = 0.001853637

Training iteration loss = 0.0034502319

Training iteration loss = 0.0037363681

Training iteration loss = 0.0038379899

Training iteration loss = 0.0025171174

Training iteration loss = 0.0057741893

Training iteration loss = 0.0032395136

Training iteration loss = 0.0024399385

Training iteration loss = 0.0020274261

Training iteration loss = 0.0025183621

Training iteration loss = 0.0020154645

Training iteration loss = 0.003443051

Training iteration loss = 0.001883626

Training iteration loss = 0.002083462

Training iteration loss = 0.0036203507

Training iteration loss = 0.0030162844

Training iteration loss = 0.003507671

Training iteration loss = 0.0026682962

Training iteration loss = 0.0041859956

Training iteration loss = 0.0041745384

Training iteration loss = 0.004551402

Training iteration loss = 0.0021267945

Training iteration loss = 0.0029222409

Training iteration loss = 0.0024401918

Training iteration loss = 0.0037958696

Training iteration loss = 0.003479794

Training iteration loss = 0.004902719

Training iteration loss = 0.0029462997

Training iteration loss = 0.002519161

Training iteration loss = 0.003148367

Training iteration loss = 0.0050150994

Training iteration loss = 0.0033626817

Training iteration loss = 0.0028857822

Training iteration loss = 0.0034430698

Training iteration loss = 0.0033705132

Training iteration loss = 0.0025115155

Training iteration loss = 0.002959239

Training iteration loss = 0.0038043605

Training iteration loss = 0.0030226435

Training iteration loss = 0.0032938567

Training iteration loss = 0.0028747218

Training iteration loss = 0.0023981933

Training iteration loss = 0.004635003

Training iteration loss = 0.004346275

Training iteration loss = 0.003811512

Training iteration loss = 0.0036849945

Training iteration loss = 0.0022626447

Training iteration loss = 0.0046789544

Training iteration loss = 0.005616169

Training iteration loss = 0.002550327

Training iteration loss = 0.003445291

Training iteration loss = 0.0024531987

Training iteration loss = 0.002703666

Training iteration loss = 0.0027822424

Training iteration loss = 0.0026448965

Training iteration loss = 0.0052545504

Training iteration loss = 0.0062443237

Training iteration loss = 0.002591266

Training iteration loss = 0.0029730068

Training iteration loss = 0.0022761256

Training iteration loss = 0.0026796877

Training iteration loss = 0.0035488287

Training iteration loss = 0.003361664

Training iteration loss = 0.003909545

Training iteration loss = 0.0022886961

Training iteration loss = 0.0038340345

Training iteration loss = 0.00757117

Training iteration loss = 0.004925698

Training iteration loss = 0.0039151

Training iteration loss = 0.0030715938

Training iteration loss = 0.0035088481

Training iteration loss = 0.0026579674

Training iteration loss = 0.0035387308

Training iteration loss = 0.002212511

Training iteration loss = 0.0027357563

Training iteration loss = 0.0027273411

Training iteration loss = 0.003007407

Training iteration loss = 0.002152406

Training iteration loss = 0.0044734715

Training iteration loss = 0.0034806996

Training iteration loss = 0.0054828296

Training iteration loss = 0.0032156266

Training iteration loss = 0.003308416

Training iteration loss = 0.0033808341

Training iteration loss = 0.007216497

Training iteration loss = 0.004301768

Training iteration loss = 0.0034142763

Training iteration loss = 0.0025668715

Training iteration loss = 0.0054105376

Training iteration loss = 0.0023600904

Training iteration loss = 0.0024268648

Training iteration loss = 0.0028497924

Training iteration loss = 0.0035864476

Training iteration loss = 0.0029329807

Training iteration loss = 0.003983354

Training iteration loss = 0.0036553312

Training iteration loss = 0.0020010862

Training iteration loss = 0.0026172204

Training iteration loss = 0.001908287

Training iteration loss = 0.0025391972

Training iteration loss = 0.0020697985

Training iteration loss = 0.002594188

Training iteration loss = 0.0034858584

Training iteration loss = 0.003477077

Training iteration loss = 0.0046367287

Training iteration loss = 0.00409135

Training iteration loss = 0.0044799955

Training iteration loss = 0.0022065078

Training iteration loss = 0.0032377706

Training iteration loss = 0.0024085853

Training iteration loss = 0.0063909623

Training iteration loss = 0.0037908899

Training iteration loss = 0.0029699886

Training iteration loss = 0.002853379

Training iteration loss = 0.0036660468

Training iteration loss = 0.007775637

Training iteration loss = 0.0023748737

Training iteration loss = 0.0038911728

Training iteration loss = 0.0036924444

Training iteration loss = 0.0023919537

Training iteration loss = 0.0035940905

Training iteration loss = 0.003851882

Training iteration loss = 0.00282515

Training iteration loss = 0.0025434552

Training iteration loss = 0.0033622757

Training iteration loss = 0.004013753

Training iteration loss = 0.0038130924

Training iteration loss = 0.0049187564

Training iteration loss = 0.0050770026

Training iteration loss = 0.00320255

Training iteration loss = 0.0037781538

Training iteration loss = 0.004706698

Training iteration loss = 0.004771079

Training iteration loss = 0.0029790371

Training iteration loss = 0.003821505

Training iteration loss = 0.0039825463

Training iteration loss = 0.002588201

Training iteration loss = 0.0022398497

Training iteration loss = 0.0036393898

Training iteration loss = 0.0025692983

Training iteration loss = 0.0022140138

Training iteration loss = 0.0032033066

Training iteration loss = 0.0023263737

Training iteration loss = 0.0019858454

Training iteration loss = 0.0018521902

Training iteration loss = 0.0031467772

Training iteration loss = 0.002093402

Training iteration loss = 0.0024101967

Training iteration loss = 0.0041322517

Training iteration loss = 0.0056418027

Training iteration loss = 0.002554448

Training iteration loss = 0.0028340619

Training iteration loss = 0.0025710044

Training iteration loss = 0.002844169

Training iteration loss = 0.0022242463

Training iteration loss = 0.00422286

Training iteration loss = 0.0034636173

Training iteration loss = 0.004918367

Training iteration loss = 0.004220853

Training iteration loss = 0.0029486904

Training iteration loss = 0.002045438

Training iteration loss = 0.002196788

Training iteration loss = 0.008561627

Training iteration loss = 0.0031978413

Training iteration loss = 0.0018595798

Training iteration loss = 0.004355729

Training iteration loss = 0.0038020161

Training iteration loss = 0.0035821272

Training iteration loss = 0.003119645

Training iteration loss = 0.0041117906

Training iteration loss = 0.0023680383

Training iteration loss = 0.0069017094

Training iteration loss = 0.0025890947

Training iteration loss = 0.003374566

Training iteration loss = 0.004039115

Training iteration loss = 0.0022181973

Training iteration loss = 0.0022718853

Training iteration loss = 0.002645315

Training iteration loss = 0.0017596855

Training iteration loss = 0.0034549816

Training iteration loss = 0.0032203917

Training iteration loss = 0.004264978

Training iteration loss = 0.0031542387

Training iteration loss = 0.0028527547

Training iteration loss = 0.0022030647

Training iteration loss = 0.0022461673

Training iteration loss = 0.0024304164

Training iteration loss = 0.0031144526

Training iteration loss = 0.00509397

Training iteration loss = 0.001929095

Training iteration loss = 0.0029457528

Training iteration loss = 0.0030781894

Training iteration loss = 0.0036328807

Training iteration loss = 0.0030352084

Training iteration loss = 0.0033861229

Training iteration loss = 0.0029159486

Training iteration loss = 0.0018987482

Training iteration loss = 0.006365344

Training iteration loss = 0.0030599178

Training iteration loss = 0.0026082273

Training iteration loss = 0.0018482936

Training iteration loss = 0.0034489566

Training iteration loss = 0.0037315525

Training iteration loss = 0.0038258343

Training iteration loss = 0.0025112738

Training iteration loss = 0.005769082

Training iteration loss = 0.0032313487

Training iteration loss = 0.0024316085

Training iteration loss = 0.0020243118

Training iteration loss = 0.0025158091

Training iteration loss = 0.0020128745

Training iteration loss = 0.0034308329

Training iteration loss = 0.0018793965

Training iteration loss = 0.002080389

Training iteration loss = 0.003617188

Training iteration loss = 0.0030116576

Training iteration loss = 0.0035011664

Training iteration loss = 0.002664137

Training iteration loss = 0.004180808

Training iteration loss = 0.004173862

Training iteration loss = 0.004549777

Training iteration loss = 0.0021227251

Training iteration loss = 0.0029191931

Training iteration loss = 0.0024392921

Training iteration loss = 0.003793355

Training iteration loss = 0.0034761943

Training iteration loss = 0.004895729

Training iteration loss = 0.0029415938

Training iteration loss = 0.0025181114

Training iteration loss = 0.0031474915

Training iteration loss = 0.0050035366

Training iteration loss = 0.0033603294

Training iteration loss = 0.0028781847

Training iteration loss = 0.0034370236

Training iteration loss = 0.0033683097

Training iteration loss = 0.0025133234

Training iteration loss = 0.0029409993

Training iteration loss = 0.0037965544

Training iteration loss = 0.0030225748

Training iteration loss = 0.0032919582

Training iteration loss = 0.0028701357

Training iteration loss = 0.0023966345

Training iteration loss = 0.0046274774

Training iteration loss = 0.004345762

Training iteration loss = 0.0038105391

Training iteration loss = 0.003696639

Training iteration loss = 0.0022606303

Training iteration loss = 0.0046709585

Training iteration loss = 0.005610371

Training iteration loss = 0.002543127

Training iteration loss = 0.003441634

Training iteration loss = 0.0024526275

Training iteration loss = 0.0026946077

Training iteration loss = 0.0027773778

Training iteration loss = 0.0026415095

Training iteration loss = 0.005242122

Training iteration loss = 0.006222123

Training iteration loss = 0.002589367

Training iteration loss = 0.0029634328

Training iteration loss = 0.0022747403

Training iteration loss = 0.0026758413

Training iteration loss = 0.0035358693

Training iteration loss = 0.0033574747

Training iteration loss = 0.0038961805

Training iteration loss = 0.002286767

Training iteration loss = 0.0038210514

Training iteration loss = 0.007546242

Training iteration loss = 0.004915431

Training iteration loss = 0.003908723

Training iteration loss = 0.0030680178

Training iteration loss = 0.0035081815

Training iteration loss = 0.0026565492

Training iteration loss = 0.003533352

Training iteration loss = 0.00220776

Training iteration loss = 0.0027346339

Training iteration loss = 0.002722218

Training iteration loss = 0.0029867068

Training iteration loss = 0.0021449204

Training iteration loss = 0.004470061

Training iteration loss = 0.0034730237

Training iteration loss = 0.005482314

Training iteration loss = 0.003211641

Training iteration loss = 0.003304042

Training iteration loss = 0.003378276

Training iteration loss = 0.007199976

Training iteration loss = 0.0042835106

Training iteration loss = 0.0034129256

Training iteration loss = 0.0025653983

Training iteration loss = 0.0053978185

Training iteration loss = 0.0023572545

Training iteration loss = 0.0024258513

Training iteration loss = 0.002848937

Training iteration loss = 0.0035865856

Training iteration loss = 0.0029308258

Training iteration loss = 0.0039836415

Training iteration loss = 0.0036496567

Training iteration loss = 0.0019960771

Training iteration loss = 0.0026072545

Training iteration loss = 0.0019074808

Training iteration loss = 0.002532806

Training iteration loss = 0.0020659685

Training iteration loss = 0.0025838912

Training iteration loss = 0.003479765

Training iteration loss = 0.0034737063

Training iteration loss = 0.004626795

Training iteration loss = 0.0040880875

Training iteration loss = 0.004468777

Training iteration loss = 0.0022039202

Training iteration loss = 0.0032308453

Training iteration loss = 0.0024023203

Training iteration loss = 0.0063736443

Training iteration loss = 0.003779601

Training iteration loss = 0.002970177

Training iteration loss = 0.002850109

Training iteration loss = 0.003665426

Training iteration loss = 0.007737435

Training iteration loss = 0.0023713391

Training iteration loss = 0.0038870983

Training iteration loss = 0.0036886877

Training iteration loss = 0.0023916012

Training iteration loss = 0.0035897351

Training iteration loss = 0.003846405

Training iteration loss = 0.0028196236

Training iteration loss = 0.0025437898

Training iteration loss = 0.0033613043

Training iteration loss = 0.004009363

Training iteration loss = 0.0038058606

Training iteration loss = 0.004894801

Training iteration loss = 0.0050636483

Training iteration loss = 0.0032035178

Training iteration loss = 0.0037652382

Training iteration loss = 0.0046905307

Training iteration loss = 0.004759724

Training iteration loss = 0.0029751072

Training iteration loss = 0.003810892

Training iteration loss = 0.0039811097

Training iteration loss = 0.0025830192

Training iteration loss = 0.0022347937

Training iteration loss = 0.0036375914

Training iteration loss = 0.0025595413

Training iteration loss = 0.002211525

Training iteration loss = 0.0031961158

Training iteration loss = 0.0023237364

Training iteration loss = 0.001984209

Training iteration loss = 0.0018487753

Training iteration loss = 0.0031402754

Training iteration loss = 0.002093117

Training iteration loss = 0.0024001172

Training iteration loss = 0.004129444

Training iteration loss = 0.0056219064

Training iteration loss = 0.0025509056

Training iteration loss = 0.0028327145

Training iteration loss = 0.0025709704

Training iteration loss = 0.0028455986

Training iteration loss = 0.002223133

Training iteration loss = 0.004219095

Training iteration loss = 0.0034627004

Training iteration loss = 0.00491666

Training iteration loss = 0.004202373

Training iteration loss = 0.0029458553

Training iteration loss = 0.0020427527

Training iteration loss = 0.0021962652

Training iteration loss = 0.008562554

Training iteration loss = 0.003185546

Training iteration loss = 0.0018608692

Training iteration loss = 0.0043471274

Training iteration loss = 0.003804025

Training iteration loss = 0.0035710668

Training iteration loss = 0.0031150905

Training iteration loss = 0.004104491

Training iteration loss = 0.0023643887

Training iteration loss = 0.006883189

Training iteration loss = 0.0025899967

Training iteration loss = 0.0033772876

Training iteration loss = 0.0040343706

Training iteration loss = 0.0022169547

Training iteration loss = 0.0022689477

Training iteration loss = 0.0026442602

Training iteration loss = 0.0017551836

Training iteration loss = 0.0034473527

Training iteration loss = 0.00321968

Training iteration loss = 0.004266757

Training iteration loss = 0.0031507087

Training iteration loss = 0.0028519325

Training iteration loss = 0.0022058608

Training iteration loss = 0.0022490334

Training iteration loss = 0.0024286394

Training iteration loss = 0.0031162342

Training iteration loss = 0.005063483

Training iteration loss = 0.0019248564

Training iteration loss = 0.0029494197

Training iteration loss = 0.0030763112

Training iteration loss = 0.0036181314

Training iteration loss = 0.0030304606

Training iteration loss = 0.0033832423

Training iteration loss = 0.0029076107

Training iteration loss = 0.0018953226

Training iteration loss = 0.0063668303

Training iteration loss = 0.0030542286

Training iteration loss = 0.0026095917

Training iteration loss = 0.0018458292

Training iteration loss = 0.00344849

Training iteration loss = 0.0037302468

Training iteration loss = 0.0038178822

Training iteration loss = 0.0025071036

Training iteration loss = 0.005767126

Training iteration loss = 0.003223844

Training iteration loss = 0.002423627

Training iteration loss = 0.0020230578

Training iteration loss = 0.002514255

Training iteration loss = 0.0020102554

Training iteration loss = 0.0034173785

Training iteration loss = 0.0018746209

Training iteration loss = 0.002078021

Training iteration loss = 0.0036171537

Training iteration loss = 0.003009132

Training iteration loss = 0.0034966345

Training iteration loss = 0.0026604685

Training iteration loss = 0.004173699

Training iteration loss = 0.0041736257

Training iteration loss = 0.0045460262

Training iteration loss = 0.0021182906

Training iteration loss = 0.0029159568

Training iteration loss = 0.0024401953

Training iteration loss = 0.003790178

Training iteration loss = 0.003472479

Training iteration loss = 0.0048878253

Training iteration loss = 0.0029394154

Training iteration loss = 0.0025196876

Training iteration loss = 0.0031463664

Training iteration loss = 0.0049920804

Training iteration loss = 0.0033606486

Training iteration loss = 0.0028712144

Training iteration loss = 0.00343093

Training iteration loss = 0.0033663649

Training iteration loss = 0.002515177

Training iteration loss = 0.0029215722

Training iteration loss = 0.0037907911

Training iteration loss = 0.0030223094

Training iteration loss = 0.003289258

Training iteration loss = 0.0028670824

Training iteration loss = 0.0023948604

Training iteration loss = 0.004619128

Training iteration loss = 0.0043351953

Training iteration loss = 0.0038100772

Training iteration loss = 0.003701337

Training iteration loss = 0.0022588498

Training iteration loss = 0.0046629957

Training iteration loss = 0.0056054867

Training iteration loss = 0.00253584

Training iteration loss = 0.0034367358

Training iteration loss = 0.0024513649

Training iteration loss = 0.0026872673

Training iteration loss = 0.0027726637

Training iteration loss = 0.0026370243

Training iteration loss = 0.0052298554

Training iteration loss = 0.006198229

Training iteration loss = 0.0025865424

Training iteration loss = 0.002955456

Training iteration loss = 0.002272162

Training iteration loss = 0.0026724273

Training iteration loss = 0.0035241616

Training iteration loss = 0.0033548318

Training iteration loss = 0.0038832033

Training iteration loss = 0.0022848244

Training iteration loss = 0.003807082

Training iteration loss = 0.007524111

Training iteration loss = 0.0049054604

Training iteration loss = 0.0039030435

Training iteration loss = 0.0030636925

Training iteration loss = 0.003506953

Training iteration loss = 0.0026537462

Training iteration loss = 0.0035274115

Training iteration loss = 0.0022025814

Training iteration loss = 0.0027321456

Training iteration loss = 0.002717576

Training iteration loss = 0.0029661015

Training iteration loss = 0.0021373113

Training iteration loss = 0.0044680275

Training iteration loss = 0.0034652771

Training iteration loss = 0.0054809344

Training iteration loss = 0.0032084081

Training iteration loss = 0.0032995688

Training iteration loss = 0.003374451

Training iteration loss = 0.007182957

Training iteration loss = 0.004267067

Training iteration loss = 0.0034123964

Training iteration loss = 0.0025663076

Training iteration loss = 0.005387993

Training iteration loss = 0.0023538133

Training iteration loss = 0.0024261505

Training iteration loss = 0.0028464363

Training iteration loss = 0.003586051

Training iteration loss = 0.0029300123

Training iteration loss = 0.003984233

Training iteration loss = 0.0036442578

Training iteration loss = 0.0019925663

Training iteration loss = 0.0025984521

Training iteration loss = 0.0019087383

Training iteration loss = 0.0025292065

Training iteration loss = 0.0020665324

Training iteration loss = 0.0025747854

Training iteration loss = 0.0034747885

Training iteration loss = 0.0034727782

Training iteration loss = 0.0046197283

Training iteration loss = 0.00408295

Training iteration loss = 0.0044565503

Training iteration loss = 0.0022009693

Training iteration loss = 0.003224521

Training iteration loss = 0.0023948

Training iteration loss = 0.0063482933

Training iteration loss = 0.0037678294

Training iteration loss = 0.0029701637

Training iteration loss = 0.0028473868

Training iteration loss = 0.0036632626

Training iteration loss = 0.0076920777

Training iteration loss = 0.0023674835

Training iteration loss = 0.0038843753

Training iteration loss = 0.003688259

Training iteration loss = 0.0023935074

Training iteration loss = 0.0035862876

Training iteration loss = 0.0038372297

Training iteration loss = 0.0028135397

Training iteration loss = 0.0025451004

Training iteration loss = 0.0033640305

Training iteration loss = 0.004002076

Training iteration loss = 0.003800439

Training iteration loss = 0.0048752488

Training iteration loss = 0.0050529093

Training iteration loss = 0.003204201

Training iteration loss = 0.0037516828

Training iteration loss = 0.0046719606

Training iteration loss = 0.004751503

Training iteration loss = 0.0029752564

Training iteration loss = 0.0038027193

Training iteration loss = 0.00398262

Training iteration loss = 0.0025778234

Training iteration loss = 0.0022301208

Training iteration loss = 0.003635397

Training iteration loss = 0.0025499978

Training iteration loss = 0.002208727

Training iteration loss = 0.003187463

Training iteration loss = 0.0023203834

Training iteration loss = 0.001982753

Training iteration loss = 0.0018455475

Training iteration loss = 0.0031351764

Training iteration loss = 0.0020912888

Training iteration loss = 0.0023922764

Training iteration loss = 0.0041241404

Training iteration loss = 0.0056076557

Training iteration loss = 0.0025494555

Training iteration loss = 0.002831896

Training iteration loss = 0.0025681525

Training iteration loss = 0.0028448168

Training iteration loss = 0.002221819

Training iteration loss = 0.0042125103

Training iteration loss = 0.0034601595

Training iteration loss = 0.004911648

Training iteration loss = 0.0041833296

Training iteration loss = 0.0029446427

Training iteration loss = 0.0020410263

Training iteration loss = 0.0021941063

Training iteration loss = 0.00857376

Training iteration loss = 0.0031770617

Training iteration loss = 0.0018588507

Training iteration loss = 0.0043417537

Training iteration loss = 0.0038044986

Training iteration loss = 0.0035616988

Training iteration loss = 0.0031119436

Training iteration loss = 0.004098087

Training iteration loss = 0.0023621083

Training iteration loss = 0.0068537164

Training iteration loss = 0.0025902926

Training iteration loss = 0.0033785042

Training iteration loss = 0.0040272996

Training iteration loss = 0.0022159948

Training iteration loss = 0.002266013

Training iteration loss = 0.0026453694

Training iteration loss = 0.0017523711

Training iteration loss = 0.003442928

Training iteration loss = 0.0032161437

Training iteration loss = 0.0042610676

Training iteration loss = 0.003145706

Training iteration loss = 0.0028509868

Training iteration loss = 0.0022058084

Training iteration loss = 0.002248172

Training iteration loss = 0.002427847

Training iteration loss = 0.0031167946

Training iteration loss = 0.0050409692

Training iteration loss = 0.0019234875

Training iteration loss = 0.0029503356

Training iteration loss = 0.0030741144

Training iteration loss = 0.003603072

Training iteration loss = 0.0030236163

Training iteration loss = 0.0033798635

Training iteration loss = 0.002897511

Training iteration loss = 0.0018937215

Training iteration loss = 0.0063533913

Training iteration loss = 0.003048757

Training iteration loss = 0.0026098453

Training iteration loss = 0.001840125

Training iteration loss = 0.0034473191

Training iteration loss = 0.003725089

Training iteration loss = 0.0038076276

Training iteration loss = 0.0025040328

Training iteration loss = 0.0057646935

Training iteration loss = 0.0032180473

Training iteration loss = 0.0024180145

Training iteration loss = 0.0020218394

Training iteration loss = 0.0025150208

Training iteration loss = 0.0020085133

Training iteration loss = 0.0034060627

Training iteration loss = 0.0018712942

Training iteration loss = 0.0020756368

Training iteration loss = 0.0036123798

Training iteration loss = 0.0030042296

Training iteration loss = 0.0034892561

Training iteration loss = 0.0026574992

Training iteration loss = 0.004164697

Training iteration loss = 0.004171432

Training iteration loss = 0.004546243

Training iteration loss = 0.0021147982

Training iteration loss = 0.002914169

Training iteration loss = 0.0024382053

Training iteration loss = 0.0037880929

Training iteration loss = 0.0034695154

Training iteration loss = 0.0048803813

Training iteration loss = 0.0029323436

Training iteration loss = 0.0025173754

Training iteration loss = 0.0031448517

Training iteration loss = 0.0049786097

Training iteration loss = 0.003358638

Training iteration loss = 0.0028637135

Training iteration loss = 0.0034247034

Training iteration loss = 0.0033631225

Training iteration loss = 0.002513639

Training iteration loss = 0.0029025294

Training iteration loss = 0.0037852444

Training iteration loss = 0.0030219194

Training iteration loss = 0.0032864949

Training iteration loss = 0.0028613897

Training iteration loss = 0.0023917898

Training iteration loss = 0.0046135527

Training iteration loss = 0.0043325853

Training iteration loss = 0.0038098942

Training iteration loss = 0.0037095242

Training iteration loss = 0.0022576777

Training iteration loss = 0.004654192

Training iteration loss = 0.0056006187

Training iteration loss = 0.002527749

Training iteration loss = 0.0034300573

Training iteration loss = 0.0024509516

Training iteration loss = 0.0026790982

Training iteration loss = 0.0027685247

Training iteration loss = 0.0026330615

Training iteration loss = 0.0052162684

Training iteration loss = 0.006174131

Training iteration loss = 0.0025839435

Training iteration loss = 0.0029470634

Training iteration loss = 0.0022699796

Training iteration loss = 0.0026700578

Training iteration loss = 0.0035122493

Training iteration loss = 0.0033511987

Training iteration loss = 0.0038711384

Training iteration loss = 0.0022829154

Training iteration loss = 0.003794358

Training iteration loss = 0.007504349

Training iteration loss = 0.0048968107

Training iteration loss = 0.0038973119

Training iteration loss = 0.0030596368

Training iteration loss = 0.0035076942

Training iteration loss = 0.002651992

Training iteration loss = 0.003521188

Training iteration loss = 0.0021977033

Training iteration loss = 0.002731024

Training iteration loss = 0.002713008

Training iteration loss = 0.0029477265

Training iteration loss = 0.0021304395

Training iteration loss = 0.004465849

Training iteration loss = 0.0034583518

Training iteration loss = 0.005480247

Training iteration loss = 0.0032050733

Training iteration loss = 0.003294967

Training iteration loss = 0.0033733717

Training iteration loss = 0.0071665044

Training iteration loss = 0.004249556

Training iteration loss = 0.003411549

Training iteration loss = 0.0025654442

Training iteration loss = 0.0053728092

Training iteration loss = 0.0023511273

Training iteration loss = 0.0024245677

Training iteration loss = 0.0028466547

Training iteration loss = 0.0035875665

Training iteration loss = 0.0029294605

Training iteration loss = 0.003985514

Training iteration loss = 0.0036400107

Training iteration loss = 0.0019869683

Training iteration loss = 0.002589165

Training iteration loss = 0.0019087596

Training iteration loss = 0.0025235612

Training iteration loss = 0.0020634958

Training iteration loss = 0.002564314

Training iteration loss = 0.003469819

Training iteration loss = 0.0034700122

Training iteration loss = 0.0046100183

Training iteration loss = 0.0040801843

Training iteration loss = 0.0044447356

Training iteration loss = 0.0021982281

Training iteration loss = 0.003217715

Training iteration loss = 0.002388557

Training iteration loss = 0.00633784

Training iteration loss = 0.0037604503

Training iteration loss = 0.0029699877

Training iteration loss = 0.0028459132

Training iteration loss = 0.0036613133

Training iteration loss = 0.00767088

Training iteration loss = 0.0023653472

Training iteration loss = 0.0038814133

Training iteration loss = 0.0036834793

Training iteration loss = 0.0023894792

Training iteration loss = 0.0035768412

Training iteration loss = 0.0038305353

Training iteration loss = 0.0028069837

Training iteration loss = 0.0025455058

Training iteration loss = 0.003360467

Training iteration loss = 0.0039927657

Training iteration loss = 0.0037943318

Training iteration loss = 0.0048529007

Training iteration loss = 0.005041884

Training iteration loss = 0.0032038325

Training iteration loss = 0.00374524

Training iteration loss = 0.004658705

Training iteration loss = 0.004745615

Training iteration loss = 0.0029692731

Training iteration loss = 0.0037960643

Training iteration loss = 0.0039839945

Training iteration loss = 0.0025774364

Training iteration loss = 0.0022253233

Training iteration loss = 0.003628276

Training iteration loss = 0.0025443078

Training iteration loss = 0.002206195

Training iteration loss = 0.0031857204

Training iteration loss = 0.0023190356

Training iteration loss = 0.00197943

Training iteration loss = 0.0018429528

Training iteration loss = 0.0031297158

Training iteration loss = 0.0020903994

Training iteration loss = 0.0023816412

Training iteration loss = 0.0041201008

Training iteration loss = 0.0055937897

Training iteration loss = 0.0025476047

Training iteration loss = 0.0028308295

Training iteration loss = 0.0025640894

Training iteration loss = 0.0028424377

Training iteration loss = 0.002221064

Training iteration loss = 0.004207824

Training iteration loss = 0.0034582121

Training iteration loss = 0.00490816

Training iteration loss = 0.004167527

Training iteration loss = 0.0029421032

Training iteration loss = 0.0020384586

Training iteration loss = 0.0021931324

Training iteration loss = 0.008572446

Training iteration loss = 0.003165935

Training iteration loss = 0.0018615448

Training iteration loss = 0.0043349946

Training iteration loss = 0.0038063386

Training iteration loss = 0.0035518736

Training iteration loss = 0.0031080337

Training iteration loss = 0.004091552

Training iteration loss = 0.002358292

Training iteration loss = 0.0068340357

Training iteration loss = 0.0025935853

Training iteration loss = 0.0033825536

Training iteration loss = 0.0040211026

Training iteration loss = 0.0022140676

Training iteration loss = 0.0022626703

Training iteration loss = 0.0026441303

Training iteration loss = 0.0017486817

Training iteration loss = 0.0034372415

Training iteration loss = 0.0032153402

Training iteration loss = 0.004259434

Training iteration loss = 0.0031420582

Training iteration loss = 0.0028503935

Training iteration loss = 0.0022078499

Training iteration loss = 0.0022513

Training iteration loss = 0.0024262194

Training iteration loss = 0.003115332

Training iteration loss = 0.0050174384

Training iteration loss = 0.0019189465

Training iteration loss = 0.0029562106

Training iteration loss = 0.0030734797

Training iteration loss = 0.0035900783

Training iteration loss = 0.0030169915

Training iteration loss = 0.0033756855

Training iteration loss = 0.0028897475

Training iteration loss = 0.0018903752

Training iteration loss = 0.0063502714

Training iteration loss = 0.0030426458

Training iteration loss = 0.002611541

Training iteration loss = 0.0018382504

Training iteration loss = 0.0034472176

Training iteration loss = 0.003723503

Training iteration loss = 0.0038012713

Training iteration loss = 0.002499703

Training iteration loss = 0.005764913

Training iteration loss = 0.0032116103

Training iteration loss = 0.0024113157

Training iteration loss = 0.0020231642

Training iteration loss = 0.0025167782

Training iteration loss = 0.0020067554

Training iteration loss = 0.0033940563

Training iteration loss = 0.0018674522

Training iteration loss = 0.0020746265

Training iteration loss = 0.0036137465

Training iteration loss = 0.0030018406

Training iteration loss = 0.003483154

Training iteration loss = 0.002653769

Training iteration loss = 0.0041588047

Training iteration loss = 0.0041710325

Training iteration loss = 0.004542128

Training iteration loss = 0.002110716

Training iteration loss = 0.002912036

Training iteration loss = 0.0024391266

Training iteration loss = 0.0037877718

Training iteration loss = 0.0034655354

Training iteration loss = 0.0048741843

Training iteration loss = 0.002929368

Training iteration loss = 0.0025172725

Training iteration loss = 0.0031451837

Training iteration loss = 0.0049679726

Training iteration loss = 0.0033579862

Training iteration loss = 0.002855829

Training iteration loss = 0.0034185199

Training iteration loss = 0.00335944

Training iteration loss = 0.0025140215

Training iteration loss = 0.0028853829

Training iteration loss = 0.003779454

Training iteration loss = 0.0030216386

Training iteration loss = 0.0032821177

Training iteration loss = 0.0028578192

Training iteration loss = 0.0023891993

Training iteration loss = 0.0046073156

Training iteration loss = 0.0043256716

Training iteration loss = 0.0038091682

Training iteration loss = 0.003714204

Training iteration loss = 0.0022566079

Training iteration loss = 0.004647884

Training iteration loss = 0.0055973493

Training iteration loss = 0.0025213098

Training iteration loss = 0.0034252666

Training iteration loss = 0.0024497511

Training iteration loss = 0.0026739233

Training iteration loss = 0.0027643926

Training iteration loss = 0.0026283504

Training iteration loss = 0.0052040606

Training iteration loss = 0.006151838

Training iteration loss = 0.0025815647

Training iteration loss = 0.002940337

Training iteration loss = 0.002266652

Training iteration loss = 0.0026674606

Training iteration loss = 0.003501186

Training iteration loss = 0.0033483813

Training iteration loss = 0.0038589367

Training iteration loss = 0.002281129

Training iteration loss = 0.0037809622

Training iteration loss = 0.007485477

Training iteration loss = 0.0048877625

Training iteration loss = 0.0038924504

Training iteration loss = 0.003055061

Training iteration loss = 0.0035076544

Training iteration loss = 0.0026490868

Training iteration loss = 0.0035149679

Training iteration loss = 0.0021928481

Training iteration loss = 0.0027290052

Training iteration loss = 0.002708639

Training iteration loss = 0.0029300582

Training iteration loss = 0.002123648

Training iteration loss = 0.0044647274

Training iteration loss = 0.0034518365

Training iteration loss = 0.005479515

Training iteration loss = 0.0032028237

Training iteration loss = 0.0032910865

Training iteration loss = 0.0033738054

Training iteration loss = 0.0071504866

Training iteration loss = 0.0042349533

Training iteration loss = 0.0034116602

Training iteration loss = 0.0025661602

Training iteration loss = 0.0053585786

Training iteration loss = 0.002347973

Training iteration loss = 0.0024236334

Training iteration loss = 0.0028453928

Training iteration loss = 0.0035889514

Training iteration loss = 0.0029289778

Training iteration loss = 0.0039859447

Training iteration loss = 0.0036362505

Training iteration loss = 0.0019829208

Training iteration loss = 0.002581238

Training iteration loss = 0.0019089044

Training iteration loss = 0.002519172

Training iteration loss = 0.0020625438

Training iteration loss = 0.0025560341

Training iteration loss = 0.0034651926

Training iteration loss = 0.0034674264

Training iteration loss = 0.0046024635

Training iteration loss = 0.004075594

Training iteration loss = 0.004432782

Training iteration loss = 0.002195341

Training iteration loss = 0.0032113632

Training iteration loss = 0.0023814111

Training iteration loss = 0.0063220975

Training iteration loss = 0.0037523403

Training iteration loss = 0.0029705868

Training iteration loss = 0.002844279

Training iteration loss = 0.0036597631

Training iteration loss = 0.0076379045

Training iteration loss = 0.0023630634

Training iteration loss = 0.0038780577

Training iteration loss = 0.0036823673

Training iteration loss = 0.0023893742

Training iteration loss = 0.003571448

Training iteration loss = 0.0038228359

Training iteration loss = 0.002801207

Training iteration loss = 0.0025463551

Training iteration loss = 0.003359617

Training iteration loss = 0.0039845593

Training iteration loss = 0.0037885846

Training iteration loss = 0.004834128

Training iteration loss = 0.0050305123

Training iteration loss = 0.0032040393

Training iteration loss = 0.0037348808

Training iteration loss = 0.004644196

Training iteration loss = 0.0047380687

Training iteration loss = 0.0029664745

Training iteration loss = 0.0037880514

Training iteration loss = 0.003986279

Training iteration loss = 0.002574228

Training iteration loss = 0.0022213468

Training iteration loss = 0.0036245568

Training iteration loss = 0.0025372982

Training iteration loss = 0.0022041134

Training iteration loss = 0.003180706

Training iteration loss = 0.0023164232

Training iteration loss = 0.0019762872

Training iteration loss = 0.0018403718

Training iteration loss = 0.0031253349

Training iteration loss = 0.0020888767

Training iteration loss = 0.0023728756

Training iteration loss = 0.0041138665

Training iteration loss = 0.005579555

Training iteration loss = 0.002546373

Training iteration loss = 0.0028293093

Training iteration loss = 0.0025590057

Training iteration loss = 0.0028400084

Training iteration loss = 0.0022204174

Training iteration loss = 0.0042029587

Training iteration loss = 0.0034557404

Training iteration loss = 0.0049035004

Training iteration loss = 0.004152251

Training iteration loss = 0.0029413123

Training iteration loss = 0.0020365166

Training iteration loss = 0.0021909927

Training iteration loss = 0.008578804

Training iteration loss = 0.0031569593

Training iteration loss = 0.0018608501

Training iteration loss = 0.0043286067

Training iteration loss = 0.003807632

Training iteration loss = 0.0035431273

Training iteration loss = 0.0031032015

Training iteration loss = 0.004085515

Training iteration loss = 0.002355664

Training iteration loss = 0.006812123

Training iteration loss = 0.0025955387

Training iteration loss = 0.0033847839

Training iteration loss = 0.0040149814

Training iteration loss = 0.002212262

Training iteration loss = 0.002259135

Training iteration loss = 0.002644106

Training iteration loss = 0.0017454434

Training iteration loss = 0.0034319882

Training iteration loss = 0.0032129837

Training iteration loss = 0.00425583

Training iteration loss = 0.0031375454

Training iteration loss = 0.0028498464

Training iteration loss = 0.0022083137

Training iteration loss = 0.002252228

Training iteration loss = 0.0024246443

Training iteration loss = 0.0031156044

Training iteration loss = 0.004996045

Training iteration loss = 0.0019163302

Training iteration loss = 0.0029596777

Training iteration loss = 0.0030726579

Training iteration loss = 0.0035762836

Training iteration loss = 0.0030099805

Training iteration loss = 0.0033729353

Training iteration loss = 0.0028812715

Training iteration loss = 0.0018877601

Training iteration loss = 0.0063396343

Training iteration loss = 0.0030373146

Training iteration loss = 0.0026131968

Training iteration loss = 0.0018339235

Training iteration loss = 0.0034453627

Training iteration loss = 0.0037198786

Training iteration loss = 0.0037933209

Training iteration loss = 0.0024961657

Training iteration loss = 0.005762898

Training iteration loss = 0.0032054316

Training iteration loss = 0.0024043792

Training iteration loss = 0.0020232967

Training iteration loss = 0.0025182322

Training iteration loss = 0.0020051182

Training iteration loss = 0.0033814153

Training iteration loss = 0.0018638297

Training iteration loss = 0.002073236

Training iteration loss = 0.0036130908

Training iteration loss = 0.002997618

Training iteration loss = 0.0034765813

Training iteration loss = 0.002650664

Training iteration loss = 0.0041519753

Training iteration loss = 0.0041693226

Training iteration loss = 0.0045387964

Training iteration loss = 0.002106977

Training iteration loss = 0.0029112713

Training iteration loss = 0.0024392793

Training iteration loss = 0.0037872295

Training iteration loss = 0.0034623567

Training iteration loss = 0.004868206

Training iteration loss = 0.0029250353

Training iteration loss = 0.0025155942

Training iteration loss = 0.0031455513

Training iteration loss = 0.004957056

Training iteration loss = 0.0033558859

Training iteration loss = 0.0028480229

Training iteration loss = 0.003412863

Training iteration loss = 0.0033560141

Training iteration loss = 0.0025138909

Training iteration loss = 0.002869311

Training iteration loss = 0.0037728008

Training iteration loss = 0.0030211192

Training iteration loss = 0.0032769404

Training iteration loss = 0.0028533873

Training iteration loss = 0.002386438

Training iteration loss = 0.0046028146

Training iteration loss = 0.0043237885

Training iteration loss = 0.0038083221

Training iteration loss = 0.0037206353

Training iteration loss = 0.0022554973

Training iteration loss = 0.0046403254

Training iteration loss = 0.0055933413

Training iteration loss = 0.0025142515

Training iteration loss = 0.0034198056

Training iteration loss = 0.0024489264

Training iteration loss = 0.0026685486

Training iteration loss = 0.0027607034

Training iteration loss = 0.0026236875

Training iteration loss = 0.005190471

Training iteration loss = 0.0061295093

Training iteration loss = 0.0025795072

Training iteration loss = 0.0029333986

Training iteration loss = 0.0022633947

Training iteration loss = 0.0026651782

Training iteration loss = 0.0034902173

Training iteration loss = 0.003344951

Training iteration loss = 0.0038472537

Training iteration loss = 0.0022795433

Training iteration loss = 0.0037678014

Training iteration loss = 0.0074672927

Training iteration loss = 0.0048792404

Training iteration loss = 0.0038881542

Training iteration loss = 0.003051019

Training iteration loss = 0.003508879

Training iteration loss = 0.0026471058

Training iteration loss = 0.0035090186

Training iteration loss = 0.0021887098

Training iteration loss = 0.0027276557

Training iteration loss = 0.00270486

Training iteration loss = 0.0029135104

Training iteration loss = 0.002117045

Training iteration loss = 0.004463498

Training iteration loss = 0.0034447673

Training iteration loss = 0.0054789274

Training iteration loss = 0.0032016004

Training iteration loss = 0.0032875522

Training iteration loss = 0.003371957

Training iteration loss = 0.007135169

Training iteration loss = 0.004219473

Training iteration loss = 0.0034122604

Training iteration loss = 0.0025668766

Training iteration loss = 0.0053435457

Training iteration loss = 0.002344923

Training iteration loss = 0.0024222587

Training iteration loss = 0.002845563

Training iteration loss = 0.0035915736

Training iteration loss = 0.002929829

Training iteration loss = 0.003987341

Training iteration loss = 0.0036324824

Training iteration loss = 0.0019794523

Training iteration loss = 0.0025740194

Training iteration loss = 0.0019103357

Training iteration loss = 0.0025150722

Training iteration loss = 0.002061785

Training iteration loss = 0.0025468804

Training iteration loss = 0.0034616173

Training iteration loss = 0.0034653603

Training iteration loss = 0.00459446

Training iteration loss = 0.004071266

Training iteration loss = 0.0044196346

Training iteration loss = 0.0021924197

Training iteration loss = 0.003205023

Training iteration loss = 0.0023743375

Training iteration loss = 0.0063079833

Training iteration loss = 0.0037449037

Training iteration loss = 0.0029714182

Training iteration loss = 0.0028447658

Training iteration loss = 0.0036586213

Training iteration loss = 0.0076069217

Training iteration loss = 0.0023607125

Training iteration loss = 0.0038748852

Training iteration loss = 0.0036819687

Training iteration loss = 0.0023890317

Training iteration loss = 0.0035663424

Training iteration loss = 0.0038151138

Training iteration loss = 0.002795509

Training iteration loss = 0.0025465065

Training iteration loss = 0.003357887

Training iteration loss = 0.003975346

Training iteration loss = 0.0037809545

Training iteration loss = 0.004812755

Training iteration loss = 0.0050177225

Training iteration loss = 0.0032053834

Training iteration loss = 0.0037257625

Training iteration loss = 0.0046293573

Training iteration loss = 0.004729986

Training iteration loss = 0.0029631555

Training iteration loss = 0.003778397

Training iteration loss = 0.0039897556

Training iteration loss = 0.0025706363

Training iteration loss = 0.002217599

Training iteration loss = 0.0036220879

Training iteration loss = 0.0025300228

Training iteration loss = 0.0022032408

Training iteration loss = 0.0031780032

Training iteration loss = 0.0023135538

Training iteration loss = 0.0019711086

Training iteration loss = 0.0018374218

Training iteration loss = 0.0031208333

Training iteration loss = 0.002089857

Training iteration loss = 0.0023633258

Training iteration loss = 0.00410601

Training iteration loss = 0.0055617266

Training iteration loss = 0.002543739

Training iteration loss = 0.0028284679

Training iteration loss = 0.00255338

Training iteration loss = 0.0028372628

Training iteration loss = 0.0022195068

Training iteration loss = 0.004198152

Training iteration loss = 0.0034520703

Training iteration loss = 0.0049003814

Training iteration loss = 0.0041373726

Training iteration loss = 0.002940134

Training iteration loss = 0.0020326546

Training iteration loss = 0.0021877547

Training iteration loss = 0.008582412

Training iteration loss = 0.0031485541

Training iteration loss = 0.0018603022

Training iteration loss = 0.004323605

Training iteration loss = 0.003807849

Training iteration loss = 0.0035342637

Training iteration loss = 0.0030957998

Training iteration loss = 0.004077663

Training iteration loss = 0.0023516528

Training iteration loss = 0.0067906813

Training iteration loss = 0.0025987234

Training iteration loss = 0.0033891136

Training iteration loss = 0.004010231

Training iteration loss = 0.0022093195

Training iteration loss = 0.002254099

Training iteration loss = 0.0026413498

Training iteration loss = 0.0017423449

Training iteration loss = 0.0034262333

Training iteration loss = 0.003212801

Training iteration loss = 0.004253958

Training iteration loss = 0.0031337782

Training iteration loss = 0.0028479155

Training iteration loss = 0.0022097912

Training iteration loss = 0.0022538349

Training iteration loss = 0.0024232848

Training iteration loss = 0.0031160011

Training iteration loss = 0.0049780216

Training iteration loss = 0.0019132247

Training iteration loss = 0.0029640973

Training iteration loss = 0.003074004

Training iteration loss = 0.0035631147

Training iteration loss = 0.0030010901

Training iteration loss = 0.0033707751

Training iteration loss = 0.0028740268

Training iteration loss = 0.0018833717

Training iteration loss = 0.0063311923

Training iteration loss = 0.0030317793

Training iteration loss = 0.002614111

Training iteration loss = 0.0018316909

Training iteration loss = 0.0034437815

Training iteration loss = 0.0037176933

Training iteration loss = 0.0037885515

Training iteration loss = 0.0024930483

Training iteration loss = 0.005761796

Training iteration loss = 0.0031993147

Training iteration loss = 0.0023991724

Training iteration loss = 0.0020267842

Training iteration loss = 0.0025223242

Training iteration loss = 0.0020018464

Training iteration loss = 0.0033696268

Training iteration loss = 0.0018606564

Training iteration loss = 0.0020729194

Training iteration loss = 0.0036107402

Training iteration loss = 0.002995021

Training iteration loss = 0.0034686287

Training iteration loss = 0.0026467629

Training iteration loss = 0.0041428027

Training iteration loss = 0.004167717

Training iteration loss = 0.004535654

Training iteration loss = 0.00210266

Training iteration loss = 0.0029110003

Training iteration loss = 0.0024393646

Training iteration loss = 0.0037855923

Training iteration loss = 0.0034590878

Training iteration loss = 0.004860709

Training iteration loss = 0.0029201435

Training iteration loss = 0.0025149242

Training iteration loss = 0.0031448035

Training iteration loss = 0.0049449517

Training iteration loss = 0.0033558998

Training iteration loss = 0.0028410861

Training iteration loss = 0.0034063624

Training iteration loss = 0.0033510595

Training iteration loss = 0.0025118887

Training iteration loss = 0.002851409

Training iteration loss = 0.003768082

Training iteration loss = 0.0030197601

Training iteration loss = 0.0032721285

Training iteration loss = 0.0028493844

Training iteration loss = 0.0023830552

Training iteration loss = 0.004596327

Training iteration loss = 0.0043142694

Training iteration loss = 0.003808515

Training iteration loss = 0.0037220533

Training iteration loss = 0.0022547615

Training iteration loss = 0.0046319324

Training iteration loss = 0.005590107

Training iteration loss = 0.002505971

Training iteration loss = 0.0034124395

Training iteration loss = 0.0024474098

Training iteration loss = 0.0026632517

Training iteration loss = 0.0027572184

Training iteration loss = 0.002618388

Training iteration loss = 0.005176597

Training iteration loss = 0.0061050244

Training iteration loss = 0.0025764203

Training iteration loss = 0.0029285236

Training iteration loss = 0.0022599362

Training iteration loss = 0.002663473

Training iteration loss = 0.003479776

Training iteration loss = 0.0033428606

Training iteration loss = 0.0038369084

Training iteration loss = 0.0022770255

Training iteration loss = 0.0037552565

Training iteration loss = 0.007452766

Training iteration loss = 0.004871641

Training iteration loss = 0.0038832866

Training iteration loss = 0.0030459457

Training iteration loss = 0.0035091557

Training iteration loss = 0.0026441964

Training iteration loss = 0.0035023673

Training iteration loss = 0.0021831833

Training iteration loss = 0.0027249053

Training iteration loss = 0.0027004052

Training iteration loss = 0.0028989303

Training iteration loss = 0.0021103418

Training iteration loss = 0.004462693

Training iteration loss = 0.0034389205

Training iteration loss = 0.005477172

Training iteration loss = 0.0031997692

Training iteration loss = 0.0032833095

Training iteration loss = 0.0033769498

Training iteration loss = 0.007119085

Training iteration loss = 0.0042070313

Training iteration loss = 0.003412008

Training iteration loss = 0.0025657015

Training iteration loss = 0.0053234342

Training iteration loss = 0.0023418504

Training iteration loss = 0.002419573

Training iteration loss = 0.0028461728

Training iteration loss = 0.0035945054

Training iteration loss = 0.0029285531

Training iteration loss = 0.003986797

Training iteration loss = 0.0036303357

Training iteration loss = 0.0019741978

Training iteration loss = 0.0025669532

Training iteration loss = 0.0019084242

Training iteration loss = 0.0025085167

Training iteration loss = 0.0020572494

Training iteration loss = 0.0025385292

Training iteration loss = 0.0034565115

Training iteration loss = 0.003460154

Training iteration loss = 0.004584936

Training iteration loss = 0.0040682866

Training iteration loss = 0.0044078305

Training iteration loss = 0.0021900255

Training iteration loss = 0.0031987894

Training iteration loss = 0.0023681612

Training iteration loss = 0.0063029774

Training iteration loss = 0.0037409354

Training iteration loss = 0.002971308

Training iteration loss = 0.002842189

Training iteration loss = 0.0036570935

Training iteration loss = 0.007592473

Training iteration loss = 0.0023610415

Training iteration loss = 0.0038711678

Training iteration loss = 0.0036767006

Training iteration loss = 0.0023852924

Training iteration loss = 0.0035581337

Training iteration loss = 0.0038101

Training iteration loss = 0.0027902173

Training iteration loss = 0.0025478483

Training iteration loss = 0.0033550935

Training iteration loss = 0.003963607

Training iteration loss = 0.003776444

Training iteration loss = 0.004797572

Training iteration loss = 0.00501077

Training iteration loss = 0.0032056672

Training iteration loss = 0.0037185308

Training iteration loss = 0.0046168524

Training iteration loss = 0.0047221067

Training iteration loss = 0.002956656

Training iteration loss = 0.003772363

Training iteration loss = 0.0039913896

Training iteration loss = 0.0025718529

Training iteration loss = 0.0022119724

Training iteration loss = 0.0036151493

Training iteration loss = 0.0025292125

Training iteration loss = 0.0022005828

Training iteration loss = 0.0031736523

Training iteration loss = 0.0023105205

Training iteration loss = 0.001968285

Training iteration loss = 0.0018348942

Training iteration loss = 0.0031181194

Training iteration loss = 0.0020853113

Training iteration loss = 0.0023557025

Training iteration loss = 0.004104284

Training iteration loss = 0.0055552204

Training iteration loss = 0.0025437376

Training iteration loss = 0.002824055

Training iteration loss = 0.0025451193

Training iteration loss = 0.0028344335

Training iteration loss = 0.0022194628

Training iteration loss = 0.0041961204

Training iteration loss = 0.0034510188

Training iteration loss = 0.004894993

Training iteration loss = 0.0041228565

Training iteration loss = 0.002939639

Training iteration loss = 0.0020309922

Training iteration loss = 0.0021857617

Training iteration loss = 0.008594037

Training iteration loss = 0.0031420288

Training iteration loss = 0.0018575513

Training iteration loss = 0.004321702

Training iteration loss = 0.003810661

Training iteration loss = 0.003528076

Training iteration loss = 0.0030883614

Training iteration loss = 0.004071669

Training iteration loss = 0.0023485979

Training iteration loss = 0.0067697633

Training iteration loss = 0.0025998096

Training iteration loss = 0.0033934265

Training iteration loss = 0.0040065283

Training iteration loss = 0.0022082462

Training iteration loss = 0.0022503433

Training iteration loss = 0.0026410967

Training iteration loss = 0.0017385231

Training iteration loss = 0.0034202512

Training iteration loss = 0.003213072

Training iteration loss = 0.004253211

Training iteration loss = 0.0031299153

Training iteration loss = 0.002847574

Training iteration loss = 0.0022111028

Training iteration loss = 0.0022569129

Training iteration loss = 0.0024219158

Training iteration loss = 0.0031151155

Training iteration loss = 0.00495955

Training iteration loss = 0.0019099759

Training iteration loss = 0.0029687025

Training iteration loss = 0.0030740427

Training iteration loss = 0.0035501851

Training iteration loss = 0.0029921643

Training iteration loss = 0.0033688091

Training iteration loss = 0.0028671492

Training iteration loss = 0.0018797027

Training iteration loss = 0.0063182637

Training iteration loss = 0.003027343

Training iteration loss = 0.0026152122

Training iteration loss = 0.0018275253

Training iteration loss = 0.0034411876

Training iteration loss = 0.0037137314

Training iteration loss = 0.0037818048

Training iteration loss = 0.0024889093

Training iteration loss = 0.005760892

Training iteration loss = 0.003193845

Training iteration loss = 0.0023913132

Training iteration loss = 0.002027175

Training iteration loss = 0.0025233552

Training iteration loss = 0.0019996641

Training iteration loss = 0.0033572812

Training iteration loss = 0.0018570325

Training iteration loss = 0.0020720607

Training iteration loss = 0.0036114154

Training iteration loss = 0.0029922219

Training iteration loss = 0.0034620883

Training iteration loss = 0.002643776

Training iteration loss = 0.0041372045

Training iteration loss = 0.0041668196

Training iteration loss = 0.0045312266

Training iteration loss = 0.002097779

Training iteration loss = 0.002908781

Training iteration loss = 0.002439952

Training iteration loss = 0.0037852966

Training iteration loss = 0.0034557413

Training iteration loss = 0.0048555722

Training iteration loss = 0.0029169656

Training iteration loss = 0.0025125218

Training iteration loss = 0.0031456156

Training iteration loss = 0.0049345023

Training iteration loss = 0.0033527215

Training iteration loss = 0.0028334698

Training iteration loss = 0.0034007756

Training iteration loss = 0.003344991

Training iteration loss = 0.0025107977

Training iteration loss = 0.0028367483

Training iteration loss = 0.003760427

Training iteration loss = 0.0030197513

Training iteration loss = 0.0032651846

Training iteration loss = 0.0028451122

Training iteration loss = 0.0023800042

Training iteration loss = 0.004592031

Training iteration loss = 0.004314767

Training iteration loss = 0.0038079405

Training iteration loss = 0.0037271755

Training iteration loss = 0.0022538267

Training iteration loss = 0.0046256282

Training iteration loss = 0.0055875927

Training iteration loss = 0.0024993198

Training iteration loss = 0.0034087354

Training iteration loss = 0.002445913

Training iteration loss = 0.0026599446

Training iteration loss = 0.002753554

Training iteration loss = 0.002613044

Training iteration loss = 0.0051637595

Training iteration loss = 0.0060840244

Training iteration loss = 0.002574668

Training iteration loss = 0.0029233529

Training iteration loss = 0.0022561122

Training iteration loss = 0.002661181

Training iteration loss = 0.003469456

Training iteration loss = 0.00333972

Training iteration loss = 0.0038257856

Training iteration loss = 0.0022753652

Training iteration loss = 0.0037428627

Training iteration loss = 0.0074337125

Training iteration loss = 0.0048633604

Training iteration loss = 0.0038801183

Training iteration loss = 0.0030419603

Training iteration loss = 0.0035106295

Training iteration loss = 0.0026420085

Training iteration loss = 0.0034966953

Training iteration loss = 0.0021798706

Training iteration loss = 0.0027232554

Training iteration loss = 0.0026974268

Training iteration loss = 0.0028850317

Training iteration loss = 0.0021039422

Training iteration loss = 0.004462337

Training iteration loss = 0.0034316394

Training iteration loss = 0.0054766275

Training iteration loss = 0.0031997499

Training iteration loss = 0.003280162

Training iteration loss = 0.0033729507

Training iteration loss = 0.0071040615

Training iteration loss = 0.004191421

Training iteration loss = 0.0034129496

Training iteration loss = 0.0025674875

Training iteration loss = 0.005309282

Training iteration loss = 0.0023388744

Training iteration loss = 0.002418756

Training iteration loss = 0.002846569

Training iteration loss = 0.003597524

Training iteration loss = 0.002931936

Training iteration loss = 0.0039888388

Training iteration loss = 0.003626926

Training iteration loss = 0.001970777

Training iteration loss = 0.0025606784

Training iteration loss = 0.0019125418

Training iteration loss = 0.0025067204

Training iteration loss = 0.0020592378

Training iteration loss = 0.0025296255

Training iteration loss = 0.0034548447

Training iteration loss = 0.003461234

Training iteration loss = 0.004578917

Training iteration loss = 0.004063714

Training iteration loss = 0.0043943846

Training iteration loss = 0.0021865694

Training iteration loss = 0.0031925

Training iteration loss = 0.0023600778

Training iteration loss = 0.0062875147

Training iteration loss = 0.0037334217

Training iteration loss = 0.0029727872

Training iteration loss = 0.002845181

Training iteration loss = 0.0036552222

Training iteration loss = 0.0075589786

Training iteration loss = 0.0023571532

Training iteration loss = 0.003868087

Training iteration loss = 0.0036790918

Training iteration loss = 0.0023847537

Training iteration loss = 0.0035528129

Training iteration loss = 0.0038005726

Training iteration loss = 0.0027836997

Training iteration loss = 0.0025470017

Training iteration loss = 0.0033505496

Training iteration loss = 0.0039554234

Training iteration loss = 0.0037697358

Training iteration loss = 0.0047793393

Training iteration loss = 0.004994791

Training iteration loss = 0.0032053504

Training iteration loss = 0.0037110501

Training iteration loss = 0.00460377

Training iteration loss = 0.004717668

Training iteration loss = 0.0029538888

Training iteration loss = 0.0037650347

Training iteration loss = 0.0039979736

Training iteration loss = 0.0025685902

Training iteration loss = 0.0022104215

Training iteration loss = 0.0036133004

Training iteration loss = 0.0025203524

Training iteration loss = 0.0022005376

Training iteration loss = 0.0031747345

Training iteration loss = 0.0023092409

Training iteration loss = 0.00196192

Training iteration loss = 0.0018329645

Training iteration loss = 0.0031141678

Training iteration loss = 0.0020874653

Training iteration loss = 0.0023449187

Training iteration loss = 0.00409365

Training iteration loss = 0.0055368557

Training iteration loss = 0.0025413213

Training iteration loss = 0.0028242553

Training iteration loss = 0.002538054

Training iteration loss = 0.002829878

Training iteration loss = 0.002217944

Training iteration loss = 0.0041902084

Training iteration loss = 0.0034472507

Training iteration loss = 0.0048932037

Training iteration loss = 0.004111121

Training iteration loss = 0.002940228

Training iteration loss = 0.0020273605

Training iteration loss = 0.0021824795

Training iteration loss = 0.008587173

Training iteration loss = 0.0031314094

Training iteration loss = 0.0018604131

Training iteration loss = 0.004314245

Training iteration loss = 0.0038102234

Training iteration loss = 0.0035184799

Training iteration loss = 0.0030823129

Training iteration loss = 0.0040641585

Training iteration loss = 0.0023456176

Training iteration loss = 0.0067588906

Training iteration loss = 0.0026056028

Training iteration loss = 0.0033971646

Training iteration loss = 0.003998079

Training iteration loss = 0.0022039462

Training iteration loss = 0.002243919

Training iteration loss = 0.002638918

Training iteration loss = 0.0017351176

Training iteration loss = 0.0034154768

Training iteration loss = 0.0032136813

Training iteration loss = 0.00425462

Training iteration loss = 0.0031257232

Training iteration loss = 0.0028484247

Training iteration loss = 0.002213093

Training iteration loss = 0.002260627

Training iteration loss = 0.002419027

Training iteration loss = 0.0031150328

Training iteration loss = 0.004938727

Training iteration loss = 0.0019053612

Training iteration loss = 0.0029749668

Training iteration loss = 0.003075095

Training iteration loss = 0.003539888

Training iteration loss = 0.0029858781

Training iteration loss = 0.0033661313

Training iteration loss = 0.002860829

Training iteration loss = 0.0018764775

Training iteration loss = 0.006309733

Training iteration loss = 0.003021964

Training iteration loss = 0.0026178313

Training iteration loss = 0.0018250727

Training iteration loss = 0.0034393035

Training iteration loss = 0.003713453

Training iteration loss = 0.0037772907

Training iteration loss = 0.0024849328

Training iteration loss = 0.005760643

Training iteration loss = 0.0031879896

Training iteration loss = 0.0023817848

Training iteration loss = 0.0020269256

Training iteration loss = 0.0025220616

Training iteration loss = 0.0019988688

Training iteration loss = 0.0033432161

Training iteration loss = 0.0018533008

Training iteration loss = 0.0020716265

Training iteration loss = 0.003618341

Training iteration loss = 0.0029883718

Training iteration loss = 0.003457634

Training iteration loss = 0.0026418918

Training iteration loss = 0.0041342466

Training iteration loss = 0.0041658017

Training iteration loss = 0.0045213643

Training iteration loss = 0.0020945158

Training iteration loss = 0.0029081826

Training iteration loss = 0.002442356

Training iteration loss = 0.0037873688

Training iteration loss = 0.0034516668

Training iteration loss = 0.004854713

Training iteration loss = 0.0029167042

Training iteration loss = 0.002510382

Training iteration loss = 0.0031485101

Training iteration loss = 0.004927674

Training iteration loss = 0.0033482893

Training iteration loss = 0.0028245144

Training iteration loss = 0.0033974757

Training iteration loss = 0.0033411065

Training iteration loss = 0.0025126033

Training iteration loss = 0.002824791

Training iteration loss = 0.0037504965

Training iteration loss = 0.0030184744

Training iteration loss = 0.003256144

Training iteration loss = 0.0028412046

Training iteration loss = 0.0023778067

Training iteration loss = 0.0045885514

Training iteration loss = 0.0043186247

Training iteration loss = 0.0038063454

Training iteration loss = 0.0037330315

Training iteration loss = 0.0022534765

Training iteration loss = 0.004620739

Training iteration loss = 0.005584046

Training iteration loss = 0.0024950725

Training iteration loss = 0.0034062937

Training iteration loss = 0.0024452507

Training iteration loss = 0.0026570975

Training iteration loss = 0.0027500808

Training iteration loss = 0.0026073747

Training iteration loss = 0.0051518455

Training iteration loss = 0.0060652643

Training iteration loss = 0.002572987

Training iteration loss = 0.0029182073

Training iteration loss = 0.0022522623

Training iteration loss = 0.0026591185

Training iteration loss = 0.003459785

Training iteration loss = 0.003335918

Training iteration loss = 0.0038145098

Training iteration loss = 0.0022742825

Training iteration loss = 0.0037304882

Training iteration loss = 0.007419886

Training iteration loss = 0.0048553464

Training iteration loss = 0.0038768714

Training iteration loss = 0.003037789

Training iteration loss = 0.0035126454

Training iteration loss = 0.0026398506

Training iteration loss = 0.0034895882

Training iteration loss = 0.002175644

Training iteration loss = 0.0027207062

Training iteration loss = 0.0026929367

Training iteration loss = 0.0028689576

Training iteration loss = 0.0020975182

Training iteration loss = 0.004461516

Training iteration loss = 0.0034257027

Training iteration loss = 0.0054750643

Training iteration loss = 0.0031991324

Training iteration loss = 0.003276783

Training iteration loss = 0.0033722196

Training iteration loss = 0.007089041

Training iteration loss = 0.0041781915

Training iteration loss = 0.003414072

Training iteration loss = 0.0025685234

Training iteration loss = 0.005293436

Training iteration loss = 0.0023355547

Training iteration loss = 0.002417365

Training iteration loss = 0.0028470652

Training iteration loss = 0.0036004428

Training iteration loss = 0.002932511

Training iteration loss = 0.0039885417

Training iteration loss = 0.0036251263

Training iteration loss = 0.0019686206

Training iteration loss = 0.0025547529

Training iteration loss = 0.0019136997

Training iteration loss = 0.0025036044

Training iteration loss = 0.0020594888

Training iteration loss = 0.002523137

Training iteration loss = 0.003450429

Training iteration loss = 0.0034589607

Training iteration loss = 0.004571996

Training iteration loss = 0.004058397

Training iteration loss = 0.004381795

Training iteration loss = 0.002184016

Training iteration loss = 0.0031868592

Training iteration loss = 0.0023526151

Training iteration loss = 0.006274697

Training iteration loss = 0.0037274293

Training iteration loss = 0.002973305

Training iteration loss = 0.0028445192

Training iteration loss = 0.0036531342

Training iteration loss = 0.00752851

Training iteration loss = 0.002355831

Training iteration loss = 0.0038635172

Training iteration loss = 0.003678563

Training iteration loss = 0.002383745

Training iteration loss = 0.003548091

Training iteration loss = 0.0037929101

Training iteration loss = 0.0027784395

Training iteration loss = 0.0025481402

Training iteration loss = 0.0033476253

Training iteration loss = 0.0039476207

Training iteration loss = 0.0037630734

Training iteration loss = 0.004757776

Training iteration loss = 0.0049846303

Training iteration loss = 0.0032050859

Training iteration loss = 0.0037059411

Training iteration loss = 0.00458888

Training iteration loss = 0.004714543

Training iteration loss = 0.0029502942

Training iteration loss = 0.0037590265

Training iteration loss = 0.0040018344

Training iteration loss = 0.0025673092

Training iteration loss = 0.0022077041

Training iteration loss = 0.0036072556

Training iteration loss = 0.0025137211

Training iteration loss = 0.002200588

Training iteration loss = 0.0031727117

Training iteration loss = 0.0023085221

Training iteration loss = 0.0019573227

Training iteration loss = 0.0018331195

Training iteration loss = 0.0031128656

Training iteration loss = 0.002085427

Training iteration loss = 0.0023341442

Training iteration loss = 0.0040838826

Training iteration loss = 0.005523274

Training iteration loss = 0.0025400112

Training iteration loss = 0.002824574

Training iteration loss = 0.0025330994

Training iteration loss = 0.0028240636

Training iteration loss = 0.0022171212

Training iteration loss = 0.0041854694

Training iteration loss = 0.0034464898

Training iteration loss = 0.004891043

Training iteration loss = 0.004102191

Training iteration loss = 0.0029405216

Training iteration loss = 0.0020264057

Training iteration loss = 0.00217944

Training iteration loss = 0.0085746115

Training iteration loss = 0.0031205695

Training iteration loss = 0.0018616518

Training iteration loss = 0.0043044253

Training iteration loss = 0.003810875

Training iteration loss = 0.003509637

Training iteration loss = 0.003077626

Training iteration loss = 0.0040590414

Training iteration loss = 0.0023428365

Training iteration loss = 0.0067464765

Training iteration loss = 0.0026060808

Training iteration loss = 0.0033972878

Training iteration loss = 0.0039891195

Training iteration loss = 0.0022012333

Training iteration loss = 0.0022421652

Training iteration loss = 0.0026387852

Training iteration loss = 0.0017328472

Training iteration loss = 0.003411696

Training iteration loss = 0.0032053695

Training iteration loss = 0.0042429375

Training iteration loss = 0.0031209884

Training iteration loss = 0.0028466245

Training iteration loss = 0.0022117866

Training iteration loss = 0.0022559476

Training iteration loss = 0.0024176103

Training iteration loss = 0.0031129664

Training iteration loss = 0.0049279397

Training iteration loss = 0.0019046691

Training iteration loss = 0.0029749013

Training iteration loss = 0.0030723512

Training iteration loss = 0.0035222562

Training iteration loss = 0.002978938

Training iteration loss = 0.0033625865

Training iteration loss = 0.0028494198

Training iteration loss = 0.0018751415

Training iteration loss = 0.006291243

Training iteration loss = 0.003014847

Training iteration loss = 0.0026156444

Training iteration loss = 0.0018217629

Training iteration loss = 0.0034367777

Training iteration loss = 0.0037072224

Training iteration loss = 0.0037678622

Training iteration loss = 0.002481111

Training iteration loss = 0.0057624467

Training iteration loss = 0.0031855619

Training iteration loss = 0.0023797392

Training iteration loss = 0.0020279905

Training iteration loss = 0.0025243321

Training iteration loss = 0.0019981219

Training iteration loss = 0.003332101

Training iteration loss = 0.001851475

Training iteration loss = 0.0020691399

Training iteration loss = 0.0036114554

Training iteration loss = 0.0029849012

Training iteration loss = 0.0034532708

Training iteration loss = 0.0026403666

Training iteration loss = 0.004120235

Training iteration loss = 0.0041623604

Training iteration loss = 0.0045215534

Training iteration loss = 0.0020925598

Training iteration loss = 0.0029092047

Training iteration loss = 0.0024400346

Training iteration loss = 0.0037880598

Training iteration loss = 0.0034492805

Training iteration loss = 0.004847894

Training iteration loss = 0.0029088052

Training iteration loss = 0.002507895

Training iteration loss = 0.0031456659

Training iteration loss = 0.004913801

Training iteration loss = 0.0033468225

Training iteration loss = 0.0028176783

Training iteration loss = 0.0033911068

Training iteration loss = 0.0033356783

Training iteration loss = 0.0025056372

Training iteration loss = 0.002806329

Training iteration loss = 0.003748601

Training iteration loss = 0.0030179338

Training iteration loss = 0.0032532483

Training iteration loss = 0.0028371129

Training iteration loss = 0.0023729515

Training iteration loss = 0.0045837224

Training iteration loss = 0.004304655

Training iteration loss = 0.0038085124

Training iteration loss = 0.003729446

Training iteration loss = 0.002253719

Training iteration loss = 0.004613275

Training iteration loss = 0.0055822837

Training iteration loss = 0.0024866483

Training iteration loss = 0.0033988974

Training iteration loss = 0.0024433576

Training iteration loss = 0.002652942

Training iteration loss = 0.0027465445

Training iteration loss = 0.0026016014

Training iteration loss = 0.0051361094

Training iteration loss = 0.006041188

Training iteration loss = 0.00256972

Training iteration loss = 0.0029145025

Training iteration loss = 0.0022482302

Training iteration loss = 0.0026575176

Training iteration loss = 0.003449742

Training iteration loss = 0.0033331474

Training iteration loss = 0.0038053344

Training iteration loss = 0.002272531

Training iteration loss = 0.0037177152

Training iteration loss = 0.007405179

Training iteration loss = 0.0048480025

Training iteration loss = 0.0038736127

Training iteration loss = 0.003032535

Training iteration loss = 0.0035131692

Training iteration loss = 0.0026375353

Training iteration loss = 0.0034826966

Training iteration loss = 0.002170701

Training iteration loss = 0.0027167983

Training iteration loss = 0.0026884156

Training iteration loss = 0.0028567256

Training iteration loss = 0.0020914413

Training iteration loss = 0.0044615194

Training iteration loss = 0.003419582

Training iteration loss = 0.00547236

Training iteration loss = 0.0031991564

Training iteration loss = 0.003273392

Training iteration loss = 0.0033760357

Training iteration loss = 0.007072937

Training iteration loss = 0.004166886

Training iteration loss = 0.0034147622

Training iteration loss = 0.002567969

Training iteration loss = 0.0052745794

Training iteration loss = 0.0023319123

Training iteration loss = 0.0024147732

Training iteration loss = 0.002848698

Training iteration loss = 0.0036039713

Training iteration loss = 0.002932396

Training iteration loss = 0.0039873524

Training iteration loss = 0.0036234455

Training iteration loss = 0.0019650927

Training iteration loss = 0.0025493605

Training iteration loss = 0.0019134843

Training iteration loss = 0.0024986763

Training iteration loss = 0.0020565738

Training iteration loss = 0.0025155193

Training iteration loss = 0.0034465615

Training iteration loss = 0.0034552098

Training iteration loss = 0.0045644226

Training iteration loss = 0.004054901

Training iteration loss = 0.004368617

Training iteration loss = 0.0021817747

Training iteration loss = 0.003180688

Training iteration loss = 0.002345559

Training iteration loss = 0.0062666475

Training iteration loss = 0.0037226088

Training iteration loss = 0.0029741637

Training iteration loss = 0.0028440088

Training iteration loss = 0.0036514408

Training iteration loss = 0.007507412

Training iteration loss = 0.0023544908

Training iteration loss = 0.0038587407

Training iteration loss = 0.0036760645

Training iteration loss = 0.0023822046

Training iteration loss = 0.0035430293

Training iteration loss = 0.0037871066

Training iteration loss = 0.0027736835

Training iteration loss = 0.002547567

Training iteration loss = 0.0033446366

Training iteration loss = 0.0039344686

Training iteration loss = 0.003754815

Training iteration loss = 0.0047419756

Training iteration loss = 0.0049752565

Training iteration loss = 0.003206245

Training iteration loss = 0.0036989432

Training iteration loss = 0.004573995

Training iteration loss = 0.004705815

Training iteration loss = 0.0029453663

Training iteration loss = 0.0037511613

Training iteration loss = 0.0040077786

Training iteration loss = 0.0025660458

Training iteration loss = 0.0022033853

Training iteration loss = 0.0036046738

Training iteration loss = 0.002509551

Training iteration loss = 0.0021990656

Training iteration loss = 0.003172445

Training iteration loss = 0.002305691

Training iteration loss = 0.0019508571

Training iteration loss = 0.0018304609

Training iteration loss = 0.0031101566

Training iteration loss = 0.002084241

Training iteration loss = 0.0023258927

Training iteration loss = 0.0040780245

Training iteration loss = 0.005513273

Training iteration loss = 0.0025379125

Training iteration loss = 0.002821317

Training iteration loss = 0.0025234532

Training iteration loss = 0.0028205712

Training iteration loss = 0.0022162255

Training iteration loss = 0.004180977

Training iteration loss = 0.0034439422

Training iteration loss = 0.0048877713

Training iteration loss = 0.004089342

Training iteration loss = 0.00294053

Training iteration loss = 0.002022195

Training iteration loss = 0.0021755511

Training iteration loss = 0.008582132

Training iteration loss = 0.003115395

Training iteration loss = 0.0018571249

Training iteration loss = 0.0043039797

Training iteration loss = 0.003811213

Training iteration loss = 0.0035029696

Training iteration loss = 0.0030677954

Training iteration loss = 0.004051385

Training iteration loss = 0.00233937

Training iteration loss = 0.006728656

Training iteration loss = 0.0026076203

Training iteration loss = 0.0034025137

Training iteration loss = 0.0039845817

Training iteration loss = 0.00219782

Training iteration loss = 0.00223558

Training iteration loss = 0.0026352594

Training iteration loss = 0.0017287651

Training iteration loss = 0.003406234

Training iteration loss = 0.0032077355

Training iteration loss = 0.0042430917

Training iteration loss = 0.0031170389

Training iteration loss = 0.0028439502

Training iteration loss = 0.0022137987

Training iteration loss = 0.002258951

Training iteration loss = 0.0024155679

Training iteration loss = 0.0031121683

Training iteration loss = 0.004917336

Training iteration loss = 0.0019007245

Training iteration loss = 0.0029807093

Training iteration loss = 0.0030763606

Training iteration loss = 0.0035125215

Training iteration loss = 0.0029684342

Training iteration loss = 0.0033602577

Training iteration loss = 0.0028450517

Training iteration loss = 0.0018687872

Training iteration loss = 0.0062810592

Training iteration loss = 0.003010555

Training iteration loss = 0.0026163335

Training iteration loss = 0.0018202661

Training iteration loss = 0.0034346206

Training iteration loss = 0.00370655

Training iteration loss = 0.0037649225

Training iteration loss = 0.0024777632

Training iteration loss = 0.005761143

Training iteration loss = 0.0031793017

Training iteration loss = 0.0023731673

Training iteration loss = 0.0020309314

Training iteration loss = 0.0025255622

Training iteration loss = 0.0019945505

Training iteration loss = 0.003318647

Training iteration loss = 0.0018478321

Training iteration loss = 0.0020695615

Training iteration loss = 0.0036148175

Training iteration loss = 0.0029819272

Training iteration loss = 0.0034449084

Training iteration loss = 0.0026380944

Training iteration loss = 0.0041154493

Training iteration loss = 0.0041613416

Training iteration loss = 0.004515955

Training iteration loss = 0.0020884087

Training iteration loss = 0.0029084785

Training iteration loss = 0.00244152

Training iteration loss = 0.003787895

Training iteration loss = 0.0034441513

Training iteration loss = 0.004844142

Training iteration loss = 0.0029076652

Training iteration loss = 0.0025060163

Training iteration loss = 0.0031468377

Training iteration loss = 0.004905822

Training iteration loss = 0.0033427316

Training iteration loss = 0.0028092864

Training iteration loss = 0.0033867862

Training iteration loss = 0.0033279704

Training iteration loss = 0.0025049415

Training iteration loss = 0.0027942609

Training iteration loss = 0.0037393824

Training iteration loss = 0.003017853

Training iteration loss = 0.003243359

Training iteration loss = 0.0028331848

Training iteration loss = 0.0023709012

Training iteration loss = 0.004579612

Training iteration loss = 0.0043069497

Training iteration loss = 0.0038074015

Training iteration loss = 0.0037322706

Training iteration loss = 0.0022522926

Training iteration loss = 0.004608301

Training iteration loss = 0.0055784048

Training iteration loss = 0.0024796182

Training iteration loss = 0.0033954764

Training iteration loss = 0.0024411655

Training iteration loss = 0.0026515692

Training iteration loss = 0.0027425683

Training iteration loss = 0.002595424

Training iteration loss = 0.0051247687

Training iteration loss = 0.0060205585

Training iteration loss = 0.002567563

Training iteration loss = 0.0029119805

Training iteration loss = 0.0022441305

Training iteration loss = 0.0026548759

Training iteration loss = 0.0034412595

Training iteration loss = 0.003330272

Training iteration loss = 0.0037954755

Training iteration loss = 0.0022707218

Training iteration loss = 0.003705803

Training iteration loss = 0.0073886323

Training iteration loss = 0.004841286

Training iteration loss = 0.0038697596

Training iteration loss = 0.0030277

Training iteration loss = 0.003514778

Training iteration loss = 0.0026355705

Training iteration loss = 0.0034770148

Training iteration loss = 0.002167092

Training iteration loss = 0.002714093

Training iteration loss = 0.0026862705

Training iteration loss = 0.0028495975

Training iteration loss = 0.0020862035

Training iteration loss = 0.0044617667

Training iteration loss = 0.0034141324

Training iteration loss = 0.0054700696

Training iteration loss = 0.003198994

Training iteration loss = 0.0032694899

Training iteration loss = 0.0033800248

Training iteration loss = 0.007057131

Training iteration loss = 0.004154748

Training iteration loss = 0.0034139457

Training iteration loss = 0.0025654885

Training iteration loss = 0.0052525024

Training iteration loss = 0.0023279204

Training iteration loss = 0.0024121522

Training iteration loss = 0.0028508592

Training iteration loss = 0.0036092207

Training iteration loss = 0.002934467

Training iteration loss = 0.0039872793

Training iteration loss = 0.0036213861

Training iteration loss = 0.0019582906

Training iteration loss = 0.0025433132

Training iteration loss = 0.0019143377

Training iteration loss = 0.0024938616

Training iteration loss = 0.0020535996

Training iteration loss = 0.0025074882

Training iteration loss = 0.003443702

Training iteration loss = 0.0034545336

Training iteration loss = 0.0045567597

Training iteration loss = 0.004052152

Training iteration loss = 0.004357507

Training iteration loss = 0.002179045

Training iteration loss = 0.003174234

Training iteration loss = 0.0023391382

Training iteration loss = 0.0062694824

Training iteration loss = 0.0037218789

Training iteration loss = 0.0029753102

Training iteration loss = 0.0028452503

Training iteration loss = 0.0036476841

Training iteration loss = 0.0075057517

Training iteration loss = 0.0023538289

Training iteration loss = 0.0038554908

Training iteration loss = 0.0036691164

Training iteration loss = 0.0023723554

Training iteration loss = 0.0035302558

Training iteration loss = 0.0037810986

Training iteration loss = 0.0027688525

Training iteration loss = 0.0025501556

Training iteration loss = 0.003337589

Training iteration loss = 0.003923926

Training iteration loss = 0.0037539501

Training iteration loss = 0.00473742

Training iteration loss = 0.0049636974

Training iteration loss = 0.003204793

Training iteration loss = 0.00369802

Training iteration loss = 0.0045677847

Training iteration loss = 0.0047018114

Training iteration loss = 0.0029377246

Training iteration loss = 0.00375008

Training iteration loss = 0.004008287

Training iteration loss = 0.0025710866

Training iteration loss = 0.0021972333

Training iteration loss = 0.003594807

Training iteration loss = 0.002512805

Training iteration loss = 0.0021980016

Training iteration loss = 0.0031694986

Training iteration loss = 0.0023034273

Training iteration loss = 0.0019480834

Training iteration loss = 0.0018294392

Training iteration loss = 0.0031107403

Training iteration loss = 0.002077827

Training iteration loss = 0.0023161548

Training iteration loss = 0.004078749

Training iteration loss = 0.005509885

Training iteration loss = 0.0025372666

Training iteration loss = 0.0028180552

Training iteration loss = 0.0025142247

Training iteration loss = 0.0028184934

Training iteration loss = 0.002215417

Training iteration loss = 0.004180249

Training iteration loss = 0.00344766

Training iteration loss = 0.004889525

Training iteration loss = 0.004074684

Training iteration loss = 0.002942803

Training iteration loss = 0.0020202377

Training iteration loss = 0.0021732845

Training iteration loss = 0.008585648

Training iteration loss = 0.003106573

Training iteration loss = 0.0018572685

Training iteration loss = 0.0043006768

Training iteration loss = 0.0038128085

Training iteration loss = 0.0034965842

Training iteration loss = 0.0030545453

Training iteration loss = 0.004043028

Training iteration loss = 0.0023315193

Training iteration loss = 0.0067175957

Training iteration loss = 0.0026119594

Training iteration loss = 0.0034151897

Training iteration loss = 0.003983067

Training iteration loss = 0.0021958074

Training iteration loss = 0.002226244

Training iteration loss = 0.0026309937

Training iteration loss = 0.0017229927

Training iteration loss = 0.0034040278

Training iteration loss = 0.0032179626

Training iteration loss = 0.004248219

Training iteration loss = 0.0031112598

Training iteration loss = 0.0028474156

Training iteration loss = 0.0022171845

Training iteration loss = 0.0022701437

Training iteration loss = 0.0024099571

Training iteration loss = 0.0031114724

Training iteration loss = 0.0049081105

Training iteration loss = 0.0018939002

Training iteration loss = 0.0029977504

Training iteration loss = 0.0030837841

Training iteration loss = 0.0035080698

Training iteration loss = 0.0029572833

Training iteration loss = 0.0033559408

Training iteration loss = 0.00284278

Training iteration loss = 0.0018599575

Training iteration loss = 0.0062710247

Training iteration loss = 0.0030077694

Training iteration loss = 0.0026215827

Training iteration loss = 0.001825739

Training iteration loss = 0.0034346438

Training iteration loss = 0.0037100601

Training iteration loss = 0.0037652187

Training iteration loss = 0.002468656

Training iteration loss = 0.005759019

Training iteration loss = 0.0031710898

Training iteration loss = 0.0023635584

Training iteration loss = 0.0020394493

Training iteration loss = 0.002533761

Training iteration loss = 0.0019912513

Training iteration loss = 0.0033032226

Training iteration loss = 0.0018437398

Training iteration loss = 0.002070739

Training iteration loss = 0.003627562

Training iteration loss = 0.0029780718

Training iteration loss = 0.0034367254

Training iteration loss = 0.0026323993

Training iteration loss = 0.0041173156

Training iteration loss = 0.0041594384

Training iteration loss = 0.004503003

Training iteration loss = 0.002085895

Training iteration loss = 0.002906571

Training iteration loss = 0.0024474533

Training iteration loss = 0.0037969358

Training iteration loss = 0.0034371123

Training iteration loss = 0.0048475955

Training iteration loss = 0.0029084024

Training iteration loss = 0.0025048207

Training iteration loss = 0.0031527996

Training iteration loss = 0.004903464

Training iteration loss = 0.0033371567

Training iteration loss = 0.002798368

Training iteration loss = 0.0033826604

Training iteration loss = 0.0033219492

Training iteration loss = 0.002502922

Training iteration loss = 0.0027833318

Training iteration loss = 0.0037317052

Training iteration loss = 0.0030188642

Training iteration loss = 0.0032336155

Training iteration loss = 0.002830725

Training iteration loss = 0.0023672823

Training iteration loss = 0.0045779557

Training iteration loss = 0.0042983308

Training iteration loss = 0.0038080162

Training iteration loss = 0.0037300596

Training iteration loss = 0.0022555368

Training iteration loss = 0.0046055354

Training iteration loss = 0.005577516

Training iteration loss = 0.0024770172

Training iteration loss = 0.0033973877

Training iteration loss = 0.0024414703

Training iteration loss = 0.0026495645

Training iteration loss = 0.0027394535

Training iteration loss = 0.0025896549

Training iteration loss = 0.005107953

Training iteration loss = 0.0060011446

Training iteration loss = 0.0025663977

Training iteration loss = 0.0029051441

Training iteration loss = 0.0022396604

Training iteration loss = 0.0026521275

Training iteration loss = 0.003431659

Training iteration loss = 0.0033241452

Training iteration loss = 0.0037823103

Training iteration loss = 0.0022706734

Training iteration loss = 0.0036915445

Training iteration loss = 0.0073632314

Training iteration loss = 0.004832068

Training iteration loss = 0.0038689424

Training iteration loss = 0.0030246042

Training iteration loss = 0.0035174284

Training iteration loss = 0.0026339155

Training iteration loss = 0.0034695223

Training iteration loss = 0.0021637885

Training iteration loss = 0.0027094118

Training iteration loss = 0.0026805417

Training iteration loss = 0.0028312223

Training iteration loss = 0.0020792948

Training iteration loss = 0.0044619297

Training iteration loss = 0.003406847

Training iteration loss = 0.005470145

Training iteration loss = 0.0032013422

Training iteration loss = 0.0032684216

Training iteration loss = 0.0033720823

Training iteration loss = 0.007043661

Training iteration loss = 0.0041422644

Training iteration loss = 0.0034163576

Training iteration loss = 0.002569372

Training iteration loss = 0.005244104

Training iteration loss = 0.002324174

Training iteration loss = 0.0024124747

Training iteration loss = 0.002850721

Training iteration loss = 0.0036124056

Training iteration loss = 0.0029370186

Training iteration loss = 0.003986186

Training iteration loss = 0.0036184143

Training iteration loss = 0.0019608021

Training iteration loss = 0.0025404757

Training iteration loss = 0.0019183499

Training iteration loss = 0.0024938094

Training iteration loss = 0.002058355

Training iteration loss = 0.0025041436

Training iteration loss = 0.003440982

Training iteration loss = 0.0034545304

Training iteration loss = 0.004553842

Training iteration loss = 0.0040448536

Training iteration loss = 0.0043431693

Training iteration loss = 0.0021767216

Training iteration loss = 0.0031675464

Training iteration loss = 0.0023300794

Training iteration loss = 0.0062438063

Training iteration loss = 0.003710694

Training iteration loss = 0.0029768522

Training iteration loss = 0.002847665

Training iteration loss = 0.0036465947

Training iteration loss = 0.00744818

Training iteration loss = 0.0023492116

Training iteration loss = 0.003846978

Training iteration loss = 0.0036790383

Training iteration loss = 0.0023777846

Training iteration loss = 0.0035354507

Training iteration loss = 0.0037729193

Training iteration loss = 0.0027642169

Training iteration loss = 0.0025476555

Training iteration loss = 0.003333086

Training iteration loss = 0.003919164

Training iteration loss = 0.003738854

Training iteration loss = 0.004708674

Training iteration loss = 0.00494515

Training iteration loss = 0.0032063785

Training iteration loss = 0.0036878577

Training iteration loss = 0.004548148

Training iteration loss = 0.004694708

Training iteration loss = 0.002935107

Training iteration loss = 0.003736198

Training iteration loss = 0.0040130634

Training iteration loss = 0.0025636796

Training iteration loss = 0.0021997637

Training iteration loss = 0.003599598

Training iteration loss = 0.0024970032

Training iteration loss = 0.002202133

Training iteration loss = 0.003169546

Training iteration loss = 0.0023028974

Training iteration loss = 0.0019395299

Training iteration loss = 0.0018303375

Training iteration loss = 0.0031093468

Training iteration loss = 0.002082301

Training iteration loss = 0.002306762

Training iteration loss = 0.0040638926

Training iteration loss = 0.0054856273

Training iteration loss = 0.0025335934

Training iteration loss = 0.0028203882

Training iteration loss = 0.0025084638

Training iteration loss = 0.0028082866

Training iteration loss = 0.0022130397

Training iteration loss = 0.004171799

Training iteration loss = 0.0034441256

Training iteration loss = 0.004891154

Training iteration loss = 0.004067587

Training iteration loss = 0.0029432345

Training iteration loss = 0.0020185483

Training iteration loss = 0.0021690251

Training iteration loss = 0.008567442

Training iteration loss = 0.0030958494

Training iteration loss = 0.0018566139

Training iteration loss = 0.004291612

Training iteration loss = 0.0038106618

Training iteration loss = 0.0034867178

Training iteration loss = 0.0030503199

Training iteration loss = 0.004036077

Training iteration loss = 0.0023308636

Training iteration loss = 0.0067141536

Training iteration loss = 0.0026118278

Training iteration loss = 0.0034108723

Training iteration loss = 0.0039700563

Training iteration loss = 0.002190414

Training iteration loss = 0.002221749

Training iteration loss = 0.0026299704

Training iteration loss = 0.0017220001

Training iteration loss = 0.003399035

Training iteration loss = 0.0032082412

Training iteration loss = 0.0042394255

Training iteration loss = 0.003107612

Training iteration loss = 0.0028435288

Training iteration loss = 0.0022176476

Training iteration loss = 0.0022615965

Training iteration loss = 0.0024096188

Training iteration loss = 0.0031105152

Training iteration loss = 0.0048946887

Training iteration loss = 0.001892683

Training iteration loss = 0.0029917706

Training iteration loss = 0.00307999

Training iteration loss = 0.0034908392

Training iteration loss = 0.0029518716

Training iteration loss = 0.0033528942

Training iteration loss = 0.0028304292

Training iteration loss = 0.0018583256

Training iteration loss = 0.0062538856

Training iteration loss = 0.0029993923

Training iteration loss = 0.0026176737

Training iteration loss = 0.0018202249

Training iteration loss = 0.0034313833

Training iteration loss = 0.0037042005

Training iteration loss = 0.0037551112

Training iteration loss = 0.002466101

Training iteration loss = 0.0057593607

Training iteration loss = 0.0031694826

Training iteration loss = 0.0023629523

Training iteration loss = 0.0020390383

Training iteration loss = 0.0025312104

Training iteration loss = 0.0019904033

Training iteration loss = 0.0032903927

Training iteration loss = 0.0018432917

Training iteration loss = 0.0020687368

Training iteration loss = 0.0036181405

Training iteration loss = 0.0029730396

Training iteration loss = 0.003431704

Training iteration loss = 0.0026317837

Training iteration loss = 0.0041009025

Training iteration loss = 0.004156561

Training iteration loss = 0.004502086

Training iteration loss = 0.002082683

Training iteration loss = 0.0029062994

Training iteration loss = 0.0024444524

Training iteration loss = 0.00379403

Training iteration loss = 0.0034342872

Training iteration loss = 0.0048387772

Training iteration loss = 0.0029025113

Training iteration loss = 0.0025021695

Training iteration loss = 0.0031483527

Training iteration loss = 0.0048886384

Training iteration loss = 0.0033342128

Training iteration loss = 0.002791417

Training iteration loss = 0.0033768695

Training iteration loss = 0.003314926

Training iteration loss = 0.002497442

Training iteration loss = 0.0027656031

Training iteration loss = 0.0037275904

Training iteration loss = 0.0030182747

Training iteration loss = 0.0032291783

Training iteration loss = 0.0028267314

Training iteration loss = 0.0023630203

Training iteration loss = 0.0045731044

Training iteration loss = 0.0042878482

Training iteration loss = 0.003810592

Training iteration loss = 0.0037253394

Training iteration loss = 0.00225487

Training iteration loss = 0.0045969696

Training iteration loss = 0.005574712

Training iteration loss = 0.0024677052

Training iteration loss = 0.0033897508

Training iteration loss = 0.002438358

Training iteration loss = 0.0026477836

Training iteration loss = 0.0027358877

Training iteration loss = 0.0025833712

Training iteration loss = 0.005091852

Training iteration loss = 0.005976379

Training iteration loss = 0.0025636798

Training iteration loss = 0.0029046421

Training iteration loss = 0.0022359088

Training iteration loss = 0.0026495773

Training iteration loss = 0.0034241872

Training iteration loss = 0.0033234041

Training iteration loss = 0.0037753002

Training iteration loss = 0.002268904

Training iteration loss = 0.0036789766

Training iteration loss = 0.007348861

Training iteration loss = 0.0048256107

Training iteration loss = 0.0038657885

Training iteration loss = 0.003019456

Training iteration loss = 0.0035172382

Training iteration loss = 0.0026317372

Training iteration loss = 0.003463722

Training iteration loss = 0.00216063

Training iteration loss = 0.0027039733

Training iteration loss = 0.0026771522

Training iteration loss = 0.0028200264

Training iteration loss = 0.002072221

Training iteration loss = 0.004463167

Training iteration loss = 0.003397309

Training iteration loss = 0.005464953

Training iteration loss = 0.003204289

Training iteration loss = 0.0032645976

Training iteration loss = 0.0033590726

Training iteration loss = 0.0070269234

Training iteration loss = 0.0041305874

Training iteration loss = 0.0034186377

Training iteration loss = 0.0025735807

Training iteration loss = 0.005232326

Training iteration loss = 0.0023179967

Training iteration loss = 0.0024132405

Training iteration loss = 0.0028501607

Training iteration loss = 0.0036156408

Training iteration loss = 0.0029441223

Training iteration loss = 0.0039846734

Training iteration loss = 0.003610687

Training iteration loss = 0.001959443

Training iteration loss = 0.0025423032

Training iteration loss = 0.0019282819

Training iteration loss = 0.0024975797

Training iteration loss = 0.002069128

Training iteration loss = 0.0024991247

Training iteration loss = 0.0034451752

Training iteration loss = 0.0034568168

Training iteration loss = 0.0045527

Training iteration loss = 0.004046269

Training iteration loss = 0.004320853

Training iteration loss = 0.0021722054

Training iteration loss = 0.0031584317

Training iteration loss = 0.0023186526

Training iteration loss = 0.006223358

Training iteration loss = 0.0037014298

Training iteration loss = 0.0029779307

Training iteration loss = 0.0028604928

Training iteration loss = 0.0036447896

Training iteration loss = 0.0074279006

Training iteration loss = 0.0023425303

Training iteration loss = 0.0038389226

Training iteration loss = 0.0036810238

Training iteration loss = 0.0023696441

Training iteration loss = 0.0035307184

Training iteration loss = 0.0037622235

Training iteration loss = 0.0027600673

Training iteration loss = 0.002546753

Training iteration loss = 0.0033255462

Training iteration loss = 0.0039038053

Training iteration loss = 0.003731655

Training iteration loss = 0.004692912

Training iteration loss = 0.0049370825

Training iteration loss = 0.0032083017

Training iteration loss = 0.0036897769

Training iteration loss = 0.00452593

Training iteration loss = 0.004691415

Training iteration loss = 0.0029323064

Training iteration loss = 0.0037365612

Training iteration loss = 0.004035249

Training iteration loss = 0.0025663231

Training iteration loss = 0.0021965539

Training iteration loss = 0.0035942679

Training iteration loss = 0.0024936644

Training iteration loss = 0.0021984652

Training iteration loss = 0.003173656

Training iteration loss = 0.0023025656

Training iteration loss = 0.0019326358

Training iteration loss = 0.0018300273

Training iteration loss = 0.003112214

Training iteration loss = 0.0020763655

Training iteration loss = 0.0022992988

Training iteration loss = 0.0040547433

Training iteration loss = 0.0054836697

Training iteration loss = 0.002530284

Training iteration loss = 0.002817316

Training iteration loss = 0.0024971922

Training iteration loss = 0.0028044411

Training iteration loss = 0.0022116113

Training iteration loss = 0.0041643195

Training iteration loss = 0.003436736

Training iteration loss = 0.004885357

Training iteration loss = 0.004057165

Training iteration loss = 0.00294424

Training iteration loss = 0.0020127166

Training iteration loss = 0.0021638414

Training iteration loss = 0.008573147

Training iteration loss = 0.0030893742

Training iteration loss = 0.0018569832

Training iteration loss = 0.0042947703

Training iteration loss = 0.003809504

Training iteration loss = 0.003480669

Training iteration loss = 0.0030394976

Training iteration loss = 0.004027672

Training iteration loss = 0.0023296194

Training iteration loss = 0.0067004333

Training iteration loss = 0.002613454

Training iteration loss = 0.003415319

Training iteration loss = 0.003962965

Training iteration loss = 0.002185604

Training iteration loss = 0.0022142883

Training iteration loss = 0.002626723

Training iteration loss = 0.0017179941

Training iteration loss = 0.003393511

Training iteration loss = 0.0032117115

Training iteration loss = 0.004243011

Training iteration loss = 0.003105049

Training iteration loss = 0.0028420773

Training iteration loss = 0.002221751

Training iteration loss = 0.00226555

Training iteration loss = 0.0024071177

Training iteration loss = 0.003111627

Training iteration loss = 0.0048772707

Training iteration loss = 0.0018870985

Training iteration loss = 0.0029949415

Training iteration loss = 0.0030809909

Training iteration loss = 0.0034811709

Training iteration loss = 0.002944055

Training iteration loss = 0.0033513987

Training iteration loss = 0.0028272353

Training iteration loss = 0.0018542396

Training iteration loss = 0.0062425137

Training iteration loss = 0.0029959593

Training iteration loss = 0.0026176905

Training iteration loss = 0.0018182875

Training iteration loss = 0.0034293237

Training iteration loss = 0.0037038876

Training iteration loss = 0.0037507473

Training iteration loss = 0.0024637512

Training iteration loss = 0.005760011

Training iteration loss = 0.0031662358

Training iteration loss = 0.0023530547

Training iteration loss = 0.002035953

Training iteration loss = 0.0025238583

Training iteration loss = 0.0019887814

Training iteration loss = 0.0032758638

Training iteration loss = 0.001837449

Training iteration loss = 0.0020673852

Training iteration loss = 0.003626671

Training iteration loss = 0.002969845

Training iteration loss = 0.0034288883

Training iteration loss = 0.0026330578

Training iteration loss = 0.004097207

Training iteration loss = 0.0041560777

Training iteration loss = 0.0044915355

Training iteration loss = 0.002078985

Training iteration loss = 0.0029048414

Training iteration loss = 0.002447299

Training iteration loss = 0.0037935423

Training iteration loss = 0.0034321249

Training iteration loss = 0.0048386515

Training iteration loss = 0.0029043376

Training iteration loss = 0.0024991746

Training iteration loss = 0.003150229

Training iteration loss = 0.0048809717

Training iteration loss = 0.00332695

Training iteration loss = 0.0027853893

Training iteration loss = 0.0033734983

Training iteration loss = 0.0033083633

Training iteration loss = 0.0024966758

Training iteration loss = 0.002753986

Training iteration loss = 0.003718202

Training iteration loss = 0.0030186495

Training iteration loss = 0.003218787

Training iteration loss = 0.002823836

Training iteration loss = 0.0023618124

Training iteration loss = 0.004567328

Training iteration loss = 0.004289711

Training iteration loss = 0.003809709

Training iteration loss = 0.003726746

Training iteration loss = 0.0022538474

Training iteration loss = 0.0045914366

Training iteration loss = 0.005569378

Training iteration loss = 0.0024630376

Training iteration loss = 0.003385151

Training iteration loss = 0.002436008

Training iteration loss = 0.0026457356

Training iteration loss = 0.0027322713

Training iteration loss = 0.0025754631

Training iteration loss = 0.0050816364

Training iteration loss = 0.005959749

Training iteration loss = 0.0025599

Training iteration loss = 0.002901284

Training iteration loss = 0.002232083

Training iteration loss = 0.002647226

Training iteration loss = 0.00341689

Training iteration loss = 0.0033174884

Training iteration loss = 0.0037655344

Training iteration loss = 0.002267097

Training iteration loss = 0.0036665462

Training iteration loss = 0.007338824

Training iteration loss = 0.004817925

Training iteration loss = 0.0038621454

Training iteration loss = 0.0030147415

Training iteration loss = 0.0035185402

Training iteration loss = 0.0026327025

Training iteration loss = 0.0034574978

Training iteration loss = 0.0021578528

Training iteration loss = 0.002699935

Training iteration loss = 0.0026741617

Training iteration loss = 0.0028145583

Training iteration loss = 0.0020677869

Training iteration loss = 0.00446193

Training iteration loss = 0.003392877

Training iteration loss = 0.0054616216

Training iteration loss = 0.0032039108

Training iteration loss = 0.0032606476

Training iteration loss = 0.0033746173

Training iteration loss = 0.0070093214

Training iteration loss = 0.0041215443

Training iteration loss = 0.0034170467

Training iteration loss = 0.0025654796

Training iteration loss = 0.0051975558

Training iteration loss = 0.0023135717

Training iteration loss = 0.0024086323

Training iteration loss = 0.0028580707

Training iteration loss = 0.0036245065

Training iteration loss = 0.0029440357

Training iteration loss = 0.0039845905

Training iteration loss = 0.0036113288

Training iteration loss = 0.0019479765

Training iteration loss = 0.0025341331

Training iteration loss = 0.0019236504

Training iteration loss = 0.0024864299

Training iteration loss = 0.0020549942

Training iteration loss = 0.002487271

Training iteration loss = 0.0034388492

Training iteration loss = 0.0034551956

Training iteration loss = 0.004540176

Training iteration loss = 0.0040427293

Training iteration loss = 0.004313442

Training iteration loss = 0.0021723842

Training iteration loss = 0.0031539702

Training iteration loss = 0.002315273

Training iteration loss = 0.006239465

Training iteration loss = 0.003704724

Training iteration loss = 0.002979434

Training iteration loss = 0.0028553836

Training iteration loss = 0.0036407814

Training iteration loss = 0.0074329474

Training iteration loss = 0.0023479015

Training iteration loss = 0.0038356187

Training iteration loss = 0.0036706731

Training iteration loss = 0.0023658588

Training iteration loss = 0.0035206873

Training iteration loss = 0.0037600584

Training iteration loss = 0.0027564336

Training iteration loss = 0.0025479523

Training iteration loss = 0.0033207703

Training iteration loss = 0.0038952297

Training iteration loss = 0.0037324775

Training iteration loss = 0.0047062845

Training iteration loss = 0.004913174

Training iteration loss = 0.0032101527

Training iteration loss = 0.0036739607

Training iteration loss = 0.0045284885

Training iteration loss = 0.0046717017

Training iteration loss = 0.002921275

Training iteration loss = 0.0037240547

Training iteration loss = 0.004026987

Training iteration loss = 0.0025648808

Training iteration loss = 0.0021889822

Training iteration loss = 0.0036004225

Training iteration loss = 0.002498862

Training iteration loss = 0.0021983832

Training iteration loss = 0.0031602567

Training iteration loss = 0.0022914524

Training iteration loss = 0.0019265567

Training iteration loss = 0.0018217708

Training iteration loss = 0.0031080216

Training iteration loss = 0.0020790373

Training iteration loss = 0.0022942254

Training iteration loss = 0.0040620784

Training iteration loss = 0.0054725627

Training iteration loss = 0.00252804

Training iteration loss = 0.0028077697

Training iteration loss = 0.0024878301

Training iteration loss = 0.002810391

Training iteration loss = 0.0022112962

Training iteration loss = 0.004167875

Training iteration loss = 0.003444857

Training iteration loss = 0.004893121

Training iteration loss = 0.004037324

Training iteration loss = 0.0029421735

Training iteration loss = 0.0020062907

Training iteration loss = 0.0021595373

Training iteration loss = 0.008599696

Training iteration loss = 0.0030912973

Training iteration loss = 0.0018454308

Training iteration loss = 0.004297592

Training iteration loss = 0.0038073463

Training iteration loss = 0.0034728607

Training iteration loss = 0.0030188542

Training iteration loss = 0.0040159905

Training iteration loss = 0.0023228354

Training iteration loss = 0.006713199

Training iteration loss = 0.0026235934

Training iteration loss = 0.0034288263

Training iteration loss = 0.003960402

Training iteration loss = 0.002181959

Training iteration loss = 0.0022034312

Training iteration loss = 0.002621256

Training iteration loss = 0.0017102327

Training iteration loss = 0.0033862581

Training iteration loss = 0.0032267424

Training iteration loss = 0.0042544454

Training iteration loss = 0.003102446

Training iteration loss = 0.0028463302

Training iteration loss = 0.0022262873

Training iteration loss = 0.0022775608

Training iteration loss = 0.002402247

Training iteration loss = 0.0031140011

Training iteration loss = 0.004851487

Training iteration loss = 0.0018797461

Training iteration loss = 0.0030087149

Training iteration loss = 0.0030864074

Training iteration loss = 0.0034722427

Training iteration loss = 0.0029357865

Training iteration loss = 0.0033478441

Training iteration loss = 0.0028239049

Training iteration loss = 0.0018474626

Training iteration loss = 0.006234797

Training iteration loss = 0.0029891178

Training iteration loss = 0.0026187282

Training iteration loss = 0.0018295598

Training iteration loss = 0.0034343062

Training iteration loss = 0.0037146003

Training iteration loss = 0.0037549676

Training iteration loss = 0.0024575808

Training iteration loss = 0.0057545775

Training iteration loss = 0.0031609777

Training iteration loss = 0.002345401

Training iteration loss = 0.0020408921

Training iteration loss = 0.0025197857

Training iteration loss = 0.0019883842

Training iteration loss = 0.0032626886

Training iteration loss = 0.001837996

Training iteration loss = 0.0020659657

Training iteration loss = 0.0036293678

Training iteration loss = 0.0029694878

Training iteration loss = 0.0034313472

Training iteration loss = 0.0026321134

Training iteration loss = 0.0040824385

Training iteration loss = 0.0041520917

Training iteration loss = 0.0044798567

Training iteration loss = 0.0020773942

Training iteration loss = 0.0029036303

Training iteration loss = 0.0024522175

Training iteration loss = 0.0037946634

Training iteration loss = 0.0034268203

Training iteration loss = 0.0048370548

Training iteration loss = 0.0029057267

Training iteration loss = 0.0025035408

Training iteration loss = 0.003151425

Training iteration loss = 0.00487276

Training iteration loss = 0.0033253075

Training iteration loss = 0.0027772544

Training iteration loss = 0.0033673707

Training iteration loss = 0.0033070073

Training iteration loss = 0.0024976062

Training iteration loss = 0.0027378842

Training iteration loss = 0.0037138427

Training iteration loss = 0.003016212

Training iteration loss = 0.0032101003

Training iteration loss = 0.0028224874

Training iteration loss = 0.0023593456

Training iteration loss = 0.0045608035

Training iteration loss = 0.0042726626

Training iteration loss = 0.0038075717

Training iteration loss = 0.0037185338

Training iteration loss = 0.0022537108

Training iteration loss = 0.00458046

Training iteration loss = 0.0055633

Training iteration loss = 0.0024569135

Training iteration loss = 0.0033738352

Training iteration loss = 0.0024323086

Training iteration loss = 0.00264383

Training iteration loss = 0.0027291395

Training iteration loss = 0.002567863

Training iteration loss = 0.0050648316

Training iteration loss = 0.005935757

Training iteration loss = 0.0025549552

Training iteration loss = 0.0028993825

Training iteration loss = 0.002227361

Training iteration loss = 0.0026460213

Training iteration loss = 0.0034106846

Training iteration loss = 0.0033161212

Training iteration loss = 0.0037579786

Training iteration loss = 0.0022638561

Training iteration loss = 0.003650686

Training iteration loss = 0.007334236

Training iteration loss = 0.0048098336

Training iteration loss = 0.0038580773

Training iteration loss = 0.0030074406

Training iteration loss = 0.003515443

Training iteration loss = 0.0026299844

Training iteration loss = 0.0034482211

Training iteration loss = 0.0021527149

Training iteration loss = 0.0026907388

Training iteration loss = 0.0026650606

Training iteration loss = 0.0027976453

Training iteration loss = 0.0020587477

Training iteration loss = 0.00446251

Training iteration loss = 0.0033871483

Training iteration loss = 0.0054567955

Training iteration loss = 0.0032050302

Training iteration loss = 0.0032570132

Training iteration loss = 0.0033797503

Training iteration loss = 0.0069926367

Training iteration loss = 0.004115901

Training iteration loss = 0.0034187632

Training iteration loss = 0.0025645567

Training iteration loss = 0.0051738736

Training iteration loss = 0.0023072062

Training iteration loss = 0.0024075655

Training iteration loss = 0.0028618684

Training iteration loss = 0.0036301296

Training iteration loss = 0.002940894

Training iteration loss = 0.003981712

Training iteration loss = 0.003610391

Training iteration loss = 0.001950099

Training iteration loss = 0.0025303755

Training iteration loss = 0.0019202475

Training iteration loss = 0.0024789015

Training iteration loss = 0.002048226

Training iteration loss = 0.00248107

Training iteration loss = 0.0034311358

Training iteration loss = 0.0034460544

Training iteration loss = 0.0045309123

Training iteration loss = 0.004038477

Training iteration loss = 0.0042969235

Training iteration loss = 0.0021729467

Training iteration loss = 0.003148882

Training iteration loss = 0.0023097727

Training iteration loss = 0.006225046

Training iteration loss = 0.003698216

Training iteration loss = 0.0029744012

Training iteration loss = 0.0028452126

Training iteration loss = 0.0036388598

Training iteration loss = 0.007403504

Training iteration loss = 0.002351225

Training iteration loss = 0.0038260792

Training iteration loss = 0.0036670782

Training iteration loss = 0.0023692048

Training iteration loss = 0.0035213784

Training iteration loss = 0.003758232

Training iteration loss = 0.0027542242

Training iteration loss = 0.0025473088

Training iteration loss = 0.003322608

Training iteration loss = 0.0038743299

Training iteration loss = 0.00371378

Training iteration loss = 0.004673963

Training iteration loss = 0.0049151457

Training iteration loss = 0.0032144797

Training iteration loss = 0.0036691688

Training iteration loss = 0.004500431

Training iteration loss = 0.0046608117

Training iteration loss = 0.0029167237

Training iteration loss = 0.0037152348

Training iteration loss = 0.004039321

Training iteration loss = 0.002562571

Training iteration loss = 0.0021830183

Training iteration loss = 0.0035947252

Training iteration loss = 0.002486632

Training iteration loss = 0.0021918325

Training iteration loss = 0.0031618318

Training iteration loss = 0.0022922715

Training iteration loss = 0.0019171904

Training iteration loss = 0.0018235525

Training iteration loss = 0.0031073436

Training iteration loss = 0.0020709345

Training iteration loss = 0.0022869187

Training iteration loss = 0.0040474352

Training iteration loss = 0.005470591

Training iteration loss = 0.0025248027

Training iteration loss = 0.0028080388

Training iteration loss = 0.002481757

Training iteration loss = 0.0028004532

Training iteration loss = 0.0022116143

Training iteration loss = 0.004156934

Training iteration loss = 0.0034384772

Training iteration loss = 0.0048828484

Training iteration loss = 0.0040287757

Training iteration loss = 0.0029428827

Training iteration loss = 0.0020038332

Training iteration loss = 0.0021526788

Training iteration loss = 0.008593214

Training iteration loss = 0.003084422

Training iteration loss = 0.0018392421

Training iteration loss = 0.0043003294

Training iteration loss = 0.0038056455

Training iteration loss = 0.0034661004

Training iteration loss = 0.0030134656

Training iteration loss = 0.0040105465

Training iteration loss = 0.002322409

Training iteration loss = 0.006666476

Training iteration loss = 0.00261499

Training iteration loss = 0.0034295951

Training iteration loss = 0.00395302

Training iteration loss = 0.002176672

Training iteration loss = 0.0021979392

Training iteration loss = 0.0026118085

Training iteration loss = 0.0017091358

Training iteration loss = 0.0033832027

Training iteration loss = 0.0032206625

Training iteration loss = 0.0042417143

Training iteration loss = 0.0030967304

Training iteration loss = 0.002835828

Training iteration loss = 0.0022284107

Training iteration loss = 0.0022703083

Training iteration loss = 0.0024026134

Training iteration loss = 0.0031083126

Training iteration loss = 0.004862007

Training iteration loss = 0.0018763533

Training iteration loss = 0.0030040888

Training iteration loss = 0.0030883148

Training iteration loss = 0.0034650352

Training iteration loss = 0.0029217151

Training iteration loss = 0.0033435076

Training iteration loss = 0.0028169963

Training iteration loss = 0.0018373007

Training iteration loss = 0.0062225186

Training iteration loss = 0.002987996

Training iteration loss = 0.0026201298

Training iteration loss = 0.0018222482

Training iteration loss = 0.003428

Training iteration loss = 0.00370474

Training iteration loss = 0.0037429335

Training iteration loss = 0.0024556117

Training iteration loss = 0.005747478

Training iteration loss = 0.0031553751

Training iteration loss = 0.0023461562

Training iteration loss = 0.0020472913

Training iteration loss = 0.0025282286

Training iteration loss = 0.0019798086

Training iteration loss = 0.0032455046

Training iteration loss = 0.0018306663

Training iteration loss = 0.0020673275

Training iteration loss = 0.0036301352

Training iteration loss = 0.0029577557

Training iteration loss = 0.003412326

Training iteration loss = 0.0026270614

Training iteration loss = 0.0040841564

Training iteration loss = 0.0041493042

Training iteration loss = 0.0044718753

Training iteration loss = 0.0020735192

Training iteration loss = 0.0029037828

Training iteration loss = 0.0024504934

Training iteration loss = 0.003789195

Training iteration loss = 0.0034239816

Training iteration loss = 0.004827472

Training iteration loss = 0.002902746

Training iteration loss = 0.0024973543

Training iteration loss = 0.0031516887

Training iteration loss = 0.0048624226

Training iteration loss = 0.0033165812

Training iteration loss = 0.0027698975

Training iteration loss = 0.0033619453

Training iteration loss = 0.0032900234

Training iteration loss = 0.0024911761

Training iteration loss = 0.0027271768

Training iteration loss = 0.003702662

Training iteration loss = 0.0030214183

Training iteration loss = 0.0031991543

Training iteration loss = 0.002817367

Training iteration loss = 0.0023585598

Training iteration loss = 0.00455815

Training iteration loss = 0.004281988

Training iteration loss = 0.0038101806

Training iteration loss = 0.0037175908

Training iteration loss = 0.0022532495

Training iteration loss = 0.004580895

Training iteration loss = 0.0055633155

Training iteration loss = 0.0024496566

Training iteration loss = 0.0033796446

Training iteration loss = 0.0024295014

Training iteration loss = 0.0026483766

Training iteration loss = 0.002724061

Training iteration loss = 0.0025636188

Training iteration loss = 0.0050552594

Training iteration loss = 0.0059170774

Training iteration loss = 0.0025561044

Training iteration loss = 0.0028985264

Training iteration loss = 0.0022247492

Training iteration loss = 0.0026414683

Training iteration loss = 0.0034047214

Training iteration loss = 0.0033112236

Training iteration loss = 0.003748221

Training iteration loss = 0.0022634212

Training iteration loss = 0.003639591

Training iteration loss = 0.007300762

Training iteration loss = 0.0048036813

Training iteration loss = 0.0038548342

Training iteration loss = 0.003004195

Training iteration loss = 0.003516101

Training iteration loss = 0.002630974

Training iteration loss = 0.003447092

Training iteration loss = 0.0021524227

Training iteration loss = 0.002685502

Training iteration loss = 0.00266736

Training iteration loss = 0.0027981338

Training iteration loss = 0.0020554576

Training iteration loss = 0.0044665006

Training iteration loss = 0.0033773873

Training iteration loss = 0.0054517463

Training iteration loss = 0.0032093395

Training iteration loss = 0.0032542634

Training iteration loss = 0.0033618417

Training iteration loss = 0.006972292

Training iteration loss = 0.004099907

Training iteration loss = 0.00341826

Training iteration loss = 0.0025662368

Training iteration loss = 0.00516565

Training iteration loss = 0.0023005803

Training iteration loss = 0.0024105415

Training iteration loss = 0.0028623873

Training iteration loss = 0.00363571

Training iteration loss = 0.0029535645

Training iteration loss = 0.0039783237

Training iteration loss = 0.0035983163

Training iteration loss = 0.0019395575

Training iteration loss = 0.002534235

Training iteration loss = 0.0019355534

Training iteration loss = 0.0024857253

Training iteration loss = 0.002063025

Training iteration loss = 0.0024784037

Training iteration loss = 0.0034420032

Training iteration loss = 0.0034611172

Training iteration loss = 0.004536805

Training iteration loss = 0.004044107

Training iteration loss = 0.004283521

Training iteration loss = 0.0021667823

Training iteration loss = 0.0031361738

Training iteration loss = 0.0022941455

Training iteration loss = 0.0062092245

Training iteration loss = 0.003688517

Training iteration loss = 0.0029848982

Training iteration loss = 0.002869228

Training iteration loss = 0.0036360314

Training iteration loss = 0.0073726685

Training iteration loss = 0.0023349023

Training iteration loss = 0.0038127694

Training iteration loss = 0.0036826795

Training iteration loss = 0.0023659884

Training iteration loss = 0.0035205248

Training iteration loss = 0.003747276

Training iteration loss = 0.0027484752

Training iteration loss = 0.0025394987

Training iteration loss = 0.0033008412

Training iteration loss = 0.003870367

Training iteration loss = 0.0037064273

Training iteration loss = 0.004696663

Training iteration loss = 0.0048769596

Training iteration loss = 0.0032173928

Training iteration loss = 0.0036534977

Training iteration loss = 0.004485275

Training iteration loss = 0.0046406225

Training iteration loss = 0.002919718

Training iteration loss = 0.0037130602

Training iteration loss = 0.004054898

Training iteration loss = 0.0025572602

Training iteration loss = 0.002185165

Training iteration loss = 0.0036090594

Training iteration loss = 0.0024811705

Training iteration loss = 0.0021921936

Training iteration loss = 0.0031568345

Training iteration loss = 0.002282732

Training iteration loss = 0.0019056891

Training iteration loss = 0.0018197311

Training iteration loss = 0.0031071564

Training iteration loss = 0.0020755348

Training iteration loss = 0.0022832314

Training iteration loss = 0.004035417

Training iteration loss = 0.0054591666

Training iteration loss = 0.0025202564

Training iteration loss = 0.0027971314

Training iteration loss = 0.0024644476

Training iteration loss = 0.0027975908

Training iteration loss = 0.0022117756

Training iteration loss = 0.004145147

Training iteration loss = 0.003432313

Training iteration loss = 0.0048866724

Training iteration loss = 0.004009833

Training iteration loss = 0.0029432802

Training iteration loss = 0.0019966885

Training iteration loss = 0.0021468115

Training iteration loss = 0.008615903

Training iteration loss = 0.0030780125

Training iteration loss = 0.0018368703

Training iteration loss = 0.0042907787

Training iteration loss = 0.0038011111

Training iteration loss = 0.003455356

Training iteration loss = 0.002997535

Training iteration loss = 0.004004482

Training iteration loss = 0.0023183592

Training iteration loss = 0.006706094

Training iteration loss = 0.0026307276

Training iteration loss = 0.0034333381

Training iteration loss = 0.003939024

Training iteration loss = 0.0021739854

Training iteration loss = 0.0021882472

Training iteration loss = 0.002616276

Training iteration loss = 0.0017011967

Training iteration loss = 0.003376114

Training iteration loss = 0.0032335527

Training iteration loss = 0.0042563723

Training iteration loss = 0.0030939404

Training iteration loss = 0.0028433793

Training iteration loss = 0.0022361905

Training iteration loss = 0.0022883224

Training iteration loss = 0.002396112

Training iteration loss = 0.003113186

Training iteration loss = 0.0048290216

Training iteration loss = 0.0018710525

Training iteration loss = 0.0030141433

Training iteration loss = 0.0030959267

Training iteration loss = 0.0034599316

Training iteration loss = 0.0029203212

Training iteration loss = 0.0033448038

Training iteration loss = 0.0028199411

Training iteration loss = 0.0018383019

Training iteration loss = 0.0062053795

Training iteration loss = 0.0029852334

Training iteration loss = 0.0026263166

Training iteration loss = 0.0018290658

Training iteration loss = 0.003427499

Training iteration loss = 0.003714229

Training iteration loss = 0.0037518993

Training iteration loss = 0.00245362

Training iteration loss = 0.0057529327

Training iteration loss = 0.003152829

Training iteration loss = 0.0023283565

Training iteration loss = 0.002042529

Training iteration loss = 0.002515215

Training iteration loss = 0.0019888023

Training iteration loss = 0.0032289736

Training iteration loss = 0.0018271435

Training iteration loss = 0.0020675657

Training iteration loss = 0.0036464557

Training iteration loss = 0.0029606244

Training iteration loss = 0.0034180684

Training iteration loss = 0.0026267115

Training iteration loss = 0.0040784436

Training iteration loss = 0.0041447575

Training iteration loss = 0.0044537783

Training iteration loss = 0.0020718996

Training iteration loss = 0.0028973736

Training iteration loss = 0.0024592667

Training iteration loss = 0.0037949013

Training iteration loss = 0.0034202868

Training iteration loss = 0.00483398

Training iteration loss = 0.0029088662

Training iteration loss = 0.0024982963

Training iteration loss = 0.003152381

Training iteration loss = 0.0048552137

Training iteration loss = 0.0033091418

Training iteration loss = 0.0027652609

Training iteration loss = 0.0033602854

Training iteration loss = 0.003289805

Training iteration loss = 0.002492131

Training iteration loss = 0.0027128628

Training iteration loss = 0.0036989877

Training iteration loss = 0.003018378

Training iteration loss = 0.003190851

Training iteration loss = 0.0028145097

Training iteration loss = 0.002357189

Training iteration loss = 0.004554452

Training iteration loss = 0.0042748167

Training iteration loss = 0.0038063617

Training iteration loss = 0.0037170786

Training iteration loss = 0.0022537634

Training iteration loss = 0.0045704767

Training iteration loss = 0.005556975

Training iteration loss = 0.002450217

Training iteration loss = 0.003365472

Training iteration loss = 0.002426275

Training iteration loss = 0.0026431747

Training iteration loss = 0.0027202424

Training iteration loss = 0.0025512876

Training iteration loss = 0.0050428696

Training iteration loss = 0.0059003676

Training iteration loss = 0.0025463772

Training iteration loss = 0.0028944255

Training iteration loss = 0.0022206686

Training iteration loss = 0.0026396222

Training iteration loss = 0.003399911

Training iteration loss = 0.00330346

Training iteration loss = 0.0037387905

Training iteration loss = 0.0022613972

Training iteration loss = 0.003624309

Training iteration loss = 0.0073153074

Training iteration loss = 0.004793635

Training iteration loss = 0.003848536

Training iteration loss = 0.0029965376

Training iteration loss = 0.0035132868

Training iteration loss = 0.0026295672

Training iteration loss = 0.0034305274

Training iteration loss = 0.002144566

Training iteration loss = 0.0026736066

Training iteration loss = 0.002652595

Training iteration loss = 0.0027707338

Training iteration loss = 0.0020453448

Training iteration loss = 0.004463553

Training iteration loss = 0.003375858

Training iteration loss = 0.0054476764

Training iteration loss = 0.0032043902

Training iteration loss = 0.003248969

Training iteration loss = 0.0033830097

Training iteration loss = 0.006955933

Training iteration loss = 0.0040960945

Training iteration loss = 0.0034169278

Training iteration loss = 0.0025581147

Training iteration loss = 0.0051326305

Training iteration loss = 0.0022949148

Training iteration loss = 0.0024055804

Training iteration loss = 0.0028677315

Training iteration loss = 0.0036400303

Training iteration loss = 0.002941056

Training iteration loss = 0.003971902

Training iteration loss = 0.003601595

Training iteration loss = 0.0019431347

Training iteration loss = 0.0025269042

Training iteration loss = 0.0019223718

Training iteration loss = 0.002469381

Training iteration loss = 0.0020459907

Training iteration loss = 0.0024745048

Training iteration loss = 0.0034206773

Training iteration loss = 0.0034424427

Training iteration loss = 0.0045223045

Training iteration loss = 0.0040316083

Training iteration loss = 0.0042657754

Training iteration loss = 0.002169585

Training iteration loss = 0.0031334197

Training iteration loss = 0.0022942023

Training iteration loss = 0.0062112063

Training iteration loss = 0.003687378

Training iteration loss = 0.0029706524

Training iteration loss = 0.0028457846

Training iteration loss = 0.0036313722

Training iteration loss = 0.007361327

Training iteration loss = 0.002349022

Training iteration loss = 0.0038032718

Training iteration loss = 0.003661666

Training iteration loss = 0.0023591463

Training iteration loss = 0.003512215

Training iteration loss = 0.0037440534

Training iteration loss = 0.0027472058

Training iteration loss = 0.0025513563

Training iteration loss = 0.0033052017

Training iteration loss = 0.0038581446

Training iteration loss = 0.0036945401

Training iteration loss = 0.004644129

Training iteration loss = 0.004881688

Training iteration loss = 0.0032164648

Training iteration loss = 0.003664704

Training iteration loss = 0.004468297

Training iteration loss = 0.004645799

Training iteration loss = 0.0028986642

Training iteration loss = 0.0037013504

Training iteration loss = 0.0040506497

Training iteration loss = 0.0025637234

Training iteration loss = 0.0021792063

Training iteration loss = 0.0035918846

Training iteration loss = 0.0024727203

Training iteration loss = 0.0021890763

Training iteration loss = 0.003158529

Training iteration loss = 0.002289973

Training iteration loss = 0.0019000223

Training iteration loss = 0.0018258305

Training iteration loss = 0.003108061

Training iteration loss = 0.0020708542

Training iteration loss = 0.002276317

Training iteration loss = 0.004029348

Training iteration loss = 0.005446017

Training iteration loss = 0.0025191223

Training iteration loss = 0.0028015412

Training iteration loss = 0.0024625422

Training iteration loss = 0.0027803846

Training iteration loss = 0.0022092431

Training iteration loss = 0.004144076

Training iteration loss = 0.0034378392

Training iteration loss = 0.0048873336

Training iteration loss = 0.004008422

Training iteration loss = 0.0029436967

Training iteration loss = 0.001998887

Training iteration loss = 0.0021425763

Training iteration loss = 0.008576973

Training iteration loss = 0.0030675977

Training iteration loss = 0.0018316512

Training iteration loss = 0.004289165

Training iteration loss = 0.0037990294

Training iteration loss = 0.003446131

Training iteration loss = 0.002997664

Training iteration loss = 0.00399546

Training iteration loss = 0.0023190198

Training iteration loss = 0.0066663395

Training iteration loss = 0.0026167643

Training iteration loss = 0.0034316555

Training iteration loss = 0.003931074

Training iteration loss = 0.0021633229

Training iteration loss = 0.0021821938

Training iteration loss = 0.0025998347

Training iteration loss = 0.0017004017

Training iteration loss = 0.0033766096

Training iteration loss = 0.003219201

Training iteration loss = 0.004233859

Training iteration loss = 0.0030850114

Training iteration loss = 0.0028276842

Training iteration loss = 0.002235174

Training iteration loss = 0.0022698713

Training iteration loss = 0.002391875

Training iteration loss = 0.0031035196

Training iteration loss = 0.0048528323

Training iteration loss = 0.0018651914

Training iteration loss = 0.003016227

Training iteration loss = 0.0030954482

Training iteration loss = 0.0034462458

Training iteration loss = 0.0029034906

Training iteration loss = 0.0033324768

Training iteration loss = 0.0028039475

Training iteration loss = 0.0018263237

Training iteration loss = 0.0062240106

Training iteration loss = 0.00298171

Training iteration loss = 0.0026312275

Training iteration loss = 0.0018286941

Training iteration loss = 0.0034273204

Training iteration loss = 0.0037018184

Training iteration loss = 0.0037307572

Training iteration loss = 0.0024455437

Training iteration loss = 0.0057366937

Training iteration loss = 0.0031531323

Training iteration loss = 0.0023431962

Training iteration loss = 0.002060538

Training iteration loss = 0.0025324656

Training iteration loss = 0.0019750493

Training iteration loss = 0.0032067914

Training iteration loss = 0.0018221085

Training iteration loss = 0.0020726228

Training iteration loss = 0.0036464073

Training iteration loss = 0.0029386182

Training iteration loss = 0.0033918563

Training iteration loss = 0.0026167936

Training iteration loss = 0.0040820385

Training iteration loss = 0.004144088

Training iteration loss = 0.0044510565

Training iteration loss = 0.0020687045

Training iteration loss = 0.0028942085

Training iteration loss = 0.0024536105

Training iteration loss = 0.0037858577

Training iteration loss = 0.0034157524

Training iteration loss = 0.0048205922

Training iteration loss = 0.0029081013

Training iteration loss = 0.0024964276

Training iteration loss = 0.0031554175

Training iteration loss = 0.0048455177

Training iteration loss = 0.0033024484

Training iteration loss = 0.0027572333

Training iteration loss = 0.0033501268

Training iteration loss = 0.0032737618

Training iteration loss = 0.002484529

Training iteration loss = 0.0026982427

Training iteration loss = 0.003693292

Training iteration loss = 0.003023577

Training iteration loss = 0.003182804

Training iteration loss = 0.002811969

Training iteration loss = 0.0023537907

Training iteration loss = 0.0045517036

Training iteration loss = 0.004262348

Training iteration loss = 0.0038129708

Training iteration loss = 0.0037068862

Training iteration loss = 0.0022551746

Training iteration loss = 0.0045696427

Training iteration loss = 0.0055556404

Training iteration loss = 0.0024382414

Training iteration loss = 0.003373069

Training iteration loss = 0.002423831

Training iteration loss = 0.0026483515

Training iteration loss = 0.002715491

Training iteration loss = 0.002549146

Training iteration loss = 0.0050261253

Training iteration loss = 0.005876214

Training iteration loss = 0.002550186

Training iteration loss = 0.002893462

Training iteration loss = 0.0022188702

Training iteration loss = 0.0026351549

Training iteration loss = 0.0033937555

Training iteration loss = 0.0032974398

Training iteration loss = 0.0037301092

Training iteration loss = 0.0022603038

Training iteration loss = 0.0036106072

Training iteration loss = 0.007272186

Training iteration loss = 0.004786548

Training iteration loss = 0.0038454793

Training iteration loss = 0.0029931543

Training iteration loss = 0.0035106558

Training iteration loss = 0.00263114

Training iteration loss = 0.0034314748

Training iteration loss = 0.0021440794

Training iteration loss = 0.0026651016

Training iteration loss = 0.0026527885

Training iteration loss = 0.002770947

Training iteration loss = 0.0020421

Training iteration loss = 0.004468387

Training iteration loss = 0.0033646056

Training iteration loss = 0.005441643

Training iteration loss = 0.003212655

Training iteration loss = 0.0032493107

Training iteration loss = 0.0033660727

Training iteration loss = 0.006935178

Training iteration loss = 0.0040828814

Training iteration loss = 0.0034178616

Training iteration loss = 0.002561089

Training iteration loss = 0.00512177

Training iteration loss = 0.0022858088

Training iteration loss = 0.0024092484

Training iteration loss = 0.0028708037

Training iteration loss = 0.0036485123

Training iteration loss = 0.0029513966

Training iteration loss = 0.003966009

Training iteration loss = 0.0035875337

Training iteration loss = 0.001939237

Training iteration loss = 0.0025295762

Training iteration loss = 0.001934735

Training iteration loss = 0.0024745

Training iteration loss = 0.0020575484

Training iteration loss = 0.0024712526

Training iteration loss = 0.0034304734

Training iteration loss = 0.0034549942

Training iteration loss = 0.0045280904

Training iteration loss = 0.0040365453

Training iteration loss = 0.00425142

Training iteration loss = 0.002166283

Training iteration loss = 0.0031200275

Training iteration loss = 0.0022776967

Training iteration loss = 0.006181773

Training iteration loss = 0.0036708948

Training iteration loss = 0.0029775363

Training iteration loss = 0.002866368

Training iteration loss = 0.0036317527

Training iteration loss = 0.0073155244

Training iteration loss = 0.00233477

Training iteration loss = 0.0037862603

Training iteration loss = 0.0036777284

Training iteration loss = 0.0023646005

Training iteration loss = 0.003520361

Training iteration loss = 0.0037399319

Training iteration loss = 0.0027453098

Training iteration loss = 0.002544309

Training iteration loss = 0.0032901212

Training iteration loss = 0.0038534522

Training iteration loss = 0.0036844464

Training iteration loss = 0.004644443

Training iteration loss = 0.004851987

Training iteration loss = 0.0032228483

Training iteration loss = 0.003646652

Training iteration loss = 0.004439226

Training iteration loss = 0.004617425

Training iteration loss = 0.0029001974

Training iteration loss = 0.0036941946

Training iteration loss = 0.004057162

Training iteration loss = 0.0025574535

Training iteration loss = 0.0021765241

Training iteration loss = 0.003607569

Training iteration loss = 0.0024636595

Training iteration loss = 0.002193216

Training iteration loss = 0.0031464386

Training iteration loss = 0.002281952

Training iteration loss = 0.0018917322

Training iteration loss = 0.0018215139

Training iteration loss = 0.003106689

Training iteration loss = 0.0020740472

Training iteration loss = 0.0022722129

Training iteration loss = 0.0040241536

Training iteration loss = 0.005432369

Training iteration loss = 0.0025158073

Training iteration loss = 0.0027997328

Training iteration loss = 0.0024576392

Training iteration loss = 0.0027771853

Training iteration loss = 0.0022108748

Training iteration loss = 0.0041337484

Training iteration loss = 0.0034377333

Training iteration loss = 0.004890205

Training iteration loss = 0.0039891354

Training iteration loss = 0.002944013

Training iteration loss = 0.0019943083

Training iteration loss = 0.0021379543

Training iteration loss = 0.008597575

Training iteration loss = 0.0030669149

Training iteration loss = 0.0018260119

Training iteration loss = 0.004284738

Training iteration loss = 0.0037957767

Training iteration loss = 0.0034386583

Training iteration loss = 0.0029807172

Training iteration loss = 0.003986584

Training iteration loss = 0.0023083007

Training iteration loss = 0.0066701504

Training iteration loss = 0.0026208435

Training iteration loss = 0.0034353475

Training iteration loss = 0.003919354

Training iteration loss = 0.0021587831

Training iteration loss = 0.002174116

Training iteration loss = 0.0026004994

Training iteration loss = 0.00169494

Training iteration loss = 0.0033687726

Training iteration loss = 0.0032222995

Training iteration loss = 0.004234318

Training iteration loss = 0.003082183

Training iteration loss = 0.0028392908

Training iteration loss = 0.0022392168

Training iteration loss = 0.0022706916

Training iteration loss = 0.0023904126

Training iteration loss = 0.0031145404

Training iteration loss = 0.004799686

Training iteration loss = 0.0018618471

Training iteration loss = 0.0030055626

Training iteration loss = 0.003086786

Training iteration loss = 0.0034341402

Training iteration loss = 0.0029055532

Training iteration loss = 0.0033318887

Training iteration loss = 0.0027975533

Training iteration loss = 0.0018236119

Training iteration loss = 0.0061768666

Training iteration loss = 0.0029721789

Training iteration loss = 0.0026169019

Training iteration loss = 0.0018343177

Training iteration loss = 0.0034231048

Training iteration loss = 0.0037029814

Training iteration loss = 0.0037380208

Training iteration loss = 0.0024374092

Training iteration loss = 0.005748762

Training iteration loss = 0.0031483069

Training iteration loss = 0.0023228938

Training iteration loss = 0.002052741

Training iteration loss = 0.0025126382

Training iteration loss = 0.0019786346

Training iteration loss = 0.0031948497

Training iteration loss = 0.0018196591

Training iteration loss = 0.0020605626

Training iteration loss = 0.0036415597

Training iteration loss = 0.0029380133

Training iteration loss = 0.00340995

Training iteration loss = 0.0026209764

Training iteration loss = 0.0040507796

Training iteration loss = 0.0041444674

Training iteration loss = 0.0044416273

Training iteration loss = 0.0020649254

Training iteration loss = 0.0028920106

Training iteration loss = 0.0024517959

Training iteration loss = 0.0037853054

Training iteration loss = 0.0034177655

Training iteration loss = 0.0048192493

Training iteration loss = 0.0029047302

Training iteration loss = 0.0024944195

Training iteration loss = 0.0031498615

Training iteration loss = 0.0048345616

Training iteration loss = 0.0032977501

Training iteration loss = 0.0027511502

Training iteration loss = 0.003344873

Training iteration loss = 0.0032721672

Training iteration loss = 0.002479349

Training iteration loss = 0.0026767256

Training iteration loss = 0.003688942

Training iteration loss = 0.0030174304

Training iteration loss = 0.0031769609

Training iteration loss = 0.0028094247

Training iteration loss = 0.0023469753

Training iteration loss = 0.0045396267

Training iteration loss = 0.0042514126

Training iteration loss = 0.0038114593

Training iteration loss = 0.003703647

Training iteration loss = 0.002251364

Training iteration loss = 0.0045569893

Training iteration loss = 0.0055508516

Training iteration loss = 0.0024351578

Training iteration loss = 0.0033548332

Training iteration loss = 0.0024175763

Training iteration loss = 0.0026482483

Training iteration loss = 0.002711706

Training iteration loss = 0.002535629

Training iteration loss = 0.0050150394

Training iteration loss = 0.005862508

Training iteration loss = 0.0025394787

Training iteration loss = 0.0028909591

Training iteration loss = 0.0022098406

Training iteration loss = 0.002630857

Training iteration loss = 0.0033881094

Training iteration loss = 0.0032932851

Training iteration loss = 0.0037238458

Training iteration loss = 0.002258163

Training iteration loss = 0.003596458

Training iteration loss = 0.0072830296

Training iteration loss = 0.00477329

Training iteration loss = 0.003839041

Training iteration loss = 0.002982815

Training iteration loss = 0.0035054733

Training iteration loss = 0.0026279988

Training iteration loss = 0.0034159005

Training iteration loss = 0.0021388943

Training iteration loss = 0.0026513515

Training iteration loss = 0.002642486

Training iteration loss = 0.0027523339

Training iteration loss = 0.0020316276

Training iteration loss = 0.0044652564

Training iteration loss = 0.0033599306

Training iteration loss = 0.0054371892

Training iteration loss = 0.0032085616

Training iteration loss = 0.0032433018

Training iteration loss = 0.0033833745

Training iteration loss = 0.0069141653

Training iteration loss = 0.004075438

Training iteration loss = 0.0034163538

Training iteration loss = 0.0025545293

Training iteration loss = 0.0050875014

Training iteration loss = 0.002278892

Training iteration loss = 0.0024052646

Training iteration loss = 0.0028761474

Training iteration loss = 0.003653053

Training iteration loss = 0.0029445228

Training iteration loss = 0.0039618807

Training iteration loss = 0.0035863777

Training iteration loss = 0.0019376423

Training iteration loss = 0.0025241706

Training iteration loss = 0.001927821

Training iteration loss = 0.0024604516

Training iteration loss = 0.0020401669

Training iteration loss = 0.0024643205

Training iteration loss = 0.0034203047

Training iteration loss = 0.0034414483

Training iteration loss = 0.004517123

Training iteration loss = 0.004030793

Training iteration loss = 0.0042365887

Training iteration loss = 0.0021679793

Training iteration loss = 0.0031176696

Training iteration loss = 0.002276242

Training iteration loss = 0.006180547

Training iteration loss = 0.0036690596

Training iteration loss = 0.002970036

Training iteration loss = 0.0028520012

Training iteration loss = 0.0036286644

Training iteration loss = 0.007297853

Training iteration loss = 0.002339698

Training iteration loss = 0.0037763936

Training iteration loss = 0.003668174

Training iteration loss = 0.0023662122

Training iteration loss = 0.0035150659

Training iteration loss = 0.003737374

Training iteration loss = 0.002740565

Training iteration loss = 0.0025387446

Training iteration loss = 0.003286678

Training iteration loss = 0.0038234058

Training iteration loss = 0.0036648307

Training iteration loss = 0.004629928

Training iteration loss = 0.004849061

Training iteration loss = 0.0032285182

Training iteration loss = 0.003639779

Training iteration loss = 0.004416273

Training iteration loss = 0.0045946366

Training iteration loss = 0.0028937387

Training iteration loss = 0.0036851193

Training iteration loss = 0.004070503

Training iteration loss = 0.0025552954

Training iteration loss = 0.0021691665

Training iteration loss = 0.0036061362

Training iteration loss = 0.0024556525

Training iteration loss = 0.002181107

Training iteration loss = 0.0031486012

Training iteration loss = 0.002280558

Training iteration loss = 0.0018767227

Training iteration loss = 0.0018197194

Training iteration loss = 0.0031037906

Training iteration loss = 0.002065913

Training iteration loss = 0.0022675714

Training iteration loss = 0.0040108734

Training iteration loss = 0.005433111

Training iteration loss = 0.0025106093

Training iteration loss = 0.0027905174

Training iteration loss = 0.0024465604

Training iteration loss = 0.002769177

Training iteration loss = 0.002211195

Training iteration loss = 0.004124407

Training iteration loss = 0.0034314366

Training iteration loss = 0.0048820847

Training iteration loss = 0.003979958

Training iteration loss = 0.00294015

Training iteration loss = 0.0019890268

Training iteration loss = 0.0021326381

Training iteration loss = 0.008604051

Training iteration loss = 0.0030628704

Training iteration loss = 0.001816297

Training iteration loss = 0.004279649

Training iteration loss = 0.003793938

Training iteration loss = 0.0034303556

Training iteration loss = 0.0029699968

Training iteration loss = 0.0039838483

Training iteration loss = 0.002310387

Training iteration loss = 0.0066529773

Training iteration loss = 0.0026128998

Training iteration loss = 0.0034339402

Training iteration loss = 0.0039083348

Training iteration loss = 0.0021542464

Training iteration loss = 0.002169077

Training iteration loss = 0.0025963793

Training iteration loss = 0.0016888793

Training iteration loss = 0.003362055

Training iteration loss = 0.0032242595

Training iteration loss = 0.0042364206

Training iteration loss = 0.0030763892

Training iteration loss = 0.0028360952

Training iteration loss = 0.0022456355

Training iteration loss = 0.0022716774

Training iteration loss = 0.002383497

Training iteration loss = 0.0031102905

Training iteration loss = 0.004786382

Training iteration loss = 0.0018537883

Training iteration loss = 0.003003508

Training iteration loss = 0.0030884373

Training iteration loss = 0.0034308026

Training iteration loss = 0.0028940241

Training iteration loss = 0.0033279567

Training iteration loss = 0.0027950474

Training iteration loss = 0.0018146815

Training iteration loss = 0.006164447

Training iteration loss = 0.002972709

Training iteration loss = 0.0026162134

Training iteration loss = 0.0018343971

Training iteration loss = 0.0034203182

Training iteration loss = 0.0037017504

Training iteration loss = 0.003732486

Training iteration loss = 0.0024316947

Training iteration loss = 0.005741498

Training iteration loss = 0.0031483497

Training iteration loss = 0.0023177152

Training iteration loss = 0.002057856

Training iteration loss = 0.0025060829

Training iteration loss = 0.0019752954

Training iteration loss = 0.0031774014

Training iteration loss = 0.0018140437

Training iteration loss = 0.0020610346

Training iteration loss = 0.003647465

Training iteration loss = 0.0029252565

Training iteration loss = 0.0034042166

Training iteration loss = 0.0026161578

Training iteration loss = 0.004048862

Training iteration loss = 0.0041398876

Training iteration loss = 0.0044186898

Training iteration loss = 0.002062763

Training iteration loss = 0.0028842129

Training iteration loss = 0.0024534145

Training iteration loss = 0.0037837417

Training iteration loss = 0.0034129154

Training iteration loss = 0.004820286

Training iteration loss = 0.0029094017

Training iteration loss = 0.0024920518

Training iteration loss = 0.0031505774

Training iteration loss = 0.0048237406

Training iteration loss = 0.0032884618

Training iteration loss = 0.002745918

Training iteration loss = 0.003337062

Training iteration loss = 0.0032630174

Training iteration loss = 0.0024771688

Training iteration loss = 0.002663072

Training iteration loss = 0.003683353

Training iteration loss = 0.0030177748

Training iteration loss = 0.0031687934

Training iteration loss = 0.0028077748

Training iteration loss = 0.002343368

Training iteration loss = 0.004535489

Training iteration loss = 0.0042398954

Training iteration loss = 0.0038134346

Training iteration loss = 0.0037006962

Training iteration loss = 0.002250218

Training iteration loss = 0.004549864

Training iteration loss = 0.005547555

Training iteration loss = 0.0024323903

Training iteration loss = 0.0033469712

Training iteration loss = 0.0024151863

Training iteration loss = 0.0026480465

Training iteration loss = 0.0027075484

Training iteration loss = 0.002527704

Training iteration loss = 0.004998978

Training iteration loss = 0.005844677

Training iteration loss = 0.0025339539

Training iteration loss = 0.0028851144

Training iteration loss = 0.0022065283

Training iteration loss = 0.0026283555

Training iteration loss = 0.003382282

Training iteration loss = 0.0032823847

Training iteration loss = 0.0037137528

Training iteration loss = 0.0022575653

Training iteration loss = 0.0035826117

Training iteration loss = 0.0072695147

Training iteration loss = 0.0047636325

Training iteration loss = 0.0038326709

Training iteration loss = 0.0029774206

Training iteration loss = 0.0035033422

Training iteration loss = 0.0026291183

Training iteration loss = 0.0034043964

Training iteration loss = 0.0021338372

Training iteration loss = 0.0026386331

Training iteration loss = 0.002634298

Training iteration loss = 0.002735545

Training iteration loss = 0.0020257263

Training iteration loss = 0.004465686

Training iteration loss = 0.0033570833

Training iteration loss = 0.0054334947

Training iteration loss = 0.0032061301

Training iteration loss = 0.0032390754

Training iteration loss = 0.0034002333

Training iteration loss = 0.0068919957

Training iteration loss = 0.0040643564

Training iteration loss = 0.0034126502

Training iteration loss = 0.002546925

Training iteration loss = 0.005055619

Training iteration loss = 0.0022717323

Training iteration loss = 0.0024033396

Training iteration loss = 0.0028810448

Training iteration loss = 0.0036586656

Training iteration loss = 0.002938212

Training iteration loss = 0.003953518

Training iteration loss = 0.0035795372

Training iteration loss = 0.0019315062

Training iteration loss = 0.0025182443

Training iteration loss = 0.0019215964

Training iteration loss = 0.00244923

Training iteration loss = 0.0020297389

Training iteration loss = 0.0024608038

Training iteration loss = 0.003407933

Training iteration loss = 0.003434718

Training iteration loss = 0.004510795

Training iteration loss = 0.004025265

Training iteration loss = 0.004218525

Training iteration loss = 0.0021714475

Training iteration loss = 0.0031084996

Training iteration loss = 0.0022754208

Training iteration loss = 0.0061883554

Training iteration loss = 0.0036664351

Training iteration loss = 0.0029590663

Training iteration loss = 0.0028439506

Training iteration loss = 0.0036246374

Training iteration loss = 0.0073067755

Training iteration loss = 0.0023487983

Training iteration loss = 0.0037617022

Training iteration loss = 0.0036438054

Training iteration loss = 0.0023493937

Training iteration loss = 0.00350341

Training iteration loss = 0.0037331984

Training iteration loss = 0.0027403587

Training iteration loss = 0.0025565943

Training iteration loss = 0.0032876574

Training iteration loss = 0.0038254315

Training iteration loss = 0.0036687853

Training iteration loss = 0.004597651

Training iteration loss = 0.004839038

Training iteration loss = 0.0032241847

Training iteration loss = 0.0036459693

Training iteration loss = 0.004407212

Training iteration loss = 0.004594084

Training iteration loss = 0.002878819

Training iteration loss = 0.00368206

Training iteration loss = 0.004061259

Training iteration loss = 0.0025562323

Training iteration loss = 0.0021611082

Training iteration loss = 0.0036009771

Training iteration loss = 0.0024569219

Training iteration loss = 0.0021789644

Training iteration loss = 0.0031358057

Training iteration loss = 0.0022766804

Training iteration loss = 0.001870546

Training iteration loss = 0.0018180221

Training iteration loss = 0.0031021636

Training iteration loss = 0.0020627447

Training iteration loss = 0.0022665167

Training iteration loss = 0.0040203533

Training iteration loss = 0.0054216045

Training iteration loss = 0.0025109288

Training iteration loss = 0.0027928099

Training iteration loss = 0.002440029

Training iteration loss = 0.002757169

Training iteration loss = 0.0022114525

Training iteration loss = 0.00411893

Training iteration loss = 0.0034366504

Training iteration loss = 0.0048843403

Training iteration loss = 0.003962581

Training iteration loss = 0.0029436108

Training iteration loss = 0.0019901232

Training iteration loss = 0.0021285194

Training iteration loss = 0.008608959

Training iteration loss = 0.0030602263

Training iteration loss = 0.0018072871

Training iteration loss = 0.0042886506

Training iteration loss = 0.0037895879

Training iteration loss = 0.0034231397

Training iteration loss = 0.002957966

Training iteration loss = 0.003972558

Training iteration loss = 0.002303545

Training iteration loss = 0.006610077

Training iteration loss = 0.002604908

Training iteration loss = 0.0034336764

Training iteration loss = 0.0038979335

Training iteration loss = 0.002145119

Training iteration loss = 0.002161168

Training iteration loss = 0.0025864893

Training iteration loss = 0.0016878821

Training iteration loss = 0.0033645257

Training iteration loss = 0.0032254967

Training iteration loss = 0.0042263516

Training iteration loss = 0.003065564

Training iteration loss = 0.0028296614

Training iteration loss = 0.0022441659

Training iteration loss = 0.0022656273

Training iteration loss = 0.0023821115

Training iteration loss = 0.0031071345

Training iteration loss = 0.0047878465

Training iteration loss = 0.0018511118

Training iteration loss = 0.003005705

Training iteration loss = 0.0030860004

Training iteration loss = 0.0034217786

Training iteration loss = 0.0028789227

Training iteration loss = 0.0033168418

Training iteration loss = 0.0027837001

Training iteration loss = 0.001805914

Training iteration loss = 0.0061324933

Training iteration loss = 0.002968314

Training iteration loss = 0.0026087745

Training iteration loss = 0.0018382389

Training iteration loss = 0.0034170076

Training iteration loss = 0.0036911361

Training iteration loss = 0.003727978

Training iteration loss = 0.0024218326

Training iteration loss = 0.00573628

Training iteration loss = 0.0031482622

Training iteration loss = 0.0023255695

Training iteration loss = 0.0020788466

Training iteration loss = 0.00252195

Training iteration loss = 0.001972477

Training iteration loss = 0.0031644625

Training iteration loss = 0.0018149685

Training iteration loss = 0.002057112

Training iteration loss = 0.0036304898

Training iteration loss = 0.0029080624

Training iteration loss = 0.003382924

Training iteration loss = 0.0026052257

Training iteration loss = 0.004045579

Training iteration loss = 0.0041428455

Training iteration loss = 0.0044295858

Training iteration loss = 0.002059352

Training iteration loss = 0.0028740633

Training iteration loss = 0.0024397965

Training iteration loss = 0.0037716795

Training iteration loss = 0.0034072616

Training iteration loss = 0.0048047146

Training iteration loss = 0.0029067157

Training iteration loss = 0.0024958125

Training iteration loss = 0.0031507534

Training iteration loss = 0.0048053246

Training iteration loss = 0.0032832

Training iteration loss = 0.0027404216

Training iteration loss = 0.0033217042

Training iteration loss = 0.0032412221

Training iteration loss = 0.00246692

Training iteration loss = 0.0026431784

Training iteration loss = 0.003681781

Training iteration loss = 0.0030195825

Training iteration loss = 0.0031626525

Training iteration loss = 0.0028013606

Training iteration loss = 0.0023374981

Training iteration loss = 0.004535354

Training iteration loss = 0.004231823

Training iteration loss = 0.0038118444

Training iteration loss = 0.0036976088

Training iteration loss = 0.0022484502

Training iteration loss = 0.004541004

Training iteration loss = 0.0055493475

Training iteration loss = 0.002422327

Training iteration loss = 0.003342962

Training iteration loss = 0.002409545

Training iteration loss = 0.0026566994

Training iteration loss = 0.0027020203

Training iteration loss = 0.002522262

Training iteration loss = 0.00498602

Training iteration loss = 0.005820812

Training iteration loss = 0.0025334854

Training iteration loss = 0.0028817186

Training iteration loss = 0.002201526

Training iteration loss = 0.0026225185

Training iteration loss = 0.003376071

Training iteration loss = 0.0032743958

Training iteration loss = 0.0037093034

Training iteration loss = 0.0022545827

Training iteration loss = 0.003567851

Training iteration loss = 0.007248686

Training iteration loss = 0.004750066

Training iteration loss = 0.0038270105

Training iteration loss = 0.0029694631

Training iteration loss = 0.0034949158

Training iteration loss = 0.0026299825

Training iteration loss = 0.003398978

Training iteration loss = 0.0021324698

Training iteration loss = 0.0026224768

Training iteration loss = 0.0026293918

Training iteration loss = 0.0027292229

Training iteration loss = 0.0020191653

Training iteration loss = 0.0044710613

Training iteration loss = 0.0033454893

Training iteration loss = 0.0054269577

Training iteration loss = 0.003210253

Training iteration loss = 0.003237699

Training iteration loss = 0.0033908112

Training iteration loss = 0.0068662274

Training iteration loss = 0.004049074

Training iteration loss = 0.0034111328

Training iteration loss = 0.002549193

Training iteration loss = 0.005038838

Training iteration loss = 0.0022622

Training iteration loss = 0.0024045373

Training iteration loss = 0.002884288

Training iteration loss = 0.0036630316

Training iteration loss = 0.0029394429

Training iteration loss = 0.0039407425

Training iteration loss = 0.0035609938

Training iteration loss = 0.0019319138

Training iteration loss = 0.002522664

Training iteration loss = 0.0019295925

Training iteration loss = 0.0024517751

Training iteration loss = 0.002038472

Training iteration loss = 0.0024645885

Training iteration loss = 0.003418031

Training iteration loss = 0.003437803

Training iteration loss = 0.0045191585

Training iteration loss = 0.0040291226

Training iteration loss = 0.004196582

Training iteration loss = 0.002167633

Training iteration loss = 0.0030938291

Training iteration loss = 0.00225896

Training iteration loss = 0.0061497637

Training iteration loss = 0.0036425448

Training iteration loss = 0.002966699

Training iteration loss = 0.002869389

Training iteration loss = 0.003631994

Training iteration loss = 0.007229541

Training iteration loss = 0.0023274056

Training iteration loss = 0.003737178

Training iteration loss = 0.0036726173

Training iteration loss = 0.0023663456

Training iteration loss = 0.003524743

Training iteration loss = 0.00373336

Training iteration loss = 0.0027370632

Training iteration loss = 0.0025331413

Training iteration loss = 0.0032580951

Training iteration loss = 0.003804717

Training iteration loss = 0.0036352223

Training iteration loss = 0.0046051466

Training iteration loss = 0.0048153843

Training iteration loss = 0.0032428952

Training iteration loss = 0.003621854

Training iteration loss = 0.004362039

Training iteration loss = 0.0045506894

Training iteration loss = 0.0028775847

Training iteration loss = 0.0036658838

Training iteration loss = 0.0040853745

Training iteration loss = 0.0025507377

Training iteration loss = 0.0021639985

Training iteration loss = 0.0036150406

Training iteration loss = 0.0024416137

Training iteration loss = 0.0021751502

Training iteration loss = 0.0031249467

Training iteration loss = 0.0022625022

Training iteration loss = 0.0018557957

Training iteration loss = 0.0018228852

Training iteration loss = 0.0031016953

Training iteration loss = 0.0020707308

Training iteration loss = 0.002264344

Training iteration loss = 0.0039978405

Training iteration loss = 0.0054073613

Training iteration loss = 0.0025018973

Training iteration loss = 0.0027768153

Training iteration loss = 0.0024290176

Training iteration loss = 0.002745282

Training iteration loss = 0.002212093

Training iteration loss = 0.004097558

Training iteration loss = 0.0034254913

Training iteration loss = 0.0048933136

Training iteration loss = 0.003953625

Training iteration loss = 0.0029389123

Training iteration loss = 0.0019835948

Training iteration loss = 0.0021207433

Training iteration loss = 0.00861574

Training iteration loss = 0.0030619788

Training iteration loss = 0.001801874

Training iteration loss = 0.0042837765

Training iteration loss = 0.0037803154

Training iteration loss = 0.003414575

Training iteration loss = 0.0029461263

Training iteration loss = 0.003968553

Training iteration loss = 0.002302045

Training iteration loss = 0.0066123144

Training iteration loss = 0.0026097102

Training iteration loss = 0.0034336147

Training iteration loss = 0.0038789036

Training iteration loss = 0.0021362372

Training iteration loss = 0.0021530013

Training iteration loss = 0.0025815372

Training iteration loss = 0.0016820249

Training iteration loss = 0.0033525191

Training iteration loss = 0.0032147635

Training iteration loss = 0.004213019

Training iteration loss = 0.0030622052

Training iteration loss = 0.0028278206

Training iteration loss = 0.002255279

Training iteration loss = 0.0022631139

Training iteration loss = 0.0023770032

Training iteration loss = 0.0031123736

Training iteration loss = 0.004762215

Training iteration loss = 0.0018429771

Training iteration loss = 0.0029948538

Training iteration loss = 0.003082649

Training iteration loss = 0.0034132658

Training iteration loss = 0.0028815838

Training iteration loss = 0.0033146834

Training iteration loss = 0.0027786356

Training iteration loss = 0.0018023612

Training iteration loss = 0.0061416333

Training iteration loss = 0.0029646382

Training iteration loss = 0.0026116222

Training iteration loss = 0.0018380219

Training iteration loss = 0.003407791

Training iteration loss = 0.0036906188

Training iteration loss = 0.0037235164

Training iteration loss = 0.0024199795

Training iteration loss = 0.0057295174

Training iteration loss = 0.0031449015

Training iteration loss = 0.0023084062

Training iteration loss = 0.0020623126

Training iteration loss = 0.0024946018

Training iteration loss = 0.0019703715

Training iteration loss = 0.0031388476

Training iteration loss = 0.001801849

Training iteration loss = 0.0020562266

Training iteration loss = 0.0036512145

Training iteration loss = 0.0029012344

Training iteration loss = 0.0033915453

Training iteration loss = 0.0026083274

Training iteration loss = 0.0040337467

Training iteration loss = 0.0041392925

Training iteration loss = 0.0044000726

Training iteration loss = 0.0020536934

Training iteration loss = 0.0028678288

Training iteration loss = 0.0024467253

Training iteration loss = 0.0037644145

Training iteration loss = 0.00340572

Training iteration loss = 0.004802728

Training iteration loss = 0.0029128382

Training iteration loss = 0.002487446

Training iteration loss = 0.0031476803

Training iteration loss = 0.0047989683

Training iteration loss = 0.0032709457

Training iteration loss = 0.0027347952

Training iteration loss = 0.0033225825

Training iteration loss = 0.003238817

Training iteration loss = 0.0024699154

Training iteration loss = 0.0026311188

Training iteration loss = 0.0036713565

Training iteration loss = 0.0030190994

Training iteration loss = 0.0031496955

Training iteration loss = 0.0027959815

Training iteration loss = 0.0023378255

Training iteration loss = 0.004527692

Training iteration loss = 0.0042462363

Training iteration loss = 0.0038093487

Training iteration loss = 0.0037014375

Training iteration loss = 0.002243265

Training iteration loss = 0.004532687

Training iteration loss = 0.005542051

Training iteration loss = 0.0024222312

Training iteration loss = 0.0033342661

Training iteration loss = 0.0024042807

Training iteration loss = 0.0026568982

Training iteration loss = 0.0026978664

Training iteration loss = 0.0025151148

Training iteration loss = 0.0049778353

Training iteration loss = 0.005798885

Training iteration loss = 0.0025260032

Training iteration loss = 0.0028780412

Training iteration loss = 0.0021989688

Training iteration loss = 0.0026194295

Training iteration loss = 0.003374044

Training iteration loss = 0.0032647483

Training iteration loss = 0.0037013146

Training iteration loss = 0.0022536763

Training iteration loss = 0.0035551449

Training iteration loss = 0.007229956

Training iteration loss = 0.0047402536

Training iteration loss = 0.003815668

Training iteration loss = 0.0029662866

Training iteration loss = 0.0034881618

Training iteration loss = 0.0026336417

Training iteration loss = 0.0033906593

Training iteration loss = 0.002132291

Training iteration loss = 0.0026116755

Training iteration loss = 0.0026278605

Training iteration loss = 0.002724175

Training iteration loss = 0.0020121087

Training iteration loss = 0.004469756

Training iteration loss = 0.0033346887

Training iteration loss = 0.005417667

Training iteration loss = 0.0032112703

Training iteration loss = 0.003231169

Training iteration loss = 0.0033845736

Training iteration loss = 0.0068365727

Training iteration loss = 0.0040346864

Training iteration loss = 0.003410539

Training iteration loss = 0.0025459414

Training iteration loss = 0.005005501

Training iteration loss = 0.002249759

Training iteration loss = 0.002410552

Training iteration loss = 0.0028932365

Training iteration loss = 0.0036695038

Training iteration loss = 0.0029380762

Training iteration loss = 0.003930935

Training iteration loss = 0.003542155

Training iteration loss = 0.0019207842

Training iteration loss = 0.0025281964

Training iteration loss = 0.0019415575

Training iteration loss = 0.0024504378

Training iteration loss = 0.002037657

Training iteration loss = 0.0024614208

Training iteration loss = 0.003418248

Training iteration loss = 0.0034431063

Training iteration loss = 0.0045214067

Training iteration loss = 0.0040417206

Training iteration loss = 0.0041728024

Training iteration loss = 0.0021667134

Training iteration loss = 0.003082241

Training iteration loss = 0.0022513783

Training iteration loss = 0.006145919

Training iteration loss = 0.003639892

Training iteration loss = 0.0029629571

Training iteration loss = 0.0028752254

Training iteration loss = 0.003628216

Training iteration loss = 0.0072360267

Training iteration loss = 0.0023249148

Training iteration loss = 0.0037200833

Training iteration loss = 0.0036569545

Training iteration loss = 0.0023520158

Training iteration loss = 0.0035107054

Training iteration loss = 0.003721361

Training iteration loss = 0.0027322115

Training iteration loss = 0.0025400931

Training iteration loss = 0.003247813

Training iteration loss = 0.003804093

Training iteration loss = 0.0036466876

Training iteration loss = 0.0046184347

Training iteration loss = 0.0047925324

Training iteration loss = 0.003238814

Training iteration loss = 0.0036220532

Training iteration loss = 0.0043615787

Training iteration loss = 0.004536276

Training iteration loss = 0.0028730382

Training iteration loss = 0.0036752832

Training iteration loss = 0.004092461

Training iteration loss = 0.0025523708

Training iteration loss = 0.0021588765

Training iteration loss = 0.0036206485

Training iteration loss = 0.0024469935

Training iteration loss = 0.0021651278

Training iteration loss = 0.003116997

Training iteration loss = 0.002258996

Training iteration loss = 0.0018426894

Training iteration loss = 0.00181966

Training iteration loss = 0.0031045217

Training iteration loss = 0.0020640444

Training iteration loss = 0.00226407

Training iteration loss = 0.003992329

Training iteration loss = 0.0054044374

Training iteration loss = 0.002498126

Training iteration loss = 0.0027624778

Training iteration loss = 0.0024142305

Training iteration loss = 0.0027379326

Training iteration loss = 0.0022110874

Training iteration loss = 0.0040905993

Training iteration loss = 0.0034179294

Training iteration loss = 0.0048890472

Training iteration loss = 0.0039362987

Training iteration loss = 0.0029386596

Training iteration loss = 0.0019803443

Training iteration loss = 0.0021169814

Training iteration loss = 0.008621775

Training iteration loss = 0.003057685

Training iteration loss = 0.0017967495

Training iteration loss = 0.004274624

Training iteration loss = 0.003776091

Training iteration loss = 0.0034063414

Training iteration loss = 0.0029399593

Training iteration loss = 0.0039639743

Training iteration loss = 0.0023014394

Training iteration loss = 0.0066346764

Training iteration loss = 0.0026131484

Training iteration loss = 0.0034355011

Training iteration loss = 0.0038632713

Training iteration loss = 0.0021344784

Training iteration loss = 0.0021471165

Training iteration loss = 0.0025784574

Training iteration loss = 0.0016738522

Training iteration loss = 0.0033468232

Training iteration loss = 0.0032185607

Training iteration loss = 0.004208282

Training iteration loss = 0.0030578806

Training iteration loss = 0.002824925

Training iteration loss = 0.0022620596

Training iteration loss = 0.002262966

Training iteration loss = 0.0023648099

Training iteration loss = 0.003112648

Training iteration loss = 0.004738867

Training iteration loss = 0.0018351047

Training iteration loss = 0.0029984582

Training iteration loss = 0.0030835986

Training iteration loss = 0.0034071908

Training iteration loss = 0.0028720638

Training iteration loss = 0.0033061672

Training iteration loss = 0.0027752258

Training iteration loss = 0.00179586

Training iteration loss = 0.0061263

Training iteration loss = 0.0029642573

Training iteration loss = 0.0026070618

Training iteration loss = 0.0018497343

Training iteration loss = 0.003408446

Training iteration loss = 0.0036927054

Training iteration loss = 0.003722775

Training iteration loss = 0.0024169406

Training iteration loss = 0.005714964

Training iteration loss = 0.0031504573

Training iteration loss = 0.002312058

Training iteration loss = 0.0020703077

Training iteration loss = 0.0024868594

Training iteration loss = 0.0019674774

Training iteration loss = 0.0031235947

Training iteration loss = 0.0018007569

Training iteration loss = 0.0020579665

Training iteration loss = 0.0036505861

Training iteration loss = 0.0028884916

Training iteration loss = 0.0033843752

Training iteration loss = 0.0026072056

Training iteration loss = 0.0040185223

Training iteration loss = 0.004136963

Training iteration loss = 0.004391091

Training iteration loss = 0.0020489537

Training iteration loss = 0.002858258

Training iteration loss = 0.002436323

Training iteration loss = 0.0037493526

Training iteration loss = 0.0034029211

Training iteration loss = 0.0047911904

Training iteration loss = 0.002914438

Training iteration loss = 0.0024877707

Training iteration loss = 0.0031442167

Training iteration loss = 0.004785345

Training iteration loss = 0.003265637

Training iteration loss = 0.0027314133

Training iteration loss = 0.0033162355

Training iteration loss = 0.0032361604

Training iteration loss = 0.0024640716

Training iteration loss = 0.0026069407

Training iteration loss = 0.0036737293

Training iteration loss = 0.0030107412

Training iteration loss = 0.00314686

Training iteration loss = 0.0027914431

Training iteration loss = 0.0023319798

Training iteration loss = 0.0045196447

Training iteration loss = 0.0042220284

Training iteration loss = 0.0038090164

Training iteration loss = 0.0036985658

Training iteration loss = 0.0022391255

Training iteration loss = 0.0045198672

Training iteration loss = 0.005542237

Training iteration loss = 0.0024182429

Training iteration loss = 0.003317619

Training iteration loss = 0.002398189

Training iteration loss = 0.0026555278

Training iteration loss = 0.0026949595

Training iteration loss = 0.0025043604

Training iteration loss = 0.0049589467

Training iteration loss = 0.0057760957

Training iteration loss = 0.0025169167

Training iteration loss = 0.0028730861

Training iteration loss = 0.0021939555

Training iteration loss = 0.0026158139

Training iteration loss = 0.0033672543

Training iteration loss = 0.0032553233

Training iteration loss = 0.0036970032

Training iteration loss = 0.0022531354

Training iteration loss = 0.0035448112

Training iteration loss = 0.0072261207

Training iteration loss = 0.004727174

Training iteration loss = 0.003807228

Training iteration loss = 0.0029594714

Training iteration loss = 0.0034799967

Training iteration loss = 0.0026325157

Training iteration loss = 0.0033741712

Training iteration loss = 0.0021277217

Training iteration loss = 0.002595491

Training iteration loss = 0.0026175

Training iteration loss = 0.0026978487

Training iteration loss = 0.0020034912

Training iteration loss = 0.004468989

Training iteration loss = 0.0033302044

Training iteration loss = 0.0054104608

Training iteration loss = 0.0032052882

Training iteration loss = 0.0032219335

Training iteration loss = 0.0033892544

Training iteration loss = 0.0068092793

Training iteration loss = 0.004020939

Training iteration loss = 0.0034083643

Training iteration loss = 0.002542131

Training iteration loss = 0.004983299

Training iteration loss = 0.0022410683

Training iteration loss = 0.0024109585

Training iteration loss = 0.0028937869

Training iteration loss = 0.0036713928

Training iteration loss = 0.0029284554

Training iteration loss = 0.003920939

Training iteration loss = 0.0035323754

Training iteration loss = 0.0019178959

Training iteration loss = 0.0025214993

Training iteration loss = 0.0019393702

Training iteration loss = 0.0024418465

Training iteration loss = 0.0020287132

Training iteration loss = 0.0024587512

Training iteration loss = 0.0034039645

Training iteration loss = 0.0034366613

Training iteration loss = 0.0045191874

Training iteration loss = 0.004036642

Training iteration loss = 0.004156966

Training iteration loss = 0.0021679995

Training iteration loss = 0.0030756255

Training iteration loss = 0.0022494006

Training iteration loss = 0.006133023

Training iteration loss = 0.0036380664

Training iteration loss = 0.0029475603

Training iteration loss = 0.0028594863

Training iteration loss = 0.0036205817

Training iteration loss = 0.0072356607

Training iteration loss = 0.0023318364

Training iteration loss = 0.003704992

Training iteration loss = 0.0036285892

Training iteration loss = 0.0023281637

Training iteration loss = 0.0034893968

Training iteration loss = 0.0037142877

Training iteration loss = 0.0027289782

Training iteration loss = 0.002557696

Training iteration loss = 0.0032521856

Training iteration loss = 0.0037950173

Training iteration loss = 0.0036475696

Training iteration loss = 0.004565928

Training iteration loss = 0.004786667

Training iteration loss = 0.003224072

Training iteration loss = 0.0036440215

Training iteration loss = 0.0043455022

Training iteration loss = 0.004543454

Training iteration loss = 0.0028624665

Training iteration loss = 0.003678031

Training iteration loss = 0.004086982

Training iteration loss = 0.00255409

Training iteration loss = 0.002150037

Training iteration loss = 0.0036093583

Training iteration loss = 0.002446213

Training iteration loss = 0.0021580702

Training iteration loss = 0.003116295

Training iteration loss = 0.0022637274

Training iteration loss = 0.0018348723

Training iteration loss = 0.0018190723

Training iteration loss = 0.0031009277

Training iteration loss = 0.0020576364

Training iteration loss = 0.002264563

Training iteration loss = 0.003992648

Training iteration loss = 0.005385073

Training iteration loss = 0.0024987103

Training iteration loss = 0.0027653992

Training iteration loss = 0.0024106114

Training iteration loss = 0.0027235087

Training iteration loss = 0.0022139524

Training iteration loss = 0.004085406

Training iteration loss = 0.0034191885

Training iteration loss = 0.0048893215

Training iteration loss = 0.0039258283

Training iteration loss = 0.0029419065

Training iteration loss = 0.0019812083

Training iteration loss = 0.0021145109

Training iteration loss = 0.008607679

Training iteration loss = 0.0030471825

Training iteration loss = 0.001796144

Training iteration loss = 0.004279363

Training iteration loss = 0.0037725593

Training iteration loss = 0.0033973297

Training iteration loss = 0.0029300991

Training iteration loss = 0.003957589

Training iteration loss = 0.002300737

Training iteration loss = 0.006607095

Training iteration loss = 0.0026065528

Training iteration loss = 0.0034285777

Training iteration loss = 0.0038483273

Training iteration loss = 0.0021248169

Training iteration loss = 0.0021415625

Training iteration loss = 0.0025738853

Training iteration loss = 0.0016703381

Training iteration loss = 0.0033466667

Training iteration loss = 0.0032208685

Training iteration loss = 0.0042127925

Training iteration loss = 0.0030487517

Training iteration loss = 0.0028143052

Training iteration loss = 0.0022656228

Training iteration loss = 0.002264323

Training iteration loss = 0.0023592308

Training iteration loss = 0.0031061436

Training iteration loss = 0.0047490825

Training iteration loss = 0.0018332083

Training iteration loss = 0.0030093763

Training iteration loss = 0.003090905

Training iteration loss = 0.0034033854

Training iteration loss = 0.0028561784

Training iteration loss = 0.003301559

Training iteration loss = 0.002772931

Training iteration loss = 0.0017932868

Training iteration loss = 0.0061182487

Training iteration loss = 0.0029708545

Training iteration loss = 0.0026112394

Training iteration loss = 0.0018484561

Training iteration loss = 0.0033989444

Training iteration loss = 0.0036812958

Training iteration loss = 0.0037108564

Training iteration loss = 0.0024129534

Training iteration loss = 0.005699719

Training iteration loss = 0.0031550343

Training iteration loss = 0.0023218372

Training iteration loss = 0.002086254

Training iteration loss = 0.0024956344

Training iteration loss = 0.0019667973

Training iteration loss = 0.003109429

Training iteration loss = 0.0018025074

Training iteration loss = 0.00206576

Training iteration loss = 0.003649044

Training iteration loss = 0.0028728612

Training iteration loss = 0.0033585413

Training iteration loss = 0.0025927734

Training iteration loss = 0.0040393025

Training iteration loss = 0.004140491

Training iteration loss = 0.004380368

Training iteration loss = 0.0020453718

Training iteration loss = 0.0028472955

Training iteration loss = 0.002427277

Training iteration loss = 0.0037384692

Training iteration loss = 0.0033979006

Training iteration loss = 0.00478504

Training iteration loss = 0.0029169687

Training iteration loss = 0.0024878841

Training iteration loss = 0.0031538696

Training iteration loss = 0.004765041

Training iteration loss = 0.003254557

Training iteration loss = 0.0027293304

Training iteration loss = 0.003305774

Training iteration loss = 0.0032227163

Training iteration loss = 0.002461396

Training iteration loss = 0.0025943327

Training iteration loss = 0.0036756257

Training iteration loss = 0.0030042715

Training iteration loss = 0.0031379852

Training iteration loss = 0.0027834133

Training iteration loss = 0.00232858

Training iteration loss = 0.0045202733

Training iteration loss = 0.004226264

Training iteration loss = 0.0038029074

Training iteration loss = 0.0037081623

Training iteration loss = 0.0022370424

Training iteration loss = 0.004505605

Training iteration loss = 0.005539754

Training iteration loss = 0.0024174748

Training iteration loss = 0.0033053674

Training iteration loss = 0.0023948487

Training iteration loss = 0.002656257

Training iteration loss = 0.002692744

Training iteration loss = 0.0024988381

Training iteration loss = 0.0049410737

Training iteration loss = 0.0057491288

Training iteration loss = 0.0025145991

Training iteration loss = 0.0028655084

Training iteration loss = 0.002193

Training iteration loss = 0.0026136665

Training iteration loss = 0.0033615187

Training iteration loss = 0.0032449558

Training iteration loss = 0.0036914775

Training iteration loss = 0.0022526013

Training iteration loss = 0.0035343857

Training iteration loss = 0.007216677

Training iteration loss = 0.004716964

Training iteration loss = 0.0037984026

Training iteration loss = 0.0029558418

Training iteration loss = 0.0034732304

Training iteration loss = 0.0026370028

Training iteration loss = 0.003363261

Training iteration loss = 0.0021247787

Training iteration loss = 0.0025806876

Training iteration loss = 0.0026071037

Training iteration loss = 0.0026774881

Training iteration loss = 0.0019977542

Training iteration loss = 0.0044704243

Training iteration loss = 0.0033223222

Training iteration loss = 0.0054033897

Training iteration loss = 0.0032063753

Training iteration loss = 0.0032186538

Training iteration loss = 0.0033944033

Training iteration loss = 0.006780947

Training iteration loss = 0.0040058536

Training iteration loss = 0.0034070052

Training iteration loss = 0.0025393188

Training iteration loss = 0.004954154

Training iteration loss = 0.002233414

Training iteration loss = 0.0024084728

Training iteration loss = 0.0029005501

Training iteration loss = 0.0036752203

Training iteration loss = 0.0029188234

Training iteration loss = 0.0039120764

Training iteration loss = 0.0035179083

Training iteration loss = 0.0019141585

Training iteration loss = 0.002511115

Training iteration loss = 0.0019368067

Training iteration loss = 0.0024336528

Training iteration loss = 0.0020173173

Training iteration loss = 0.002453137

Training iteration loss = 0.003399119

Training iteration loss = 0.003430641

Training iteration loss = 0.004515256

Training iteration loss = 0.0040351446

Training iteration loss = 0.004136856

Training iteration loss = 0.0021704396

Training iteration loss = 0.0030657602

Training iteration loss = 0.002249293

Training iteration loss = 0.0061180196

Training iteration loss = 0.0036265252

Training iteration loss = 0.0029416073

Training iteration loss = 0.0028568523

Training iteration loss = 0.003624851

Training iteration loss = 0.0071820784

Training iteration loss = 0.0023349558

Training iteration loss = 0.0036885217

Training iteration loss = 0.0036263028

Training iteration loss = 0.002335432

Training iteration loss = 0.003498743

Training iteration loss = 0.0037117654

Training iteration loss = 0.0027299442

Training iteration loss = 0.002554313

Training iteration loss = 0.0032425344

Training iteration loss = 0.0037935528

Training iteration loss = 0.0036355425

Training iteration loss = 0.004542642

Training iteration loss = 0.004766246

Training iteration loss = 0.003231164

Training iteration loss = 0.0036276218

Training iteration loss = 0.004323237

Training iteration loss = 0.004518567

Training iteration loss = 0.0028482925

Training iteration loss = 0.0036554981

Training iteration loss = 0.004080745

Training iteration loss = 0.0025475842

Training iteration loss = 0.0021495295

Training iteration loss = 0.00362017

Training iteration loss = 0.002442701

Training iteration loss = 0.002157715

Training iteration loss = 0.0030932662

Training iteration loss = 0.0022550893

Training iteration loss = 0.0018268198

Training iteration loss = 0.0018218035

Training iteration loss = 0.003101226

Training iteration loss = 0.0020703406

Training iteration loss = 0.0022706236

Training iteration loss = 0.0039818105

Training iteration loss = 0.005347643

Training iteration loss = 0.0024991257

Training iteration loss = 0.0027597488

Training iteration loss = 0.0024090302

Training iteration loss = 0.002708703

Training iteration loss = 0.0022194283

Training iteration loss = 0.004080622

Training iteration loss = 0.0034151704

Training iteration loss = 0.00489961

Training iteration loss = 0.0039238366

Training iteration loss = 0.0029363784

Training iteration loss = 0.0019803469

Training iteration loss = 0.0021104186

Training iteration loss = 0.008587195

Training iteration loss = 0.0030468404

Training iteration loss = 0.001790226

Training iteration loss = 0.004276225

Training iteration loss = 0.0037693672

Training iteration loss = 0.0033906568

Training iteration loss = 0.0029260572

Training iteration loss = 0.0039531705

Training iteration loss = 0.0023011903

Training iteration loss = 0.0066045

Training iteration loss = 0.0026043924

Training iteration loss = 0.0034245315

Training iteration loss = 0.0038341973

Training iteration loss = 0.0021162145

Training iteration loss = 0.0021397849

Training iteration loss = 0.0025660652

Training iteration loss = 0.0016657865

Training iteration loss = 0.0033343078

Training iteration loss = 0.0032054838

Training iteration loss = 0.0041978597

Training iteration loss = 0.003048539

Training iteration loss = 0.002810449

Training iteration loss = 0.002271678

Training iteration loss = 0.0022501852

Training iteration loss = 0.002359946

Training iteration loss = 0.0031132288

Training iteration loss = 0.004710125

Training iteration loss = 0.0018293407

Training iteration loss = 0.0029943802

Training iteration loss = 0.0030795636

Training iteration loss = 0.003397091

Training iteration loss = 0.0028597724

Training iteration loss = 0.003293698

Training iteration loss = 0.0027628595

Training iteration loss = 0.001788999

Training iteration loss = 0.0061110505

Training iteration loss = 0.002961947

Training iteration loss = 0.0026017067

Training iteration loss = 0.0018421548

Training iteration loss = 0.003384059

Training iteration loss = 0.003676313

Training iteration loss = 0.003704523

Training iteration loss = 0.0023983896

Training iteration loss = 0.0057073454

Training iteration loss = 0.0031440295

Training iteration loss = 0.002307723

Training iteration loss = 0.0020751264

Training iteration loss = 0.0024816843

Training iteration loss = 0.001965618

Training iteration loss = 0.003096728

Training iteration loss = 0.00178954

Training iteration loss = 0.0020496321

Training iteration loss = 0.0036452047

Training iteration loss = 0.0028619126

Training iteration loss = 0.0033659402

Training iteration loss = 0.0025960577

Training iteration loss = 0.004013061

Training iteration loss = 0.00413979

Training iteration loss = 0.0043642963

Training iteration loss = 0.0020408544

Training iteration loss = 0.0028467234

Training iteration loss = 0.0024284262

Training iteration loss = 0.003734896

Training iteration loss = 0.0033996142

Training iteration loss = 0.0047658053

Training iteration loss = 0.0029099525

Training iteration loss = 0.002478446

Training iteration loss = 0.0031460507

Training iteration loss = 0.0047634416

Training iteration loss = 0.0032507663

Training iteration loss = 0.0027244508

Training iteration loss = 0.0033009825

Training iteration loss = 0.0032196324

Training iteration loss = 0.0024519507

Training iteration loss = 0.002572934

Training iteration loss = 0.0036714089

Training iteration loss = 0.0030006208

Training iteration loss = 0.0031341137

Training iteration loss = 0.0027821122

Training iteration loss = 0.0023189317

Training iteration loss = 0.0045044473

Training iteration loss = 0.004199129

Training iteration loss = 0.0038114544

Training iteration loss = 0.0036976961

Training iteration loss = 0.0022321343

Training iteration loss = 0.004503725

Training iteration loss = 0.0055375746

Training iteration loss = 0.002411911

Training iteration loss = 0.0033034768

Training iteration loss = 0.0023929384

Training iteration loss = 0.002655208

Training iteration loss = 0.002690744

Training iteration loss = 0.0024929715

Training iteration loss = 0.004925883

Training iteration loss = 0.005729196

Training iteration loss = 0.002508859

Training iteration loss = 0.002861339

Training iteration loss = 0.0021888989

Training iteration loss = 0.0026119621

Training iteration loss = 0.0033594526

Training iteration loss = 0.0032374572

Training iteration loss = 0.0036872888

Training iteration loss = 0.0022555033

Training iteration loss = 0.003524353

Training iteration loss = 0.0072067925

Training iteration loss = 0.0047049336

Training iteration loss = 0.0037911031

Training iteration loss = 0.0029526409

Training iteration loss = 0.0034643428

Training iteration loss = 0.0026346997

Training iteration loss = 0.0033501226

Training iteration loss = 0.0021234583

Training iteration loss = 0.0025674722

Training iteration loss = 0.0026023635

Training iteration loss = 0.002657404

Training iteration loss = 0.0019915844

Training iteration loss = 0.0044714636

Training iteration loss = 0.003315782

Training iteration loss = 0.0053929877

Training iteration loss = 0.0032045662

Training iteration loss = 0.0032096587

Training iteration loss = 0.0033812746

Training iteration loss = 0.0067504123

Training iteration loss = 0.003996943

Training iteration loss = 0.0034075982

Training iteration loss = 0.0025419553

Training iteration loss = 0.004942781

Training iteration loss = 0.00222214

Training iteration loss = 0.002415125

Training iteration loss = 0.0028990668

Training iteration loss = 0.0036743535

Training iteration loss = 0.0029106343

Training iteration loss = 0.0038942175

Training iteration loss = 0.0035033785

Training iteration loss = 0.0019190251

Training iteration loss = 0.0025161814

Training iteration loss = 0.0019430914

Training iteration loss = 0.0024402847

Training iteration loss = 0.0020303691

Training iteration loss = 0.0024665797

Training iteration loss = 0.0033921394

Training iteration loss = 0.003431055

Training iteration loss = 0.0045259013

Training iteration loss = 0.0040384014

Training iteration loss = 0.00412209

Training iteration loss = 0.0021679907

Training iteration loss = 0.00305527

Training iteration loss = 0.0022390385

Training iteration loss = 0.0060874666

Training iteration loss = 0.0036159449

Training iteration loss = 0.002935163

Training iteration loss = 0.0028570613

Training iteration loss = 0.0036213205

Training iteration loss = 0.0071533695

Training iteration loss = 0.0023257483

Training iteration loss = 0.003667527

Training iteration loss = 0.003622518

Training iteration loss = 0.0023239183

Training iteration loss = 0.0034968846

Training iteration loss = 0.0037087724

Training iteration loss = 0.0027257064

Training iteration loss = 0.002557486

Training iteration loss = 0.0032368256

Training iteration loss = 0.0037779452

Training iteration loss = 0.0036198264

Training iteration loss = 0.0045046927

Training iteration loss = 0.004767287

Training iteration loss = 0.003227464

Training iteration loss = 0.003644582

Training iteration loss = 0.004300437

Training iteration loss = 0.0045151873

Training iteration loss = 0.002844517

Training iteration loss = 0.0036535996

Training iteration loss = 0.004087529

Training iteration loss = 0.0025493882

Training iteration loss = 0.0021516096

Training iteration loss = 0.0036136878

Training iteration loss = 0.0024411634

Training iteration loss = 0.0021495125

Training iteration loss = 0.003094481

Training iteration loss = 0.0022549867

Training iteration loss = 0.0018179944

Training iteration loss = 0.0018285345

Training iteration loss = 0.0031048607

Training iteration loss = 0.0020739876

Training iteration loss = 0.0022689803

Training iteration loss = 0.003970738

Training iteration loss = 0.005336491

Training iteration loss = 0.00249599

Training iteration loss = 0.0027487369

Training iteration loss = 0.0023984576

Training iteration loss = 0.002693518

Training iteration loss = 0.002225196

Training iteration loss = 0.004068719

Training iteration loss = 0.0034079375

Training iteration loss = 0.0049007083

Training iteration loss = 0.003925625

Training iteration loss = 0.0029282828

Training iteration loss = 0.0019758577

Training iteration loss = 0.0021054212

Training iteration loss = 0.008566775

Training iteration loss = 0.0030436143

Training iteration loss = 0.0017844609

Training iteration loss = 0.004281696

Training iteration loss = 0.0037640894

Training iteration loss = 0.0033854786

Training iteration loss = 0.002922828

Training iteration loss = 0.003952414

Training iteration loss = 0.0023081512

Training iteration loss = 0.00657347

Training iteration loss = 0.0025973765

Training iteration loss = 0.0034212135

Training iteration loss = 0.0038205932

Training iteration loss = 0.0021106515

Training iteration loss = 0.0021411423

Training iteration loss = 0.0025691134

Training iteration loss = 0.0016654885

Training iteration loss = 0.003335172

Training iteration loss = 0.0031971459

Training iteration loss = 0.0041861976

Training iteration loss = 0.0030466367

Training iteration loss = 0.0028073175

Training iteration loss = 0.0022778541

Training iteration loss = 0.0022401381

Training iteration loss = 0.0023604163

Training iteration loss = 0.003111834

Training iteration loss = 0.0047085397

Training iteration loss = 0.0018265652

Training iteration loss = 0.0029939965

Training iteration loss = 0.003076784

Training iteration loss = 0.0033910435

Training iteration loss = 0.0028567726

Training iteration loss = 0.0032881927

Training iteration loss = 0.002757812

Training iteration loss = 0.0017869839

Training iteration loss = 0.00609535

Training iteration loss = 0.0029594582

Training iteration loss = 0.0025997737

Training iteration loss = 0.0018392891

Training iteration loss = 0.003372871

Training iteration loss = 0.0036628714

Training iteration loss = 0.0036936959

Training iteration loss = 0.0023904876

Training iteration loss = 0.0057039857

Training iteration loss = 0.0031431105

Training iteration loss = 0.0023100877

Training iteration loss = 0.0020816787

Training iteration loss = 0.0024837742

Training iteration loss = 0.0019639346

Training iteration loss = 0.003082569

Training iteration loss = 0.0017878348

Training iteration loss = 0.0020439227

Training iteration loss = 0.0036354475

Training iteration loss = 0.0028481882

Training iteration loss = 0.0033463854

Training iteration loss = 0.0025913883

Training iteration loss = 0.0040175617

Training iteration loss = 0.0041486756

Training iteration loss = 0.004364161

Training iteration loss = 0.0020305552

Training iteration loss = 0.0028374156

Training iteration loss = 0.002416243

Training iteration loss = 0.0037179755

Training iteration loss = 0.00339715

Training iteration loss = 0.004748587

Training iteration loss = 0.0029102063

Training iteration loss = 0.0024785239

Training iteration loss = 0.0031545789

Training iteration loss = 0.0047466187

Training iteration loss = 0.0032420205

Training iteration loss = 0.002724536

Training iteration loss = 0.0032927098

Training iteration loss = 0.0032080961

Training iteration loss = 0.002451634

Training iteration loss = 0.0025588262

Training iteration loss = 0.0036689697

Training iteration loss = 0.0029977106

Training iteration loss = 0.0031273144

Training iteration loss = 0.002777031

Training iteration loss = 0.002318423

Training iteration loss = 0.0045053526

Training iteration loss = 0.0041992944

Training iteration loss = 0.0038046117

Training iteration loss = 0.0037037956

Training iteration loss = 0.0022274205

Training iteration loss = 0.0044895806

Training iteration loss = 0.0055336836

Training iteration loss = 0.0024085583

Training iteration loss = 0.0032921506

Training iteration loss = 0.0023894047

Training iteration loss = 0.002660462

Training iteration loss = 0.0026899327

Training iteration loss = 0.0024865733

Training iteration loss = 0.0049119606

Training iteration loss = 0.0057064234

Training iteration loss = 0.0025093185

Training iteration loss = 0.002855813

Training iteration loss = 0.0021898854

Training iteration loss = 0.0026097812

Training iteration loss = 0.003353746

Training iteration loss = 0.003231869

Training iteration loss = 0.0036850898

Training iteration loss = 0.0022537152

Training iteration loss = 0.0035203137

Training iteration loss = 0.007195515

Training iteration loss = 0.0046941196

Training iteration loss = 0.0037826046

Training iteration loss = 0.0029497577

Training iteration loss = 0.0034566056

Training iteration loss = 0.002638786

Training iteration loss = 0.003345498

Training iteration loss = 0.0021239365

Training iteration loss = 0.0025560441

Training iteration loss = 0.002598724

Training iteration loss = 0.0026476244

Training iteration loss = 0.0019877201

Training iteration loss = 0.0044761053

Training iteration loss = 0.003306644

Training iteration loss = 0.0053846887

Training iteration loss = 0.003212706

Training iteration loss = 0.0032089388

Training iteration loss = 0.0033728064

Training iteration loss = 0.006723136

Training iteration loss = 0.003982987

Training iteration loss = 0.003409951

Training iteration loss = 0.0025437365

Training iteration loss = 0.0049217376

Training iteration loss = 0.0022126795

Training iteration loss = 0.002416898

Training iteration loss = 0.002908008

Training iteration loss = 0.0036803384

Training iteration loss = 0.0029033215

Training iteration loss = 0.0038853744

Training iteration loss = 0.0034876845

Training iteration loss = 0.0019196924

Training iteration loss = 0.0025110343

Training iteration loss = 0.0019450979

Training iteration loss = 0.002438729

Training iteration loss = 0.0020234273

Training iteration loss = 0.0024616832

Training iteration loss = 0.0033974138

Training iteration loss = 0.003427513

Training iteration loss = 0.0045264796

Training iteration loss = 0.0040435526

Training iteration loss = 0.004109954

Training iteration loss = 0.0021664028

Training iteration loss = 0.003047457

Training iteration loss = 0.0022348196

Training iteration loss = 0.006067624

Training iteration loss = 0.0036079865

Training iteration loss = 0.0029349988

Training iteration loss = 0.0028604663

Training iteration loss = 0.003624253

Training iteration loss = 0.007111745

Training iteration loss = 0.002324774

Training iteration loss = 0.0036554628

Training iteration loss = 0.003627331

Training iteration loss = 0.0023338979

Training iteration loss = 0.0035053445

Training iteration loss = 0.0037110513

Training iteration loss = 0.0027262245

Training iteration loss = 0.0025459966

Training iteration loss = 0.0032210648

Training iteration loss = 0.003762203

Training iteration loss = 0.00360414

Training iteration loss = 0.004508565

Training iteration loss = 0.0047504134

Training iteration loss = 0.003232519

Training iteration loss = 0.0036338437

Training iteration loss = 0.004280551

Training iteration loss = 0.004493181

Training iteration loss = 0.0028363094

Training iteration loss = 0.0036461481

Training iteration loss = 0.004087563

Training iteration loss = 0.002550353

Training iteration loss = 0.002143792

Training iteration loss = 0.003615617

Training iteration loss = 0.0024296104

Training iteration loss = 0.002143061

Training iteration loss = 0.0030883588

Training iteration loss = 0.0022576172

Training iteration loss = 0.0018120784

Training iteration loss = 0.0018272876

Training iteration loss = 0.0031020641

Training iteration loss = 0.002065629

Training iteration loss = 0.0022676585

Training iteration loss = 0.0039617936

Training iteration loss = 0.0053134835

Training iteration loss = 0.0024928085

Training iteration loss = 0.0027446493

Training iteration loss = 0.0023966094

Training iteration loss = 0.002680215

Training iteration loss = 0.0022233727

Training iteration loss = 0.004060753

Training iteration loss = 0.0034018287

Training iteration loss = 0.0049080956

Training iteration loss = 0.0039171134

Training iteration loss = 0.0029270325

Training iteration loss = 0.0019744944

Training iteration loss = 0.0021063797

Training iteration loss = 0.008548048

Training iteration loss = 0.0030415182

Training iteration loss = 0.0017933366

Training iteration loss = 0.00427572

Training iteration loss = 0.0037605518

Training iteration loss = 0.0033829908

Training iteration loss = 0.0029197617

Training iteration loss = 0.003948148

Training iteration loss = 0.0022989567

Training iteration loss = 0.0065627284

Training iteration loss = 0.0025953886

Training iteration loss = 0.0034221755

Training iteration loss = 0.0038098504

Training iteration loss = 0.0021057713

Training iteration loss = 0.0021325285

Training iteration loss = 0.0025632484

Training iteration loss = 0.0016583909

Training iteration loss = 0.0033297858

Training iteration loss = 0.0031972567

Training iteration loss = 0.004181308

Training iteration loss = 0.003046692

Training iteration loss = 0.0028021575

Training iteration loss = 0.0022841918

Training iteration loss = 0.002237888

Training iteration loss = 0.0023503082

Training iteration loss = 0.003112682

Training iteration loss = 0.004694455

Training iteration loss = 0.001822064

Training iteration loss = 0.002995043

Training iteration loss = 0.0030772788

Training iteration loss = 0.0033875948

Training iteration loss = 0.0028527456

Training iteration loss = 0.0032838713

Training iteration loss = 0.0027547737

Training iteration loss = 0.0017846021

Training iteration loss = 0.006086853

Training iteration loss = 0.0029619734

Training iteration loss = 0.0025985693

Training iteration loss = 0.001838685

Training iteration loss = 0.0033620512

Training iteration loss = 0.0036625313

Training iteration loss = 0.003687796

Training iteration loss = 0.0023843658

Training iteration loss = 0.0056868778

Training iteration loss = 0.0031381526

Training iteration loss = 0.002303918

Training iteration loss = 0.0020818394

Training iteration loss = 0.0024761788

Training iteration loss = 0.0019648075

Training iteration loss = 0.003071728

Training iteration loss = 0.0017845989

Training iteration loss = 0.0020415874

Training iteration loss = 0.0036370931

Training iteration loss = 0.002836256

Training iteration loss = 0.0033480234

Training iteration loss = 0.0025919

Training iteration loss = 0.003998609

Training iteration loss = 0.004143678

Training iteration loss = 0.0043476657

Training iteration loss = 0.0020284378

Training iteration loss = 0.0028340751

Training iteration loss = 0.0024195495

Training iteration loss = 0.0037196681

Training iteration loss = 0.0033931176

Training iteration loss = 0.0047371145

Training iteration loss = 0.00290477

Training iteration loss = 0.0024702952

Training iteration loss = 0.0031523611

Training iteration loss = 0.0047450517

Training iteration loss = 0.0032368947

Training iteration loss = 0.0027204573

Training iteration loss = 0.0032903906

Training iteration loss = 0.0032030006

Training iteration loss = 0.0024415464

Training iteration loss = 0.0025462273

Training iteration loss = 0.0036666675

Training iteration loss = 0.0029973865

Training iteration loss = 0.0031231164

Training iteration loss = 0.0027749396

Training iteration loss = 0.0023108225

Training iteration loss = 0.004494149

Training iteration loss = 0.00417325

Training iteration loss = 0.003812772

Training iteration loss = 0.0036932987

Training iteration loss = 0.0022237708

Training iteration loss = 0.004488883

Training iteration loss = 0.0055331415

Training iteration loss = 0.0024037443

Training iteration loss = 0.0032918125

Training iteration loss = 0.0023874342

Training iteration loss = 0.0026588126

Training iteration loss = 0.0026877534

Training iteration loss = 0.0024833146

Training iteration loss = 0.0048944806

Training iteration loss = 0.0056867595

Training iteration loss = 0.0025067541

Training iteration loss = 0.0028515363

Training iteration loss = 0.0021868446

Training iteration loss = 0.0026062925

Training iteration loss = 0.0033527936

Training iteration loss = 0.0032251289

Training iteration loss = 0.00367989

Training iteration loss = 0.0022581576

Training iteration loss = 0.003511743

Training iteration loss = 0.0071745533

Training iteration loss = 0.0046849116

Training iteration loss = 0.003774831

Training iteration loss = 0.0029477037

Training iteration loss = 0.0034512223

Training iteration loss = 0.0026385935

Training iteration loss = 0.0033365472

Training iteration loss = 0.0021230706

Training iteration loss = 0.00254775

Training iteration loss = 0.002598176

Training iteration loss = 0.0026366499

Training iteration loss = 0.001985615

Training iteration loss = 0.004477626

Training iteration loss = 0.0033024976

Training iteration loss = 0.0053767837

Training iteration loss = 0.0032133441

Training iteration loss = 0.0032011804

Training iteration loss = 0.0033657448

Training iteration loss = 0.0066952356

Training iteration loss = 0.0039755334

Training iteration loss = 0.003409231

Training iteration loss = 0.0025433137

Training iteration loss = 0.004907588

Training iteration loss = 0.0022042694

Training iteration loss = 0.0024202392

Training iteration loss = 0.0029090329

Training iteration loss = 0.003680927

Training iteration loss = 0.002895327

Training iteration loss = 0.0038717578

Training iteration loss = 0.0034747384

Training iteration loss = 0.0019200497

Training iteration loss = 0.0025095332

Training iteration loss = 0.0019465677

Training iteration loss = 0.0024410787

Training iteration loss = 0.0020270566

Training iteration loss = 0.00247069

Training iteration loss = 0.0033924577

Training iteration loss = 0.0034283567

Training iteration loss = 0.004532613

Training iteration loss = 0.0040458613

Training iteration loss = 0.0041036773

Training iteration loss = 0.0021638076

Training iteration loss = 0.0030379137

Training iteration loss = 0.0022272218

Training iteration loss = 0.0060584196

Training iteration loss = 0.0036075078

Training iteration loss = 0.002932164

Training iteration loss = 0.0028590614

Training iteration loss = 0.0036192557

Training iteration loss = 0.007097168

Training iteration loss = 0.0023211099

Training iteration loss = 0.0036440864

Training iteration loss = 0.0036224585

Training iteration loss = 0.0023277304

Training iteration loss = 0.0035023037

Training iteration loss = 0.0037095677

Training iteration loss = 0.002723908

Training iteration loss = 0.0025490753

Training iteration loss = 0.0032143702

Training iteration loss = 0.0037545057

Training iteration loss = 0.003599916

Training iteration loss = 0.0045089344

Training iteration loss = 0.0047385055

Training iteration loss = 0.0032301638

Training iteration loss = 0.0036352044

Training iteration loss = 0.004273739

Training iteration loss = 0.0044846945

Training iteration loss = 0.002836705

Training iteration loss = 0.0036440918

Training iteration loss = 0.0040772134

Training iteration loss = 0.0025490106

Training iteration loss = 0.0021412603

Training iteration loss = 0.0036185768

Training iteration loss = 0.0024280865

Training iteration loss = 0.0021385108

Training iteration loss = 0.0030801783

Training iteration loss = 0.002259263

Training iteration loss = 0.0018061805

Training iteration loss = 0.001826434

Training iteration loss = 0.003102355

Training iteration loss = 0.002063302

Training iteration loss = 0.0022703581

Training iteration loss = 0.0039566844

Training iteration loss = 0.005293676

Training iteration loss = 0.0024943429

Training iteration loss = 0.0027412332

Training iteration loss = 0.0023882864

Training iteration loss = 0.0026675065

Training iteration loss = 0.0022296305

Training iteration loss = 0.0040520728

Training iteration loss = 0.0033947602

Training iteration loss = 0.004914153

Training iteration loss = 0.0039102254

Training iteration loss = 0.0029286107

Training iteration loss = 0.0019763268

Training iteration loss = 0.0021051525

Training iteration loss = 0.008531351

Training iteration loss = 0.003032827

Training iteration loss = 0.0017936818

Training iteration loss = 0.0042731874

Training iteration loss = 0.0037594351

Training iteration loss = 0.0033779393

Training iteration loss = 0.0029165093

Training iteration loss = 0.0039455993

Training iteration loss = 0.002293662

Training iteration loss = 0.0065671224

Training iteration loss = 0.0025982596

Training iteration loss = 0.0034223946

Training iteration loss = 0.0038022418

Training iteration loss = 0.0021062575

Training iteration loss = 0.0021288013

Training iteration loss = 0.0025643613

Training iteration loss = 0.0016526437

Training iteration loss = 0.003322569

Training iteration loss = 0.003192155

Training iteration loss = 0.004171607

Training iteration loss = 0.0030483576

Training iteration loss = 0.002801459

Training iteration loss = 0.0022885331

Training iteration loss = 0.0022340782

Training iteration loss = 0.0023467357

Training iteration loss = 0.0031169544

Training iteration loss = 0.0046778168

Training iteration loss = 0.0018187496

Training iteration loss = 0.0029915806

Training iteration loss = 0.0030756805

Training iteration loss = 0.0033831627

Training iteration loss = 0.0028545503

Training iteration loss = 0.0032793188

Training iteration loss = 0.002754665

Training iteration loss = 0.0017834591

Training iteration loss = 0.00607609

Training iteration loss = 0.0029589206

Training iteration loss = 0.0025938672

Training iteration loss = 0.0018365438

Training iteration loss = 0.0033515224

Training iteration loss = 0.0036606751

Training iteration loss = 0.0036846881

Training iteration loss = 0.002378492

Training iteration loss = 0.005690564

Training iteration loss = 0.0031320064

Training iteration loss = 0.0022978547

Training iteration loss = 0.002074525

Training iteration loss = 0.0024670402

Training iteration loss = 0.0019620117

Training iteration loss = 0.0030609893

Training iteration loss = 0.0017784574

Training iteration loss = 0.0020373084

Training iteration loss = 0.0036381409

Training iteration loss = 0.0028273806

Training iteration loss = 0.0033433093

Training iteration loss = 0.0025970575

Training iteration loss = 0.003984446

Training iteration loss = 0.0041432264

Training iteration loss = 0.0043386277

Training iteration loss = 0.0020231348

Training iteration loss = 0.0028349634

Training iteration loss = 0.0024140486

Training iteration loss = 0.0037096746

Training iteration loss = 0.0033943898

Training iteration loss = 0.004718823

Training iteration loss = 0.002899346

Training iteration loss = 0.0024636695

Training iteration loss = 0.0031527586

Training iteration loss = 0.0047397423

Training iteration loss = 0.0032329655

Training iteration loss = 0.0027178947

Training iteration loss = 0.0032895405

Training iteration loss = 0.0032041084

Training iteration loss = 0.002437486

Training iteration loss = 0.0025323739

Training iteration loss = 0.0036650065

Training iteration loss = 0.002988468

Training iteration loss = 0.0031186284

Training iteration loss = 0.0027711575

Training iteration loss = 0.0023058108

Training iteration loss = 0.0044829985

Training iteration loss = 0.0041583623

Training iteration loss = 0.0038132172

Training iteration loss = 0.00369181

Training iteration loss = 0.002219028

Training iteration loss = 0.0044829734

Training iteration loss = 0.0055275685

Training iteration loss = 0.0023996208

Training iteration loss = 0.0032802273

Training iteration loss = 0.002383333

Training iteration loss = 0.0026557464

Training iteration loss = 0.0026863927

Training iteration loss = 0.002476325

Training iteration loss = 0.0048815724

Training iteration loss = 0.00566488

Training iteration loss = 0.0025020458

Training iteration loss = 0.0028491737

Training iteration loss = 0.0021851717

Training iteration loss = 0.0026043542

Training iteration loss = 0.0033495855

Training iteration loss = 0.003220435

Training iteration loss = 0.0036769116

Training iteration loss = 0.002260812

Training iteration loss = 0.0035068973

Training iteration loss = 0.0071766204

Training iteration loss = 0.0046752635

Training iteration loss = 0.0037662548

Training iteration loss = 0.002944975

Training iteration loss = 0.0034453243

Training iteration loss = 0.0026407272

Training iteration loss = 0.0033275473

Training iteration loss = 0.002122489

Training iteration loss = 0.002540295

Training iteration loss = 0.0025935362

Training iteration loss = 0.0026210267

Training iteration loss = 0.001981797

Training iteration loss = 0.004478954

Training iteration loss = 0.0032970284

Training iteration loss = 0.005369581

Training iteration loss = 0.0032152107

Training iteration loss = 0.003196765

Training iteration loss = 0.0033700578

Training iteration loss = 0.0066687907

Training iteration loss = 0.003963346

Training iteration loss = 0.003411116

Training iteration loss = 0.0025416643

Training iteration loss = 0.0048754155

Training iteration loss = 0.0021954537

Training iteration loss = 0.002422082

Training iteration loss = 0.0029166508

Training iteration loss = 0.0036815498

Training iteration loss = 0.00288593

Training iteration loss = 0.0038648627

Training iteration loss = 0.0034615388

Training iteration loss = 0.001913536

Training iteration loss = 0.0025036177

Training iteration loss = 0.0019481651

Training iteration loss = 0.0024395818

Training iteration loss = 0.0020188193

Training iteration loss = 0.002465131

Training iteration loss = 0.0033870668

Training iteration loss = 0.003421489

Training iteration loss = 0.004531057

Training iteration loss = 0.004056569

Training iteration loss = 0.004079969

Training iteration loss = 0.0021640577

Training iteration loss = 0.0030298708

Training iteration loss = 0.0022292954

Training iteration loss = 0.006065134

Training iteration loss = 0.0036067704

Training iteration loss = 0.0029269226

Training iteration loss = 0.0028553568

Training iteration loss = 0.0036207081

Training iteration loss = 0.0070969486

Training iteration loss = 0.0023204242

Training iteration loss = 0.0036327431

Training iteration loss = 0.0036059376

Training iteration loss = 0.0023181573

Training iteration loss = 0.0034966366

Training iteration loss = 0.0037033253

Training iteration loss = 0.0027220452

Training iteration loss = 0.0025544313

Training iteration loss = 0.0032155132

Training iteration loss = 0.0037487212

Training iteration loss = 0.0036028847

Training iteration loss = 0.0044944044

Training iteration loss = 0.0047377106

Training iteration loss = 0.0032314444

Training iteration loss = 0.0036357192

Training iteration loss = 0.004272519

Training iteration loss = 0.00446994

Training iteration loss = 0.002834387

Training iteration loss = 0.003629855

Training iteration loss = 0.004071426

Training iteration loss = 0.0025447102

Training iteration loss = 0.0021442159

Training iteration loss = 0.0036221172

Training iteration loss = 0.0024459793

Training iteration loss = 0.0021292137

Training iteration loss = 0.0030615665

Training iteration loss = 0.0022483224

Training iteration loss = 0.0018005102

Training iteration loss = 0.0018291413

Training iteration loss = 0.0031117203

Training iteration loss = 0.0020753567

Training iteration loss = 0.0022767729

Training iteration loss = 0.0039502927

Training iteration loss = 0.0052789133

Training iteration loss = 0.0024953915

Training iteration loss = 0.0027272024

Training iteration loss = 0.0023828868

Training iteration loss = 0.0026642994

Training iteration loss = 0.002238359

Training iteration loss = 0.004046858

Training iteration loss = 0.0033884626

Training iteration loss = 0.0049207117

Training iteration loss = 0.0039084866

Training iteration loss = 0.0029200364

Training iteration loss = 0.0019715326

Training iteration loss = 0.002096773

Training iteration loss = 0.008527571

Training iteration loss = 0.0030442458

Training iteration loss = 0.0017762012

Training iteration loss = 0.004289442

Training iteration loss = 0.0037530425

Training iteration loss = 0.003372237

Training iteration loss = 0.0029109754

Training iteration loss = 0.0039426954

Training iteration loss = 0.0022991516

Training iteration loss = 0.006553775

Training iteration loss = 0.0025932463

Training iteration loss = 0.0034132127

Training iteration loss = 0.0037861771

Training iteration loss = 0.0020985617

Training iteration loss = 0.0021275065

Training iteration loss = 0.0025642316

Training iteration loss = 0.0016489137

Training iteration loss = 0.0033169724

Training iteration loss = 0.003186655

Training iteration loss = 0.004165583

Training iteration loss = 0.00305131

Training iteration loss = 0.002794123

Training iteration loss = 0.0022932536

Training iteration loss = 0.0022289006

Training iteration loss = 0.002346359

Training iteration loss = 0.0031131022

Training iteration loss = 0.0046653426

Training iteration loss = 0.0018167933

Training iteration loss = 0.0029915927

Training iteration loss = 0.003074602

Training iteration loss = 0.0033768474

Training iteration loss = 0.0028513204

Training iteration loss = 0.0032753025

Training iteration loss = 0.0027533525

Training iteration loss = 0.0017828558

Training iteration loss = 0.006058308

Training iteration loss = 0.002958903

Training iteration loss = 0.0025888144

Training iteration loss = 0.0018340494

Training iteration loss = 0.0033404445

Training iteration loss = 0.00365603

Training iteration loss = 0.003680146

Training iteration loss = 0.0023743447

Training iteration loss = 0.005686937

Training iteration loss = 0.0031232473

Training iteration loss = 0.002294203

Training iteration loss = 0.0020728572

Training iteration loss = 0.0024593214

Training iteration loss = 0.0019652445

Training iteration loss = 0.0030520388

Training iteration loss = 0.0017782928

Training iteration loss = 0.002032379

Training iteration loss = 0.0036295827

Training iteration loss = 0.0028254632

Training iteration loss = 0.0033403889

Training iteration loss = 0.0025924896

Training iteration loss = 0.003984428

Training iteration loss = 0.004145262

Training iteration loss = 0.004317639

Training iteration loss = 0.0020178421

Training iteration loss = 0.002828115

Training iteration loss = 0.00241415

Training iteration loss = 0.0037065141

Training iteration loss = 0.003388159

Training iteration loss = 0.004708834

Training iteration loss = 0.002896875

Training iteration loss = 0.0024595752

Training iteration loss = 0.003156948

Training iteration loss = 0.0047311443

Training iteration loss = 0.00322784

Training iteration loss = 0.0027182915

Training iteration loss = 0.003284848

Training iteration loss = 0.0031923663

Training iteration loss = 0.0024376207

Training iteration loss = 0.0025232756

Training iteration loss = 0.0036641045

Training iteration loss = 0.0029929394

Training iteration loss = 0.0031143127

Training iteration loss = 0.00276912

Training iteration loss = 0.0023033319

Training iteration loss = 0.0044803033

Training iteration loss = 0.0041616545

Training iteration loss = 0.0038135534

Training iteration loss = 0.0036942225

Training iteration loss = 0.0022163356

Training iteration loss = 0.00447583

Training iteration loss = 0.0055327476

Training iteration loss = 0.0023980236

Training iteration loss = 0.003272552

Training iteration loss = 0.0023796863

Training iteration loss = 0.0026598808

Training iteration loss = 0.0026852211

Training iteration loss = 0.0024705057

Training iteration loss = 0.0048716725

Training iteration loss = 0.005654637

Training iteration loss = 0.0025007352

Training iteration loss = 0.0028461907

Training iteration loss = 0.0021864779

Training iteration loss = 0.002601632

Training iteration loss = 0.0033475012

Training iteration loss = 0.003217079

Training iteration loss = 0.0036739956

Training iteration loss = 0.0022651919

Training iteration loss = 0.0035075303

Training iteration loss = 0.0071661356

Training iteration loss = 0.0046634884

Training iteration loss = 0.0037621402

Training iteration loss = 0.0029441987

Training iteration loss = 0.0034406949

Training iteration loss = 0.0026407957

Training iteration loss = 0.0033218774

Training iteration loss = 0.0021241335

Training iteration loss = 0.00253343

Training iteration loss = 0.0025912998

Training iteration loss = 0.002603216

Training iteration loss = 0.0019759156

Training iteration loss = 0.0044818018

Training iteration loss = 0.0032872132

Training iteration loss = 0.00536597

Training iteration loss = 0.0032205274

Training iteration loss = 0.0031922853

Training iteration loss = 0.0033425468

Training iteration loss = 0.0066495948

Training iteration loss = 0.003952164

Training iteration loss = 0.0034127163

Training iteration loss = 0.002547213

Training iteration loss = 0.004871977

Training iteration loss = 0.0021906255

Training iteration loss = 0.0024258923

Training iteration loss = 0.002913994

Training iteration loss = 0.0036783572

Training iteration loss = 0.0028864378

Training iteration loss = 0.003858476

Training iteration loss = 0.0034548957

Training iteration loss = 0.0019164808

Training iteration loss = 0.0025010577

Training iteration loss = 0.0019537457

Training iteration loss = 0.0024463667

Training iteration loss = 0.002025784

Training iteration loss = 0.0024657582

Training iteration loss = 0.0033896044

Training iteration loss = 0.0034287218

Training iteration loss = 0.004537422

Training iteration loss = 0.0040581287

Training iteration loss = 0.0040820776

Training iteration loss = 0.002159172

Training iteration loss = 0.003023783

Training iteration loss = 0.0022218423

Training iteration loss = 0.0060413345

Training iteration loss = 0.0036009671

Training iteration loss = 0.002926196

Training iteration loss = 0.0028538543

Training iteration loss = 0.0036120582

Training iteration loss = 0.0070698913

Training iteration loss = 0.002317127

Training iteration loss = 0.0036219049

Training iteration loss = 0.0036063946

Training iteration loss = 0.0023139229

Training iteration loss = 0.0034948708

Training iteration loss = 0.0037047837

Training iteration loss = 0.0027171324

Training iteration loss = 0.0025467013

Training iteration loss = 0.0032056372

Training iteration loss = 0.003735528

Training iteration loss = 0.0035863463

Training iteration loss = 0.004473478

Training iteration loss = 0.0047265706

Training iteration loss = 0.0032235868

Training iteration loss = 0.0036380098

Training iteration loss = 0.0042572375

Training iteration loss = 0.004462595

Training iteration loss = 0.0028304243

Training iteration loss = 0.0036338915

Training iteration loss = 0.004067763

Training iteration loss = 0.0025457067

Training iteration loss = 0.0021384668

Training iteration loss = 0.0036187537

Training iteration loss = 0.0024351433

Training iteration loss = 0.00212748

Training iteration loss = 0.0030649109

Training iteration loss = 0.002249025

Training iteration loss = 0.0017948196

Training iteration loss = 0.0018331333

Training iteration loss = 0.0031098665

Training iteration loss = 0.0020730228

Training iteration loss = 0.0022714082

Training iteration loss = 0.00394028

Training iteration loss = 0.0052569583

Training iteration loss = 0.0024918187

Training iteration loss = 0.0027258915

Training iteration loss = 0.00237827

Training iteration loss = 0.0026536174

Training iteration loss = 0.002236181

Training iteration loss = 0.0040398757

Training iteration loss = 0.0033839887

Training iteration loss = 0.004925286

Training iteration loss = 0.003907956

Training iteration loss = 0.0029145975

Training iteration loss = 0.0019713503

Training iteration loss = 0.0020985974

Training iteration loss = 0.008497494

Training iteration loss = 0.0030303935

Training iteration loss = 0.0017901531

Training iteration loss = 0.004278124

Training iteration loss = 0.0037552796

Training iteration loss = 0.0033719323

Training iteration loss = 0.0029059183

Training iteration loss = 0.003940799

Training iteration loss = 0.0022904377

Training iteration loss = 0.006546928

Training iteration loss = 0.0025931445

Training iteration loss = 0.0034142227

Training iteration loss = 0.0037829895

Training iteration loss = 0.0020951033

Training iteration loss = 0.0021238409

Training iteration loss = 0.002565655

Training iteration loss = 0.0016466015

Training iteration loss = 0.0033121537

Training iteration loss = 0.003181508

Training iteration loss = 0.0041601234

Training iteration loss = 0.0030524556

Training iteration loss = 0.0027862096

Training iteration loss = 0.002298494

Training iteration loss = 0.0022289709

Training iteration loss = 0.0023448889

Training iteration loss = 0.0031117909

Training iteration loss = 0.0046651424

Training iteration loss = 0.0018157894

Training iteration loss = 0.0029944712

Training iteration loss = 0.003079825

Training iteration loss = 0.003373386

Training iteration loss = 0.0028488934

Training iteration loss = 0.00327282

Training iteration loss = 0.0027559493

Training iteration loss = 0.0017844145

Training iteration loss = 0.0060587395

Training iteration loss = 0.002959175

Training iteration loss = 0.002590773

Training iteration loss = 0.0018264651

Training iteration loss = 0.0033290256

Training iteration loss = 0.0036527587

Training iteration loss = 0.0036742922

Training iteration loss = 0.0023706495

Training iteration loss = 0.005690096

Training iteration loss = 0.003119075

Training iteration loss = 0.0022946869

Training iteration loss = 0.0020745657

Training iteration loss = 0.0024624802

Training iteration loss = 0.0019634739

Training iteration loss = 0.0030421836

Training iteration loss = 0.0017733108

Training iteration loss = 0.0020316083

Training iteration loss = 0.003630625

Training iteration loss = 0.002811567

Training iteration loss = 0.003331693

Training iteration loss = 0.0025891743

Training iteration loss = 0.0039772238

Training iteration loss = 0.0041412846

Training iteration loss = 0.004304247

Training iteration loss = 0.002019699

Training iteration loss = 0.002831056

Training iteration loss = 0.002413124

Training iteration loss = 0.0037049947

Training iteration loss = 0.0033868502

Training iteration loss = 0.004694513

Training iteration loss = 0.002891049

Training iteration loss = 0.0024556073

Training iteration loss = 0.0031590378

Training iteration loss = 0.0047291345

Training iteration loss = 0.0032253752

Training iteration loss = 0.0027128998

Training iteration loss = 0.0032810064

Training iteration loss = 0.0031874392

Training iteration loss = 0.0024282655

Training iteration loss = 0.002512522

Training iteration loss = 0.0036622004

Training iteration loss = 0.0029848388

Training iteration loss = 0.00311009

Training iteration loss = 0.0027677005

Training iteration loss = 0.002295622

Training iteration loss = 0.0044696126

Training iteration loss = 0.0041307914

Training iteration loss = 0.0038186682

Training iteration loss = 0.0036803707

Training iteration loss = 0.0022133247

Training iteration loss = 0.0044820015

Training iteration loss = 0.0055301753

Training iteration loss = 0.0023929416

Training iteration loss = 0.0032718747

Training iteration loss = 0.0023795448

Training iteration loss = 0.0026578468

Training iteration loss = 0.002682531

Training iteration loss = 0.0024677813

Training iteration loss = 0.004856791

Training iteration loss = 0.005636718

Training iteration loss = 0.00250037

Training iteration loss = 0.002844816

Training iteration loss = 0.0021852267

Training iteration loss = 0.002599492

Training iteration loss = 0.0033482022

Training iteration loss = 0.0032134205

Training iteration loss = 0.0036719227

Training iteration loss = 0.0022703502

Training iteration loss = 0.0035023626

Training iteration loss = 0.007158155

Training iteration loss = 0.0046576643

Training iteration loss = 0.0037554763

Training iteration loss = 0.0029404259

Training iteration loss = 0.0034354718

Training iteration loss = 0.002639112

Training iteration loss = 0.0033145368

Training iteration loss = 0.0021193612

Training iteration loss = 0.002526663

Training iteration loss = 0.0025870085

Training iteration loss = 0.0025856164

Training iteration loss = 0.001976282

Training iteration loss = 0.004484423

Training iteration loss = 0.0032875873

Training iteration loss = 0.0053559057

Training iteration loss = 0.0032184406

Training iteration loss = 0.003185772

Training iteration loss = 0.003343533

Training iteration loss = 0.0066263503

Training iteration loss = 0.00394641

Training iteration loss = 0.0034111252

Training iteration loss = 0.002545298

Training iteration loss = 0.0048598344

Training iteration loss = 0.0021838755

Training iteration loss = 0.0024260003

Training iteration loss = 0.0029135905

Training iteration loss = 0.0036764115

Training iteration loss = 0.0028762335

Training iteration loss = 0.0038437478

Training iteration loss = 0.0034461494

Training iteration loss = 0.0019208106

Training iteration loss = 0.0024943233

Training iteration loss = 0.0019479864

Training iteration loss = 0.0024486484

Training iteration loss = 0.0020289759

Training iteration loss = 0.0024736964

Training iteration loss = 0.0033802718

Training iteration loss = 0.003423313

Training iteration loss = 0.004541417

Training iteration loss = 0.004056212

Training iteration loss = 0.004072998

Training iteration loss = 0.002157353

Training iteration loss = 0.0030151175

Training iteration loss = 0.0022170274

Training iteration loss = 0.0060343216

Training iteration loss = 0.0035958544

Training iteration loss = 0.002921977

Training iteration loss = 0.0028489435

Training iteration loss = 0.0036121893

Training iteration loss = 0.0070417444

Training iteration loss = 0.0023142938

Training iteration loss = 0.0036133416

Training iteration loss = 0.0036082969

Training iteration loss = 0.0023185324

Training iteration loss = 0.0035011459

Training iteration loss = 0.0037066673

Training iteration loss = 0.002717103

Training iteration loss = 0.002545959

Training iteration loss = 0.003201179

Training iteration loss = 0.0037202323

Training iteration loss = 0.0035723

Training iteration loss = 0.004460124

Training iteration loss = 0.0047307685

Training iteration loss = 0.0032275927

Training iteration loss = 0.003633721

Training iteration loss = 0.004241399

Training iteration loss = 0.00445372

Training iteration loss = 0.0028335021

Training iteration loss = 0.0036216788

Training iteration loss = 0.0040564085

Training iteration loss = 0.0025421197

Training iteration loss = 0.0021386815

Training iteration loss = 0.0036189668

Training iteration loss = 0.0024337366

Training iteration loss = 0.002124329

Training iteration loss = 0.0030583946

Training iteration loss = 0.0022498854

Training iteration loss = 0.0017910303

Training iteration loss = 0.0018372586

Training iteration loss = 0.0031122752

Training iteration loss = 0.002076601

Training iteration loss = 0.0022723768

Training iteration loss = 0.0039323024

Training iteration loss = 0.005242016

Training iteration loss = 0.0024937363

Training iteration loss = 0.0027224247

Training iteration loss = 0.002373299

Training iteration loss = 0.00263968

Training iteration loss = 0.0022467405

Training iteration loss = 0.0040296656

Training iteration loss = 0.0033740597

Training iteration loss = 0.004929585

Training iteration loss = 0.0039093946

Training iteration loss = 0.0029103523

Training iteration loss = 0.0019695547

Training iteration loss = 0.002095733

Training iteration loss = 0.008479973

Training iteration loss = 0.0030297681

Training iteration loss = 0.0017815044

Training iteration loss = 0.0042869584

Training iteration loss = 0.0037564102

Training iteration loss = 0.0033709675

Training iteration loss = 0.0029063094

Training iteration loss = 0.0039391434

Training iteration loss = 0.0022875995

Training iteration loss = 0.006507102

Training iteration loss = 0.002586068

Training iteration loss = 0.003412286

Training iteration loss = 0.0037795978

Training iteration loss = 0.0020936762

Training iteration loss = 0.0021244402

Training iteration loss = 0.0025687905

Training iteration loss = 0.0016453619

Training iteration loss = 0.0033124778

Training iteration loss = 0.0031750689

Training iteration loss = 0.0041475976

Training iteration loss = 0.0030558782

Training iteration loss = 0.002790383

Training iteration loss = 0.0022979018

Training iteration loss = 0.002217066

Training iteration loss = 0.002346306

Training iteration loss = 0.0031108046

Training iteration loss = 0.0046497886

Training iteration loss = 0.0018138605

Training iteration loss = 0.0029847778

Training iteration loss = 0.0030702397

Training iteration loss = 0.0033700776

Training iteration loss = 0.002852456

Training iteration loss = 0.003268114

Training iteration loss = 0.0027520435

Training iteration loss = 0.0017807679

Training iteration loss = 0.006019473

Training iteration loss = 0.0029547138

Training iteration loss = 0.0025795691

Training iteration loss = 0.0018252019

Training iteration loss = 0.003318819

Training iteration loss = 0.003642802

Training iteration loss = 0.0036688447

Training iteration loss = 0.0023594776

Training iteration loss = 0.00569392

Training iteration loss = 0.0031093454

Training iteration loss = 0.002285965

Training iteration loss = 0.0020722717

Training iteration loss = 0.0024582192

Training iteration loss = 0.0019655477

Training iteration loss = 0.003036142

Training iteration loss = 0.001771159

Training iteration loss = 0.0020166263

Training iteration loss = 0.0036184292

Training iteration loss = 0.00280675

Training iteration loss = 0.0033279639

Training iteration loss = 0.0025893585

Training iteration loss = 0.0039747893

Training iteration loss = 0.0041474733

Training iteration loss = 0.0042969626

Training iteration loss = 0.0020105054

Training iteration loss = 0.0028261628

Training iteration loss = 0.0024067734

Training iteration loss = 0.003701627

Training iteration loss = 0.0033865126

Training iteration loss = 0.004682774

Training iteration loss = 0.0028852283

Training iteration loss = 0.0024511998

Training iteration loss = 0.003164772

Training iteration loss = 0.0047242977

Training iteration loss = 0.00321996

Training iteration loss = 0.002713226

Training iteration loss = 0.0032789952

Training iteration loss = 0.0031796824

Training iteration loss = 0.0024277226

Training iteration loss = 0.0025053902

Training iteration loss = 0.0036560216

Training iteration loss = 0.002988218

Training iteration loss = 0.0031056758

Training iteration loss = 0.0027652972

Training iteration loss = 0.0022935981

Training iteration loss = 0.004467133

Training iteration loss = 0.004141004

Training iteration loss = 0.0038163178

Training iteration loss = 0.0036863962

Training iteration loss = 0.002210535

Training iteration loss = 0.0044777566

Training iteration loss = 0.0055302125

Training iteration loss = 0.0023890056

Training iteration loss = 0.003264187

Training iteration loss = 0.0023761333

Training iteration loss = 0.0026599225

Training iteration loss = 0.002680368

Training iteration loss = 0.0024603189

Training iteration loss = 0.004853983

Training iteration loss = 0.005627195

Training iteration loss = 0.0024988905

Training iteration loss = 0.0028431795

Training iteration loss = 0.0021843927

Training iteration loss = 0.0025959027

Training iteration loss = 0.0033451433

Training iteration loss = 0.0032099122

Training iteration loss = 0.0036696407

Training iteration loss = 0.002272598

Training iteration loss = 0.0035043538

Training iteration loss = 0.00716073

Training iteration loss = 0.004647276

Training iteration loss = 0.0037500465

Training iteration loss = 0.0029376699

Training iteration loss = 0.0034325437

Training iteration loss = 0.002641391

Training iteration loss = 0.0033106217

Training iteration loss = 0.0021188648

Training iteration loss = 0.0025232283

Training iteration loss = 0.00258571

Training iteration loss = 0.0025756436

Training iteration loss = 0.0019743026

Training iteration loss = 0.0044862246

Training iteration loss = 0.0032835437

Training iteration loss = 0.005351614

Training iteration loss = 0.003221563

Training iteration loss = 0.0031829735

Training iteration loss = 0.0033440143

Training iteration loss = 0.0066072885

Training iteration loss = 0.0039334395

Training iteration loss = 0.0034110069

Training iteration loss = 0.0025432743

Training iteration loss = 0.004835088

Training iteration loss = 0.0021785211

Training iteration loss = 0.0024252713

Training iteration loss = 0.0029186707

Training iteration loss = 0.003678589

Training iteration loss = 0.002869888

Training iteration loss = 0.0038402749

Training iteration loss = 0.0034361782

Training iteration loss = 0.0019144554

Training iteration loss = 0.0024839826

Training iteration loss = 0.0019443942

Training iteration loss = 0.0024404146

Training iteration loss = 0.002014483

Training iteration loss = 0.0024647454

Training iteration loss = 0.003377848

Training iteration loss = 0.0034166668

Training iteration loss = 0.004534874

Training iteration loss = 0.004060375

Training iteration loss = 0.0040605674

Training iteration loss = 0.0021550457

Training iteration loss = 0.0030112553

Training iteration loss = 0.0022184327

Training iteration loss = 0.006046791

Training iteration loss = 0.0036045946

Training iteration loss = 0.0029191554

Training iteration loss = 0.0028425772

Training iteration loss = 0.0036079132

Training iteration loss = 0.007055634

Training iteration loss = 0.0023160116

Training iteration loss = 0.0036095902

Training iteration loss = 0.0035955394

Training iteration loss = 0.0023105538

Training iteration loss = 0.0034883004

Training iteration loss = 0.003702359

Training iteration loss = 0.00271484

Training iteration loss = 0.0025490446

Training iteration loss = 0.0031968763

Training iteration loss = 0.0037142325

Training iteration loss = 0.003575321

Training iteration loss = 0.004462728

Training iteration loss = 0.0047155884

Training iteration loss = 0.0032185453

Training iteration loss = 0.0036409104

Training iteration loss = 0.0042467103

Training iteration loss = 0.0044472273

Training iteration loss = 0.002822745

Training iteration loss = 0.0036244104

Training iteration loss = 0.0040533706

Training iteration loss = 0.0025437193

Training iteration loss = 0.0021355122

Training iteration loss = 0.0036158364

Training iteration loss = 0.0024316527

Training iteration loss = 0.0021180313

Training iteration loss = 0.0030572342

Training iteration loss = 0.0022508958

Training iteration loss = 0.0017853421

Training iteration loss = 0.0018342553

Training iteration loss = 0.0031137478

Training iteration loss = 0.0020732102

Training iteration loss = 0.0022754022

Training iteration loss = 0.0039312653

Training iteration loss = 0.0052262903

Training iteration loss = 0.0024921084

Training iteration loss = 0.0027174933

Training iteration loss = 0.0023681188

Training iteration loss = 0.0026358403

Training iteration loss = 0.00224553

Training iteration loss = 0.0040286644

Training iteration loss = 0.0033738154

Training iteration loss = 0.0049365484

Training iteration loss = 0.0039040959

Training iteration loss = 0.0029064622

Training iteration loss = 0.001969803

Training iteration loss = 0.0020951508

Training iteration loss = 0.008459373

Training iteration loss = 0.0030220866

Training iteration loss = 0.0017869431

Training iteration loss = 0.0042797667

Training iteration loss = 0.0037562952

Training iteration loss = 0.0033689986

Training iteration loss = 0.0029002393

Training iteration loss = 0.0039375494

Training iteration loss = 0.0022813356

Training iteration loss = 0.006518764

Training iteration loss = 0.0025867445

Training iteration loss = 0.003410695

Training iteration loss = 0.003777961

Training iteration loss = 0.0020928995

Training iteration loss = 0.002120572

Training iteration loss = 0.0025724762

Training iteration loss = 0.0016394045

Training iteration loss = 0.0033029013

Training iteration loss = 0.0031727974

Training iteration loss = 0.00414243

Training iteration loss = 0.0030576224

Training iteration loss = 0.0027825094

Training iteration loss = 0.0023011996

Training iteration loss = 0.0022207948

Training iteration loss = 0.0023450907

Training iteration loss = 0.0031115718

Training iteration loss = 0.0046458407

Training iteration loss = 0.0018121732

Training iteration loss = 0.002988261

Training iteration loss = 0.0030745314

Training iteration loss = 0.003365755

Training iteration loss = 0.0028520124

Training iteration loss = 0.0032656041

Training iteration loss = 0.0027590937

Training iteration loss = 0.0017805652

Training iteration loss = 0.0060177855

Training iteration loss = 0.0029564835

Training iteration loss = 0.002580758

Training iteration loss = 0.0018191021

Training iteration loss = 0.0033089397

Training iteration loss = 0.0036442522

Training iteration loss = 0.003667554

Training iteration loss = 0.0023583889

Training iteration loss = 0.0056947465

Training iteration loss = 0.0031036206

Training iteration loss = 0.0022828926

Training iteration loss = 0.0020667093

Training iteration loss = 0.0024529172

Training iteration loss = 0.001962927

Training iteration loss = 0.0030238947

Training iteration loss = 0.0017661612

Training iteration loss = 0.002021222

Training iteration loss = 0.0036278216

Training iteration loss = 0.002798588

Training iteration loss = 0.003327605

Training iteration loss = 0.0025883275

Training iteration loss = 0.0039623827

Training iteration loss = 0.00414076

Training iteration loss = 0.0042754044

Training iteration loss = 0.002012774

Training iteration loss = 0.0028293522

Training iteration loss = 0.002411833

Training iteration loss = 0.0037024405

Training iteration loss = 0.003382671

Training iteration loss = 0.0046701995

Training iteration loss = 0.0028806108

Training iteration loss = 0.0024434347

Training iteration loss = 0.0031624585

Training iteration loss = 0.004724898

Training iteration loss = 0.003218199

Training iteration loss = 0.0027091848

Training iteration loss = 0.0032774012

Training iteration loss = 0.0031760873

Training iteration loss = 0.0024208452

Training iteration loss = 0.0024980968

Training iteration loss = 0.0036547843

Training iteration loss = 0.0029844937

Training iteration loss = 0.0031014113

Training iteration loss = 0.0027651684

Training iteration loss = 0.0022861182

Training iteration loss = 0.0044565643

Training iteration loss = 0.0041147545

Training iteration loss = 0.0038230428

Training iteration loss = 0.0036716398

Training iteration loss = 0.0022068678

Training iteration loss = 0.0044844723

Training iteration loss = 0.0055280644

Training iteration loss = 0.0023824943

Training iteration loss = 0.0032631091

Training iteration loss = 0.0023747853

Training iteration loss = 0.0026564312

Training iteration loss = 0.0026777352

Training iteration loss = 0.0024590555

Training iteration loss = 0.004840866

Training iteration loss = 0.005608324

Training iteration loss = 0.0024975894

Training iteration loss = 0.0028432785

Training iteration loss = 0.0021834862

Training iteration loss = 0.0025934535

Training iteration loss = 0.0033467852

Training iteration loss = 0.0032073625

Training iteration loss = 0.003668126

Training iteration loss = 0.0022778336

Training iteration loss = 0.0035002131

Training iteration loss = 0.007152932

Training iteration loss = 0.004642541

Training iteration loss = 0.003744322

Training iteration loss = 0.0029342119

Training iteration loss = 0.0034277618

Training iteration loss = 0.0026398199

Training iteration loss = 0.0033055742

Training iteration loss = 0.0021149162

Training iteration loss = 0.0025190522

Training iteration loss = 0.0025823417

Training iteration loss = 0.0025596255

Training iteration loss = 0.0019742886

Training iteration loss = 0.0044878083

Training iteration loss = 0.00328316

Training iteration loss = 0.0053427704

Training iteration loss = 0.0032196117

Training iteration loss = 0.003176531

Training iteration loss = 0.0033432252

Training iteration loss = 0.006589228

Training iteration loss = 0.0039275615

Training iteration loss = 0.0034086602

Training iteration loss = 0.002540245

Training iteration loss = 0.0048235003

Training iteration loss = 0.002173789

Training iteration loss = 0.0024233658

Training iteration loss = 0.002915252

Training iteration loss = 0.003678495

Training iteration loss = 0.0028628018

Training iteration loss = 0.0038299977

Training iteration loss = 0.0034289835

Training iteration loss = 0.0019128869

Training iteration loss = 0.0024751897

Training iteration loss = 0.0019373096

Training iteration loss = 0.0024340393

Training iteration loss = 0.0020070346

Training iteration loss = 0.0024652418

Training iteration loss = 0.0033709167

Training iteration loss = 0.003409802

Training iteration loss = 0.004532762

Training iteration loss = 0.004060059

Training iteration loss = 0.0040584807

Training iteration loss = 0.0021522597

Training iteration loss = 0.0030074276

Training iteration loss = 0.002216363

Training iteration loss = 0.0060487557

Training iteration loss = 0.0036109202

Training iteration loss = 0.002912813

Training iteration loss = 0.0028258879

Training iteration loss = 0.0035998786

Training iteration loss = 0.0070520644

Training iteration loss = 0.0023193446

Training iteration loss = 0.0036078568

Training iteration loss = 0.0035905319

Training iteration loss = 0.0023101012

Training iteration loss = 0.0034796668

Training iteration loss = 0.0037048187

Training iteration loss = 0.002715528

Training iteration loss = 0.0025529931

Training iteration loss = 0.003198363

Training iteration loss = 0.0036991162

Training iteration loss = 0.0035704141

Training iteration loss = 0.0044403686

Training iteration loss = 0.0047070435

Training iteration loss = 0.0032080591

Training iteration loss = 0.0036438776

Training iteration loss = 0.004238782

Training iteration loss = 0.004441932

Training iteration loss = 0.0028191719

Training iteration loss = 0.0036310342

Training iteration loss = 0.0040397802

Training iteration loss = 0.0025417057

Training iteration loss = 0.0021268812

Training iteration loss = 0.0036124883

Training iteration loss = 0.0024148778

Training iteration loss = 0.0021168133

Training iteration loss = 0.003066371

Training iteration loss = 0.0022607576

Training iteration loss = 0.001781269

Training iteration loss = 0.0018321545

Training iteration loss = 0.003109078

Training iteration loss = 0.0020615824

Training iteration loss = 0.002271035

Training iteration loss = 0.0039306227

Training iteration loss = 0.0052118488

Training iteration loss = 0.0024895456

Training iteration loss = 0.0027246338

Training iteration loss = 0.002369271

Training iteration loss = 0.002626947

Training iteration loss = 0.0022434355

Training iteration loss = 0.004025128

Training iteration loss = 0.0033738248

Training iteration loss = 0.0049368865

Training iteration loss = 0.0039010346

Training iteration loss = 0.002903369

Training iteration loss = 0.0019704502

Training iteration loss = 0.002098604

Training iteration loss = 0.008432707

Training iteration loss = 0.0030095326

Training iteration loss = 0.0017943525

Training iteration loss = 0.004274571

Training iteration loss = 0.0037600643

Training iteration loss = 0.0033688005

Training iteration loss = 0.002899389

Training iteration loss = 0.003932306

Training iteration loss = 0.0022725675

Training iteration loss = 0.0064991643

Training iteration loss = 0.0025798713

Training iteration loss = 0.0034100327

Training iteration loss = 0.0037755545

Training iteration loss = 0.002087294

Training iteration loss = 0.0021118547

Training iteration loss = 0.0025709586

Training iteration loss = 0.0016394816

Training iteration loss = 0.0033108725

Training iteration loss = 0.0031821057

Training iteration loss = 0.0041400273

Training iteration loss = 0.0030527243

Training iteration loss = 0.0027812978

Training iteration loss = 0.0023009928

Training iteration loss = 0.0022177019

Training iteration loss = 0.0023369868

Training iteration loss = 0.00310769

Training iteration loss = 0.0046454375

Training iteration loss = 0.001811218

Training iteration loss = 0.0029984415

Training iteration loss = 0.0030771643

Training iteration loss = 0.0033612528

Training iteration loss = 0.0028419571

Training iteration loss = 0.0032627413

Training iteration loss = 0.002757386

Training iteration loss = 0.0017778309

Training iteration loss = 0.005987218

Training iteration loss = 0.0029620396

Training iteration loss = 0.002580848

Training iteration loss = 0.0018260475

Training iteration loss = 0.003306278

Training iteration loss = 0.0036326258

Training iteration loss = 0.003659199

Training iteration loss = 0.0023567153

Training iteration loss = 0.0056745335

Training iteration loss = 0.00311202

Training iteration loss = 0.0022945467

Training iteration loss = 0.0020839935

Training iteration loss = 0.0024640495

Training iteration loss = 0.0019610412

Training iteration loss = 0.003011369

Training iteration loss = 0.0017754495

Training iteration loss = 0.0020243542

Training iteration loss = 0.0036194902

Training iteration loss = 0.0027851798

Training iteration loss = 0.003306513

Training iteration loss = 0.0025858583

Training iteration loss = 0.003968074

Training iteration loss = 0.00414831

Training iteration loss = 0.004282675

Training iteration loss = 0.0019982557

Training iteration loss = 0.0028140505

Training iteration loss = 0.0023967877

Training iteration loss = 0.003688813

Training iteration loss = 0.0033804544

Training iteration loss = 0.004661255

Training iteration loss = 0.0028822701

Training iteration loss = 0.0024471676

Training iteration loss = 0.00317413

Training iteration loss = 0.0047120187

Training iteration loss = 0.0032129267

Training iteration loss = 0.0027146672

Training iteration loss = 0.003274437

Training iteration loss = 0.0031680565

Training iteration loss = 0.0024239228

Training iteration loss = 0.0024873267

Training iteration loss = 0.0036548867

Training iteration loss = 0.0029837796

Training iteration loss = 0.003101933

Training iteration loss = 0.0027647149

Training iteration loss = 0.0022900444

Training iteration loss = 0.004458424

Training iteration loss = 0.004090994

Training iteration loss = 0.003816952

Training iteration loss = 0.0036627736

Training iteration loss = 0.0022057358

Training iteration loss = 0.0044737207

Training iteration loss = 0.0055292957

Training iteration loss = 0.0023813618

Training iteration loss = 0.0032537028

Training iteration loss = 0.0023719694

Training iteration loss = 0.0026613453

Training iteration loss = 0.0026766015

Training iteration loss = 0.0024514445

Training iteration loss = 0.004834024

Training iteration loss = 0.005589869

Training iteration loss = 0.0024994628

Training iteration loss = 0.00284008

Training iteration loss = 0.002185059

Training iteration loss = 0.0025896863

Training iteration loss = 0.0033426376

Training iteration loss = 0.003205228

Training iteration loss = 0.0036654035

Training iteration loss = 0.0022753126

Training iteration loss = 0.0034993335

Training iteration loss = 0.0071468144

Training iteration loss = 0.0046387934

Training iteration loss = 0.0037360645

Training iteration loss = 0.0029302856

Training iteration loss = 0.00342374

Training iteration loss = 0.0026423691

Training iteration loss = 0.003305654

Training iteration loss = 0.0021127507

Training iteration loss = 0.0025143174

Training iteration loss = 0.0025838253

Training iteration loss = 0.0025586712

Training iteration loss = 0.0019737983

Training iteration loss = 0.004492086

Training iteration loss = 0.0032798862

Training iteration loss = 0.005337067

Training iteration loss = 0.0032291505

Training iteration loss = 0.0031781632

Training iteration loss = 0.0033447419

Training iteration loss = 0.006571227

Training iteration loss = 0.0039196913

Training iteration loss = 0.003408429

Training iteration loss = 0.0025390822

Training iteration loss = 0.0047993567

Training iteration loss = 0.002167042

Training iteration loss = 0.0024237612

Training iteration loss = 0.0029235017

Training iteration loss = 0.003680675

Training iteration loss = 0.0028537589

Training iteration loss = 0.0038229916

Training iteration loss = 0.0034164682

Training iteration loss = 0.0019166329

Training iteration loss = 0.0024705369

Training iteration loss = 0.0019346458

Training iteration loss = 0.002434406

Training iteration loss = 0.0020015815

Training iteration loss = 0.0024649089

Training iteration loss = 0.0033719214

Training iteration loss = 0.003402422

Training iteration loss = 0.004533156

Training iteration loss = 0.0040635555

Training iteration loss = 0.0040421425

Training iteration loss = 0.0021500692

Training iteration loss = 0.002999692

Training iteration loss = 0.0022164546

Training iteration loss = 0.0060525783

Training iteration loss = 0.0036024668

Training iteration loss = 0.0029194197

Training iteration loss = 0.0028405848

Training iteration loss = 0.0036113106

Training iteration loss = 0.007023515

Training iteration loss = 0.002316165

Training iteration loss = 0.0035998493

Training iteration loss = 0.0036051848

Training iteration loss = 0.0023264154

Training iteration loss = 0.0034951775

Training iteration loss = 0.003707569

Training iteration loss = 0.0027124786

Training iteration loss = 0.0025344756

Training iteration loss = 0.003171637

Training iteration loss = 0.0036844097

Training iteration loss = 0.0035491006

Training iteration loss = 0.0044907057

Training iteration loss = 0.004702584

Training iteration loss = 0.0032266276

Training iteration loss = 0.0036156469

Training iteration loss = 0.004228798

Training iteration loss = 0.004412658

Training iteration loss = 0.002819808

Training iteration loss = 0.0036146312

Training iteration loss = 0.004040233

Training iteration loss = 0.00254327

Training iteration loss = 0.0021306688

Training iteration loss = 0.0036160408

Training iteration loss = 0.0024159907

Training iteration loss = 0.002105087

Training iteration loss = 0.0030526072

Training iteration loss = 0.0022500772

Training iteration loss = 0.0017758696

Training iteration loss = 0.0018368186

Training iteration loss = 0.0031174866

Training iteration loss = 0.0020661887

Training iteration loss = 0.0022675714

Training iteration loss = 0.0039147497

Training iteration loss = 0.0052041677

Training iteration loss = 0.002483051

Training iteration loss = 0.0027050534

Training iteration loss = 0.002361361

Training iteration loss = 0.0026201976

Training iteration loss = 0.0022425405

Training iteration loss = 0.004011668

Training iteration loss = 0.003359368

Training iteration loss = 0.004946329

Training iteration loss = 0.00389787

Training iteration loss = 0.0028954512

Training iteration loss = 0.001967992

Training iteration loss = 0.0020973638

Training iteration loss = 0.008429995

Training iteration loss = 0.0030116912

Training iteration loss = 0.0017892946

Training iteration loss = 0.004270755

Training iteration loss = 0.0037600559

Training iteration loss = 0.0033707384

Training iteration loss = 0.0028916516

Training iteration loss = 0.0039340956

Training iteration loss = 0.0022628175

Training iteration loss = 0.006486055

Training iteration loss = 0.0025778932

Training iteration loss = 0.0034109212

Training iteration loss = 0.0037776437

Training iteration loss = 0.0020901829

Training iteration loss = 0.0021123735

Training iteration loss = 0.0025756417

Training iteration loss = 0.0016317064

Training iteration loss = 0.0032937312

Training iteration loss = 0.0031685259

Training iteration loss = 0.0041261106

Training iteration loss = 0.0030616724

Training iteration loss = 0.0027775296

Training iteration loss = 0.0023057996

Training iteration loss = 0.0022150364

Training iteration loss = 0.002338815

Training iteration loss = 0.003109833

Training iteration loss = 0.0046254047

Training iteration loss = 0.0018072812

Training iteration loss = 0.002983015

Training iteration loss = 0.0030733591

Training iteration loss = 0.0033594966

Training iteration loss = 0.0028499924

Training iteration loss = 0.0032597512

Training iteration loss = 0.002763733

Training iteration loss = 0.0017745835

Training iteration loss = 0.005975771

Training iteration loss = 0.002958482

Training iteration loss = 0.0025774126

Training iteration loss = 0.001818902

Training iteration loss = 0.0032936495

Training iteration loss = 0.0036362503

Training iteration loss = 0.0036593648

Training iteration loss = 0.0023504074

Training iteration loss = 0.0056818724

Training iteration loss = 0.0030942934

Training iteration loss = 0.0022760655

Training iteration loss = 0.0020644113

Training iteration loss = 0.0024461178

Training iteration loss = 0.001959883

Training iteration loss = 0.0030028606

Training iteration loss = 0.0017651791

Training iteration loss = 0.002016714

Training iteration loss = 0.0036280027

Training iteration loss = 0.002782695

Training iteration loss = 0.003320786

Training iteration loss = 0.0025876942

Training iteration loss = 0.003952543

Training iteration loss = 0.004138399

Training iteration loss = 0.004252383

Training iteration loss = 0.0020026914

Training iteration loss = 0.0028229102

Training iteration loss = 0.0024099296

Training iteration loss = 0.0036975036

Training iteration loss = 0.0033773317

Training iteration loss = 0.004653103

Training iteration loss = 0.0028754922

Training iteration loss = 0.002434907

Training iteration loss = 0.0031688418

Training iteration loss = 0.0047192033

Training iteration loss = 0.0032113816

Training iteration loss = 0.0027090404

Training iteration loss = 0.003275689

Training iteration loss = 0.00316807

Training iteration loss = 0.0024194631

Training iteration loss = 0.0024843442

Training iteration loss = 0.0036492997

Training iteration loss = 0.0029805684

Training iteration loss = 0.00309344

Training iteration loss = 0.0027646592

Training iteration loss = 0.002279918

Training iteration loss = 0.004443668

Training iteration loss = 0.004085321

Training iteration loss = 0.0038232545

Training iteration loss = 0.0036545766

Training iteration loss = 0.0022005609

Training iteration loss = 0.0044869543

Training iteration loss = 0.0055252113

Training iteration loss = 0.002375153

Training iteration loss = 0.0032503319

Training iteration loss = 0.0023694641

Training iteration loss = 0.0026582277

Training iteration loss = 0.0026740178

Training iteration loss = 0.0024506843

Training iteration loss = 0.0048256

Training iteration loss = 0.0055804807

Training iteration loss = 0.0024969408

Training iteration loss = 0.0028427572

Training iteration loss = 0.0021849005

Training iteration loss = 0.0025877992

Training iteration loss = 0.0033452054

Training iteration loss = 0.003202718

Training iteration loss = 0.0036638118

Training iteration loss = 0.0022845112

Training iteration loss = 0.0034957519

Training iteration loss = 0.007150803

Training iteration loss = 0.0046304744

Training iteration loss = 0.003731055

Training iteration loss = 0.0029290544

Training iteration loss = 0.00342042

Training iteration loss = 0.0026422015

Training iteration loss = 0.0032983318

Training iteration loss = 0.0021103346

Training iteration loss = 0.0025128198

Training iteration loss = 0.0025777346

Training iteration loss = 0.0025356805

Training iteration loss = 0.0019701659

Training iteration loss = 0.0044928356

Training iteration loss = 0.003275174

Training iteration loss = 0.0053315586

Training iteration loss = 0.0032271722

Training iteration loss = 0.0031720698

Training iteration loss = 0.003336887

Training iteration loss = 0.006554369

Training iteration loss = 0.0039106333

Training iteration loss = 0.003408257

Training iteration loss = 0.0025377264

Training iteration loss = 0.004777721

Training iteration loss = 0.0021628663

Training iteration loss = 0.0024258627

Training iteration loss = 0.002922231

Training iteration loss = 0.0036752538

Training iteration loss = 0.0028513286

Training iteration loss = 0.003817983

Training iteration loss = 0.0034100416

Training iteration loss = 0.0019143628

Training iteration loss = 0.0024658984

Training iteration loss = 0.0019356931

Training iteration loss = 0.002435072

Training iteration loss = 0.0020014674

Training iteration loss = 0.0024626846

Training iteration loss = 0.0033633758

Training iteration loss = 0.0034013104

Training iteration loss = 0.0045336504

Training iteration loss = 0.0040690545

Training iteration loss = 0.004029814

Training iteration loss = 0.0021474757

Training iteration loss = 0.002994637

Training iteration loss = 0.0022150015

Training iteration loss = 0.006058205

Training iteration loss = 0.0036045413

Training iteration loss = 0.0029133065

Training iteration loss = 0.002829156

Training iteration loss = 0.0036055471

Training iteration loss = 0.0070250705

Training iteration loss = 0.0023140248

Training iteration loss = 0.003592004

Training iteration loss = 0.0035900474

Training iteration loss = 0.0023144637

Training iteration loss = 0.0034866622

Training iteration loss = 0.0037015982

Training iteration loss = 0.0027099398

Training iteration loss = 0.0025431553

Training iteration loss = 0.0031805297

Training iteration loss = 0.003683305

Training iteration loss = 0.00355767

Training iteration loss = 0.004456102

Training iteration loss = 0.004706668

Training iteration loss = 0.0032221368

Training iteration loss = 0.0036260954

Training iteration loss = 0.004230403

Training iteration loss = 0.004412433

Training iteration loss = 0.0028221589

Training iteration loss = 0.0036056247

Training iteration loss = 0.004032262

Training iteration loss = 0.002538704

Training iteration loss = 0.002135095

Training iteration loss = 0.003616643

Training iteration loss = 0.0024317242

Training iteration loss = 0.0020982323

Training iteration loss = 0.0030438155

Training iteration loss = 0.0022462015

Training iteration loss = 0.0017721379

Training iteration loss = 0.0018388337

Training iteration loss = 0.0031259947

Training iteration loss = 0.0020704276

Training iteration loss = 0.0022708713

Training iteration loss = 0.0039110794

Training iteration loss = 0.0051863776

Training iteration loss = 0.0024858702

Training iteration loss = 0.0027008879

Training iteration loss = 0.0023596797

Training iteration loss = 0.0026171077

Training iteration loss = 0.0022526023

Training iteration loss = 0.0040104273

Training iteration loss = 0.003354121

Training iteration loss = 0.004949653

Training iteration loss = 0.0038989482

Training iteration loss = 0.0028890173

Training iteration loss = 0.001964101

Training iteration loss = 0.0020917524

Training iteration loss = 0.008406535

Training iteration loss = 0.0030104946

Training iteration loss = 0.0017764132

Training iteration loss = 0.0042794175

Training iteration loss = 0.0037595027

Training iteration loss = 0.0033668817

Training iteration loss = 0.0028911002

Training iteration loss = 0.003930772

Training iteration loss = 0.0022643337

Training iteration loss = 0.006476033

Training iteration loss = 0.0025732908

Training iteration loss = 0.0034050576

Training iteration loss = 0.0037729582

Training iteration loss = 0.002084804

Training iteration loss = 0.0021118775

Training iteration loss = 0.002576769

Training iteration loss = 0.0016313555

Training iteration loss = 0.003293453

Training iteration loss = 0.003165303

Training iteration loss = 0.004117647

Training iteration loss = 0.0030633062

Training iteration loss = 0.002774898

Training iteration loss = 0.0023045812

Training iteration loss = 0.002205958

Training iteration loss = 0.002341789

Training iteration loss = 0.003105561

Training iteration loss = 0.004615384

Training iteration loss = 0.0018077776

Training iteration loss = 0.0029807016

Training iteration loss = 0.0030683929

Training iteration loss = 0.0033552537

Training iteration loss = 0.0028501784

Training iteration loss = 0.0032550627

Training iteration loss = 0.0027644162

Training iteration loss = 0.0017762617

Training iteration loss = 0.0059577324

Training iteration loss = 0.0029560237

Training iteration loss = 0.0025695907

Training iteration loss = 0.0018161484

Training iteration loss = 0.0032848965

Training iteration loss = 0.0036293075

Training iteration loss = 0.003660418

Training iteration loss = 0.0023468111

Training iteration loss = 0.0056924354

Training iteration loss = 0.0030876172

Training iteration loss = 0.0022721866

Training iteration loss = 0.0020655666

Training iteration loss = 0.0024445641

Training iteration loss = 0.0019633516

Training iteration loss = 0.0030027449

Training iteration loss = 0.0017634326

Training iteration loss = 0.0020046248

Training iteration loss = 0.003614188

Training iteration loss = 0.0027781336

Training iteration loss = 0.0033169705

Training iteration loss = 0.0025835794

Training iteration loss = 0.003946288

Training iteration loss = 0.0041413107

Training iteration loss = 0.004240766

Training iteration loss = 0.0019997016

Training iteration loss = 0.002819215

Training iteration loss = 0.0024050022

Training iteration loss = 0.0036962696

Training iteration loss = 0.00337475

Training iteration loss = 0.0046404772

Training iteration loss = 0.0028702812

Training iteration loss = 0.0024340553

Training iteration loss = 0.003169574

Training iteration loss = 0.004715937

Training iteration loss = 0.003212628

Training iteration loss = 0.0027091186

Training iteration loss = 0.003267645

Training iteration loss = 0.0031587488

Training iteration loss = 0.002414848

Training iteration loss = 0.0024742514

Training iteration loss = 0.003650614

Training iteration loss = 0.0029811596

Training iteration loss = 0.0030946292

Training iteration loss = 0.002766845

Training iteration loss = 0.002274181

Training iteration loss = 0.0044385917

Training iteration loss = 0.0040673283

Training iteration loss = 0.0038264582

Training iteration loss = 0.0036452152

Training iteration loss = 0.0021977515

Training iteration loss = 0.004487997

Training iteration loss = 0.0055261757

Training iteration loss = 0.0023665077

Training iteration loss = 0.0032433392

Training iteration loss = 0.0023683237

Training iteration loss = 0.0026604442

Training iteration loss = 0.0026721426

Training iteration loss = 0.0024477036

Training iteration loss = 0.0048168884

Training iteration loss = 0.0055672624

Training iteration loss = 0.0024957655

Training iteration loss = 0.0028429322

Training iteration loss = 0.0021863533

Training iteration loss = 0.0025867315

Training iteration loss = 0.0033430064

Training iteration loss = 0.0031998728

Training iteration loss = 0.0036653418

Training iteration loss = 0.0022877392

Training iteration loss = 0.003496925

Training iteration loss = 0.007149495

Training iteration loss = 0.00462154

Training iteration loss = 0.0037291946

Training iteration loss = 0.0029269152

Training iteration loss = 0.0034162665

Training iteration loss = 0.0026405428

Training iteration loss = 0.003295688

Training iteration loss = 0.0021066915

Training iteration loss = 0.002509606

Training iteration loss = 0.0025743106

Training iteration loss = 0.002516541

Training iteration loss = 0.0019686949

Training iteration loss = 0.004495338

Training iteration loss = 0.0032716591

Training iteration loss = 0.0053245947

Training iteration loss = 0.003229568

Training iteration loss = 0.0031690642

Training iteration loss = 0.0033223394

Training iteration loss = 0.0065386295

Training iteration loss = 0.0039046127

Training iteration loss = 0.0034064874

Training iteration loss = 0.0025398133

Training iteration loss = 0.00476816

Training iteration loss = 0.0021579077

Training iteration loss = 0.00242834

Training iteration loss = 0.002917193

Training iteration loss = 0.003672434

Training iteration loss = 0.0028487125

Training iteration loss = 0.0038096504

Training iteration loss = 0.003406129

Training iteration loss = 0.0019195001

Training iteration loss = 0.0024621026

Training iteration loss = 0.0019341098

Training iteration loss = 0.0024389306

Training iteration loss = 0.0020080365

Training iteration loss = 0.0024646432

Training iteration loss = 0.003359872

Training iteration loss = 0.0034027386

Training iteration loss = 0.004536307

Training iteration loss = 0.00406896

Training iteration loss = 0.0040308754

Training iteration loss = 0.0021429395

Training iteration loss = 0.0029901934

Training iteration loss = 0.0022088669

Training iteration loss = 0.006048953

Training iteration loss = 0.0036028319

Training iteration loss = 0.0029097076

Training iteration loss = 0.002821113

Training iteration loss = 0.0035975745

Training iteration loss = 0.0070264866

Training iteration loss = 0.0023117426

Training iteration loss = 0.0035837519

Training iteration loss = 0.0035863903

Training iteration loss = 0.0023063056

Training iteration loss = 0.003477671

Training iteration loss = 0.0037038897

Training iteration loss = 0.002706277

Training iteration loss = 0.0025445546

Training iteration loss = 0.0031808077

Training iteration loss = 0.0036707267

Training iteration loss = 0.003545602

Training iteration loss = 0.0044214255

Training iteration loss = 0.004699767

Training iteration loss = 0.003207492

Training iteration loss = 0.0036426487

Training iteration loss = 0.0042250166

Training iteration loss = 0.00440977

Training iteration loss = 0.0028094277

Training iteration loss = 0.0036072554

Training iteration loss = 0.0040318277

Training iteration loss = 0.0025391232

Training iteration loss = 0.0021316803

Training iteration loss = 0.0036101167

Training iteration loss = 0.0024193497

Training iteration loss = 0.0020971957

Training iteration loss = 0.0030517632

Training iteration loss = 0.0022495806

Training iteration loss = 0.0017678086

Training iteration loss = 0.0018393435

Training iteration loss = 0.0031221306

Training iteration loss = 0.00206904

Training iteration loss = 0.0022716566

Training iteration loss = 0.003909631

Training iteration loss = 0.0051774625

Training iteration loss = 0.002485544

Training iteration loss = 0.0027016292

Training iteration loss = 0.0023570035

Training iteration loss = 0.002610312

Training iteration loss = 0.0022549697

Training iteration loss = 0.0040091095

Training iteration loss = 0.003355562

Training iteration loss = 0.004950641

Training iteration loss = 0.0039034996

Training iteration loss = 0.0028791158

Training iteration loss = 0.0019617432

Training iteration loss = 0.0020889214

Training iteration loss = 0.008378605

Training iteration loss = 0.003004288

Training iteration loss = 0.0017774645

Training iteration loss = 0.0042836

Training iteration loss = 0.003760068

Training iteration loss = 0.0033648685

Training iteration loss = 0.0028911885

Training iteration loss = 0.0039281263

Training iteration loss = 0.0022646387

Training iteration loss = 0.006460359

Training iteration loss = 0.0025692787

Training iteration loss = 0.0034021365

Training iteration loss = 0.0037698497

Training iteration loss = 0.002079039

Training iteration loss = 0.0021094764

Training iteration loss = 0.0025798592

Training iteration loss = 0.0016320186

Training iteration loss = 0.0032959215

Training iteration loss = 0.0031689478

Training iteration loss = 0.0041136504

Training iteration loss = 0.0030614624

Training iteration loss = 0.0027747639

Training iteration loss = 0.002305222

Training iteration loss = 0.0022015853

Training iteration loss = 0.0023398795

Training iteration loss = 0.0031000886

Training iteration loss = 0.0046171932

Training iteration loss = 0.0018073571

Training iteration loss = 0.0029866938

Training iteration loss = 0.0030684087

Training iteration loss = 0.0033506881

Training iteration loss = 0.0028458198

Training iteration loss = 0.0032521884

Training iteration loss = 0.0027649775

Training iteration loss = 0.0017759823

Training iteration loss = 0.005938265

Training iteration loss = 0.002957467

Training iteration loss = 0.0025660777

Training iteration loss = 0.0018170257

Training iteration loss = 0.0032813146

Training iteration loss = 0.0036231873

Training iteration loss = 0.0036601254

Training iteration loss = 0.002344156

Training iteration loss = 0.005690874

Training iteration loss = 0.003088632

Training iteration loss = 0.0022771934

Training iteration loss = 0.002075107

Training iteration loss = 0.002447896

Training iteration loss = 0.001964936

Training iteration loss = 0.0029954603

Training iteration loss = 0.0017667165

Training iteration loss = 0.0020022944

Training iteration loss = 0.0036082088

Training iteration loss = 0.0027704884

Training iteration loss = 0.003306776

Training iteration loss = 0.0025779055

Training iteration loss = 0.003944414

Training iteration loss = 0.0041446183

Training iteration loss = 0.00423361

Training iteration loss = 0.0019928634

Training iteration loss = 0.0028086824

Training iteration loss = 0.002399355

Training iteration loss = 0.0036927706

Training iteration loss = 0.0033703835

Training iteration loss = 0.00463096

Training iteration loss = 0.002869212

Training iteration loss = 0.0024336826

Training iteration loss = 0.003172316

Training iteration loss = 0.004709478

Training iteration loss = 0.0032115222

Training iteration loss = 0.0027128821

Training iteration loss = 0.0032618279

Training iteration loss = 0.003148119

Training iteration loss = 0.0024117616

Training iteration loss = 0.0024658905

Training iteration loss = 0.0036523177

Training iteration loss = 0.0029852295

Training iteration loss = 0.0030960294

Training iteration loss = 0.0027690914

Training iteration loss = 0.0022730818

Training iteration loss = 0.004437813

Training iteration loss = 0.0040495037

Training iteration loss = 0.0038266915

Training iteration loss = 0.003633084

Training iteration loss = 0.0021958554

Training iteration loss = 0.004487343

Training iteration loss = 0.005529105

Training iteration loss = 0.0023604475

Training iteration loss = 0.0032375983

Training iteration loss = 0.0023671072

Training iteration loss = 0.0026639246

Training iteration loss = 0.0026704136

Training iteration loss = 0.0024447648

Training iteration loss = 0.004808985

Training iteration loss = 0.005551834

Training iteration loss = 0.0024961228

Training iteration loss = 0.0028425765

Training iteration loss = 0.0021886344

Training iteration loss = 0.0025840586

Training iteration loss = 0.003340303

Training iteration loss = 0.0031989992

Training iteration loss = 0.0036666275

Training iteration loss = 0.0022871525

Training iteration loss = 0.0034981451

Training iteration loss = 0.0071347333

Training iteration loss = 0.0046168775

Training iteration loss = 0.0037269306

Training iteration loss = 0.0029259964

Training iteration loss = 0.0034132788

Training iteration loss = 0.0026405586

Training iteration loss = 0.0032991061

Training iteration loss = 0.002106013

Training iteration loss = 0.0025085353

Training iteration loss = 0.0025755113

Training iteration loss = 0.0025059206

Training iteration loss = 0.001967904

Training iteration loss = 0.004499285

Training iteration loss = 0.0032654621

Training iteration loss = 0.005318092

Training iteration loss = 0.0032378703

Training iteration loss = 0.0031691594

Training iteration loss = 0.0032965366

Training iteration loss = 0.0065257126

Training iteration loss = 0.0039009145

Training iteration loss = 0.0034055568

Training iteration loss = 0.002544366

Training iteration loss = 0.004763155

Training iteration loss = 0.002152087

Training iteration loss = 0.0024329226

Training iteration loss = 0.0029136653

Training iteration loss = 0.003671392

Training iteration loss = 0.0028474226

Training iteration loss = 0.00380197

Training iteration loss = 0.003400961

Training iteration loss = 0.0019254336

Training iteration loss = 0.0024601186

Training iteration loss = 0.0019364301

Training iteration loss = 0.0024454815

Training iteration loss = 0.002013785

Training iteration loss = 0.0024658618

Training iteration loss = 0.0033637544

Training iteration loss = 0.0034061347

Training iteration loss = 0.0045433003

Training iteration loss = 0.004074264

Training iteration loss = 0.0040327027

Training iteration loss = 0.002138926

Training iteration loss = 0.0029856164

Training iteration loss = 0.002202402

Training iteration loss = 0.006034111

Training iteration loss = 0.0035969976

Training iteration loss = 0.002911281

Training iteration loss = 0.0028193567

Training iteration loss = 0.0035915708

Training iteration loss = 0.007005123

Training iteration loss = 0.002309675

Training iteration loss = 0.0035799898

Training iteration loss = 0.0035902977

Training iteration loss = 0.0023086115

Training iteration loss = 0.003476762

Training iteration loss = 0.0037097635

Training iteration loss = 0.002703312

Training iteration loss = 0.00253955

Training iteration loss = 0.0031726984

Training iteration loss = 0.0036597846

Training iteration loss = 0.0035344895

Training iteration loss = 0.004424418

Training iteration loss = 0.0046955985

Training iteration loss = 0.003203132

Training iteration loss = 0.003636638

Training iteration loss = 0.0042132908

Training iteration loss = 0.0043996726

Training iteration loss = 0.0028134815

Training iteration loss = 0.0036141549

Training iteration loss = 0.004020331

Training iteration loss = 0.0025358486

Training iteration loss = 0.0021237296

Training iteration loss = 0.0036100491

Training iteration loss = 0.0024052018

Training iteration loss = 0.002093563

Training iteration loss = 0.0030613588

Training iteration loss = 0.0022564295

Training iteration loss = 0.0017636353

Training iteration loss = 0.0018372926

Training iteration loss = 0.0031171653

Training iteration loss = 0.0020576373

Training iteration loss = 0.002266147

Training iteration loss = 0.003906301

Training iteration loss = 0.005163389

Training iteration loss = 0.0024815057

Training iteration loss = 0.002706444

Training iteration loss = 0.0023580266

Training iteration loss = 0.0026040415

Training iteration loss = 0.0022506756

Training iteration loss = 0.0040031774

Training iteration loss = 0.0033518875

Training iteration loss = 0.004952162

Training iteration loss = 0.0038984988

Training iteration loss = 0.002876616

Training iteration loss = 0.001961945

Training iteration loss = 0.0020930467

Training iteration loss = 0.008355063

Training iteration loss = 0.0029893124

Training iteration loss = 0.0017872842

Training iteration loss = 0.0042691734

Training iteration loss = 0.0037650864

Training iteration loss = 0.0033684662

Training iteration loss = 0.00288702

Training iteration loss = 0.003924642

Training iteration loss = 0.002249861

Training iteration loss = 0.00644963

Training iteration loss = 0.0025683674

Training iteration loss = 0.0034040448

Training iteration loss = 0.0037759983

Training iteration loss = 0.002079782

Training iteration loss = 0.002104964

Training iteration loss = 0.002581437

Training iteration loss = 0.0016293664

Training iteration loss = 0.0032914437

Training iteration loss = 0.0031673685

Training iteration loss = 0.0041072075

Training iteration loss = 0.0030625165

Training iteration loss = 0.0027716502

Training iteration loss = 0.0023044997

Training iteration loss = 0.0022010051

Training iteration loss = 0.0023409068

Training iteration loss = 0.0031000264

Training iteration loss = 0.0046079624

Training iteration loss = 0.0018053752

Training iteration loss = 0.0029821573

Training iteration loss = 0.0030670061

Training iteration loss = 0.0033483163

Training iteration loss = 0.0028470755

Training iteration loss = 0.0032503104

Training iteration loss = 0.0027708292

Training iteration loss = 0.0017745538

Training iteration loss = 0.0059250016

Training iteration loss = 0.0029573867

Training iteration loss = 0.002562411

Training iteration loss = 0.0018111294

Training iteration loss = 0.0032710477

Training iteration loss = 0.0036227845

Training iteration loss = 0.0036599617

Training iteration loss = 0.002340901

Training iteration loss = 0.0056930915

Training iteration loss = 0.0030818044

Training iteration loss = 0.0022695877

Training iteration loss = 0.0020696998

Training iteration loss = 0.0024433874

Training iteration loss = 0.0019623959

Training iteration loss = 0.002989754

Training iteration loss = 0.0017616661

Training iteration loss = 0.0019975947

Training iteration loss = 0.0036111355

Training iteration loss = 0.0027617095

Training iteration loss = 0.0033071095

Training iteration loss = 0.002578083

Training iteration loss = 0.0039313333

Training iteration loss = 0.0041392557

Training iteration loss = 0.0042213597

Training iteration loss = 0.0019934175

Training iteration loss = 0.002811428

Training iteration loss = 0.002399361

Training iteration loss = 0.003695158

Training iteration loss = 0.0033681847

Training iteration loss = 0.0046201595

Training iteration loss = 0.0028625838

Training iteration loss = 0.0024271996

Training iteration loss = 0.003170153

Training iteration loss = 0.0047124512

Training iteration loss = 0.0032112524

Training iteration loss = 0.002709808

Training iteration loss = 0.0032599855

Training iteration loss = 0.0031457988

Training iteration loss = 0.002403999

Training iteration loss = 0.0024614

Training iteration loss = 0.0036496157

Training iteration loss = 0.0029800972

Training iteration loss = 0.0030923458

Training iteration loss = 0.0027706723

Training iteration loss = 0.0022655774

Training iteration loss = 0.0044256193

Training iteration loss = 0.0040214336

Training iteration loss = 0.0038313817

Training iteration loss = 0.0036185186

Training iteration loss = 0.0021923024

Training iteration loss = 0.0044957935

Training iteration loss = 0.005525436

Training iteration loss = 0.0023541786

Training iteration loss = 0.0032367455

Training iteration loss = 0.0023658213

Training iteration loss = 0.0026612182

Training iteration loss = 0.002668354

Training iteration loss = 0.0024429122

Training iteration loss = 0.0048014363

Training iteration loss = 0.0055376007

Training iteration loss = 0.0024945831

Training iteration loss = 0.002843145

Training iteration loss = 0.0021867382

Training iteration loss = 0.0025804949

Training iteration loss = 0.0033403486

Training iteration loss = 0.0031963836

Training iteration loss = 0.0036649627

Training iteration loss = 0.0022912596

Training iteration loss = 0.003495002

Training iteration loss = 0.0071316813

Training iteration loss = 0.004613059

Training iteration loss = 0.0037215082

Training iteration loss = 0.0029213822

Training iteration loss = 0.0034107293

Training iteration loss = 0.0026403882

Training iteration loss = 0.003295753

Training iteration loss = 0.0021026165

Training iteration loss = 0.0025078598

Training iteration loss = 0.0025730922

Training iteration loss = 0.0024949692

Training iteration loss = 0.001968147

Training iteration loss = 0.0045004045

Training iteration loss = 0.0032666686

Training iteration loss = 0.0053120684

Training iteration loss = 0.0032358598

Training iteration loss = 0.0031643035

Training iteration loss = 0.0033032366

Training iteration loss = 0.006508995

Training iteration loss = 0.003894155

Training iteration loss = 0.0034030955

Training iteration loss = 0.002539761

Training iteration loss = 0.0047431183

Training iteration loss = 0.0021483642

Training iteration loss = 0.002432049

Training iteration loss = 0.0029123658

Training iteration loss = 0.0036715744

Training iteration loss = 0.0028413401

Training iteration loss = 0.00379417

Training iteration loss = 0.0033936873

Training iteration loss = 0.0019226585

Training iteration loss = 0.0024548473

Training iteration loss = 0.001930307

Training iteration loss = 0.0024392277

Training iteration loss = 0.0020060788

Training iteration loss = 0.0024644488

Training iteration loss = 0.0033550672

Training iteration loss = 0.0033980655

Training iteration loss = 0.004540829

Training iteration loss = 0.004075637

Training iteration loss = 0.0040239184

Training iteration loss = 0.00213633

Training iteration loss = 0.002981912

Training iteration loss = 0.0022018282

Training iteration loss = 0.006048472

Training iteration loss = 0.003603274

Training iteration loss = 0.0029086804

Training iteration loss = 0.0028103432

Training iteration loss = 0.0035873558

Training iteration loss = 0.0070229038

Training iteration loss = 0.0023092015

Training iteration loss = 0.0035775572

Training iteration loss = 0.0035826517

Training iteration loss = 0.0023013405

Training iteration loss = 0.0034644317

Training iteration loss = 0.0037081956

Training iteration loss = 0.0027001612

Training iteration loss = 0.0025434184

Training iteration loss = 0.0031702614

Training iteration loss = 0.0036506278

Training iteration loss = 0.0035347089

Training iteration loss = 0.004424145

Training iteration loss = 0.0046871454

Training iteration loss = 0.0031943347

Training iteration loss = 0.0036474736

Training iteration loss = 0.0042174812

Training iteration loss = 0.004396629

Training iteration loss = 0.0028053243

Training iteration loss = 0.0036187563

Training iteration loss = 0.0040173014

Training iteration loss = 0.0025368347

Training iteration loss = 0.002123205

Training iteration loss = 0.0036035366

Training iteration loss = 0.002398426

Training iteration loss = 0.0020868497

Training iteration loss = 0.0030677244

Training iteration loss = 0.0022608403

Training iteration loss = 0.001759278

Training iteration loss = 0.0018350943

Training iteration loss = 0.0031180307

Training iteration loss = 0.002050383

Training iteration loss = 0.002267217

Training iteration loss = 0.0039067576

Training iteration loss = 0.0051600467

Training iteration loss = 0.0024801476

Training iteration loss = 0.0027020944

Training iteration loss = 0.002352632

Training iteration loss = 0.002600495

Training iteration loss = 0.002251306

Training iteration loss = 0.0040012053

Training iteration loss = 0.0033507317

Training iteration loss = 0.004955122

Training iteration loss = 0.0038952834

Training iteration loss = 0.0028709646

Training iteration loss = 0.0019603784

Training iteration loss = 0.002091985

Training iteration loss = 0.008337597

Training iteration loss = 0.0029827144

Training iteration loss = 0.0017865212

Training iteration loss = 0.004264296

Training iteration loss = 0.0037660487

Training iteration loss = 0.003366772

Training iteration loss = 0.00288667

Training iteration loss = 0.0039234287

Training iteration loss = 0.0022461994

Training iteration loss = 0.006441768

Training iteration loss = 0.0025667737

Training iteration loss = 0.0034043796

Training iteration loss = 0.0037774723

Training iteration loss = 0.0020796016

Training iteration loss = 0.0021011834

Training iteration loss = 0.0025855072

Training iteration loss = 0.0016267592

Training iteration loss = 0.0032894313

Training iteration loss = 0.0031712025

Training iteration loss = 0.00410133

Training iteration loss = 0.0030614336

Training iteration loss = 0.0027683806

Training iteration loss = 0.0023052397

Training iteration loss = 0.00220313

Training iteration loss = 0.0023373687

Training iteration loss = 0.003096467

Training iteration loss = 0.004609061

Training iteration loss = 0.0018035489

Training iteration loss = 0.0029891056

Training iteration loss = 0.0030699794

Training iteration loss = 0.003343396

Training iteration loss = 0.002843259

Training iteration loss = 0.0032480669

Training iteration loss = 0.0027754733

Training iteration loss = 0.0017718682

Training iteration loss = 0.0059222006

Training iteration loss = 0.0029615464

Training iteration loss = 0.0025672119

Training iteration loss = 0.0018137853

Training iteration loss = 0.0032685066

Training iteration loss = 0.0036197284

Training iteration loss = 0.0036557037

Training iteration loss = 0.0023405773

Training iteration loss = 0.0056761387

Training iteration loss = 0.0030821932

Training iteration loss = 0.0022729228

Training iteration loss = 0.0020735564

Training iteration loss = 0.0024439658

Training iteration loss = 0.0019587807

Training iteration loss = 0.002973943

Training iteration loss = 0.0017645896

Training iteration loss = 0.0020053114

Training iteration loss = 0.003619767

Training iteration loss = 0.0027540831

Training iteration loss = 0.0032960577

Training iteration loss = 0.0025755533

Training iteration loss = 0.003937683

Training iteration loss = 0.004142305

Training iteration loss = 0.004211615

Training iteration loss = 0.0019841276

Training iteration loss = 0.002802916

Training iteration loss = 0.0023986339

Training iteration loss = 0.003684698

Training iteration loss = 0.0033642186

Training iteration loss = 0.004612986

Training iteration loss = 0.0028674137

Training iteration loss = 0.0024247093

Training iteration loss = 0.0031763094

Training iteration loss = 0.0047041606

Training iteration loss = 0.0032059737

Training iteration loss = 0.0027159334

Training iteration loss = 0.0032598602

Training iteration loss = 0.0031416167

Training iteration loss = 0.0024102512

Training iteration loss = 0.0024566536

Training iteration loss = 0.0036485002

Training iteration loss = 0.0029810902

Training iteration loss = 0.0030877974

Training iteration loss = 0.0027695885

Training iteration loss = 0.0022682988

Training iteration loss = 0.004428477

Training iteration loss = 0.004024394

Training iteration loss = 0.0038252126

Training iteration loss = 0.003614539

Training iteration loss = 0.0021898306

Training iteration loss = 0.004491136

Training iteration loss = 0.0055187917

Training iteration loss = 0.00234866

Training iteration loss = 0.0032274437

Training iteration loss = 0.002361809

Training iteration loss = 0.002664984

Training iteration loss = 0.0026667288

Training iteration loss = 0.0024444023

Training iteration loss = 0.004794937

Training iteration loss = 0.00551532

Training iteration loss = 0.0024967012

Training iteration loss = 0.0028438035

Training iteration loss = 0.0021945008

Training iteration loss = 0.0025794313

Training iteration loss = 0.003341904

Training iteration loss = 0.003193266

Training iteration loss = 0.003664977

Training iteration loss = 0.0022893548

Training iteration loss = 0.0034900426

Training iteration loss = 0.0071303733

Training iteration loss = 0.00461136

Training iteration loss = 0.003712382

Training iteration loss = 0.00292244

Training iteration loss = 0.003406928

Training iteration loss = 0.00264299

Training iteration loss = 0.0032973967

Training iteration loss = 0.002098091

Training iteration loss = 0.0025070517

Training iteration loss = 0.0025726354

Training iteration loss = 0.0024913135

Training iteration loss = 0.0019681305

Training iteration loss = 0.004506675

Training iteration loss = 0.0032618784

Training iteration loss = 0.005301533

Training iteration loss = 0.0032461397

Training iteration loss = 0.0031677252

Training iteration loss = 0.003292559

Training iteration loss = 0.0064943493

Training iteration loss = 0.0038932965

Training iteration loss = 0.0034016652

Training iteration loss = 0.0025395604

Training iteration loss = 0.0047210865

Training iteration loss = 0.0021411746

Training iteration loss = 0.002437396

Training iteration loss = 0.0029166525

Training iteration loss = 0.0036727528

Training iteration loss = 0.002835635

Training iteration loss = 0.0037897287

Training iteration loss = 0.0033870554

Training iteration loss = 0.0019307123

Training iteration loss = 0.0024536464

Training iteration loss = 0.001934561

Training iteration loss = 0.0024459232

Training iteration loss = 0.002008865

Training iteration loss = 0.0024627761

Training iteration loss = 0.0033559345

Training iteration loss = 0.0033971563

Training iteration loss = 0.0045445664

Training iteration loss = 0.004082398

Training iteration loss = 0.00401649

Training iteration loss = 0.002133386

Training iteration loss = 0.0029780397

Training iteration loss = 0.0021989958

Training iteration loss = 0.0060470016

Training iteration loss = 0.0035967275

Training iteration loss = 0.0029106466

Training iteration loss = 0.0028125958

Training iteration loss = 0.0035928758

Training iteration loss = 0.0070117316

Training iteration loss = 0.0023073384

Training iteration loss = 0.0035693357

Training iteration loss = 0.003584033

Training iteration loss = 0.0023033356

Training iteration loss = 0.0034657817

Training iteration loss = 0.0037071586

Training iteration loss = 0.0026949707

Training iteration loss = 0.0025391537

Training iteration loss = 0.00316133

Training iteration loss = 0.0036419763

Training iteration loss = 0.0035277652

Training iteration loss = 0.004434062

Training iteration loss = 0.0046879947

Training iteration loss = 0.003199111

Training iteration loss = 0.0036447414

Training iteration loss = 0.00421546

Training iteration loss = 0.004386266

Training iteration loss = 0.0028013482

Training iteration loss = 0.0036097683

Training iteration loss = 0.0040174215

Training iteration loss = 0.0025373169

Training iteration loss = 0.0021272488

Training iteration loss = 0.0036020987

Training iteration loss = 0.0024022243

Training iteration loss = 0.0020779585

Training iteration loss = 0.0030638017

Training iteration loss = 0.0022574908

Training iteration loss = 0.0017551035

Training iteration loss = 0.0018373352

Training iteration loss = 0.003125252

Training iteration loss = 0.0020536608

Training iteration loss = 0.0022674657

Training iteration loss = 0.0038971903

Training iteration loss = 0.0051521217

Training iteration loss = 0.0024778119

Training iteration loss = 0.002689979

Training iteration loss = 0.002349242

Training iteration loss = 0.0025965439

Training iteration loss = 0.0022532197

Training iteration loss = 0.0039983667

Training iteration loss = 0.0033438168

Training iteration loss = 0.0049557104

Training iteration loss = 0.003895418

Training iteration loss = 0.002860253

Training iteration loss = 0.001953958

Training iteration loss = 0.0020864878

Training iteration loss = 0.008321894

Training iteration loss = 0.002984294

Training iteration loss = 0.0017756479

Training iteration loss = 0.004270865

Training iteration loss = 0.0037633495

Training iteration loss = 0.003364307

Training iteration loss = 0.0028857735

Training iteration loss = 0.003922412

Training iteration loss = 0.002247545

Training iteration loss = 0.006434878

Training iteration loss = 0.002566131

Training iteration loss = 0.0034026243

Training iteration loss = 0.0037768018

Training iteration loss = 0.0020772659

Training iteration loss = 0.00210273

Training iteration loss = 0.0025876092

Training iteration loss = 0.001624632

Training iteration loss = 0.0032794513

Training iteration loss = 0.0031594215

Training iteration loss = 0.004088568

Training iteration loss = 0.003067279

Training iteration loss = 0.002766137

Training iteration loss = 0.0023092085

Training iteration loss = 0.0021977818

Training iteration loss = 0.0023438642

Training iteration loss = 0.0030979915

Training iteration loss = 0.004589398

Training iteration loss = 0.001803379

Training iteration loss = 0.002977851

Training iteration loss = 0.0030672206

Training iteration loss = 0.0033407342

Training iteration loss = 0.0028509814

Training iteration loss = 0.0032465614

Training iteration loss = 0.0027813416

Training iteration loss = 0.0017722999

Training iteration loss = 0.005925584

Training iteration loss = 0.0029575059

Training iteration loss = 0.002571185

Training iteration loss = 0.0018062183

Training iteration loss = 0.003258068

Training iteration loss = 0.003612822

Training iteration loss = 0.0036519337

Training iteration loss = 0.0023330823

Training iteration loss = 0.0056863427

Training iteration loss = 0.0030716795

Training iteration loss = 0.0022626999

Training iteration loss = 0.0020631405

Training iteration loss = 0.0024390523

Training iteration loss = 0.001955982

Training iteration loss = 0.0029661935

Training iteration loss = 0.0017579793

Training iteration loss = 0.0020051606

Training iteration loss = 0.0036268253

Training iteration loss = 0.0027531188

Training iteration loss = 0.0033044117

Training iteration loss = 0.0025771544

Training iteration loss = 0.003930964

Training iteration loss = 0.0041402206

Training iteration loss = 0.0041925716

Training iteration loss = 0.0019821154

Training iteration loss = 0.0028092063

Training iteration loss = 0.0024028395

Training iteration loss = 0.0036850413

Training iteration loss = 0.003362836

Training iteration loss = 0.0046010124

Training iteration loss = 0.0028602954

Training iteration loss = 0.0024107946

Training iteration loss = 0.0031758717

Training iteration loss = 0.00470906

Training iteration loss = 0.0032010654

Training iteration loss = 0.0027125266

Training iteration loss = 0.0032652095

Training iteration loss = 0.003143224

Training iteration loss = 0.0024097015

Training iteration loss = 0.0024614225

Training iteration loss = 0.003637652

Training iteration loss = 0.0029803787

Training iteration loss = 0.0030797154

Training iteration loss = 0.002767578

Training iteration loss = 0.002262402

Training iteration loss = 0.0044153607

Training iteration loss = 0.0040287897

Training iteration loss = 0.0038307067

Training iteration loss = 0.0036089346

Training iteration loss = 0.0021909222

Training iteration loss = 0.004497778

Training iteration loss = 0.005518546

Training iteration loss = 0.0023454127

Training iteration loss = 0.0032320665

Training iteration loss = 0.0023585574

Training iteration loss = 0.0026591716

Training iteration loss = 0.00266496

Training iteration loss = 0.0024437066

Training iteration loss = 0.0047951345

Training iteration loss = 0.0055016745

Training iteration loss = 0.0024951922

Training iteration loss = 0.0028448347

Training iteration loss = 0.0021945331

Training iteration loss = 0.0025751626

Training iteration loss = 0.0033430392

Training iteration loss = 0.003193708

Training iteration loss = 0.0036628665

Training iteration loss = 0.002292617

Training iteration loss = 0.0034909633

Training iteration loss = 0.0071154083

Training iteration loss = 0.004607877

Training iteration loss = 0.0037077991

Training iteration loss = 0.0029199065

Training iteration loss = 0.0034053165

Training iteration loss = 0.0026451827

Training iteration loss = 0.0032975657

Training iteration loss = 0.0021008223

Training iteration loss = 0.0025078622

Training iteration loss = 0.0025741234

Training iteration loss = 0.0024851498

Training iteration loss = 0.001964361

Training iteration loss = 0.004508027

Training iteration loss = 0.0032540632

Training iteration loss = 0.005300131

Training iteration loss = 0.0032510217

Training iteration loss = 0.0031661408

Training iteration loss = 0.003270167

Training iteration loss = 0.0064833225

Training iteration loss = 0.0038869157

Training iteration loss = 0.003403518

Training iteration loss = 0.0025407753

Training iteration loss = 0.0047081853

Training iteration loss = 0.0021376172

Training iteration loss = 0.0024416812

Training iteration loss = 0.0029148923

Training iteration loss = 0.0036695178

Training iteration loss = 0.0028374873

Training iteration loss = 0.0037877539

Training iteration loss = 0.0033821694

Training iteration loss = 0.0019292873

Training iteration loss = 0.002452703

Training iteration loss = 0.0019408284

Training iteration loss = 0.0024480512

Training iteration loss = 0.0020066493

Training iteration loss = 0.0024586706

Training iteration loss = 0.0033584603

Training iteration loss = 0.0033975833

Training iteration loss = 0.0045479177

Training iteration loss = 0.0040928912

Training iteration loss = 0.0040066917

Training iteration loss = 0.0021317399

Training iteration loss = 0.0029741693

Training iteration loss = 0.002198579

Training iteration loss = 0.006044447

Training iteration loss = 0.0035925116

Training iteration loss = 0.0029126245

Training iteration loss = 0.002812678

Training iteration loss = 0.0035900092

Training iteration loss = 0.006994651

Training iteration loss = 0.0023030387

Training iteration loss = 0.0035627976

Training iteration loss = 0.0035842462

Training iteration loss = 0.0023028555

Training iteration loss = 0.0034660324

Training iteration loss = 0.0037029132

Training iteration loss = 0.002689163

Training iteration loss = 0.0025327976

Training iteration loss = 0.0031514382

Training iteration loss = 0.0036377655

Training iteration loss = 0.0035243733

Training iteration loss = 0.0044431626

Training iteration loss = 0.0046833293

Training iteration loss = 0.0032036675

Training iteration loss = 0.0036356912

Training iteration loss = 0.004209706

Training iteration loss = 0.004374359

Training iteration loss = 0.0028025014

Training iteration loss = 0.0036046393

Training iteration loss = 0.0040133256

Training iteration loss = 0.0025391534

Training iteration loss = 0.0021335937

Training iteration loss = 0.003601905

Training iteration loss = 0.002409506

Training iteration loss = 0.0020701864

Training iteration loss = 0.0030593302

Training iteration loss = 0.0022538302

Training iteration loss = 0.0017518577

Training iteration loss = 0.0018411794

Training iteration loss = 0.0031340003

Training iteration loss = 0.0020577118

Training iteration loss = 0.0022646647

Training iteration loss = 0.0038872398

Training iteration loss = 0.005141541

Training iteration loss = 0.0024760438

Training iteration loss = 0.0026831964

Training iteration loss = 0.0023513

Training iteration loss = 0.0025955532

Training iteration loss = 0.0022546835

Training iteration loss = 0.003994349

Training iteration loss = 0.0033379553

Training iteration loss = 0.004959386

Training iteration loss = 0.0038941198

Training iteration loss = 0.0028546415

Training iteration loss = 0.0019537492

Training iteration loss = 0.0020850434

Training iteration loss = 0.008308464

Training iteration loss = 0.0029810788

Training iteration loss = 0.0017704709

Training iteration loss = 0.00426676

Training iteration loss = 0.0037658317

Training iteration loss = 0.0033645164

Training iteration loss = 0.002884033

Training iteration loss = 0.0039203595

Training iteration loss = 0.002241865

Training iteration loss = 0.006430765

Training iteration loss = 0.002564196

Training iteration loss = 0.0034000536

Training iteration loss = 0.0037751757

Training iteration loss = 0.0020736728

Training iteration loss = 0.0020999003

Training iteration loss = 0.0025886006

Training iteration loss = 0.0016220385

Training iteration loss = 0.003277002

Training iteration loss = 0.0031578343

Training iteration loss = 0.004082021

Training iteration loss = 0.0030683756

Training iteration loss = 0.0027631598

Training iteration loss = 0.0023082544

Training iteration loss = 0.002194877

Training iteration loss = 0.002341509

Training iteration loss = 0.0030933733

Training iteration loss = 0.0045814635

Training iteration loss = 0.00180247

Training iteration loss = 0.0029767442

Training iteration loss = 0.0030650664

Training iteration loss = 0.0033372098

Training iteration loss = 0.0028501416

Training iteration loss = 0.0032449283

Training iteration loss = 0.0027850193

Training iteration loss = 0.0017732596

Training iteration loss = 0.005906194

Training iteration loss = 0.0029588165

Training iteration loss = 0.0025647404

Training iteration loss = 0.0018047519

Training iteration loss = 0.0032494457

Training iteration loss = 0.0036146238

Training iteration loss = 0.0036560197

Training iteration loss = 0.0023330024

Training iteration loss = 0.005684819

Training iteration loss = 0.003066724

Training iteration loss = 0.0022558563

Training iteration loss = 0.0020602914

Training iteration loss = 0.0024320302

Training iteration loss = 0.00195955

Training iteration loss = 0.0029650265

Training iteration loss = 0.0017580893

Training iteration loss = 0.001997947

Training iteration loss = 0.0036256372

Training iteration loss = 0.0027504433

Training iteration loss = 0.0033072873

Training iteration loss = 0.0025751109

Training iteration loss = 0.0039178394

Training iteration loss = 0.0041362

Training iteration loss = 0.0041778665

Training iteration loss = 0.0019829946

Training iteration loss = 0.002805189

Training iteration loss = 0.0024037159

Training iteration loss = 0.0036921806

Training iteration loss = 0.003356167

Training iteration loss = 0.0045948606

Training iteration loss = 0.0028547968

Training iteration loss = 0.0024068651

Training iteration loss = 0.0031716293

Training iteration loss = 0.0047110138

Training iteration loss = 0.003203041

Training iteration loss = 0.0027121913

Training iteration loss = 0.003260292

Training iteration loss = 0.0031356176

Training iteration loss = 0.0024008139

Training iteration loss = 0.0024548392

Training iteration loss = 0.0036389136

Training iteration loss = 0.0029793691

Training iteration loss = 0.0030797136

Training iteration loss = 0.0027707343

Training iteration loss = 0.0022561387

Training iteration loss = 0.0044085844

Training iteration loss = 0.0040066275

Training iteration loss = 0.003834762

Training iteration loss = 0.003595616

Training iteration loss = 0.0021869286

Training iteration loss = 0.004505935

Training iteration loss = 0.0055177547

Training iteration loss = 0.0023387454

Training iteration loss = 0.0032273827

Training iteration loss = 0.002357508

Training iteration loss = 0.0026619146

Training iteration loss = 0.00266219

Training iteration loss = 0.002443866

Training iteration loss = 0.004788429

Training iteration loss = 0.0054914006

Training iteration loss = 0.0024925002

Training iteration loss = 0.0028460587

Training iteration loss = 0.0021948114

Training iteration loss = 0.0025721667

Training iteration loss = 0.003342787

Training iteration loss = 0.003190009

Training iteration loss = 0.0036625974

Training iteration loss = 0.0022975202

Training iteration loss = 0.0034886478

Training iteration loss = 0.00711301

Training iteration loss = 0.004601365

Training iteration loss = 0.003705289

Training iteration loss = 0.002917274

Training iteration loss = 0.0034033312

Training iteration loss = 0.0026430574

Training iteration loss = 0.0032945073

Training iteration loss = 0.002097096

Training iteration loss = 0.002507264

Training iteration loss = 0.0025711157

Training iteration loss = 0.0024713937

Training iteration loss = 0.0019640394

Training iteration loss = 0.0045092874

Training iteration loss = 0.0032534685

Training iteration loss = 0.005294508

Training iteration loss = 0.0032488622

Training iteration loss = 0.0031620674

Training iteration loss = 0.0032650866

Training iteration loss = 0.0064684306

Training iteration loss = 0.003882048

Training iteration loss = 0.003399084

Training iteration loss = 0.0025390552

Training iteration loss = 0.0046973075

Training iteration loss = 0.0021354696

Training iteration loss = 0.0024418293

Training iteration loss = 0.002907986

Training iteration loss = 0.003667754

Training iteration loss = 0.002835159

Training iteration loss = 0.003781479

Training iteration loss = 0.0033798786

Training iteration loss = 0.0019306927

Training iteration loss = 0.0024487237

Training iteration loss = 0.0019362597

Training iteration loss = 0.0024478221

Training iteration loss = 0.0020089522

Training iteration loss = 0.0024605503

Training iteration loss = 0.003353461

Training iteration loss = 0.003396739

Training iteration loss = 0.004548115

Training iteration loss = 0.0040910146

Training iteration loss = 0.004011611

Training iteration loss = 0.002127181

Training iteration loss = 0.0029713882

Training iteration loss = 0.0021929045

Training iteration loss = 0.006044324

Training iteration loss = 0.0035959843

Training iteration loss = 0.0029099446

Training iteration loss = 0.0028021534

Training iteration loss = 0.0035798661

Training iteration loss = 0.0070043537

Training iteration loss = 0.0023022033

Training iteration loss = 0.0035627324

Training iteration loss = 0.0035780768

Training iteration loss = 0.0022934456

Training iteration loss = 0.0034523096

Training iteration loss = 0.0037074909

Training iteration loss = 0.0026865357

Training iteration loss = 0.0025371767

Training iteration loss = 0.0031560678

Training iteration loss = 0.0036283887

Training iteration loss = 0.003521557

Training iteration loss = 0.004421128

Training iteration loss = 0.0046766326

Training iteration loss = 0.00318586

Training iteration loss = 0.0036499754

Training iteration loss = 0.0042092763

Training iteration loss = 0.004371665

Training iteration loss = 0.0027980069

Training iteration loss = 0.003620091

Training iteration loss = 0.0040041995

Training iteration loss = 0.0025332738

Training iteration loss = 0.002123345

Training iteration loss = 0.0035965296

Training iteration loss = 0.0023926136

Training iteration loss = 0.0020698577

Training iteration loss = 0.0030727393

Training iteration loss = 0.0022605483

Training iteration loss = 0.0017476184

Training iteration loss = 0.0018368494

Training iteration loss = 0.0031264916

Training iteration loss = 0.0020415268

Training iteration loss = 0.002262542

Training iteration loss = 0.0038934734

Training iteration loss = 0.00514037

Training iteration loss = 0.0024749187

Training iteration loss = 0.002690552

Training iteration loss = 0.0023476097

Training iteration loss = 0.0025933555

Training iteration loss = 0.0022525159

Training iteration loss = 0.0039925035

Training iteration loss = 0.0033395428

Training iteration loss = 0.004954755

Training iteration loss = 0.00389185

Training iteration loss = 0.002848788

Training iteration loss = 0.0019519557

Training iteration loss = 0.0020865577

Training iteration loss = 0.008285593

Training iteration loss = 0.0029645583

Training iteration loss = 0.0017827185

Training iteration loss = 0.0042510377

Training iteration loss = 0.0037705358

Training iteration loss = 0.0033669376

Training iteration loss = 0.0028803817

Training iteration loss = 0.003917678

Training iteration loss = 0.00223569

Training iteration loss = 0.0064258142

Training iteration loss = 0.0025638794

Training iteration loss = 0.003402369

Training iteration loss = 0.003783845

Training iteration loss = 0.0020768943

Training iteration loss = 0.0020980332

Training iteration loss = 0.0025950342

Training iteration loss = 0.0016223261

Training iteration loss = 0.0032773546

Training iteration loss = 0.0031668365

Training iteration loss = 0.0040817596

Training iteration loss = 0.003065468

Training iteration loss = 0.002761726

Training iteration loss = 0.0023079156

Training iteration loss = 0.002196345

Training iteration loss = 0.0023421305

Training iteration loss = 0.0030920142

Training iteration loss = 0.0045823925

Training iteration loss = 0.0018024091

Training iteration loss = 0.0029826623

Training iteration loss = 0.003064426

Training iteration loss = 0.003332868

Training iteration loss = 0.0028473726

Training iteration loss = 0.003243347

Training iteration loss = 0.002790047

Training iteration loss = 0.001772025

Training iteration loss = 0.0058951564

Training iteration loss = 0.002960992

Training iteration loss = 0.002560302

Training iteration loss = 0.0018002022

Training iteration loss = 0.003242457

Training iteration loss = 0.0036130606

Training iteration loss = 0.0036596789

Training iteration loss = 0.0023322676

Training iteration loss = 0.0056868396

Training iteration loss = 0.0030664764

Training iteration loss = 0.0022566058

Training iteration loss = 0.0020630725

Training iteration loss = 0.002431432

Training iteration loss = 0.0019571849

Training iteration loss = 0.0029564826

Training iteration loss = 0.0017547702

Training iteration loss = 0.0019974723

Training iteration loss = 0.0036310765

Training iteration loss = 0.0027403878

Training iteration loss = 0.003300085

Training iteration loss = 0.0025700938

Training iteration loss = 0.0039088274

Training iteration loss = 0.0041360953

Training iteration loss = 0.0041690664

Training iteration loss = 0.0019819182

Training iteration loss = 0.0027990004

Training iteration loss = 0.0024029296

Training iteration loss = 0.0036910465

Training iteration loss = 0.0033499764

Training iteration loss = 0.004582837

Training iteration loss = 0.0028538555

Training iteration loss = 0.002404712

Training iteration loss = 0.003168341

Training iteration loss = 0.004710417

Training iteration loss = 0.0032048058

Training iteration loss = 0.0027158346

Training iteration loss = 0.0032532278

Training iteration loss = 0.003127469

Training iteration loss = 0.0023938927

Training iteration loss = 0.002444561

Training iteration loss = 0.0036422622

Training iteration loss = 0.0029780695

Training iteration loss = 0.0030814037

Training iteration loss = 0.0027770603

Training iteration loss = 0.00225047

Training iteration loss = 0.004401075

Training iteration loss = 0.0039698756

Training iteration loss = 0.0038399112

Training iteration loss = 0.0035744691

Training iteration loss = 0.0021829975

Training iteration loss = 0.004510667

Training iteration loss = 0.0055158236

Training iteration loss = 0.0023314222

Training iteration loss = 0.0032232413

Training iteration loss = 0.0023577076

Training iteration loss = 0.0026618473

Training iteration loss = 0.002660976

Training iteration loss = 0.0024432712

Training iteration loss = 0.0047783125

Training iteration loss = 0.005477389

Training iteration loss = 0.002489804

Training iteration loss = 0.0028469365

Training iteration loss = 0.0021951913

Training iteration loss = 0.0025702866

Training iteration loss = 0.003340192

Training iteration loss = 0.0031888364

Training iteration loss = 0.0036636607

Training iteration loss = 0.002299355

Training iteration loss = 0.0034866876

Training iteration loss = 0.0071104565

Training iteration loss = 0.0045991703

Training iteration loss = 0.003703285

Training iteration loss = 0.002914398

Training iteration loss = 0.003402015

Training iteration loss = 0.0026408897

Training iteration loss = 0.0032924113

Training iteration loss = 0.0020937847

Training iteration loss = 0.002505739

Training iteration loss = 0.0025661043

Training iteration loss = 0.0024561004

Training iteration loss = 0.0019633085

Training iteration loss = 0.0045103915

Training iteration loss = 0.0032546185

Training iteration loss = 0.0052897427

Training iteration loss = 0.003247836

Training iteration loss = 0.0031596653

Training iteration loss = 0.0032632134

Training iteration loss = 0.006453319

Training iteration loss = 0.0038790097

Training iteration loss = 0.0033961702

Training iteration loss = 0.0025385998

Training iteration loss = 0.0046829996

Training iteration loss = 0.0021320663

Training iteration loss = 0.0024443255

Training iteration loss = 0.0029027052

Training iteration loss = 0.0036682906

Training iteration loss = 0.0028310856

Training iteration loss = 0.0037743852

Training iteration loss = 0.003376513

Training iteration loss = 0.0019334086

Training iteration loss = 0.0024475858

Training iteration loss = 0.0019286876

Training iteration loss = 0.0024459949

Training iteration loss = 0.0020098004

Training iteration loss = 0.002463035

Training iteration loss = 0.0033457

Training iteration loss = 0.0033902347

Training iteration loss = 0.0045472244

Training iteration loss = 0.004089723

Training iteration loss = 0.0040061423

Training iteration loss = 0.0021244257

Training iteration loss = 0.0029672887

Training iteration loss = 0.0021916057

Training iteration loss = 0.0060410015

Training iteration loss = 0.0035938455

Training iteration loss = 0.002907647

Training iteration loss = 0.002794762

Training iteration loss = 0.0035764656

Training iteration loss = 0.0069970316

Training iteration loss = 0.0023040494

Training iteration loss = 0.0035607703

Training iteration loss = 0.0035790233

Training iteration loss = 0.0022946873

Training iteration loss = 0.003452411

Training iteration loss = 0.003711805

Training iteration loss = 0.0026866794

Training iteration loss = 0.0025402533

Training iteration loss = 0.0031581612

Training iteration loss = 0.003621243

Training iteration loss = 0.0035153457

Training iteration loss = 0.0044036084

Training iteration loss = 0.004675001

Training iteration loss = 0.0031832948

Training iteration loss = 0.0036494648

Training iteration loss = 0.0041960985

Training iteration loss = 0.0043677115

Training iteration loss = 0.0027984332

Training iteration loss = 0.0036162436

Training iteration loss = 0.003994415

Training iteration loss = 0.0025301285

Training iteration loss = 0.00212166

Training iteration loss = 0.003595426

Training iteration loss = 0.002385767

Training iteration loss = 0.002065458

Training iteration loss = 0.0030787995

Training iteration loss = 0.0022664329

Training iteration loss = 0.0017452916

Training iteration loss = 0.0018374954

Training iteration loss = 0.0031251071

Training iteration loss = 0.002038722

Training iteration loss = 0.0022604465

Training iteration loss = 0.0038846778

Training iteration loss = 0.005123661

Training iteration loss = 0.0024747315

Training iteration loss = 0.0026954187

Training iteration loss = 0.00235362

Training iteration loss = 0.0025878476

Training iteration loss = 0.0022523662

Training iteration loss = 0.0039890627

Training iteration loss = 0.0033365693

Training iteration loss = 0.004956642

Training iteration loss = 0.003891188

Training iteration loss = 0.0028458254

Training iteration loss = 0.0019523032

Training iteration loss = 0.0020873605

Training iteration loss = 0.008260416

Training iteration loss = 0.0029579296

Training iteration loss = 0.0017833369

Training iteration loss = 0.004247651

Training iteration loss = 0.003775278

Training iteration loss = 0.003366283

Training iteration loss = 0.002881377

Training iteration loss = 0.0039151865

Training iteration loss = 0.0022305108

Training iteration loss = 0.0064132456

Training iteration loss = 0.0025627532

Training iteration loss = 0.0034022275

Training iteration loss = 0.003784646

Training iteration loss = 0.0020714204

Training iteration loss = 0.0020930723

Training iteration loss = 0.0025891655

Training iteration loss = 0.0016225856

Training iteration loss = 0.003278063

Training iteration loss = 0.0031624464

Training iteration loss = 0.0040735453

Training iteration loss = 0.0030633637

Training iteration loss = 0.0027611835

Training iteration loss = 0.0023064462

Training iteration loss = 0.002191224

Training iteration loss = 0.0023401256

Training iteration loss = 0.0030904792

Training iteration loss = 0.0045675244

Training iteration loss = 0.0018016902

Training iteration loss = 0.002979227

Training iteration loss = 0.0030631332

Training iteration loss = 0.0033299166

Training iteration loss = 0.0028453693

Training iteration loss = 0.0032418761

Training iteration loss = 0.002790075

Training iteration loss = 0.0017708185

Training iteration loss = 0.005881492

Training iteration loss = 0.002960547

Training iteration loss = 0.002560175

Training iteration loss = 0.0018036998

Training iteration loss = 0.0032383173

Training iteration loss = 0.0036099935

Training iteration loss = 0.0036550418

Training iteration loss = 0.0023308028

Training iteration loss = 0.005678078

Training iteration loss = 0.0030654392

Training iteration loss = 0.0022602475

Training iteration loss = 0.0020668057

Training iteration loss = 0.002434636

Training iteration loss = 0.001956671

Training iteration loss = 0.0029492744

Training iteration loss = 0.0017572902

Training iteration loss = 0.0019888212

Training iteration loss = 0.0036131826

Training iteration loss = 0.002734049

Training iteration loss = 0.003292529

Training iteration loss = 0.0025705316

Training iteration loss = 0.0039109974

Training iteration loss = 0.004135224

Training iteration loss = 0.0041694944

Training iteration loss = 0.0019759685

Training iteration loss = 0.0027965095

Training iteration loss = 0.0023908585

Training iteration loss = 0.0036816888

Training iteration loss = 0.003352349

Training iteration loss = 0.004572057

Training iteration loss = 0.002853026

Training iteration loss = 0.0024105052

Training iteration loss = 0.0031784151

Training iteration loss = 0.004701376

Training iteration loss = 0.003205113

Training iteration loss = 0.0027200805

Training iteration loss = 0.0032470895

Training iteration loss = 0.0031280902

Training iteration loss = 0.002398312

Training iteration loss = 0.0024377806

Training iteration loss = 0.0036467777

Training iteration loss = 0.0029784087

Training iteration loss = 0.0030824894

Training iteration loss = 0.0027781336

Training iteration loss = 0.0022512341

Training iteration loss = 0.004397853

Training iteration loss = 0.0039637918

Training iteration loss = 0.0038310003

Training iteration loss = 0.0035735045

Training iteration loss = 0.002181128

Training iteration loss = 0.0044988417

Training iteration loss = 0.0055172904

Training iteration loss = 0.0023297956

Training iteration loss = 0.0032065092

Training iteration loss = 0.0023505373

Training iteration loss = 0.0026645951

Training iteration loss = 0.0026599707

Training iteration loss = 0.0024379396

Training iteration loss = 0.004776025

Training iteration loss = 0.0054619927

Training iteration loss = 0.0024877386

Training iteration loss = 0.0028486627

Training iteration loss = 0.0021966835

Training iteration loss = 0.0025677737

Training iteration loss = 0.003335968

Training iteration loss = 0.0031904534

Training iteration loss = 0.0036634326

Training iteration loss = 0.002297424

Training iteration loss = 0.003488144

Training iteration loss = 0.007119508

Training iteration loss = 0.0045921463

Training iteration loss = 0.0036961893

Training iteration loss = 0.0029103344

Training iteration loss = 0.0033979819

Training iteration loss = 0.0026434474

Training iteration loss = 0.0032895552

Training iteration loss = 0.0020927524

Training iteration loss = 0.0025048358

Training iteration loss = 0.002563024

Training iteration loss = 0.0024518413

Training iteration loss = 0.0019597553

Training iteration loss = 0.004510682

Training iteration loss = 0.003251466

Training iteration loss = 0.0052861385

Training iteration loss = 0.0032540075

Training iteration loss = 0.0031611898

Training iteration loss = 0.0032651613

Training iteration loss = 0.0064395107

Training iteration loss = 0.0038730695

Training iteration loss = 0.0033979965

Training iteration loss = 0.002534888

Training iteration loss = 0.0046593794

Training iteration loss = 0.002129187

Training iteration loss = 0.0024433236

Training iteration loss = 0.0029073923

Training iteration loss = 0.0036690657

Training iteration loss = 0.002825612

Training iteration loss = 0.0037759412

Training iteration loss = 0.0033710434

Training iteration loss = 0.0019313722

Training iteration loss = 0.002443358

Training iteration loss = 0.0019266759

Training iteration loss = 0.002439412

Training iteration loss = 0.0019989882

Training iteration loss = 0.002456853

Training iteration loss = 0.0033442585

Training iteration loss = 0.0033809582

Training iteration loss = 0.0045416113

Training iteration loss = 0.004090891

Training iteration loss = 0.0039936285

Training iteration loss = 0.0021213992

Training iteration loss = 0.0029660715

Training iteration loss = 0.002194204

Training iteration loss = 0.0060471743

Training iteration loss = 0.003588055

Training iteration loss = 0.0029113349

Training iteration loss = 0.00280026

Training iteration loss = 0.003585053

Training iteration loss = 0.0069755907

Training iteration loss = 0.002307907

Training iteration loss = 0.0035546469

Training iteration loss = 0.0035856394

Training iteration loss = 0.0023056862

Training iteration loss = 0.0034608648

Training iteration loss = 0.0037093137

Training iteration loss = 0.0026816993

Training iteration loss = 0.0025259976

Training iteration loss = 0.0031373587

Training iteration loss = 0.003606691

Training iteration loss = 0.0034974155

Training iteration loss = 0.004429693

Training iteration loss = 0.004672781

Training iteration loss = 0.0031960316

Training iteration loss = 0.0036295864

Training iteration loss = 0.0041874284

Training iteration loss = 0.0043429895

Training iteration loss = 0.0027895703

Training iteration loss = 0.003610041

Training iteration loss = 0.003997719

Training iteration loss = 0.0025377634

Training iteration loss = 0.0021292686

Training iteration loss = 0.0035971005

Training iteration loss = 0.0023824621

Training iteration loss = 0.0020608867

Training iteration loss = 0.0030770302

Training iteration loss = 0.002259149

Training iteration loss = 0.0017406399

Training iteration loss = 0.0018444668

Training iteration loss = 0.0031339016

Training iteration loss = 0.002046587

Training iteration loss = 0.0022536174

Training iteration loss = 0.0038746598

Training iteration loss = 0.005127434

Training iteration loss = 0.002466471

Training iteration loss = 0.002680816

Training iteration loss = 0.0023532275

Training iteration loss = 0.0025910728

Training iteration loss = 0.0022450238

Training iteration loss = 0.003984044

Training iteration loss = 0.0033310652

Training iteration loss = 0.0049558864

Training iteration loss = 0.0038913488

Training iteration loss = 0.0028320148

Training iteration loss = 0.0019479421

Training iteration loss = 0.002087201

Training iteration loss = 0.008260104

Training iteration loss = 0.0029588456

Training iteration loss = 0.0017785209

Training iteration loss = 0.0042395093

Training iteration loss = 0.0037760306

Training iteration loss = 0.0033703232

Training iteration loss = 0.0028762713

Training iteration loss = 0.003915139

Training iteration loss = 0.002226156

Training iteration loss = 0.006397961

Training iteration loss = 0.0025589631

Training iteration loss = 0.003401819

Training iteration loss = 0.0037868733

Training iteration loss = 0.0020677417

Training iteration loss = 0.0020937058

Training iteration loss = 0.0025930272

Training iteration loss = 0.0016208024

Training iteration loss = 0.0032719222

Training iteration loss = 0.0031555053

Training iteration loss = 0.004061284

Training iteration loss = 0.0030655349

Training iteration loss = 0.0027566329

Training iteration loss = 0.0023098628

Training iteration loss = 0.0021884518

Training iteration loss = 0.002346021

Training iteration loss = 0.0030899846

Training iteration loss = 0.0045586345

Training iteration loss = 0.0018019328

Training iteration loss = 0.0029736646

Training iteration loss = 0.0030630373

Training iteration loss = 0.00332571

Training iteration loss = 0.002847499

Training iteration loss = 0.003241453

Training iteration loss = 0.0027968872

Training iteration loss = 0.0017703274

Training iteration loss = 0.005879406

Training iteration loss = 0.0029586165

Training iteration loss = 0.002562876

Training iteration loss = 0.0017992441

Training iteration loss = 0.00323017

Training iteration loss = 0.0036043718

Training iteration loss = 0.0036520746

Training iteration loss = 0.0023250699

Training iteration loss = 0.005675726

Training iteration loss = 0.0030598824

Training iteration loss = 0.0022534037

Training iteration loss = 0.0020630423

Training iteration loss = 0.0024336695

Training iteration loss = 0.0019555858

Training iteration loss = 0.00294168

Training iteration loss = 0.0017568207

Training iteration loss = 0.0019903835

Training iteration loss = 0.0036216436

Training iteration loss = 0.0027320113

Training iteration loss = 0.0032952428

Training iteration loss = 0.0025691576

Training iteration loss = 0.0039077895

Training iteration loss = 0.0041338736

Training iteration loss = 0.0041561457

Training iteration loss = 0.001971166

Training iteration loss = 0.0027964048

Training iteration loss = 0.0023939167

Training iteration loss = 0.003681047

Training iteration loss = 0.0033485144

Training iteration loss = 0.004565581

Training iteration loss = 0.002849676

Training iteration loss = 0.0023988264

Training iteration loss = 0.0031781755

Training iteration loss = 0.0047022807

Training iteration loss = 0.003198305

Training iteration loss = 0.0027195467

Training iteration loss = 0.003252574

Training iteration loss = 0.0031268827

Training iteration loss = 0.0023983766

Training iteration loss = 0.002443998

Training iteration loss = 0.0036356729

Training iteration loss = 0.0029773063

Training iteration loss = 0.0030747496

Training iteration loss = 0.0027757671

Training iteration loss = 0.002248957

Training iteration loss = 0.004393124

Training iteration loss = 0.003973087

Training iteration loss = 0.0038332578

Training iteration loss = 0.0035699748

Training iteration loss = 0.0021820266

Training iteration loss = 0.004504411

Training iteration loss = 0.0055136285

Training iteration loss = 0.0023268275

Training iteration loss = 0.003212956

Training iteration loss = 0.0023484698

Training iteration loss = 0.0026609497

Training iteration loss = 0.0026579339

Training iteration loss = 0.0024396603

Training iteration loss = 0.004774216

Training iteration loss = 0.005448651

Training iteration loss = 0.0024874725

Training iteration loss = 0.0028485123

Training iteration loss = 0.0021996682

Training iteration loss = 0.0025633348

Training iteration loss = 0.003340753

Training iteration loss = 0.003189236

Training iteration loss = 0.003660599

Training iteration loss = 0.0022969595

Training iteration loss = 0.003484893

Training iteration loss = 0.0070982724

Training iteration loss = 0.004591752

Training iteration loss = 0.003690928

Training iteration loss = 0.002910176

Training iteration loss = 0.0033977155

Training iteration loss = 0.0026456388

Training iteration loss = 0.0032936502

Training iteration loss = 0.0020942413

Training iteration loss = 0.0025067786

Training iteration loss = 0.0025676908

Training iteration loss = 0.0024518

Training iteration loss = 0.0019589805

Training iteration loss = 0.004515665

Training iteration loss = 0.0032438051

Training iteration loss = 0.005281407

Training iteration loss = 0.003263883

Training iteration loss = 0.0031633943

Training iteration loss = 0.0032358887

Training iteration loss = 0.0064301374

Training iteration loss = 0.0038733731

Training iteration loss = 0.0033984259

Training iteration loss = 0.0025385926

Training iteration loss = 0.0046528564

Training iteration loss = 0.0021244439

Training iteration loss = 0.0024495758

Training iteration loss = 0.0029053593

Training iteration loss = 0.0036653199

Training iteration loss = 0.0028264823

Training iteration loss = 0.003771784

Training iteration loss = 0.0033707188

Training iteration loss = 0.0019367402

Training iteration loss = 0.0024448805

Training iteration loss = 0.0019357476

Training iteration loss = 0.0024510727

Training iteration loss = 0.0020068993

Training iteration loss = 0.0024563184

Training iteration loss = 0.00335023

Training iteration loss = 0.0033877045

Training iteration loss = 0.0045505003

Training iteration loss = 0.004100056

Training iteration loss = 0.003994959

Training iteration loss = 0.0021199172

Training iteration loss = 0.0029615008

Training iteration loss = 0.0021895713

Training iteration loss = 0.006039874

Training iteration loss = 0.003580706

Training iteration loss = 0.002914362

Training iteration loss = 0.0028012078

Training iteration loss = 0.003580276

Training iteration loss = 0.006963926

Training iteration loss = 0.0023024783

Training iteration loss = 0.0035492682

Training iteration loss = 0.0035822636

Training iteration loss = 0.0022988147

Training iteration loss = 0.0034574494

Training iteration loss = 0.003707647

Training iteration loss = 0.002675235

Training iteration loss = 0.0025276225

Training iteration loss = 0.0031383794

Training iteration loss = 0.003610189

Training iteration loss = 0.0035000083

Training iteration loss = 0.004421029

Training iteration loss = 0.004675405

Training iteration loss = 0.0031927843

Training iteration loss = 0.0036269042

Training iteration loss = 0.0041832305

Training iteration loss = 0.004344733

Training iteration loss = 0.002794755

Training iteration loss = 0.003609515

Training iteration loss = 0.003990177

Training iteration loss = 0.0025296232

Training iteration loss = 0.0021260215

Training iteration loss = 0.0035976318

Training iteration loss = 0.0023852815

Training iteration loss = 0.0020559025

Training iteration loss = 0.0030729845

Training iteration loss = 0.0022582503

Training iteration loss = 0.0017388985

Training iteration loss = 0.0018416807

Training iteration loss = 0.00313373

Training iteration loss = 0.002041805

Training iteration loss = 0.0022544882

Training iteration loss = 0.0038719752

Training iteration loss = 0.005112821

Training iteration loss = 0.0024691776

Training iteration loss = 0.0026838388

Training iteration loss = 0.0023555162

Training iteration loss = 0.0025877275

Training iteration loss = 0.0022496562

Training iteration loss = 0.003981034

Training iteration loss = 0.0033286402

Training iteration loss = 0.004953565

Training iteration loss = 0.0038857916

Training iteration loss = 0.0028300087

Training iteration loss = 0.0019445908

Training iteration loss = 0.002084465

Training iteration loss = 0.008242057

Training iteration loss = 0.0029550828

Training iteration loss = 0.0017712286

Training iteration loss = 0.0042409077

Training iteration loss = 0.003777193

Training iteration loss = 0.0033686887

Training iteration loss = 0.0028774263

Training iteration loss = 0.003910652

Training iteration loss = 0.0022237059

Training iteration loss = 0.006396591

Training iteration loss = 0.0025628184

Training iteration loss = 0.0034016632

Training iteration loss = 0.0037853562

Training iteration loss = 0.0020667217

Training iteration loss = 0.002089889

Training iteration loss = 0.0025878719

Training iteration loss = 0.001617374

Training iteration loss = 0.0032665276

Training iteration loss = 0.0031544592

Training iteration loss = 0.0040616114

Training iteration loss = 0.0030682797

Training iteration loss = 0.0027512906

Training iteration loss = 0.0023106372

Training iteration loss = 0.0021894479

Training iteration loss = 0.0023414688

Training iteration loss = 0.0030834237

Training iteration loss = 0.004551866

Training iteration loss = 0.0018000557

Training iteration loss = 0.0029733106

Training iteration loss = 0.0030646014

Training iteration loss = 0.0033221592

Training iteration loss = 0.002844396

Training iteration loss = 0.0032398256

Training iteration loss = 0.0027991002

Training iteration loss = 0.0017697937

Training iteration loss = 0.005881667

Training iteration loss = 0.0029600665

Training iteration loss = 0.0025697157

Training iteration loss = 0.001799391

Training iteration loss = 0.0032264302

Training iteration loss = 0.0036041776

Training iteration loss = 0.0036430887

Training iteration loss = 0.0023254761

Training iteration loss = 0.0056573506

Training iteration loss = 0.003060866

Training iteration loss = 0.0022611658

Training iteration loss = 0.0020673247

Training iteration loss = 0.0024358

Training iteration loss = 0.001953156

Training iteration loss = 0.0029322365

Training iteration loss = 0.0017570615

Training iteration loss = 0.0019931986

Training iteration loss = 0.0036205018

Training iteration loss = 0.0027265155

Training iteration loss = 0.0032887121

Training iteration loss = 0.0025667811

Training iteration loss = 0.003911384

Training iteration loss = 0.0041311686

Training iteration loss = 0.004147026

Training iteration loss = 0.0019694408

Training iteration loss = 0.002794395

Training iteration loss = 0.0023917968

Training iteration loss = 0.003674633

Training iteration loss = 0.003343735

Training iteration loss = 0.004554571

Training iteration loss = 0.0028506306

Training iteration loss = 0.0023986523

Training iteration loss = 0.0031812114

Training iteration loss = 0.004698884

Training iteration loss = 0.0031968902

Training iteration loss = 0.002721506

Training iteration loss = 0.003249617

Training iteration loss = 0.0031260888

Training iteration loss = 0.0023991794

Training iteration loss = 0.0024395734

Training iteration loss = 0.0036367902

Training iteration loss = 0.0029765174

Training iteration loss = 0.0030734113

Training iteration loss = 0.0027776172

Training iteration loss = 0.002247078

Training iteration loss = 0.0043884274

Training iteration loss = 0.0039594364

Training iteration loss = 0.003831719

Training iteration loss = 0.0035584664

Training iteration loss = 0.0021807055

Training iteration loss = 0.004504239

Training iteration loss = 0.0055137877

Training iteration loss = 0.0023240522

Training iteration loss = 0.0032062642

Training iteration loss = 0.002345101

Training iteration loss = 0.002662943

Training iteration loss = 0.0026556773

Training iteration loss = 0.0024405736

Training iteration loss = 0.004768517

Training iteration loss = 0.0054340796

Training iteration loss = 0.0024866157

Training iteration loss = 0.0028509304

Training iteration loss = 0.0022019304

Training iteration loss = 0.002560145

Training iteration loss = 0.003340574

Training iteration loss = 0.0031901568

Training iteration loss = 0.003660397

Training iteration loss = 0.0022971188

Training iteration loss = 0.0034836282

Training iteration loss = 0.0070985015

Training iteration loss = 0.0045904205

Training iteration loss = 0.0036855408

Training iteration loss = 0.0029075807

Training iteration loss = 0.0033965085

Training iteration loss = 0.0026436595

Training iteration loss = 0.0032907035

Training iteration loss = 0.0020914536

Training iteration loss = 0.0025039623

Training iteration loss = 0.002563269

Training iteration loss = 0.0024427413

Training iteration loss = 0.001956487

Training iteration loss = 0.0045164605

Training iteration loss = 0.0032441888

Training iteration loss = 0.0052778893

Training iteration loss = 0.0032639496

Training iteration loss = 0.0031610152

Training iteration loss = 0.003228741

Training iteration loss = 0.0064175255

Training iteration loss = 0.0038713673

Training iteration loss = 0.003395346

Training iteration loss = 0.0025366265

Training iteration loss = 0.004644628

Training iteration loss = 0.0021227764

Training iteration loss = 0.0024509162

Training iteration loss = 0.0029000137

Training iteration loss = 0.0036653068

Training iteration loss = 0.0028246772

Training iteration loss = 0.0037680834

Training iteration loss = 0.003369555

Training iteration loss = 0.0019406821

Training iteration loss = 0.0024427867

Training iteration loss = 0.0019317066

Training iteration loss = 0.0024507863

Training iteration loss = 0.0020085543

Training iteration loss = 0.002458492

Training iteration loss = 0.0033468232

Training iteration loss = 0.0033829724

Training iteration loss = 0.004548051

Training iteration loss = 0.004095839

Training iteration loss = 0.0039965976

Training iteration loss = 0.0021162138

Training iteration loss = 0.0029600908

Training iteration loss = 0.0021863768

Training iteration loss = 0.006032152

Training iteration loss = 0.0035792228

Training iteration loss = 0.0029138017

Training iteration loss = 0.0027959486

Training iteration loss = 0.0035803567

Training iteration loss = 0.006959231

Training iteration loss = 0.0023036916

Training iteration loss = 0.0035478391

Training iteration loss = 0.0035827402

Training iteration loss = 0.0022960769

Training iteration loss = 0.0034520337

Training iteration loss = 0.0037103284

Training iteration loss = 0.0026732094

Training iteration loss = 0.0025263487

Training iteration loss = 0.0031390649

Training iteration loss = 0.0035966716

Training iteration loss = 0.0034911025

Training iteration loss = 0.00440604

Training iteration loss = 0.0046680383

Training iteration loss = 0.0031882015

Training iteration loss = 0.003638016

Training iteration loss = 0.0041789557

Training iteration loss = 0.004338436

Training iteration loss = 0.002785078

Training iteration loss = 0.0036019862

Training iteration loss = 0.0039867656

Training iteration loss = 0.0025267524

Training iteration loss = 0.0021246788

Training iteration loss = 0.0035949436

Training iteration loss = 0.0023769918

Training iteration loss = 0.0020524396

Training iteration loss = 0.003074741

Training iteration loss = 0.0022614805

Training iteration loss = 0.0017369017

Training iteration loss = 0.0018403134

Training iteration loss = 0.003132146

Training iteration loss = 0.002039423

Training iteration loss = 0.0022581033

Training iteration loss = 0.0038710579

Training iteration loss = 0.005107331

Training iteration loss = 0.0024697322

Training iteration loss = 0.0026832663

Training iteration loss = 0.0023539711

Training iteration loss = 0.0025835356

Training iteration loss = 0.0022533021

Training iteration loss = 0.003979201

Training iteration loss = 0.003326567

Training iteration loss = 0.004952591

Training iteration loss = 0.0038867146

Training iteration loss = 0.002822063

Training iteration loss = 0.0019409548

Training iteration loss = 0.0020802827

Training iteration loss = 0.00822609

Training iteration loss = 0.002952065

Training iteration loss = 0.0017656783

Training iteration loss = 0.004244504

Training iteration loss = 0.0037767955

Training iteration loss = 0.0033667677

Training iteration loss = 0.0028769132

Training iteration loss = 0.003909256

Training iteration loss = 0.0022266645

Training iteration loss = 0.0063898023

Training iteration loss = 0.0025641483

Training iteration loss = 0.0034019712

Training iteration loss = 0.0037874987

Training iteration loss = 0.002066372

Training iteration loss = 0.0020903978

Training iteration loss = 0.0025900842

Training iteration loss = 0.0016165838

Training iteration loss = 0.0032637615

Training iteration loss = 0.0031551532

Training iteration loss = 0.004055808

Training iteration loss = 0.003069441

Training iteration loss = 0.002752432

Training iteration loss = 0.002311683

Training iteration loss = 0.0021867675

Training iteration loss = 0.0023447524

Training iteration loss = 0.003082943

Training iteration loss = 0.004548291

Training iteration loss = 0.0018002097

Training iteration loss = 0.0029702887

Training iteration loss = 0.0030620133

Training iteration loss = 0.0033192178

Training iteration loss = 0.0028480308

Training iteration loss = 0.0032391797

Training iteration loss = 0.0028026681

Training iteration loss = 0.0017699568

Training iteration loss = 0.0058844984

Training iteration loss = 0.002957402

Training iteration loss = 0.0025682978

Training iteration loss = 0.0017929511

Training iteration loss = 0.0032192068

Training iteration loss = 0.0035980372

Training iteration loss = 0.0036456008

Training iteration loss = 0.00231891

Training iteration loss = 0.0056650867

Training iteration loss = 0.0030546666

Training iteration loss = 0.0022533021

Training iteration loss = 0.002061014

Training iteration loss = 0.0024309296

Training iteration loss = 0.001949757

Training iteration loss = 0.0029252598

Training iteration loss = 0.001752216

Training iteration loss = 0.0019964327

Training iteration loss = 0.003635116

Training iteration loss = 0.0027244652

Training iteration loss = 0.0032931797

Training iteration loss = 0.0025678712

Training iteration loss = 0.0038997687

Training iteration loss = 0.0041322336

Training iteration loss = 0.004130341

Training iteration loss = 0.0019647642

Training iteration loss = 0.0027938283

Training iteration loss = 0.0023969815

Training iteration loss = 0.003673936

Training iteration loss = 0.0033411924

Training iteration loss = 0.004543743

Training iteration loss = 0.0028472673

Training iteration loss = 0.002383509

Training iteration loss = 0.0031777043

Training iteration loss = 0.0047004265

Training iteration loss = 0.003191647

Training iteration loss = 0.002724101

Training iteration loss = 0.003253111

Training iteration loss = 0.0031256604

Training iteration loss = 0.0023975621

Training iteration loss = 0.0024469213

Training iteration loss = 0.0036276495

Training iteration loss = 0.0029780334

Training iteration loss = 0.0030666527

Training iteration loss = 0.002776715

Training iteration loss = 0.0022444527

Training iteration loss = 0.004382081

Training iteration loss = 0.0039649024

Training iteration loss = 0.0038373948

Training iteration loss = 0.0035534725

Training iteration loss = 0.0021799614

Training iteration loss = 0.004505647

Training iteration loss = 0.0055049756

Training iteration loss = 0.0023157063

Training iteration loss = 0.0032104896

Training iteration loss = 0.0023426411

Training iteration loss = 0.002656634

Training iteration loss = 0.002655015

Training iteration loss = 0.0024460747

Training iteration loss = 0.004764424

Training iteration loss = 0.0054123513

Training iteration loss = 0.00248438

Training iteration loss = 0.0028507325

Training iteration loss = 0.0022050925

Training iteration loss = 0.002556945

Training iteration loss = 0.003342983

Training iteration loss = 0.0031893596

Training iteration loss = 0.0036597494

Training iteration loss = 0.0022937818

Training iteration loss = 0.0034812104

Training iteration loss = 0.007080398

Training iteration loss = 0.004589754

Training iteration loss = 0.003681048

Training iteration loss = 0.002908499

Training iteration loss = 0.0033964235

Training iteration loss = 0.0026475003

Training iteration loss = 0.0032971555

Training iteration loss = 0.0020938676

Training iteration loss = 0.002508708

Training iteration loss = 0.0025687723

Training iteration loss = 0.0024446577

Training iteration loss = 0.0019572543

Training iteration loss = 0.004521437

Training iteration loss = 0.003236743

Training iteration loss = 0.005270798

Training iteration loss = 0.0032749411

Training iteration loss = 0.0031646763

Training iteration loss = 0.0032029662

Training iteration loss = 0.0064082886

Training iteration loss = 0.003874943

Training iteration loss = 0.0033960529

Training iteration loss = 0.0025404715

Training iteration loss = 0.004632632

Training iteration loss = 0.002117022

Training iteration loss = 0.0024585214

Training iteration loss = 0.002898385

Training iteration loss = 0.0036642526

Training iteration loss = 0.0028242664

Training iteration loss = 0.0037654452

Training iteration loss = 0.0033676568

Training iteration loss = 0.0019420199

Training iteration loss = 0.0024487907

Training iteration loss = 0.0019394696

Training iteration loss = 0.0024572622

Training iteration loss = 0.0020110325

Training iteration loss = 0.002457054

Training iteration loss = 0.0033522602

Training iteration loss = 0.0033845287

Training iteration loss = 0.004555905

Training iteration loss = 0.0041105556

Training iteration loss = 0.0039963746

Training iteration loss = 0.0021160238

Training iteration loss = 0.0029584598

Training iteration loss = 0.0021843023

Training iteration loss = 0.00603809

Training iteration loss = 0.0035788373

Training iteration loss = 0.0029155314

Training iteration loss = 0.002792147

Training iteration loss = 0.0035753127

Training iteration loss = 0.006966327

Training iteration loss = 0.0023013814

Training iteration loss = 0.0035438444

Training iteration loss = 0.0035759956

Training iteration loss = 0.0022898614

Training iteration loss = 0.0034459059

Training iteration loss = 0.0037080513

Training iteration loss = 0.0026650734

Training iteration loss = 0.0025292684

Training iteration loss = 0.0031367627

Training iteration loss = 0.0035968504

Training iteration loss = 0.0034944045

Training iteration loss = 0.0044084447

Training iteration loss = 0.004671506

Training iteration loss = 0.003183771

Training iteration loss = 0.0036391926

Training iteration loss = 0.004177596

Training iteration loss = 0.0043365913

Training iteration loss = 0.002784226

Training iteration loss = 0.0036128408

Training iteration loss = 0.003983664

Training iteration loss = 0.0025284875

Training iteration loss = 0.002125585

Training iteration loss = 0.0035893584

Training iteration loss = 0.0023764982

Training iteration loss = 0.0020464566

Training iteration loss = 0.0030838565

Training iteration loss = 0.0022632696

Training iteration loss = 0.001734489

Training iteration loss = 0.0018420013

Training iteration loss = 0.0031343375

Training iteration loss = 0.0020325633

Training iteration loss = 0.002253698

Training iteration loss = 0.0038673796

Training iteration loss = 0.0051049157

Training iteration loss = 0.0024675445

Training iteration loss = 0.00268133

Training iteration loss = 0.0023556303

Training iteration loss = 0.002587016

Training iteration loss = 0.0022482963

Training iteration loss = 0.0039778375

Training iteration loss = 0.0033258488

Training iteration loss = 0.0049467166

Training iteration loss = 0.0038837625

Training iteration loss = 0.0028177546

Training iteration loss = 0.0019380291

Training iteration loss = 0.0020800882

Training iteration loss = 0.008207974

Training iteration loss = 0.0029458469

Training iteration loss = 0.0017707814

Training iteration loss = 0.00423398

Training iteration loss = 0.0037807857

Training iteration loss = 0.003367922

Training iteration loss = 0.0028786885

Training iteration loss = 0.003906384

Training iteration loss = 0.002223298

Training iteration loss = 0.006385287

Training iteration loss = 0.0025647609

Training iteration loss = 0.0034025237

Training iteration loss = 0.0037903532

Training iteration loss = 0.002066769

Training iteration loss = 0.0020894927

Training iteration loss = 0.002592323

Training iteration loss = 0.0016173915

Training iteration loss = 0.003262533

Training iteration loss = 0.0031538412

Training iteration loss = 0.004051642

Training iteration loss = 0.003068948

Training iteration loss = 0.002749879

Training iteration loss = 0.0023112295

Training iteration loss = 0.0021873005

Training iteration loss = 0.002345333

Training iteration loss = 0.003079948

Training iteration loss = 0.004535753

Training iteration loss = 0.0017996887

Training iteration loss = 0.00296888

Training iteration loss = 0.0030602722

Training iteration loss = 0.0033166592

Training iteration loss = 0.002846824

Training iteration loss = 0.0032385665

Training iteration loss = 0.0028074859

Training iteration loss = 0.0017698384

Training iteration loss = 0.005874285

Training iteration loss = 0.0029582111

Training iteration loss = 0.0025659807

Training iteration loss = 0.0017890586

Training iteration loss = 0.0032106868

Training iteration loss = 0.003599841

Training iteration loss = 0.0036459528

Training iteration loss = 0.002317936

Training iteration loss = 0.005659731

Training iteration loss = 0.0030485427

Training iteration loss = 0.002249898

Training iteration loss = 0.0020603251

Training iteration loss = 0.0024293198

Training iteration loss = 0.0019516678

Training iteration loss = 0.0029208462

Training iteration loss = 0.00175186

Training iteration loss = 0.0019910524

Training iteration loss = 0.0036335352

Training iteration loss = 0.002721997

Training iteration loss = 0.0032953275

Training iteration loss = 0.0025647788

Training iteration loss = 0.0038923195

Training iteration loss = 0.0041273492

Training iteration loss = 0.004117074

Training iteration loss = 0.0019664841

Training iteration loss = 0.002792511

Training iteration loss = 0.0023974134

Training iteration loss = 0.0036808448

Training iteration loss = 0.0033359444

Training iteration loss = 0.0045350776

Training iteration loss = 0.002840995

Training iteration loss = 0.0023803199

Training iteration loss = 0.003175127

Training iteration loss = 0.0047043297

Training iteration loss = 0.0031933214

Training iteration loss = 0.00272388

Training iteration loss = 0.0032510983

Training iteration loss = 0.0031214242

Training iteration loss = 0.0023886657

Training iteration loss = 0.0024443658

Training iteration loss = 0.0036279184

Training iteration loss = 0.00297618

Training iteration loss = 0.0030654825

Training iteration loss = 0.002779728

Training iteration loss = 0.0022395055

Training iteration loss = 0.004374271

Training iteration loss = 0.0039506652

Training iteration loss = 0.003841038

Training iteration loss = 0.0035444463

Training iteration loss = 0.002177388

Training iteration loss = 0.00451383

Training iteration loss = 0.0055050068

Training iteration loss = 0.0023114576

Training iteration loss = 0.0032102773

Training iteration loss = 0.0023401135

Training iteration loss = 0.0026557029

Training iteration loss = 0.0026523136

Training iteration loss = 0.0024459579

Training iteration loss = 0.004760317

Training iteration loss = 0.0054036584

Training iteration loss = 0.0024799018

Training iteration loss = 0.002852604

Training iteration loss = 0.002204256

Training iteration loss = 0.0025537466

Training iteration loss = 0.0033435104

Training iteration loss = 0.0031881903

Training iteration loss = 0.0036582828

Training iteration loss = 0.0022967134

Training iteration loss = 0.0034781778

Training iteration loss = 0.007077334

Training iteration loss = 0.0045847096

Training iteration loss = 0.0036788501

Training iteration loss = 0.0029063576

Training iteration loss = 0.0033956377

Training iteration loss = 0.0026459184

Training iteration loss = 0.0032939573

Training iteration loss = 0.0020932683

Training iteration loss = 0.0025088794

Training iteration loss = 0.0025666412

Training iteration loss = 0.0024340467

Training iteration loss = 0.001955685

Training iteration loss = 0.0045218156

Training iteration loss = 0.003235874

Training iteration loss = 0.005267464

Training iteration loss = 0.0032717148

Training iteration loss = 0.0031608576

Training iteration loss = 0.0031978013

Training iteration loss = 0.0063956934

Training iteration loss = 0.0038698877

Training iteration loss = 0.0033920633

Training iteration loss = 0.0025371104

Training iteration loss = 0.004623175

Training iteration loss = 0.0021157458

Training iteration loss = 0.0024580893

Training iteration loss = 0.0028928637

Training iteration loss = 0.0036635075

Training iteration loss = 0.0028210636

Training iteration loss = 0.0037620913

Training iteration loss = 0.0033667886

Training iteration loss = 0.0019424168

Training iteration loss = 0.0024444752

Training iteration loss = 0.0019332495

Training iteration loss = 0.0024537744

Training iteration loss = 0.002010994

Training iteration loss = 0.0024569929

Training iteration loss = 0.0033458855

Training iteration loss = 0.003381146

Training iteration loss = 0.004551915

Training iteration loss = 0.0041070613

Training iteration loss = 0.003995421

Training iteration loss = 0.0021115139

Training iteration loss = 0.002955923

Training iteration loss = 0.0021811307

Training iteration loss = 0.0060344883

Training iteration loss = 0.0035788885

Training iteration loss = 0.0029138522

Training iteration loss = 0.002785284

Training iteration loss = 0.0035690714

Training iteration loss = 0.006960453

Training iteration loss = 0.0023001654

Training iteration loss = 0.0035446705

Training iteration loss = 0.0035746067

Training iteration loss = 0.002286986

Training iteration loss = 0.003441558

Training iteration loss = 0.0037101519

Training iteration loss = 0.0026637327

Training iteration loss = 0.0025311073

Training iteration loss = 0.0031446312

Training iteration loss = 0.003593268

Training iteration loss = 0.003495544

Training iteration loss = 0.0043855156

Training iteration loss = 0.0046665366

Training iteration loss = 0.0031759415

Training iteration loss = 0.0036366873

Training iteration loss = 0.0041700816

Training iteration loss = 0.0043327785

Training iteration loss = 0.0027888129

Training iteration loss = 0.0036140725

Training iteration loss = 0.003971776

Training iteration loss = 0.0025175333

Training iteration loss = 0.00211878

Training iteration loss = 0.0035911782

Training iteration loss = 0.0023720495

Training iteration loss = 0.0020464764

Training iteration loss = 0.003082795

Training iteration loss = 0.0022636757

Training iteration loss = 0.0017321733

Training iteration loss = 0.0018401927

Training iteration loss = 0.0031325493

Training iteration loss = 0.002026286

Training iteration loss = 0.0022521606

Training iteration loss = 0.0038664674

Training iteration loss = 0.0050987005

Training iteration loss = 0.0024688055

Training iteration loss = 0.0026888836

Training iteration loss = 0.0023581488

Training iteration loss = 0.0025852178

Training iteration loss = 0.0022503382

Training iteration loss = 0.0039729998

Training iteration loss = 0.0033240905

Training iteration loss = 0.004941564

Training iteration loss = 0.003878278

Training iteration loss = 0.0028140433

Training iteration loss = 0.0019366149

Training iteration loss = 0.0020804696

Training iteration loss = 0.008198041

Training iteration loss = 0.0029381604

Training iteration loss = 0.0017686553

Training iteration loss = 0.004226469

Training iteration loss = 0.0037848863

Training iteration loss = 0.0033692324

Training iteration loss = 0.0028770783

Training iteration loss = 0.0039031636

Training iteration loss = 0.002218742

Training iteration loss = 0.00637609

Training iteration loss = 0.0025657432

Training iteration loss = 0.0034040522

Training iteration loss = 0.0037926964

Training iteration loss = 0.0020671217

Training iteration loss = 0.0020864606

Training iteration loss = 0.0025889473

Training iteration loss = 0.001615868

Training iteration loss = 0.003261311

Training iteration loss = 0.003156264

Training iteration loss = 0.004050423

Training iteration loss = 0.0030678026

Training iteration loss = 0.002747738

Training iteration loss = 0.0023098518

Training iteration loss = 0.0021872292

Training iteration loss = 0.002341973

Training iteration loss = 0.0030768737

Training iteration loss = 0.004534809

Training iteration loss = 0.001798432

Training iteration loss = 0.0029705577

Training iteration loss = 0.003059617

Training iteration loss = 0.003313197

Training iteration loss = 0.0028427925

Training iteration loss = 0.0032372077

Training iteration loss = 0.0028074954

Training iteration loss = 0.0017668628

Training iteration loss = 0.005860038

Training iteration loss = 0.0029589322

Training iteration loss = 0.0025658302

Training iteration loss = 0.001790498

Training iteration loss = 0.0032068614

Training iteration loss = 0.0035945745

Training iteration loss = 0.0036404254

Training iteration loss = 0.0023169396

Training iteration loss = 0.005648921

Training iteration loss = 0.003052286

Training iteration loss = 0.0022569906

Training iteration loss = 0.0020643815

Training iteration loss = 0.0024316923

Training iteration loss = 0.001947334

Training iteration loss = 0.0029088175

Training iteration loss = 0.001752095

Training iteration loss = 0.0019916082

Training iteration loss = 0.0036311038

Training iteration loss = 0.0027142002

Training iteration loss = 0.0032809805

Training iteration loss = 0.0025630642

Training iteration loss = 0.0039011883

Training iteration loss = 0.004130609

Training iteration loss = 0.0041165943

Training iteration loss = 0.0019581162

Training iteration loss = 0.0027826491

Training iteration loss = 0.0023877027

Training iteration loss = 0.0036663895

Training iteration loss = 0.0033317676

Training iteration loss = 0.0045258095

Training iteration loss = 0.0028465248

Training iteration loss = 0.0023839576

Training iteration loss = 0.0031823104

Training iteration loss = 0.0046935827

Training iteration loss = 0.003190907

Training iteration loss = 0.0027316874

Training iteration loss = 0.003243948

Training iteration loss = 0.0031174973

Training iteration loss = 0.002396724

Training iteration loss = 0.0024362623

Training iteration loss = 0.0036316963

Training iteration loss = 0.0029808308

Training iteration loss = 0.0030683514

Training iteration loss = 0.002782297

Training iteration loss = 0.002240214

Training iteration loss = 0.0043768818

Training iteration loss = 0.00394481

Training iteration loss = 0.003834176

Training iteration loss = 0.0035409078

Training iteration loss = 0.002177282

Training iteration loss = 0.00450261

Training iteration loss = 0.0055038743

Training iteration loss = 0.0023084886

Training iteration loss = 0.0031966048

Training iteration loss = 0.0023366404

Training iteration loss = 0.002658367

Training iteration loss = 0.0026508432

Training iteration loss = 0.0024445646

Training iteration loss = 0.0047573773

Training iteration loss = 0.005385836

Training iteration loss = 0.0024776997

Training iteration loss = 0.002852395

Training iteration loss = 0.0022074464

Training iteration loss = 0.0025521994

Training iteration loss = 0.0033395998

Training iteration loss = 0.0031877626

Training iteration loss = 0.0036582102

Training iteration loss = 0.002293124

Training iteration loss = 0.0034785327

Training iteration loss = 0.007078767

Training iteration loss = 0.0045844084

Training iteration loss = 0.003671362

Training iteration loss = 0.0029031802

Training iteration loss = 0.0033945683

Training iteration loss = 0.0026480865

Training iteration loss = 0.0032933375

Training iteration loss = 0.002090739

Training iteration loss = 0.0025085707

Training iteration loss = 0.0025652426

Training iteration loss = 0.002434755

Training iteration loss = 0.0019558386

Training iteration loss = 0.004523068

Training iteration loss = 0.0032381879

Training iteration loss = 0.005264951

Training iteration loss = 0.0032740377

Training iteration loss = 0.003162618

Training iteration loss = 0.0032075776

Training iteration loss = 0.006380224

Training iteration loss = 0.0038648322

Training iteration loss = 0.0033900477

Training iteration loss = 0.0025320135

Training iteration loss = 0.0046019014

Training iteration loss = 0.0021138238

Training iteration loss = 0.0024596846

Training iteration loss = 0.0028972065

Training iteration loss = 0.0036655685

Training iteration loss = 0.0028150566

Training iteration loss = 0.0037599385

Training iteration loss = 0.0033639625

Training iteration loss = 0.0019445718

Training iteration loss = 0.002440902

Training iteration loss = 0.0019307825

Training iteration loss = 0.0024512003

Training iteration loss = 0.0020071415

Training iteration loss = 0.0024528494

Training iteration loss = 0.0033400338

Training iteration loss = 0.003376881

Training iteration loss = 0.0045472677

Training iteration loss = 0.0041053337

Training iteration loss = 0.0039856913

Training iteration loss = 0.0021104708

Training iteration loss = 0.0029521522

Training iteration loss = 0.002184018

Training iteration loss = 0.0060450775

Training iteration loss = 0.0035756417

Training iteration loss = 0.0029144005

Training iteration loss = 0.0027868748

Training iteration loss = 0.0035716358

Training iteration loss = 0.006959699

Training iteration loss = 0.0022995926

Training iteration loss = 0.003541039

Training iteration loss = 0.003572493

Training iteration loss = 0.0022850686

Training iteration loss = 0.003444502

Training iteration loss = 0.0037089605

Training iteration loss = 0.0026613239

Training iteration loss = 0.0025328298

Training iteration loss = 0.0031463986

Training iteration loss = 0.003596943

Training iteration loss = 0.003498571

Training iteration loss = 0.004376924

Training iteration loss = 0.0046645333

Training iteration loss = 0.003175895

Training iteration loss = 0.0036309122

Training iteration loss = 0.0041669714

Training iteration loss = 0.0043317825

Training iteration loss = 0.002784272

Training iteration loss = 0.0036052798

Training iteration loss = 0.003967772

Training iteration loss = 0.0025130694

Training iteration loss = 0.0021181137

Training iteration loss = 0.0035924474

Training iteration loss = 0.0023765455

Training iteration loss = 0.0020440447

Training iteration loss = 0.0030752143

Training iteration loss = 0.0022581636

Training iteration loss = 0.0017298198

Training iteration loss = 0.0018402516

Training iteration loss = 0.0031349098

Training iteration loss = 0.0020297247

Training iteration loss = 0.0022552947

Training iteration loss = 0.0038616324

Training iteration loss = 0.005084296

Training iteration loss = 0.0024716503

Training iteration loss = 0.002685549

Training iteration loss = 0.0023574152

Training iteration loss = 0.002579402

Training iteration loss = 0.0022554367

Training iteration loss = 0.003971044

Training iteration loss = 0.0033213533

Training iteration loss = 0.0049422807

Training iteration loss = 0.0038769376

Training iteration loss = 0.0028112966

Training iteration loss = 0.0019342412

Training iteration loss = 0.0020750964

Training iteration loss = 0.0081914775

Training iteration loss = 0.0029404412

Training iteration loss = 0.0017573397

Training iteration loss = 0.0042348118

Training iteration loss = 0.0037841778

Training iteration loss = 0.003368721

Training iteration loss = 0.002872548

Training iteration loss = 0.003901215

Training iteration loss = 0.002220554

Training iteration loss = 0.006372321

Training iteration loss = 0.0025674647

Training iteration loss = 0.0034008126

Training iteration loss = 0.0037911686

Training iteration loss = 0.0020638567

Training iteration loss = 0.0020838715

Training iteration loss = 0.0025876176

Training iteration loss = 0.0016133682

Training iteration loss = 0.0032584893

Training iteration loss = 0.003156647

Training iteration loss = 0.0040471065

Training iteration loss = 0.003065916

Training iteration loss = 0.0027466351

Training iteration loss = 0.0023102653

Training iteration loss = 0.0021872532

Training iteration loss = 0.0023409158

Training iteration loss = 0.0030768623

Training iteration loss = 0.0045317146

Training iteration loss = 0.001798274

Training iteration loss = 0.002970041

Training iteration loss = 0.0030604627

Training iteration loss = 0.0033107845

Training iteration loss = 0.002842678

Training iteration loss = 0.0032381474

Training iteration loss = 0.002809306

Training iteration loss = 0.001765361

Training iteration loss = 0.0058492064

Training iteration loss = 0.0029601182

Training iteration loss = 0.0025646791

Training iteration loss = 0.0017892922

Training iteration loss = 0.0032019846

Training iteration loss = 0.0035930092

Training iteration loss = 0.0036407125

Training iteration loss = 0.002313717

Training iteration loss = 0.005644458

Training iteration loss = 0.0030499352

Training iteration loss = 0.0022542423

Training iteration loss = 0.002062555

Training iteration loss = 0.0024285715

Training iteration loss = 0.0019481992

Training iteration loss = 0.0029030992

Training iteration loss = 0.0017518619

Training iteration loss = 0.0019928087

Training iteration loss = 0.0036372626

Training iteration loss = 0.002713796

Training iteration loss = 0.0032853922

Training iteration loss = 0.0025614165

Training iteration loss = 0.0038964225

Training iteration loss = 0.0041285297

Training iteration loss = 0.0040992256

Training iteration loss = 0.001957674

Training iteration loss = 0.002780481

Training iteration loss = 0.0023917665

Training iteration loss = 0.0036715856

Training iteration loss = 0.0033253443

Training iteration loss = 0.004522509

Training iteration loss = 0.002843733

Training iteration loss = 0.0023758614

Training iteration loss = 0.003180829

Training iteration loss = 0.004695617

Training iteration loss = 0.0031882739

Training iteration loss = 0.0027323805

Training iteration loss = 0.003244594

Training iteration loss = 0.0031157418

Training iteration loss = 0.0023953763

Training iteration loss = 0.0024374155

Training iteration loss = 0.003628414

Training iteration loss = 0.00298388

Training iteration loss = 0.0030659118

Training iteration loss = 0.0027825006

Training iteration loss = 0.0022367022

Training iteration loss = 0.004373904

Training iteration loss = 0.003947601

Training iteration loss = 0.0038373664

Training iteration loss = 0.0035361499

Training iteration loss = 0.0021778026

Training iteration loss = 0.0045065214

Training iteration loss = 0.0055036615

Training iteration loss = 0.0023033652

Training iteration loss = 0.0031962532

Training iteration loss = 0.0023343882

Training iteration loss = 0.002654609

Training iteration loss = 0.002648481

Training iteration loss = 0.0024471087

Training iteration loss = 0.0047541014

Training iteration loss = 0.0053725415

Training iteration loss = 0.0024734058

Training iteration loss = 0.0028536196

Training iteration loss = 0.0022105835

Training iteration loss = 0.002549384

Training iteration loss = 0.003339248

Training iteration loss = 0.0031854215

Training iteration loss = 0.0036570968

Training iteration loss = 0.002294806

Training iteration loss = 0.0034785466

Training iteration loss = 0.0070624654

Training iteration loss = 0.0045790207

Training iteration loss = 0.0036691045

Training iteration loss = 0.002902884

Training iteration loss = 0.0033952247

Training iteration loss = 0.0026504712

Training iteration loss = 0.003295281

Training iteration loss = 0.002092918

Training iteration loss = 0.002511597

Training iteration loss = 0.0025673928

Training iteration loss = 0.0024312695

Training iteration loss = 0.0019554335

Training iteration loss = 0.0045246226

Training iteration loss = 0.003232496

Training iteration loss = 0.0052618943

Training iteration loss = 0.003277423

Training iteration loss = 0.0031634036

Training iteration loss = 0.0031939792

Training iteration loss = 0.006369641

Training iteration loss = 0.0038610848

Training iteration loss = 0.0033891366

Training iteration loss = 0.0025319133

Training iteration loss = 0.004590364

Training iteration loss = 0.00211173

Training iteration loss = 0.002461784

Training iteration loss = 0.002894663

Training iteration loss = 0.0036618896

Training iteration loss = 0.002815643

Training iteration loss = 0.00375894

Training iteration loss = 0.0033646182

Training iteration loss = 0.0019430108

Training iteration loss = 0.0024409618

Training iteration loss = 0.0019345599

Training iteration loss = 0.0024535868

Training iteration loss = 0.0020090383

Training iteration loss = 0.0024489565

Training iteration loss = 0.003340707

Training iteration loss = 0.0033806248

Training iteration loss = 0.0045489315

Training iteration loss = 0.0041111954

Training iteration loss = 0.003985044

Training iteration loss = 0.0021093618

Training iteration loss = 0.002948336

Training iteration loss = 0.0021827007

Training iteration loss = 0.006050739

Training iteration loss = 0.0035735455

Training iteration loss = 0.0029161933

Training iteration loss = 0.002783789

Training iteration loss = 0.0035644977

Training iteration loss = 0.006955465

Training iteration loss = 0.0022956545

Training iteration loss = 0.0035378046

Training iteration loss = 0.003569187

Training iteration loss = 0.0022797086

Training iteration loss = 0.0034428283

Training iteration loss = 0.0037068287

Training iteration loss = 0.0026560926

Training iteration loss = 0.002533965

Training iteration loss = 0.0031494077

Training iteration loss = 0.0036017308

Training iteration loss = 0.0035036393

Training iteration loss = 0.0043619415

Training iteration loss = 0.0046662227

Training iteration loss = 0.0031714356

Training iteration loss = 0.0036225717

Training iteration loss = 0.0041604033

Training iteration loss = 0.004331131

Training iteration loss = 0.0027872913

Training iteration loss = 0.0036080636

Training iteration loss = 0.00396066

Training iteration loss = 0.0025082298

Training iteration loss = 0.0021161432

Training iteration loss = 0.0035927116

Training iteration loss = 0.002381663

Training iteration loss = 0.0020429213

Training iteration loss = 0.0030737696

Training iteration loss = 0.0022537129

Training iteration loss = 0.0017266312

Training iteration loss = 0.0018420889

Training iteration loss = 0.0031370053

Training iteration loss = 0.002029975

Training iteration loss = 0.0022527173

Training iteration loss = 0.0038559602

Training iteration loss = 0.005073803

Training iteration loss = 0.0024738624

Training iteration loss = 0.002687277

Training iteration loss = 0.0023589975

Training iteration loss = 0.0025775626

Training iteration loss = 0.0022571667

Training iteration loss = 0.0039680223

Training iteration loss = 0.0033199957

Training iteration loss = 0.0049390406

Training iteration loss = 0.0038751364

Training iteration loss = 0.0028103653

Training iteration loss = 0.0019343891

Training iteration loss = 0.002073434

Training iteration loss = 0.008183085

Training iteration loss = 0.0029370533

Training iteration loss = 0.0017544582

Training iteration loss = 0.004232629

Training iteration loss = 0.0037881832

Training iteration loss = 0.003369948

Training iteration loss = 0.002871039

Training iteration loss = 0.0038966455

Training iteration loss = 0.002218027

Training iteration loss = 0.006369317

Training iteration loss = 0.0025667578

Training iteration loss = 0.003396512

Training iteration loss = 0.0037878256

Training iteration loss = 0.002059935

Training iteration loss = 0.0020790326

Training iteration loss = 0.0025862663

Training iteration loss = 0.001613753

Training iteration loss = 0.0032615622

Training iteration loss = 0.0031602625

Training iteration loss = 0.004044126

Training iteration loss = 0.0030598503

Training iteration loss = 0.0027450735

Training iteration loss = 0.002308855

Training iteration loss = 0.0021874325

Training iteration loss = 0.002335311

Training iteration loss = 0.0030750872

Training iteration loss = 0.004529173

Training iteration loss = 0.0017992975

Training iteration loss = 0.0029761263

Training iteration loss = 0.0030610699

Training iteration loss = 0.0033076617

Training iteration loss = 0.002837991

Training iteration loss = 0.003238408

Training iteration loss = 0.0028068712

Training iteration loss = 0.0017641064

Training iteration loss = 0.0058267354

Training iteration loss = 0.002963254

Training iteration loss = 0.0025618023

Training iteration loss = 0.0017920824

Training iteration loss = 0.0031985256

Training iteration loss = 0.003594605

Training iteration loss = 0.0036399562

Training iteration loss = 0.0023143478

Training iteration loss = 0.0056327973

Training iteration loss = 0.0030538172

Training iteration loss = 0.0022602056

Training iteration loss = 0.0020696453

Training iteration loss = 0.0024336076

Training iteration loss = 0.0019513267

Training iteration loss = 0.0028955706

Training iteration loss = 0.0017547227

Training iteration loss = 0.0019891243

Training iteration loss = 0.0036282772

Training iteration loss = 0.0027065538

Training iteration loss = 0.0032836355

Training iteration loss = 0.002559287

Training iteration loss = 0.0038891563

Training iteration loss = 0.004124383

Training iteration loss = 0.0040941867

Training iteration loss = 0.0019589127

Training iteration loss = 0.002777267

Training iteration loss = 0.0023871665

Training iteration loss = 0.0036770387

Training iteration loss = 0.0033225978

Training iteration loss = 0.004518472

Training iteration loss = 0.0028395143

Training iteration loss = 0.0023779997

Training iteration loss = 0.0031829912

Training iteration loss = 0.004696175

Training iteration loss = 0.0031906383

Training iteration loss = 0.0027329267

Training iteration loss = 0.0032400768

Training iteration loss = 0.003115546

Training iteration loss = 0.002388803

Training iteration loss = 0.0024293875

Training iteration loss = 0.0036324915

Training iteration loss = 0.002979847

Training iteration loss = 0.0030682392

Training iteration loss = 0.0027850538

Training iteration loss = 0.0022317718

Training iteration loss = 0.004368149

Training iteration loss = 0.0039243014

Training iteration loss = 0.0038377654

Training iteration loss = 0.0035259314

Training iteration loss = 0.00217643

Training iteration loss = 0.0045129606

Training iteration loss = 0.0055071455

Training iteration loss = 0.0023026566

Training iteration loss = 0.0031892995

Training iteration loss = 0.0023309297

Training iteration loss = 0.002653564

Training iteration loss = 0.0026459545

Training iteration loss = 0.002443955

Training iteration loss = 0.0047496445

Training iteration loss = 0.0053648935

Training iteration loss = 0.0024691261

Training iteration loss = 0.0028572625

Training iteration loss = 0.0022070415

Training iteration loss = 0.0025472485

Training iteration loss = 0.0033369146

Training iteration loss = 0.0031865053

Training iteration loss = 0.003654361

Training iteration loss = 0.002298007

Training iteration loss = 0.0034785355

Training iteration loss = 0.0070683565

Training iteration loss = 0.004573158

Training iteration loss = 0.003665045

Training iteration loss = 0.0028965955

Training iteration loss = 0.0033929262

Training iteration loss = 0.00264795

Training iteration loss = 0.0032874795

Training iteration loss = 0.0020897826

Training iteration loss = 0.0025107458

Training iteration loss = 0.0025607573

Training iteration loss = 0.002418799

Training iteration loss = 0.001953577

Training iteration loss = 0.0045221252

Training iteration loss = 0.0032371897

Training iteration loss = 0.0052606077

Training iteration loss = 0.0032702407

Training iteration loss = 0.0031583754

Training iteration loss = 0.003208258

Training iteration loss = 0.006352497

Training iteration loss = 0.0038517173

Training iteration loss = 0.0033877173

Training iteration loss = 0.002525231

Training iteration loss = 0.0045698574

Training iteration loss = 0.0021111092

Training iteration loss = 0.0024589687

Training iteration loss = 0.0028927755

Training iteration loss = 0.0036606535

Training iteration loss = 0.0028126582

Training iteration loss = 0.0037578

Training iteration loss = 0.0033627031

Training iteration loss = 0.0019403272

Training iteration loss = 0.0024339932

Training iteration loss = 0.00192792

Training iteration loss = 0.0024466899

Training iteration loss = 0.0020038858

Training iteration loss = 0.0024451937

Training iteration loss = 0.0033308559

Training iteration loss = 0.0033726941

Training iteration loss = 0.004543212

Training iteration loss = 0.004104295

Training iteration loss = 0.0039777025

Training iteration loss = 0.0021063173

Training iteration loss = 0.0029465936

Training iteration loss = 0.0021831708

Training iteration loss = 0.006055515

Training iteration loss = 0.0035733078

Training iteration loss = 0.0029143703

Training iteration loss = 0.0027788093

Training iteration loss = 0.0035640106

Training iteration loss = 0.006952845

Training iteration loss = 0.0022941588

Training iteration loss = 0.0035358109

Training iteration loss = 0.0035652705

Training iteration loss = 0.0022763854

Training iteration loss = 0.0034422653

Training iteration loss = 0.0037041486

Training iteration loss = 0.0026528838

Training iteration loss = 0.002532508

Training iteration loss = 0.003150695

Training iteration loss = 0.0035921747

Training iteration loss = 0.0035018695

Training iteration loss = 0.004346056

Training iteration loss = 0.0046679056

Training iteration loss = 0.0031714747

Training iteration loss = 0.0036300896

Training iteration loss = 0.004154865

Training iteration loss = 0.0043318756

Training iteration loss = 0.0027819416

Training iteration loss = 0.0035989059

Training iteration loss = 0.003958085

Training iteration loss = 0.0025065131

Training iteration loss = 0.0021197998

Training iteration loss = 0.0035890976

Training iteration loss = 0.002382337

Training iteration loss = 0.0020409578

Training iteration loss = 0.0030739969

Training iteration loss = 0.002257144

Training iteration loss = 0.0017247977

Training iteration loss = 0.0018424732

Training iteration loss = 0.0031399233

Training iteration loss = 0.0020313666

Training iteration loss = 0.0022553233

Training iteration loss = 0.0038510954

Training iteration loss = 0.0050642737

Training iteration loss = 0.0024757823

Training iteration loss = 0.0026856663

Training iteration loss = 0.00235908

Training iteration loss = 0.002571048

Training iteration loss = 0.0022616135

Training iteration loss = 0.003966886

Training iteration loss = 0.0033183657

Training iteration loss = 0.004939636

Training iteration loss = 0.0038756973

Training iteration loss = 0.00280483

Training iteration loss = 0.0019299281

Training iteration loss = 0.0020693701

Training iteration loss = 0.008164339

Training iteration loss = 0.0029356387

Training iteration loss = 0.0017446075

Training iteration loss = 0.0042387024

Training iteration loss = 0.0037880419

Training iteration loss = 0.0033667115

Training iteration loss = 0.0028721194

Training iteration loss = 0.003896076

Training iteration loss = 0.0022222141

Training iteration loss = 0.006366461

Training iteration loss = 0.0025709046

Training iteration loss = 0.0033976622

Training iteration loss = 0.0037883632

Training iteration loss = 0.002059309

Training iteration loss = 0.0020798037

Training iteration loss = 0.002583383

Training iteration loss = 0.0016116902

Training iteration loss = 0.0032545736

Training iteration loss = 0.0031570776

Training iteration loss = 0.004042288

Training iteration loss = 0.003063768

Training iteration loss = 0.002744259

Training iteration loss = 0.0023106346

Training iteration loss = 0.0021872756

Training iteration loss = 0.0023363952

Training iteration loss = 0.0030715156

Training iteration loss = 0.004517971

Training iteration loss = 0.0017990493

Training iteration loss = 0.002970841

Training iteration loss = 0.003060967

Training iteration loss = 0.0033056838

Training iteration loss = 0.0028395904

Training iteration loss = 0.0032383099

Training iteration loss = 0.0028092873

Training iteration loss = 0.0017637335

Training iteration loss = 0.0058316872

Training iteration loss = 0.002960875

Training iteration loss = 0.0025666999

Training iteration loss = 0.0017903079

Training iteration loss = 0.003195501

Training iteration loss = 0.0035915438

Training iteration loss = 0.0036343746

Training iteration loss = 0.0023089044

Training iteration loss = 0.0056282748

Training iteration loss = 0.003051534

Training iteration loss = 0.0022619648

Training iteration loss = 0.0020702097

Training iteration loss = 0.002433981

Training iteration loss = 0.001950578

Training iteration loss = 0.0028902246

Training iteration loss = 0.0017543273

Training iteration loss = 0.0019879371

Training iteration loss = 0.0036278302

Training iteration loss = 0.0027041696

Training iteration loss = 0.003283487

Training iteration loss = 0.0025578619

Training iteration loss = 0.0038871057

Training iteration loss = 0.0041215373

Training iteration loss = 0.00408541

Training iteration loss = 0.001958314

Training iteration loss = 0.0027773064

Training iteration loss = 0.0023873386

Training iteration loss = 0.0036770524

Training iteration loss = 0.003319972

Training iteration loss = 0.0045073195

Training iteration loss = 0.0028373357

Training iteration loss = 0.0023736197

Training iteration loss = 0.0031824799

Training iteration loss = 0.0046966444

Training iteration loss = 0.0031903635

Training iteration loss = 0.0027342

Training iteration loss = 0.0032383439

Training iteration loss = 0.0031163956

Training iteration loss = 0.002386519

Training iteration loss = 0.0024303992

Training iteration loss = 0.003631398

Training iteration loss = 0.0029778564

Training iteration loss = 0.003066928

Training iteration loss = 0.0027877998

Training iteration loss = 0.002228303

Training iteration loss = 0.004361988

Training iteration loss = 0.0039147492

Training iteration loss = 0.0038414262

Training iteration loss = 0.0035154407

Training iteration loss = 0.0021763335

Training iteration loss = 0.004516154

Training iteration loss = 0.005506882

Training iteration loss = 0.0022991134

Training iteration loss = 0.0031905363

Training iteration loss = 0.002328865

Training iteration loss = 0.0026511278

Training iteration loss = 0.0026441521

Training iteration loss = 0.0024471264

Training iteration loss = 0.0047436776

Training iteration loss = 0.005350674

Training iteration loss = 0.0024663403

Training iteration loss = 0.0028588062

Training iteration loss = 0.002209009

Training iteration loss = 0.0025448648

Training iteration loss = 0.0033378091

Training iteration loss = 0.0031882052

Training iteration loss = 0.0036536797

Training iteration loss = 0.0022963875

Training iteration loss = 0.0034777254

Training iteration loss = 0.0070567667

Training iteration loss = 0.004570093

Training iteration loss = 0.0036627883

Training iteration loss = 0.0028958006

Training iteration loss = 0.0033922836

Training iteration loss = 0.0026472544

Training iteration loss = 0.0032878255

Training iteration loss = 0.0020906355

Training iteration loss = 0.0025099365

Training iteration loss = 0.0025603422

Training iteration loss = 0.0024110305

Training iteration loss = 0.0019511521

Training iteration loss = 0.0045233117

Training iteration loss = 0.0032329084

Training iteration loss = 0.00525747

Training iteration loss = 0.0032746028

Training iteration loss = 0.0031581486

Training iteration loss = 0.0031860846

Training iteration loss = 0.0063440274

Training iteration loss = 0.0038548897

Training iteration loss = 0.0033869406

Training iteration loss = 0.0025278423

Training iteration loss = 0.0045677596

Training iteration loss = 0.0021082794

Training iteration loss = 0.0024630455

Training iteration loss = 0.0028855698

Training iteration loss = 0.0036578944

Training iteration loss = 0.00281338

Training iteration loss = 0.0037558426

Training iteration loss = 0.0033652438

Training iteration loss = 0.0019431696

Training iteration loss = 0.0024367522

Training iteration loss = 0.0019277615

Training iteration loss = 0.0024504063

Training iteration loss = 0.002010156

Training iteration loss = 0.0024485919

Training iteration loss = 0.003332358

Training iteration loss = 0.0033712424

Training iteration loss = 0.004545756

Training iteration loss = 0.004105312

Training iteration loss = 0.003983183

Training iteration loss = 0.0021029618

Training iteration loss = 0.0029456988

Training iteration loss = 0.002179003

Training iteration loss = 0.00604127

Training iteration loss = 0.0035676563

Training iteration loss = 0.0029158443

Training iteration loss = 0.0027759902

Training iteration loss = 0.003562799

Training iteration loss = 0.006937484

Training iteration loss = 0.0022945742

Training iteration loss = 0.003533133

Training iteration loss = 0.0035680651

Training iteration loss = 0.002276011

Training iteration loss = 0.0034397626

Training iteration loss = 0.0037056904

Training iteration loss = 0.002649095

Training iteration loss = 0.0025296747

Training iteration loss = 0.0031474743

Training iteration loss = 0.0035810738

Training iteration loss = 0.0034931619

Training iteration loss = 0.004346602

Training iteration loss = 0.0046645594

Training iteration loss = 0.0031690088

Training iteration loss = 0.0036388088

Training iteration loss = 0.0041510235

Training iteration loss = 0.0043242695

Training iteration loss = 0.0027723005

Training iteration loss = 0.0035958465

Training iteration loss = 0.003957092

Training iteration loss = 0.002507169

Training iteration loss = 0.0021214632

Training iteration loss = 0.0035856816

Training iteration loss = 0.0023727326

Training iteration loss = 0.0020370355

Training iteration loss = 0.0030787885

Training iteration loss = 0.0022636733

Training iteration loss = 0.0017243576

Training iteration loss = 0.0018420308

Training iteration loss = 0.0031385198

Training iteration loss = 0.0020279558

Training iteration loss = 0.0022585692

Training iteration loss = 0.0038494433

Training iteration loss = 0.005061207

Training iteration loss = 0.0024765648

Training iteration loss = 0.0026857744

Training iteration loss = 0.0023594082

Training iteration loss = 0.0025684536

Training iteration loss = 0.0022623392

Training iteration loss = 0.003965611

Training iteration loss = 0.0033169284

Training iteration loss = 0.00493615

Training iteration loss = 0.0038764924

Training iteration loss = 0.0027987857

Training iteration loss = 0.0019259016

Training iteration loss = 0.0020661412

Training iteration loss = 0.008151243

Training iteration loss = 0.0029314372

Training iteration loss = 0.0017417711

Training iteration loss = 0.0042363503

Training iteration loss = 0.0037887609

Training iteration loss = 0.0033641905

Training iteration loss = 0.002872171

Training iteration loss = 0.003894777

Training iteration loss = 0.0022245368

Training iteration loss = 0.0063565685

Training iteration loss = 0.0025735388

Training iteration loss = 0.003399233

Training iteration loss = 0.0037914999

Training iteration loss = 0.0020615563

Training iteration loss = 0.0020810147

Training iteration loss = 0.0025848353

Training iteration loss = 0.0016110219

Training iteration loss = 0.0032509873

Training iteration loss = 0.003157262

Training iteration loss = 0.004039617

Training iteration loss = 0.0030654843

Training iteration loss = 0.002745107

Training iteration loss = 0.0023113042

Training iteration loss = 0.0021866362

Training iteration loss = 0.0023387298

Training iteration loss = 0.0030690338

Training iteration loss = 0.004512584

Training iteration loss = 0.0017972705

Training iteration loss = 0.0029666882

Training iteration loss = 0.0030590377

Training iteration loss = 0.0033038035

Training iteration loss = 0.0028411783

Training iteration loss = 0.003237987

Training iteration loss = 0.002812464

Training iteration loss = 0.0017619341

Training iteration loss = 0.0058323215

Training iteration loss = 0.0029590952

Training iteration loss = 0.0025660836

Training iteration loss = 0.0017877625

Training iteration loss = 0.0031907847

Training iteration loss = 0.0035838762

Training iteration loss = 0.0036330142

Training iteration loss = 0.0023030809

Training iteration loss = 0.0056240708

Training iteration loss = 0.003048583

Training iteration loss = 0.0022593436

Training iteration loss = 0.0020676237

Training iteration loss = 0.00242836

Training iteration loss = 0.0019477875

Training iteration loss = 0.0028828091

Training iteration loss = 0.0017529549

Training iteration loss = 0.001992359

Training iteration loss = 0.0036403157

Training iteration loss = 0.0027053012

Training iteration loss = 0.0032783395

Training iteration loss = 0.002556272

Training iteration loss = 0.0038946613

Training iteration loss = 0.0041282214

Training iteration loss = 0.004073152

Training iteration loss = 0.0019489429

Training iteration loss = 0.0027687633

Training iteration loss = 0.00238709

Training iteration loss = 0.0036676128

Training iteration loss = 0.0033137526

Training iteration loss = 0.0045012026

Training iteration loss = 0.0028420575

Training iteration loss = 0.0023666518

Training iteration loss = 0.0031849481

Training iteration loss = 0.0046920306

Training iteration loss = 0.003183345

Training iteration loss = 0.002739963

Training iteration loss = 0.0032379802

Training iteration loss = 0.0031136356

Training iteration loss = 0.0023954036

Training iteration loss = 0.0024311112

Training iteration loss = 0.003627371

Training iteration loss = 0.0029843005

Training iteration loss = 0.0030645076

Training iteration loss = 0.0027881376

Training iteration loss = 0.0022283222

Training iteration loss = 0.004364547

Training iteration loss = 0.003928841

Training iteration loss = 0.0038388232

Training iteration loss = 0.003513923

Training iteration loss = 0.0021773675

Training iteration loss = 0.0045088795

Training iteration loss = 0.005500359

Training iteration loss = 0.002294663

Training iteration loss = 0.0031849358

Training iteration loss = 0.0023273153

Training iteration loss = 0.0026500328

Training iteration loss = 0.0026421165

Training iteration loss = 0.0024497125

Training iteration loss = 0.0047440245

Training iteration loss = 0.005334581

Training iteration loss = 0.002461606

Training iteration loss = 0.002856891

Training iteration loss = 0.0022121922

Training iteration loss = 0.0025418184

Training iteration loss = 0.0033382957

Training iteration loss = 0.0031865088

Training iteration loss = 0.0036521417

Training iteration loss = 0.0022930726

Training iteration loss = 0.0034771885

Training iteration loss = 0.0070473254

Training iteration loss = 0.0045705256

Training iteration loss = 0.0036576232

Training iteration loss = 0.0028951755

Training iteration loss = 0.0033948105

Training iteration loss = 0.002651181

Training iteration loss = 0.003292797

Training iteration loss = 0.0020921042

Training iteration loss = 0.0025121584

Training iteration loss = 0.0025654107

Training iteration loss = 0.0024178268

Training iteration loss = 0.0019521768

Training iteration loss = 0.0045268335

Training iteration loss = 0.0032297692

Training iteration loss = 0.0052541415

Training iteration loss = 0.0032814548

Training iteration loss = 0.0031618888

Training iteration loss = 0.0031776829

Training iteration loss = 0.006334387

Training iteration loss = 0.0038542144

Training iteration loss = 0.003385524

Training iteration loss = 0.0025276814

Training iteration loss = 0.0045566186

Training iteration loss = 0.0021067795

Training iteration loss = 0.0024668386

Training iteration loss = 0.0028873943

Training iteration loss = 0.0036575648

Training iteration loss = 0.0028120421

Training iteration loss = 0.0037548163

Training iteration loss = 0.0033652459

Training iteration loss = 0.001946135

Training iteration loss = 0.0024374605

Training iteration loss = 0.0019317175

Training iteration loss = 0.0024558862

Training iteration loss = 0.0020135152

Training iteration loss = 0.002445702

Training iteration loss = 0.0033346924

Training iteration loss = 0.0033752944

Training iteration loss = 0.0045477026

Training iteration loss = 0.0041090553

Training iteration loss = 0.003983827

Training iteration loss = 0.0021032752

Training iteration loss = 0.0029420226

Training iteration loss = 0.002178444

Training iteration loss = 0.006048838

Training iteration loss = 0.0035625494

Training iteration loss = 0.0029213289

Training iteration loss = 0.0027804915

Training iteration loss = 0.0035632995

Training iteration loss = 0.00693354

Training iteration loss = 0.00229305

Training iteration loss = 0.003528135

Training iteration loss = 0.0035697415

Training iteration loss = 0.002277192

Training iteration loss = 0.00344457

Training iteration loss = 0.0037055246

Training iteration loss = 0.0026446094

Training iteration loss = 0.0025240704

Training iteration loss = 0.0031462042

Training iteration loss = 0.0035808466

Training iteration loss = 0.0034887649

Training iteration loss = 0.0043425323

Training iteration loss = 0.0046637086

Training iteration loss = 0.0031714311

Training iteration loss = 0.0036156839

Training iteration loss = 0.004142966

Training iteration loss = 0.0043136305

Training iteration loss = 0.0027757671

Training iteration loss = 0.0035950209

Training iteration loss = 0.003949693

Training iteration loss = 0.0025001008

Training iteration loss = 0.0021166613

Training iteration loss = 0.0035920378

Training iteration loss = 0.002373916

Training iteration loss = 0.0020384558

Training iteration loss = 0.0030735843

Training iteration loss = 0.0022528537

Training iteration loss = 0.0017208903

Training iteration loss = 0.001843304

Training iteration loss = 0.0031405159

Training iteration loss = 0.0020295286

Training iteration loss = 0.0022528581

Training iteration loss = 0.0038459096

Training iteration loss = 0.005059127

Training iteration loss = 0.0024751017

Training iteration loss = 0.0026849143

Training iteration loss = 0.0023612892

Training iteration loss = 0.0025694661

Training iteration loss = 0.0022587022

Training iteration loss = 0.003959233

Training iteration loss = 0.0033156835

Training iteration loss = 0.004929966

Training iteration loss = 0.0038707845

Training iteration loss = 0.0027939428

Training iteration loss = 0.0019237031

Training iteration loss = 0.0020677124

Training iteration loss = 0.00815346

Training iteration loss = 0.0029289806

Training iteration loss = 0.0017351375

Training iteration loss = 0.0042305016

Training iteration loss = 0.0037921409

Training iteration loss = 0.0033693046

Training iteration loss = 0.0028667382

Training iteration loss = 0.0038913414

Training iteration loss = 0.0022181745

Training iteration loss = 0.0063543734

Training iteration loss = 0.002572156

Training iteration loss = 0.003398265

Training iteration loss = 0.003791257

Training iteration loss = 0.0020592613

Training iteration loss = 0.0020780638

Training iteration loss = 0.002581359

Training iteration loss = 0.0016076658

Training iteration loss = 0.0032476478

Training iteration loss = 0.003157664

Training iteration loss = 0.0040379474

Training iteration loss = 0.0030631947

Training iteration loss = 0.0027384972

Training iteration loss = 0.0023127308

Training iteration loss = 0.0021880427

Training iteration loss = 0.002335812

Training iteration loss = 0.0030649425

Training iteration loss = 0.004520458

Training iteration loss = 0.0017969335

Training iteration loss = 0.0029701788

Training iteration loss = 0.0030617688

Training iteration loss = 0.0032994186

Training iteration loss = 0.0028351166

Training iteration loss = 0.003239088

Training iteration loss = 0.0028132666

Training iteration loss = 0.0017599245

Training iteration loss = 0.0058243647

Training iteration loss = 0.0029607387

Training iteration loss = 0.0025716668

Training iteration loss = 0.00178821

Training iteration loss = 0.0031885942

Training iteration loss = 0.003579938

Training iteration loss = 0.003624554

Training iteration loss = 0.0023046134

Training iteration loss = 0.00560675

Training iteration loss = 0.0030558258

Training iteration loss = 0.0022689959

Training iteration loss = 0.002073805

Training iteration loss = 0.0024320772

Training iteration loss = 0.0019431853

Training iteration loss = 0.002871231

Training iteration loss = 0.0017549371

Training iteration loss = 0.0019991738

Training iteration loss = 0.0036451851

Training iteration loss = 0.0026959192

Training iteration loss = 0.0032669893

Training iteration loss = 0.0025538728

Training iteration loss = 0.0039022435

Training iteration loss = 0.0041270154

Training iteration loss = 0.004067688

Training iteration loss = 0.0019445498

Training iteration loss = 0.0027611505

Training iteration loss = 0.0023815453

Training iteration loss = 0.0036573147

Training iteration loss = 0.0033070978

Training iteration loss = 0.0044967756

Training iteration loss = 0.0028457493

Training iteration loss = 0.0023663223

Training iteration loss = 0.003189289

Training iteration loss = 0.004684832

Training iteration loss = 0.0031797925

Training iteration loss = 0.0027423764

Training iteration loss = 0.0032360249

Training iteration loss = 0.003111463

Training iteration loss = 0.0023999275

Training iteration loss = 0.0024268306

Training iteration loss = 0.0036265778

Training iteration loss = 0.0029869971

Training iteration loss = 0.0030655467

Training iteration loss = 0.0027892916

Training iteration loss = 0.00222826

Training iteration loss = 0.0043655154

Training iteration loss = 0.0039210026

Training iteration loss = 0.0038359563

Training iteration loss = 0.003506054

Training iteration loss = 0.0021785717

Training iteration loss = 0.0045062215

Training iteration loss = 0.0055037024

Training iteration loss = 0.002293946

Training iteration loss = 0.0031802934

Training iteration loss = 0.0023256768

Training iteration loss = 0.002651007

Training iteration loss = 0.0026403817

Training iteration loss = 0.002448615

Training iteration loss = 0.004741466

Training iteration loss = 0.005324701

Training iteration loss = 0.0024603063

Training iteration loss = 0.0028572825

Training iteration loss = 0.0022139708

Training iteration loss = 0.0025386352

Training iteration loss = 0.0033379793

Training iteration loss = 0.0031878036

Training iteration loss = 0.003650387

Training iteration loss = 0.0022907325

Training iteration loss = 0.003478967

Training iteration loss = 0.0070410674

Training iteration loss = 0.0045703

Training iteration loss = 0.0036516346

Training iteration loss = 0.0028910516

Training iteration loss = 0.0033949157

Training iteration loss = 0.0026512865

Training iteration loss = 0.0032918358

Training iteration loss = 0.0020903393

Training iteration loss = 0.0025099346

Training iteration loss = 0.0025651744

Training iteration loss = 0.0024185774

Training iteration loss = 0.001951837

Training iteration loss = 0.004527132

Training iteration loss = 0.0032313357

Training iteration loss = 0.005252741

Training iteration loss = 0.00328447

Training iteration loss = 0.0031627675

Training iteration loss = 0.0031784195

Training iteration loss = 0.0063236137

Training iteration loss = 0.0038516892

Training iteration loss = 0.0033853697

Training iteration loss = 0.0025242732

Training iteration loss = 0.004548766

Training iteration loss = 0.0021049615

Training iteration loss = 0.0024654993

Training iteration loss = 0.0028879663

Training iteration loss = 0.0036577077

Training iteration loss = 0.0028086565

Training iteration loss = 0.00375251

Training iteration loss = 0.0033645157

Training iteration loss = 0.0019479926

Training iteration loss = 0.0024356747

Training iteration loss = 0.0019269626

Training iteration loss = 0.0024496575

Training iteration loss = 0.0020087839

Training iteration loss = 0.0024445548

Training iteration loss = 0.003335419

Training iteration loss = 0.003367198

Training iteration loss = 0.0045445743

Training iteration loss = 0.0041027945

Training iteration loss = 0.0039765183

Training iteration loss = 0.0020994965

Training iteration loss = 0.0029402396

Training iteration loss = 0.0021786834

Training iteration loss = 0.0060392623

Training iteration loss = 0.0035525598

Training iteration loss = 0.0029256393

Training iteration loss = 0.0027878378

Training iteration loss = 0.0035677713

Training iteration loss = 0.0068961023

Training iteration loss = 0.0022973667

Training iteration loss = 0.003529016

Training iteration loss = 0.0035809905

Training iteration loss = 0.002290474

Training iteration loss = 0.0034579074

Training iteration loss = 0.0037106273

Training iteration loss = 0.0026471347

Training iteration loss = 0.002515244

Training iteration loss = 0.0031334748

Training iteration loss = 0.003573301

Training iteration loss = 0.003476331

Training iteration loss = 0.004358852

Training iteration loss = 0.004659961

Training iteration loss = 0.0031808177

Training iteration loss = 0.0035932753

Training iteration loss = 0.0041271104

Training iteration loss = 0.0042963317

Training iteration loss = 0.0027732681

Training iteration loss = 0.0035866958

Training iteration loss = 0.003943995

Training iteration loss = 0.002499626

Training iteration loss = 0.0021151144

Training iteration loss = 0.0035964875

Training iteration loss = 0.002365196

Training iteration loss = 0.0020378612

Training iteration loss = 0.003069117

Training iteration loss = 0.002249649

Training iteration loss = 0.0017192377

Training iteration loss = 0.0018463215

Training iteration loss = 0.0031412663

Training iteration loss = 0.0020309638

Training iteration loss = 0.0022493645

Training iteration loss = 0.0038377417

Training iteration loss = 0.005050795

Training iteration loss = 0.0024742472

Training iteration loss = 0.0026868256

Training iteration loss = 0.0023645975

Training iteration loss = 0.002564652

Training iteration loss = 0.002254477

Training iteration loss = 0.0039529316

Training iteration loss = 0.0033117076

Training iteration loss = 0.0049288147

Training iteration loss = 0.0038679766

Training iteration loss = 0.0027914913

Training iteration loss = 0.0019252653

Training iteration loss = 0.0020702993

Training iteration loss = 0.008145786

Training iteration loss = 0.0029242293

Training iteration loss = 0.0017355002

Training iteration loss = 0.004218981

Training iteration loss = 0.0037969546

Training iteration loss = 0.003372478

Training iteration loss = 0.002861374

Training iteration loss = 0.0038902333

Training iteration loss = 0.002210247

Training iteration loss = 0.0063388054

Training iteration loss = 0.0025697541

Training iteration loss = 0.0033978026

Training iteration loss = 0.0037954953

Training iteration loss = 0.0020600364

Training iteration loss = 0.0020765841

Training iteration loss = 0.002580575

Training iteration loss = 0.0016051143

Training iteration loss = 0.0032440957

Training iteration loss = 0.0031546943

Training iteration loss = 0.0040343953

Training iteration loss = 0.0030643335

Training iteration loss = 0.0027387997

Training iteration loss = 0.0023102094

Training iteration loss = 0.0021851875

Training iteration loss = 0.0023373587

Training iteration loss = 0.0030647388

Training iteration loss = 0.0045163813

Training iteration loss = 0.001794906

Training iteration loss = 0.0029626917

Training iteration loss = 0.0030564477

Training iteration loss = 0.003298626

Training iteration loss = 0.0028367266

Training iteration loss = 0.0032389378

Training iteration loss = 0.0028167411

Training iteration loss = 0.0017587267

Training iteration loss = 0.0058042253

Training iteration loss = 0.0029581916

Training iteration loss = 0.0025625315

Training iteration loss = 0.0017794835

Training iteration loss = 0.0031759532

Training iteration loss = 0.003580585

Training iteration loss = 0.0036262646

Training iteration loss = 0.0022996012

Training iteration loss = 0.0056127342

Training iteration loss = 0.0030458104

Training iteration loss = 0.0022549268

Training iteration loss = 0.002061432

Training iteration loss = 0.002424552

Training iteration loss = 0.0019434994

Training iteration loss = 0.0028707208

Training iteration loss = 0.0017485837

Training iteration loss = 0.0019890757

Training iteration loss = 0.003650047

Training iteration loss = 0.0026948033

Training iteration loss = 0.0032755856

Training iteration loss = 0.0025549033

Training iteration loss = 0.0038843509

Training iteration loss = 0.0041199904

Training iteration loss = 0.0040527126

Training iteration loss = 0.0019484743

Training iteration loss = 0.0027650583

Training iteration loss = 0.00238601

Training iteration loss = 0.0036675427

Training iteration loss = 0.0033041935

Training iteration loss = 0.0044909013

Training iteration loss = 0.0028366551

Training iteration loss = 0.0023557045

Training iteration loss = 0.003182965

Training iteration loss = 0.004688926

Training iteration loss = 0.0031779408

Training iteration loss = 0.002739637

Training iteration loss = 0.003236129

Training iteration loss = 0.003110097

Training iteration loss = 0.002390913

Training iteration loss = 0.0024320262

Training iteration loss = 0.0036208371

Training iteration loss = 0.0029855014

Training iteration loss = 0.003060005

Training iteration loss = 0.0027895384

Training iteration loss = 0.0022252176

Training iteration loss = 0.004358538

Training iteration loss = 0.0039159087

Training iteration loss = 0.003840198

Training iteration loss = 0.0035000527

Training iteration loss = 0.002175844

Training iteration loss = 0.0045145242

Training iteration loss = 0.005497405

Training iteration loss = 0.002287417

Training iteration loss = 0.0031828042

Training iteration loss = 0.002323231

Training iteration loss = 0.0026461466

Training iteration loss = 0.0026387505

Training iteration loss = 0.002451234

Training iteration loss = 0.004737579

Training iteration loss = 0.005313402

Training iteration loss = 0.0024558676

Training iteration loss = 0.0028589405

Training iteration loss = 0.0022123856

Training iteration loss = 0.0025352906

Training iteration loss = 0.0033409784

Training iteration loss = 0.0031867276

Training iteration loss = 0.0036474082

Training iteration loss = 0.0022905783

Training iteration loss = 0.003475939

Training iteration loss = 0.007034226

Training iteration loss = 0.004565052

Training iteration loss = 0.0036485696

Training iteration loss = 0.0028908595

Training iteration loss = 0.0033942696

Training iteration loss = 0.0026525522

Training iteration loss = 0.0032938067

Training iteration loss = 0.0020925456

Training iteration loss = 0.0025147605

Training iteration loss = 0.002567245

Training iteration loss = 0.0024176408

Training iteration loss = 0.001952805

Training iteration loss = 0.0045283632

Training iteration loss = 0.0032287296

Training iteration loss = 0.0052490123

Training iteration loss = 0.0032859026

Training iteration loss = 0.0031623787

Training iteration loss = 0.00317448

Training iteration loss = 0.006312825

Training iteration loss = 0.0038490978

Training iteration loss = 0.003383293

Training iteration loss = 0.0025217214

Training iteration loss = 0.0045339414

Training iteration loss = 0.0021025161

Training iteration loss = 0.0024671855

Training iteration loss = 0.0028867088

Training iteration loss = 0.0036564574

Training iteration loss = 0.0028077671

Training iteration loss = 0.003750419

Training iteration loss = 0.0033647225

Training iteration loss = 0.0019460692

Training iteration loss = 0.0024357988

Training iteration loss = 0.0019280463

Training iteration loss = 0.0024496538

Training iteration loss = 0.0020089366

Training iteration loss = 0.002441475

Training iteration loss = 0.0033327846

Training iteration loss = 0.003368127

Training iteration loss = 0.004544619

Training iteration loss = 0.0041071414

Training iteration loss = 0.0039767115

Training iteration loss = 0.002098036

Training iteration loss = 0.0029387528

Training iteration loss = 0.0021760475

Training iteration loss = 0.006052388

Training iteration loss = 0.0035573083

Training iteration loss = 0.0029239233

Training iteration loss = 0.0027794356

Training iteration loss = 0.0035590606

Training iteration loss = 0.0069135115

Training iteration loss = 0.0022920223

Training iteration loss = 0.0035268597

Training iteration loss = 0.0035716358

Training iteration loss = 0.0022808977

Training iteration loss = 0.0034502863

Training iteration loss = 0.0037069034

Training iteration loss = 0.0026402876

Training iteration loss = 0.0025186816

Training iteration loss = 0.003141153

Training iteration loss = 0.003575463

Training iteration loss = 0.0034859471

Training iteration loss = 0.004340084

Training iteration loss = 0.0046615438

Training iteration loss = 0.003172613

Training iteration loss = 0.0035963515

Training iteration loss = 0.0041270233

Training iteration loss = 0.0042998553

Training iteration loss = 0.0027754104

Training iteration loss = 0.0035956968

Training iteration loss = 0.003937503

Training iteration loss = 0.002494197

Training iteration loss = 0.0021125053

Training iteration loss = 0.003593158

Training iteration loss = 0.0023665195

Training iteration loss = 0.0020367429

Training iteration loss = 0.003073971

Training iteration loss = 0.002250604

Training iteration loss = 0.0017167429

Training iteration loss = 0.0018439664

Training iteration loss = 0.0031421205

Training iteration loss = 0.002024824

Training iteration loss = 0.0022470967

Training iteration loss = 0.0038378723

Training iteration loss = 0.005047629

Training iteration loss = 0.002475328

Training iteration loss = 0.002689413

Training iteration loss = 0.0023660082

Training iteration loss = 0.0025653152

Training iteration loss = 0.0022534642

Training iteration loss = 0.0039511905

Training iteration loss = 0.003313868

Training iteration loss = 0.0049222694

Training iteration loss = 0.0038642616

Training iteration loss = 0.002789221

Training iteration loss = 0.001922539

Training iteration loss = 0.0020690009

Training iteration loss = 0.0081360275

Training iteration loss = 0.0029189314

Training iteration loss = 0.0017351296

Training iteration loss = 0.004211144

Training iteration loss = 0.0038009863

Training iteration loss = 0.0033724096

Training iteration loss = 0.0028598562

Training iteration loss = 0.003886646

Training iteration loss = 0.0022078895

Training iteration loss = 0.0063320627

Training iteration loss = 0.002569318

Training iteration loss = 0.003398292

Training iteration loss = 0.003797333

Training iteration loss = 0.002062097

Training iteration loss = 0.0020757057

Training iteration loss = 0.002580473

Training iteration loss = 0.0016048709

Training iteration loss = 0.0032432002

Training iteration loss = 0.003156742

Training iteration loss = 0.0040340773

Training iteration loss = 0.0030628948

Training iteration loss = 0.0027397757

Training iteration loss = 0.0023083605

Training iteration loss = 0.002185556

Training iteration loss = 0.00233596

Training iteration loss = 0.0030633176

Training iteration loss = 0.0045042406

Training iteration loss = 0.0017941269

Training iteration loss = 0.0029614537

Training iteration loss = 0.0030534621

Training iteration loss = 0.0032975078

Training iteration loss = 0.0028359324

Training iteration loss = 0.003238516

Training iteration loss = 0.0028174606

Training iteration loss = 0.0017569362

Training iteration loss = 0.0057822075

Training iteration loss = 0.0029577836

Training iteration loss = 0.002556749

Training iteration loss = 0.0017789202

Training iteration loss = 0.0031697797

Training iteration loss = 0.003581035

Training iteration loss = 0.0036284358

Training iteration loss = 0.0022967316

Training iteration loss = 0.0056094346

Training iteration loss = 0.0030438954

Training iteration loss = 0.0022513103

Training iteration loss = 0.002062172

Training iteration loss = 0.0024208191

Training iteration loss = 0.0019477598

Training iteration loss = 0.0028685692

Training iteration loss = 0.0017495612

Training iteration loss = 0.0019824577

Training iteration loss = 0.003648447

Training iteration loss = 0.002692093

Training iteration loss = 0.0032753292

Training iteration loss = 0.0025520162

Training iteration loss = 0.0038778258

Training iteration loss = 0.0041175163

Training iteration loss = 0.0040472033

Training iteration loss = 0.001950136

Training iteration loss = 0.0027590443

Training iteration loss = 0.00238465

Training iteration loss = 0.003675775

Training iteration loss = 0.0032973792

Training iteration loss = 0.00448758

Training iteration loss = 0.0028321838

Training iteration loss = 0.0023555937

Training iteration loss = 0.0031816948

Training iteration loss = 0.004691088

Training iteration loss = 0.0031800063

Training iteration loss = 0.0027406097

Training iteration loss = 0.0032309715

Training iteration loss = 0.0031041484

Training iteration loss = 0.0023827392

Training iteration loss = 0.002424444

Training iteration loss = 0.0036239547

Training iteration loss = 0.0029847138

Training iteration loss = 0.0030630298

Training iteration loss = 0.0027945489

Training iteration loss = 0.0022210805

Training iteration loss = 0.0043536057

Training iteration loss = 0.0038916992

Training iteration loss = 0.0038421585

Training iteration loss = 0.0034878794

Training iteration loss = 0.0021740433

Training iteration loss = 0.00452271

Training iteration loss = 0.0054987906

Training iteration loss = 0.0022843324

Training iteration loss = 0.0031788626

Training iteration loss = 0.0023230223

Training iteration loss = 0.0026484763

Training iteration loss = 0.0026357975

Training iteration loss = 0.0024507563

Training iteration loss = 0.0047333697

Training iteration loss = 0.0053080968

Training iteration loss = 0.0024512175

Training iteration loss = 0.0028605836

Training iteration loss = 0.002210543

Training iteration loss = 0.0025325024

Training iteration loss = 0.0033404452

Training iteration loss = 0.0031845877

Training iteration loss = 0.0036435367

Training iteration loss = 0.002294182

Training iteration loss = 0.0034742148

Training iteration loss = 0.0070372447

Training iteration loss = 0.0045594107

Training iteration loss = 0.00364609

Training iteration loss = 0.0028873328

Training iteration loss = 0.003395496

Training iteration loss = 0.0026496171

Training iteration loss = 0.0032896204

Training iteration loss = 0.0020900331

Training iteration loss = 0.0025140902

Training iteration loss = 0.0025637853

Training iteration loss = 0.002408054

Training iteration loss = 0.0019520974

Training iteration loss = 0.004527308

Training iteration loss = 0.0032319285

Training iteration loss = 0.0052486635

Training iteration loss = 0.0032795353

Training iteration loss = 0.0031586725

Training iteration loss = 0.003183509

Training iteration loss = 0.0062992596

Training iteration loss = 0.0038419608

Training iteration loss = 0.0033780888

Training iteration loss = 0.0025167444

Training iteration loss = 0.0045231697

Training iteration loss = 0.0021033203

Training iteration loss = 0.0024643785

Training iteration loss = 0.0028820492

Training iteration loss = 0.0036545836

Training iteration loss = 0.0028057313

Training iteration loss = 0.0037476288

Training iteration loss = 0.0033662878

Training iteration loss = 0.0019476752

Training iteration loss = 0.00243053

Training iteration loss = 0.0019208106

Training iteration loss = 0.0024486145

Training iteration loss = 0.0020128435

Training iteration loss = 0.002442079

Training iteration loss = 0.0033222819

Training iteration loss = 0.0033667556

Training iteration loss = 0.0045408397

Training iteration loss = 0.0040967143

Training iteration loss = 0.003978818

Training iteration loss = 0.002094736

Training iteration loss = 0.0029363304

Training iteration loss = 0.0021726165

Training iteration loss = 0.0060542356

Training iteration loss = 0.00355866

Training iteration loss = 0.002922173

Training iteration loss = 0.0027727426

Training iteration loss = 0.0035542352

Training iteration loss = 0.006926104

Training iteration loss = 0.0022893408

Training iteration loss = 0.0035263498

Training iteration loss = 0.0035653496

Training iteration loss = 0.0022710783

Training iteration loss = 0.0034417855

Training iteration loss = 0.0037064191

Training iteration loss = 0.002637734

Training iteration loss = 0.0025223813

Training iteration loss = 0.0031524894

Training iteration loss = 0.0035715064

Training iteration loss = 0.0034900007

Training iteration loss = 0.004309685

Training iteration loss = 0.004658723

Training iteration loss = 0.0031626753

Training iteration loss = 0.0036108883

Training iteration loss = 0.004124543

Training iteration loss = 0.004303627

Training iteration loss = 0.0027736276

Training iteration loss = 0.0035941026

Training iteration loss = 0.003928093

Training iteration loss = 0.00248624

Training iteration loss = 0.0021087902

Training iteration loss = 0.0035917193

Training iteration loss = 0.002364874

Training iteration loss = 0.0020387082

Training iteration loss = 0.0030745778

Training iteration loss = 0.0022529885

Training iteration loss = 0.0017159594

Training iteration loss = 0.0018416458

Training iteration loss = 0.003140023

Training iteration loss = 0.002020968

Training iteration loss = 0.002250649

Training iteration loss = 0.0038391808

Training iteration loss = 0.0050408393

Training iteration loss = 0.0024798233

Training iteration loss = 0.002693054

Training iteration loss = 0.002363665

Training iteration loss = 0.0025606789

Training iteration loss = 0.0022592938

Training iteration loss = 0.0039503663

Training iteration loss = 0.0033137684

Training iteration loss = 0.0049194153

Training iteration loss = 0.0038635235

Training iteration loss = 0.0027851902

Training iteration loss = 0.0019183281

Training iteration loss = 0.002065961

Training iteration loss = 0.008127949

Training iteration loss = 0.0029165635

Training iteration loss = 0.00172732

Training iteration loss = 0.0042118733

Training iteration loss = 0.0038022397

Training iteration loss = 0.0033711027

Training iteration loss = 0.0028572727

Training iteration loss = 0.0038842766

Training iteration loss = 0.0022098543

Training iteration loss = 0.006329349

Training iteration loss = 0.0025719025

Training iteration loss = 0.0033989921

Training iteration loss = 0.0037985092

Training iteration loss = 0.002063552

Training iteration loss = 0.0020747792

Training iteration loss = 0.0025786313

Training iteration loss = 0.0016026059

Training iteration loss = 0.0032411076

Training iteration loss = 0.0031636793

Training iteration loss = 0.0040374957

Training iteration loss = 0.0030619241

Training iteration loss = 0.0027399382

Training iteration loss = 0.0023075577

Training iteration loss = 0.002188599

Training iteration loss = 0.002333276

Training iteration loss = 0.0030594822

Training iteration loss = 0.0045035365

Training iteration loss = 0.0017932202

Training iteration loss = 0.0029646207

Training iteration loss = 0.0030521995

Training iteration loss = 0.0032948086

Training iteration loss = 0.0028335592

Training iteration loss = 0.0032387718

Training iteration loss = 0.0028170387

Training iteration loss = 0.0017542614

Training iteration loss = 0.005773473

Training iteration loss = 0.0029582828

Training iteration loss = 0.00255561

Training iteration loss = 0.0017789357

Training iteration loss = 0.0031670816

Training iteration loss = 0.0035767404

Training iteration loss = 0.0036298383

Training iteration loss = 0.0022928135

Training iteration loss = 0.0056041125

Training iteration loss = 0.0030459594

Training iteration loss = 0.0022512348

Training iteration loss = 0.0020644541

Training iteration loss = 0.0024161395

Training iteration loss = 0.0019470621

Training iteration loss = 0.0028610595

Training iteration loss = 0.0017490741

Training iteration loss = 0.0019876445

Training iteration loss = 0.0036640847

Training iteration loss = 0.0026880875

Training iteration loss = 0.0032677732

Training iteration loss = 0.0025485107

Training iteration loss = 0.003880608

Training iteration loss = 0.004122411

Training iteration loss = 0.0040387046

Training iteration loss = 0.0019449029

Training iteration loss = 0.0027471904

Training iteration loss = 0.0023853544

Training iteration loss = 0.0036722475

Training iteration loss = 0.0032868509

Training iteration loss = 0.0044866824

Training iteration loss = 0.0028352614

Training iteration loss = 0.0023499962

Training iteration loss = 0.0031815863

Training iteration loss = 0.004687881

Training iteration loss = 0.0031749585

Training iteration loss = 0.002744807

Training iteration loss = 0.0032285796

Training iteration loss = 0.0030970287

Training iteration loss = 0.0023850135

Training iteration loss = 0.0024192461

Training iteration loss = 0.0036234062

Training iteration loss = 0.0029907536

Training iteration loss = 0.003064139

Training iteration loss = 0.002796416

Training iteration loss = 0.0022194355

Training iteration loss = 0.004355696

Training iteration loss = 0.0038851916

Training iteration loss = 0.003840729

Training iteration loss = 0.0034775932

Training iteration loss = 0.002173961

Training iteration loss = 0.0045224326

Training iteration loss = 0.005497653

Training iteration loss = 0.0022808695

Training iteration loss = 0.003174384

Training iteration loss = 0.0023230803

Training iteration loss = 0.0026500525

Training iteration loss = 0.0026336827

Training iteration loss = 0.0024526361

Training iteration loss = 0.0047317357

Training iteration loss = 0.0052978727

Training iteration loss = 0.0024479271

Training iteration loss = 0.0028603764

Training iteration loss = 0.0022121265

Training iteration loss = 0.0025302365

Training iteration loss = 0.003340449

Training iteration loss = 0.0031835542

Training iteration loss = 0.0036413728

Training iteration loss = 0.0022927898

Training iteration loss = 0.0034740278

Training iteration loss = 0.0070342533

Training iteration loss = 0.004558075

Training iteration loss = 0.0036421102

Training iteration loss = 0.0028854953

Training iteration loss = 0.003397256

Training iteration loss = 0.0026507347

Training iteration loss = 0.0032909045

Training iteration loss = 0.0020892282

Training iteration loss = 0.0025142995

Training iteration loss = 0.0025647653

Training iteration loss = 0.0024092249

Training iteration loss = 0.001952812

Training iteration loss = 0.004528383

Training iteration loss = 0.0032325005

Training iteration loss = 0.005247835

Training iteration loss = 0.0032817589

Training iteration loss = 0.0031605277

Training iteration loss = 0.0031887796

Training iteration loss = 0.0062880316

Training iteration loss = 0.003839371

Training iteration loss = 0.0033756234

Training iteration loss = 0.0025138361

Training iteration loss = 0.004508321

Training iteration loss = 0.0021027757

Training iteration loss = 0.0024650835

Training iteration loss = 0.0028839547

Training iteration loss = 0.0036551543

Training iteration loss = 0.0028026095

Training iteration loss = 0.0037455054

Training iteration loss = 0.0033660335

Training iteration loss = 0.0019513868

Training iteration loss = 0.0024301945

Training iteration loss = 0.0019176187

Training iteration loss = 0.0024485334

Training iteration loss = 0.0020140081

Training iteration loss = 0.0024417383

Training iteration loss = 0.0033199245

Training iteration loss = 0.0033638766

Training iteration loss = 0.004539445

Training iteration loss = 0.0040929853

Training iteration loss = 0.0039732116

Training iteration loss = 0.0020939084

Training iteration loss = 0.0029339446

Training iteration loss = 0.0021733043

Training iteration loss = 0.0060589514

Training iteration loss = 0.0035528655

Training iteration loss = 0.0029265557

Training iteration loss = 0.0027784419

Training iteration loss = 0.003558702

Training iteration loss = 0.0069135246

Training iteration loss = 0.002288406

Training iteration loss = 0.0035240306

Training iteration loss = 0.003571903

Training iteration loss = 0.002277175

Training iteration loss = 0.0034508929

Training iteration loss = 0.0037061076

Training iteration loss = 0.0026355747

Training iteration loss = 0.002514823

Training iteration loss = 0.0031437816

Training iteration loss = 0.00356551

Training iteration loss = 0.0034832463

Training iteration loss = 0.004324681

Training iteration loss = 0.004658938

Training iteration loss = 0.0031714614

Training iteration loss = 0.003598166

Training iteration loss = 0.004120213

Training iteration loss = 0.0042910613

Training iteration loss = 0.0027694528

Training iteration loss = 0.0035902744

Training iteration loss = 0.0039309906

Training iteration loss = 0.0024894013

Training iteration loss = 0.002115258

Training iteration loss = 0.003592783

Training iteration loss = 0.002364857

Training iteration loss = 0.002036975

Training iteration loss = 0.0030740716

Training iteration loss = 0.0022475081

Training iteration loss = 0.001711287

Training iteration loss = 0.001846694

Training iteration loss = 0.003149228

Training iteration loss = 0.0020298364

Training iteration loss = 0.0022489168

Training iteration loss = 0.0038327537

Training iteration loss = 0.0050457567

Training iteration loss = 0.0024767166

Training iteration loss = 0.0026840444

Training iteration loss = 0.0023615528

Training iteration loss = 0.0025586262

Training iteration loss = 0.0022560589

Training iteration loss = 0.00394468

Training iteration loss = 0.0033107258

Training iteration loss = 0.0049186638

Training iteration loss = 0.0038634706

Training iteration loss = 0.0027798747

Training iteration loss = 0.0019175065

Training iteration loss = 0.0020655235

Training iteration loss = 0.008123311

Training iteration loss = 0.0029149344

Training iteration loss = 0.0017198647

Training iteration loss = 0.0042124074

Training iteration loss = 0.0038024185

Training iteration loss = 0.0033710992

Training iteration loss = 0.0028562548

Training iteration loss = 0.0038840638

Training iteration loss = 0.0022096517

Training iteration loss = 0.0063225846

Training iteration loss = 0.002570717

Training iteration loss = 0.0033961183

Training iteration loss = 0.0037955362

Training iteration loss = 0.002060359

Training iteration loss = 0.0020733227

Training iteration loss = 0.002579107

Training iteration loss = 0.0016018664

Training iteration loss = 0.0032398656

Training iteration loss = 0.00316188

Training iteration loss = 0.004029292

Training iteration loss = 0.0030602356

Training iteration loss = 0.002737942

Training iteration loss = 0.002308811

Training iteration loss = 0.002187348

Training iteration loss = 0.0023334648

Training iteration loss = 0.0030559984

Training iteration loss = 0.004507735

Training iteration loss = 0.0017930031

Training iteration loss = 0.0029648729

Training iteration loss = 0.0030528393

Training iteration loss = 0.0032914362

Training iteration loss = 0.0028308195

Training iteration loss = 0.003240305

Training iteration loss = 0.0028173055

Training iteration loss = 0.0017528074

Training iteration loss = 0.0057653724

Training iteration loss = 0.0029575608

Training iteration loss = 0.0025584595

Training iteration loss = 0.0017816263

Training iteration loss = 0.0031684984

Training iteration loss = 0.003571274

Training iteration loss = 0.0036236856

Training iteration loss = 0.0022919674

Training iteration loss = 0.005592575

Training iteration loss = 0.0030512295

Training iteration loss = 0.0022598857

Training iteration loss = 0.0020693054

Training iteration loss = 0.0024178107

Training iteration loss = 0.0019450122

Training iteration loss = 0.0028534764

Training iteration loss = 0.0017519303

Training iteration loss = 0.001990786

Training iteration loss = 0.0036629355

Training iteration loss = 0.0026849823

Training iteration loss = 0.0032572213

Training iteration loss = 0.002547382

Training iteration loss = 0.0038903777

Training iteration loss = 0.0041245646

Training iteration loss = 0.004035092

Training iteration loss = 0.0019374137

Training iteration loss = 0.002739412

Training iteration loss = 0.0023777436

Training iteration loss = 0.0036589338

Training iteration loss = 0.003282943

Training iteration loss = 0.004480838

Training iteration loss = 0.0028406763

Training iteration loss = 0.0023524046

Training iteration loss = 0.0031882506

Training iteration loss = 0.0046798135

Training iteration loss = 0.0031726211

Training iteration loss = 0.0027493758

Training iteration loss = 0.0032250294

Training iteration loss = 0.0030954105

Training iteration loss = 0.0023941312

Training iteration loss = 0.0024163732

Training iteration loss = 0.0036232627

Training iteration loss = 0.002995658

Training iteration loss = 0.0030667856

Training iteration loss = 0.0027971175

Training iteration loss = 0.0022203682

Training iteration loss = 0.0043601193

Training iteration loss = 0.0038919644

Training iteration loss = 0.0038357151

Training iteration loss = 0.0034763652

Training iteration loss = 0.0021750818

Training iteration loss = 0.0045116795

Training iteration loss = 0.005499815

Training iteration loss = 0.0022794283

Training iteration loss = 0.0031655438

Training iteration loss = 0.0023205911

Training iteration loss = 0.0026522083

Training iteration loss = 0.0026322745

Training iteration loss = 0.0024519982

Training iteration loss = 0.004729914

Training iteration loss = 0.005285295

Training iteration loss = 0.0024464424

Training iteration loss = 0.0028602004

Training iteration loss = 0.0022139018

Training iteration loss = 0.0025266975

Training iteration loss = 0.0033396452

Training iteration loss = 0.0031857395

Training iteration loss = 0.0036397271

Training iteration loss = 0.0022879962

Training iteration loss = 0.00347697

Training iteration loss = 0.0070283897

Training iteration loss = 0.0045564566

Training iteration loss = 0.0036367837

Training iteration loss = 0.0028825607

Training iteration loss = 0.0033975097

Training iteration loss = 0.0026530025

Training iteration loss = 0.003292786

Training iteration loss = 0.0020890764

Training iteration loss = 0.0025132378

Training iteration loss = 0.002567359

Training iteration loss = 0.0024133609

Training iteration loss = 0.0019522129

Training iteration loss = 0.004528639

Training iteration loss = 0.0032305634

Training iteration loss = 0.00524761

Training iteration loss = 0.003289857

Training iteration loss = 0.0031640958

Training iteration loss = 0.003181786

Training iteration loss = 0.0062795733

Training iteration loss = 0.003840313

Training iteration loss = 0.0033771542

Training iteration loss = 0.0025131574

Training iteration loss = 0.004501771

Training iteration loss = 0.0021014577

Training iteration loss = 0.002467001

Training iteration loss = 0.0028855184

Training iteration loss = 0.0036541487

Training iteration loss = 0.0028006954

Training iteration loss = 0.0037448655

Training iteration loss = 0.003366855

Training iteration loss = 0.0019540216

Training iteration loss = 0.0024314562

Training iteration loss = 0.001918058

Training iteration loss = 0.0024485087

Training iteration loss = 0.0020139602

Training iteration loss = 0.0024417434

Training iteration loss = 0.003322605

Training iteration loss = 0.0033606237

Training iteration loss = 0.0045400667

Training iteration loss = 0.0040926845

Training iteration loss = 0.0039700414

Training iteration loss = 0.0020917596

Training iteration loss = 0.0029323928

Training iteration loss = 0.0021733989

Training iteration loss = 0.0060530477

Training iteration loss = 0.0035427117

Training iteration loss = 0.0029306512

Training iteration loss = 0.0027850836

Training iteration loss = 0.003564129

Training iteration loss = 0.0068829264

Training iteration loss = 0.0022904968

Training iteration loss = 0.003521219

Training iteration loss = 0.0035792275

Training iteration loss = 0.0022852952

Training iteration loss = 0.0034616385

Training iteration loss = 0.0037079677

Training iteration loss = 0.0026367495

Training iteration loss = 0.0025103018

Training iteration loss = 0.003137557

Training iteration loss = 0.00356383

Training iteration loss = 0.003479645

Training iteration loss = 0.0043334365

Training iteration loss = 0.004656774

Training iteration loss = 0.0031787895

Training iteration loss = 0.0035802284

Training iteration loss = 0.0041075475

Training iteration loss = 0.004284672

Training iteration loss = 0.0027682122

Training iteration loss = 0.0035742417

Training iteration loss = 0.0039227894

Training iteration loss = 0.0024860485

Training iteration loss = 0.0021129283

Training iteration loss = 0.0035990218

Training iteration loss = 0.0023629263

Training iteration loss = 0.0020346998

Training iteration loss = 0.0030635328

Training iteration loss = 0.0022452003

Training iteration loss = 0.0017126055

Training iteration loss = 0.0018442945

Training iteration loss = 0.0031479804

Training iteration loss = 0.0020267724

Training iteration loss = 0.0022497687

Training iteration loss = 0.0038236228

Training iteration loss = 0.005023129

Training iteration loss = 0.0024811265

Training iteration loss = 0.002689342

Training iteration loss = 0.0023675852

Training iteration loss = 0.0025505794

Training iteration loss = 0.002257123

Training iteration loss = 0.003943338

Training iteration loss = 0.0033090247

Training iteration loss = 0.0049164915

Training iteration loss = 0.0038593465

Training iteration loss = 0.0027810794

Training iteration loss = 0.0019175605

Training iteration loss = 0.0020656015

Training iteration loss = 0.008113103

Training iteration loss = 0.0029122003

Training iteration loss = 0.0017144333

Training iteration loss = 0.004212679

Training iteration loss = 0.0038050336

Training iteration loss = 0.0033702224

Training iteration loss = 0.002850129

Training iteration loss = 0.003879768

Training iteration loss = 0.0022052065

Training iteration loss = 0.0063225287

Training iteration loss = 0.0025726953

Training iteration loss = 0.0033948037

Training iteration loss = 0.0037956068

Training iteration loss = 0.0020592602

Training iteration loss = 0.0020686232

Training iteration loss = 0.0025725474

Training iteration loss = 0.0015974686

Training iteration loss = 0.0032334703

Training iteration loss = 0.003161583

Training iteration loss = 0.004034092

Training iteration loss = 0.0030619705

Training iteration loss = 0.00273674

Training iteration loss = 0.0023102942

Training iteration loss = 0.002189032

Training iteration loss = 0.0023294806

Training iteration loss = 0.0030551068

Training iteration loss = 0.0044958876

Training iteration loss = 0.0017906075

Training iteration loss = 0.002960338

Training iteration loss = 0.003052948

Training iteration loss = 0.0032909606

Training iteration loss = 0.0028295394

Training iteration loss = 0.0032419525

Training iteration loss = 0.0028160478

Training iteration loss = 0.001751388

Training iteration loss = 0.0057554524

Training iteration loss = 0.0029573555

Training iteration loss = 0.0025604197

Training iteration loss = 0.0017795042

Training iteration loss = 0.0031612338

Training iteration loss = 0.0035729853

Training iteration loss = 0.0036171891

Training iteration loss = 0.0022880044

Training iteration loss = 0.005577563

Training iteration loss = 0.0030475284

Training iteration loss = 0.0022567231

Training iteration loss = 0.002067839

Training iteration loss = 0.002415868

Training iteration loss = 0.0019472064

Training iteration loss = 0.0028503938

Training iteration loss = 0.0017523022

Training iteration loss = 0.0019887488

Training iteration loss = 0.003667725

Training iteration loss = 0.0026833145

Training iteration loss = 0.0032639997

Training iteration loss = 0.0025444685

Training iteration loss = 0.0038845679

Training iteration loss = 0.0041180723

Training iteration loss = 0.0040207338

Training iteration loss = 0.0019409745

Training iteration loss = 0.002740074

Training iteration loss = 0.002383379

Training iteration loss = 0.0036701981

Training iteration loss = 0.0032787567

Training iteration loss = 0.0044814306

Training iteration loss = 0.0028350272

Training iteration loss = 0.0023444735

Training iteration loss = 0.0031849074

Training iteration loss = 0.0046818233

Training iteration loss = 0.0031699827

Training iteration loss = 0.0027476468

Training iteration loss = 0.0032258194

Training iteration loss = 0.0030965523

Training iteration loss = 0.002387679

Training iteration loss = 0.0024211493

Training iteration loss = 0.0036206506

Training iteration loss = 0.00299559

Training iteration loss = 0.0030629013

Training iteration loss = 0.0027984201

Training iteration loss = 0.0022166145

Training iteration loss = 0.0043536904

Training iteration loss = 0.003879621

Training iteration loss = 0.0038403554

Training iteration loss = 0.0034667093

Training iteration loss = 0.0021744855

Training iteration loss = 0.004520895

Training iteration loss = 0.005498724

Training iteration loss = 0.0022750178

Training iteration loss = 0.0031708933

Training iteration loss = 0.0023182307

Training iteration loss = 0.0026466846

Training iteration loss = 0.002630433

Training iteration loss = 0.0024547526

Training iteration loss = 0.0047243936

Training iteration loss = 0.005277235

Training iteration loss = 0.0024426514

Training iteration loss = 0.002861984

Training iteration loss = 0.0022144045

Training iteration loss = 0.002523417

Training iteration loss = 0.003343155

Training iteration loss = 0.0031853216

Training iteration loss = 0.0036359744

Training iteration loss = 0.0022888246

Training iteration loss = 0.0034736264

Training iteration loss = 0.007015522

Training iteration loss = 0.004552049

Training iteration loss = 0.003633866

Training iteration loss = 0.002882529

Training iteration loss = 0.0033961737

Training iteration loss = 0.0026526905

Training iteration loss = 0.0032927915

Training iteration loss = 0.002091154

Training iteration loss = 0.0025152727

Training iteration loss = 0.0025685884

Training iteration loss = 0.0024079832

Training iteration loss = 0.0019512116

Training iteration loss = 0.00453019

Training iteration loss = 0.0032269119

Training iteration loss = 0.00524539

Training iteration loss = 0.0032905582

Training iteration loss = 0.003161851

Training iteration loss = 0.0031698316

Training iteration loss = 0.0062707104

Training iteration loss = 0.003837997

Training iteration loss = 0.003376379

Training iteration loss = 0.0025118503

Training iteration loss = 0.004494391

Training iteration loss = 0.0020997904

Training iteration loss = 0.0024697967

Training iteration loss = 0.0028801

Training iteration loss = 0.0036509633

Training iteration loss = 0.0028015163

Training iteration loss = 0.003744158

Training iteration loss = 0.0033681549

Training iteration loss = 0.0019508927

Training iteration loss = 0.0024321561

Training iteration loss = 0.0019196657

Training iteration loss = 0.002449292

Training iteration loss = 0.0020154025

Training iteration loss = 0.0024386563

Training iteration loss = 0.0033216507

Training iteration loss = 0.003363001

Training iteration loss = 0.0045408984

Training iteration loss = 0.004094618

Training iteration loss = 0.0039723893

Training iteration loss = 0.002089493

Training iteration loss = 0.0029302307

Training iteration loss = 0.0021694375

Training iteration loss = 0.0060574003

Training iteration loss = 0.003544518

Training iteration loss = 0.002930633

Training iteration loss = 0.0027765299

Training iteration loss = 0.0035545789

Training iteration loss = 0.0068905223

Training iteration loss = 0.0022876998

Training iteration loss = 0.0035201646

Training iteration loss = 0.0035726018

Training iteration loss = 0.0022783654

Training iteration loss = 0.003456151

Training iteration loss = 0.003705509

Training iteration loss = 0.0026292412

Training iteration loss = 0.0025105572

Training iteration loss = 0.0031415243

Training iteration loss = 0.003560661

Training iteration loss = 0.003480904

Training iteration loss = 0.004318601

Training iteration loss = 0.004660591

Training iteration loss = 0.0031735366

Training iteration loss = 0.003580244

Training iteration loss = 0.004103567

Training iteration loss = 0.004282308

Training iteration loss = 0.0027711603

Training iteration loss = 0.0035850273

Training iteration loss = 0.0039181095

Training iteration loss = 0.0024834163

Training iteration loss = 0.002113524

Training iteration loss = 0.0035953457

Training iteration loss = 0.002362845

Training iteration loss = 0.0020335384

Training iteration loss = 0.00307143

Training iteration loss = 0.002244163

Training iteration loss = 0.0017084038

Training iteration loss = 0.001847201

Training iteration loss = 0.0031519672

Training iteration loss = 0.002025715

Training iteration loss = 0.0022444266

Training iteration loss = 0.0038242526

Training iteration loss = 0.005033495

Training iteration loss = 0.0024773653

Training iteration loss = 0.0026867602

Training iteration loss = 0.0023657575

Training iteration loss = 0.00255272

Training iteration loss = 0.0022506441

Training iteration loss = 0.003936459

Training iteration loss = 0.0033094678

Training iteration loss = 0.0049114223

Training iteration loss = 0.0038559318

Training iteration loss = 0.0027764642

Training iteration loss = 0.0019149007

Training iteration loss = 0.0020654795

Training iteration loss = 0.008105046

Training iteration loss = 0.002907934

Training iteration loss = 0.0017131625

Training iteration loss = 0.004204898

Training iteration loss = 0.0038082404

Training iteration loss = 0.0033706387

Training iteration loss = 0.0028525665

Training iteration loss = 0.0038778102

Training iteration loss = 0.0022032338

Training iteration loss = 0.006313127

Training iteration loss = 0.0025704198

Training iteration loss = 0.0033946775

Training iteration loss = 0.0037943963

Training iteration loss = 0.002058836

Training iteration loss = 0.0020678283

Training iteration loss = 0.0025733712

Training iteration loss = 0.0015994346

Training iteration loss = 0.0032350563

Training iteration loss = 0.0031585528

Training iteration loss = 0.0040242434

Training iteration loss = 0.0030590547

Training iteration loss = 0.002736096

Training iteration loss = 0.0023089263

Training iteration loss = 0.0021853156

Training iteration loss = 0.0023318816

Training iteration loss = 0.003053502

Training iteration loss = 0.0044999835

Training iteration loss = 0.0017906266

Training iteration loss = 0.0029597443

Training iteration loss = 0.0030510675

Training iteration loss = 0.003289623

Training iteration loss = 0.0028292316

Training iteration loss = 0.0032413828

Training iteration loss = 0.0028163325

Training iteration loss = 0.0017508086

Training iteration loss = 0.005751107

Training iteration loss = 0.002954643

Training iteration loss = 0.002558415

Training iteration loss = 0.0017769238

Training iteration loss = 0.0031569784

Training iteration loss = 0.0035689159

Training iteration loss = 0.0036150701

Training iteration loss = 0.0022866495

Training iteration loss = 0.0055772713

Training iteration loss = 0.0030460125

Training iteration loss = 0.002257001

Training iteration loss = 0.0020657605

Training iteration loss = 0.0024162177

Training iteration loss = 0.0019433884

Training iteration loss = 0.0028450582

Training iteration loss = 0.0017501732

Training iteration loss = 0.0019865106

Training iteration loss = 0.0036686265

Training iteration loss = 0.0026773328

Training iteration loss = 0.0032586108

Training iteration loss = 0.0025466706

Training iteration loss = 0.003880116

Training iteration loss = 0.004116547

Training iteration loss = 0.004015895

Training iteration loss = 0.0019384989

Training iteration loss = 0.002740399

Training iteration loss = 0.0023773524

Training iteration loss = 0.0036628374

Training iteration loss = 0.0032791393

Training iteration loss = 0.0044730124

Training iteration loss = 0.0028336681

Training iteration loss = 0.002341771

Training iteration loss = 0.0031868855

Training iteration loss = 0.0046778624

Training iteration loss = 0.0031670665

Training iteration loss = 0.0027481543

Training iteration loss = 0.0032242546

Training iteration loss = 0.0030979428

Training iteration loss = 0.002389182

Training iteration loss = 0.0024203893

Training iteration loss = 0.00361708

Training iteration loss = 0.0029957232

Training iteration loss = 0.0030616848

Training iteration loss = 0.002797691

Training iteration loss = 0.0022162863

Training iteration loss = 0.004352504

Training iteration loss = 0.0038830135

Training iteration loss = 0.0038383221

Training iteration loss = 0.0034652865

Training iteration loss = 0.0021736517

Training iteration loss = 0.004519909

Training iteration loss = 0.005495804

Training iteration loss = 0.0022712327

Training iteration loss = 0.003165142

Training iteration loss = 0.0023144751

Training iteration loss = 0.0026448295

Training iteration loss = 0.0026289206

Training iteration loss = 0.0024531805

Training iteration loss = 0.0047241715

Training iteration loss = 0.005266053

Training iteration loss = 0.0024403415

Training iteration loss = 0.0028629184

Training iteration loss = 0.0022119656

Training iteration loss = 0.002519884

Training iteration loss = 0.0033440671

Training iteration loss = 0.0031860003

Training iteration loss = 0.0036331753

Training iteration loss = 0.002285077

Training iteration loss = 0.0034745347

Training iteration loss = 0.007013489

Training iteration loss = 0.0045485287

Training iteration loss = 0.0036277154

Training iteration loss = 0.0028801977

Training iteration loss = 0.0033946105

Training iteration loss = 0.0026548505

Training iteration loss = 0.0032946784

Training iteration loss = 0.0020918285

Training iteration loss = 0.0025179056

Training iteration loss = 0.0025706445

Training iteration loss = 0.0024137306

Training iteration loss = 0.0019522597

Training iteration loss = 0.004530026

Training iteration loss = 0.0032276672

Training iteration loss = 0.0052441545

Training iteration loss = 0.0032937229

Training iteration loss = 0.0031637393

Training iteration loss = 0.0031855144

Training iteration loss = 0.006258694

Training iteration loss = 0.0038331952

Training iteration loss = 0.0033761335

Training iteration loss = 0.0025047224

Training iteration loss = 0.004471185

Training iteration loss = 0.0020975235

Training iteration loss = 0.0024683957

Training iteration loss = 0.0028869098

Training iteration loss = 0.0036538534

Training iteration loss = 0.002795871

Training iteration loss = 0.0037427174

Training iteration loss = 0.0033648936

Training iteration loss = 0.0019495956

Training iteration loss = 0.0024295545

Training iteration loss = 0.00191653

Training iteration loss = 0.0024394493

Training iteration loss = 0.0020050092

Training iteration loss = 0.0024336942

Training iteration loss = 0.003321346

Training iteration loss = 0.0033548633

Training iteration loss = 0.0045362716

Training iteration loss = 0.004093042

Training iteration loss = 0.0039606015

Training iteration loss = 0.002087691

Training iteration loss = 0.002930915

Training iteration loss = 0.00217156

Training iteration loss = 0.0060711093

Training iteration loss = 0.0035433911

Training iteration loss = 0.002931908

Training iteration loss = 0.0027807339

Training iteration loss = 0.0035562457

Training iteration loss = 0.006879268

Training iteration loss = 0.0022858924

Training iteration loss = 0.0035201835

Training iteration loss = 0.003573699

Training iteration loss = 0.0022845855

Training iteration loss = 0.0034643218

Training iteration loss = 0.0037026359

Training iteration loss = 0.0026276417

Training iteration loss = 0.0025065283

Training iteration loss = 0.0031377596

Training iteration loss = 0.0035649047

Training iteration loss = 0.0034904499

Training iteration loss = 0.0043316274

Training iteration loss = 0.004659751

Training iteration loss = 0.0031800356

Training iteration loss = 0.0035626024

Training iteration loss = 0.0041007833

Training iteration loss = 0.0042782854

Training iteration loss = 0.0027724458

Training iteration loss = 0.0035798596

Training iteration loss = 0.0039100684

Training iteration loss = 0.0024821686

Training iteration loss = 0.0021140038

Training iteration loss = 0.003597128

Training iteration loss = 0.0023658327

Training iteration loss = 0.0020316273

Training iteration loss = 0.0030641332

Training iteration loss = 0.0022412476

Training iteration loss = 0.0017077437

Training iteration loss = 0.0018459026

Training iteration loss = 0.003156522

Training iteration loss = 0.0020240445

Training iteration loss = 0.002244468

Training iteration loss = 0.0038196722

Training iteration loss = 0.0050223577

Training iteration loss = 0.0024798086

Training iteration loss = 0.0026885776

Training iteration loss = 0.0023691824

Training iteration loss = 0.0025477756

Training iteration loss = 0.0022494036

Training iteration loss = 0.003934001

Training iteration loss = 0.003309288

Training iteration loss = 0.004907778

Training iteration loss = 0.0038502074

Training iteration loss = 0.0027769662

Training iteration loss = 0.0019153781

Training iteration loss = 0.0020653645

Training iteration loss = 0.008101464

Training iteration loss = 0.002904442

Training iteration loss = 0.001709905

Training iteration loss = 0.0042004334

Training iteration loss = 0.0038116944

Training iteration loss = 0.0033702236

Training iteration loss = 0.0028461644

Training iteration loss = 0.0038747927

Training iteration loss = 0.0021979455

Training iteration loss = 0.006304931

Training iteration loss = 0.0025705725

Training iteration loss = 0.0033932708

Training iteration loss = 0.003795414

Training iteration loss = 0.0020590879

Training iteration loss = 0.002063981

Training iteration loss = 0.0025700305

Training iteration loss = 0.0015968926

Training iteration loss = 0.0032318216

Training iteration loss = 0.0031604979

Training iteration loss = 0.0040258514

Training iteration loss = 0.0030574899

Training iteration loss = 0.002735964

Training iteration loss = 0.0023077542

Training iteration loss = 0.0021875377

Training iteration loss = 0.0023291933

Training iteration loss = 0.0030522656

Training iteration loss = 0.0044909697

Training iteration loss = 0.0017885864

Training iteration loss = 0.0029574772

Training iteration loss = 0.0030493438

Training iteration loss = 0.0032886907

Training iteration loss = 0.002826117

Training iteration loss = 0.0032429497

Training iteration loss = 0.0028162468

Training iteration loss = 0.001748202

Training iteration loss = 0.005726749

Training iteration loss = 0.0029549764

Training iteration loss = 0.0025551242

Training iteration loss = 0.0017767628

Training iteration loss = 0.0031514745

Training iteration loss = 0.0035707077

Training iteration loss = 0.0036134438

Training iteration loss = 0.0022845443

Training iteration loss = 0.005568227

Training iteration loss = 0.003044551

Training iteration loss = 0.002255758

Training iteration loss = 0.0020659396

Training iteration loss = 0.0024136903

Training iteration loss = 0.0019468608

Training iteration loss = 0.0028436687

Training iteration loss = 0.0017522069

Training iteration loss = 0.0019797988

Training iteration loss = 0.0036632076

Training iteration loss = 0.0026754914

Training iteration loss = 0.0032595524

Training iteration loss = 0.0025447474

Training iteration loss = 0.0038766004

Training iteration loss = 0.0041118623

Training iteration loss = 0.004009511

Training iteration loss = 0.0019412435

Training iteration loss = 0.0027375866

Training iteration loss = 0.0023748

Training iteration loss = 0.0036691085

Training iteration loss = 0.0032736019

Training iteration loss = 0.004470393

Training iteration loss = 0.0028286017

Training iteration loss = 0.002342228

Training iteration loss = 0.0031868683

Training iteration loss = 0.0046787527

Training iteration loss = 0.003168315

Training iteration loss = 0.0027469622

Training iteration loss = 0.0032205088

Training iteration loss = 0.0030954918

Training iteration loss = 0.00238333

Training iteration loss = 0.0024163453

Training iteration loss = 0.0036189612

Training iteration loss = 0.002994357

Training iteration loss = 0.0030634117

Training iteration loss = 0.0028003417

Training iteration loss = 0.0022130262

Training iteration loss = 0.004349339

Training iteration loss = 0.003866282

Training iteration loss = 0.0038387303

Training iteration loss = 0.0034571749

Training iteration loss = 0.0021721558

Training iteration loss = 0.004525378

Training iteration loss = 0.0054992423

Training iteration loss = 0.0022686315

Training iteration loss = 0.003162481

Training iteration loss = 0.002313122

Training iteration loss = 0.0026460441

Training iteration loss = 0.0026264936

Training iteration loss = 0.0024528182

Training iteration loss = 0.0047197226

Training iteration loss = 0.0052621677

Training iteration loss = 0.0024361003

Training iteration loss = 0.0028644986

Training iteration loss = 0.002211214

Training iteration loss = 0.0025170096

Training iteration loss = 0.0033449093

Training iteration loss = 0.0031860443

Training iteration loss = 0.003628808

Training iteration loss = 0.0022874791

Training iteration loss = 0.0034732735

Training iteration loss = 0.0070150313

Training iteration loss = 0.004542326

Training iteration loss = 0.0036252465

Training iteration loss = 0.002878175

Training iteration loss = 0.0033946622

Training iteration loss = 0.0026519522

Training iteration loss = 0.0032899494

Training iteration loss = 0.0020908099

Training iteration loss = 0.0025159668

Training iteration loss = 0.0025672698

Training iteration loss = 0.002400663

Training iteration loss = 0.0019484063

Training iteration loss = 0.0045291176

Training iteration loss = 0.0032258825

Training iteration loss = 0.0052448413

Training iteration loss = 0.0032924006

Training iteration loss = 0.0031610385

Training iteration loss = 0.0031724612

Training iteration loss = 0.006249672

Training iteration loss = 0.003830793

Training iteration loss = 0.0033747752

Training iteration loss = 0.0025057613

Training iteration loss = 0.0044684713

Training iteration loss = 0.0020977117

Training iteration loss = 0.0024703944

Training iteration loss = 0.002877773

Training iteration loss = 0.0036474701

Training iteration loss = 0.0027999487

Training iteration loss = 0.0037418175

Training iteration loss = 0.0033705747

Training iteration loss = 0.0019504704

Training iteration loss = 0.0024296374

Training iteration loss = 0.0019181924

Training iteration loss = 0.0024483649

Training iteration loss = 0.0020165981

Training iteration loss = 0.002436178

Training iteration loss = 0.003314771

Training iteration loss = 0.0033589099

Training iteration loss = 0.004539491

Training iteration loss = 0.0040909075

Training iteration loss = 0.003967904

Training iteration loss = 0.0020862732

Training iteration loss = 0.0029276807

Training iteration loss = 0.00216844

Training iteration loss = 0.0060669966

Training iteration loss = 0.0035415832

Training iteration loss = 0.0029299601

Training iteration loss = 0.0027708944

Training iteration loss = 0.0035512894

Training iteration loss = 0.0068957065

Training iteration loss = 0.0022838863

Training iteration loss = 0.0035124219

Training iteration loss = 0.0035643468

Training iteration loss = 0.0022686257

Training iteration loss = 0.0034513911

Training iteration loss = 0.0036981516

Training iteration loss = 0.002621509

Training iteration loss = 0.002512702

Training iteration loss = 0.0031470081

Training iteration loss = 0.003558702

Training iteration loss = 0.0034877213

Training iteration loss = 0.00429656

Training iteration loss = 0.0046579563

Training iteration loss = 0.003167636

Training iteration loss = 0.0035886585

Training iteration loss = 0.0040975143

Training iteration loss = 0.004287749

Training iteration loss = 0.002763753

Training iteration loss = 0.003572341

Training iteration loss = 0.0039090123

Training iteration loss = 0.0024780843

Training iteration loss = 0.0021158217

Training iteration loss = 0.0035929743

Training iteration loss = 0.0023672543

Training iteration loss = 0.0020286448

Training iteration loss = 0.0030700697

Training iteration loss = 0.0022478383

Training iteration loss = 0.0017060161

Training iteration loss = 0.0018414272

Training iteration loss = 0.0031538967

Training iteration loss = 0.002023027

Training iteration loss = 0.002251194

Training iteration loss = 0.0038173029

Training iteration loss = 0.005011583

Training iteration loss = 0.002484936

Training iteration loss = 0.0026892482

Training iteration loss = 0.0023663815

Training iteration loss = 0.0025422059

Training iteration loss = 0.0022568356

Training iteration loss = 0.003936243

Training iteration loss = 0.0033096883

Training iteration loss = 0.0049052807

Training iteration loss = 0.0038551483

Training iteration loss = 0.0027728525

Training iteration loss = 0.0019100271

Training iteration loss = 0.0020618988

Training iteration loss = 0.008088906

Training iteration loss = 0.0029000978

Training iteration loss = 0.0017026437

Training iteration loss = 0.004202412

Training iteration loss = 0.003812617

Training iteration loss = 0.0033654075

Training iteration loss = 0.0028450133

Training iteration loss = 0.003874017

Training iteration loss = 0.002202632

Training iteration loss = 0.0063024857

Training iteration loss = 0.0025732822

Training iteration loss = 0.0033938289

Training iteration loss = 0.0037986522

Training iteration loss = 0.0020621372

Training iteration loss = 0.0020671226

Training iteration loss = 0.0025698885

Training iteration loss = 0.0015963092

Training iteration loss = 0.003226555

Training iteration loss = 0.0031605961

Training iteration loss = 0.0040272013

Training iteration loss = 0.0030602682

Training iteration loss = 0.0027362483

Training iteration loss = 0.0023062853

Training iteration loss = 0.002188313

Training iteration loss = 0.0023324483

Training iteration loss = 0.0030523378

Training iteration loss = 0.0044790073

Training iteration loss = 0.0017877003

Training iteration loss = 0.0029542528

Training iteration loss = 0.0030465375

Training iteration loss = 0.0032867242

Training iteration loss = 0.0028294541

Training iteration loss = 0.0032430582

Training iteration loss = 0.0028190864

Training iteration loss = 0.0017479198

Training iteration loss = 0.0057259947

Training iteration loss = 0.0029520176

Training iteration loss = 0.0025549347

Training iteration loss = 0.0017751567

Training iteration loss = 0.0031448815

Training iteration loss = 0.0035654204

Training iteration loss = 0.0036145428

Training iteration loss = 0.0022785768

Training iteration loss = 0.0055716042

Training iteration loss = 0.0030401552

Training iteration loss = 0.0022505026

Training iteration loss = 0.0020629363

Training iteration loss = 0.002409568

Training iteration loss = 0.0019466508

Training iteration loss = 0.0028382326

Training iteration loss = 0.0017497409

Training iteration loss = 0.0019798432

Training iteration loss = 0.003672058

Training iteration loss = 0.0026748702

Training iteration loss = 0.0032613163

Training iteration loss = 0.0025447311

Training iteration loss = 0.0038719315

Training iteration loss = 0.0041140555

Training iteration loss = 0.0040005688

Training iteration loss = 0.0019395375

Training iteration loss = 0.00273695

Training iteration loss = 0.002375327

Training iteration loss = 0.0036689609

Training iteration loss = 0.0032702463

Training iteration loss = 0.0044647474

Training iteration loss = 0.0028264457

Training iteration loss = 0.0023356143

Training iteration loss = 0.0031856147

Training iteration loss = 0.0046799984

Training iteration loss = 0.0031646232

Training iteration loss = 0.0027475972

Training iteration loss = 0.003220877

Training iteration loss = 0.0030948166

Training iteration loss = 0.0023824186

Training iteration loss = 0.00241568

Training iteration loss = 0.0036145805

Training iteration loss = 0.0029934477

Training iteration loss = 0.0030612878

Training iteration loss = 0.002802441

Training iteration loss = 0.002211172

Training iteration loss = 0.0043458804

Training iteration loss = 0.0038616823

Training iteration loss = 0.0038402292

Training iteration loss = 0.0034481252

Training iteration loss = 0.002171498

Training iteration loss = 0.0045307367

Training iteration loss = 0.0054955524

Training iteration loss = 0.0022650429

Training iteration loss = 0.0031628644

Training iteration loss = 0.0023124327

Training iteration loss = 0.00264343

Training iteration loss = 0.0026247234

Training iteration loss = 0.0024542103

Training iteration loss = 0.0047182753

Training iteration loss = 0.0052533387

Training iteration loss = 0.0024323603

Training iteration loss = 0.0028651159

Training iteration loss = 0.002210061

Training iteration loss = 0.0025142103

Training iteration loss = 0.0033467722

Training iteration loss = 0.0031863034

Training iteration loss = 0.0036254467

Training iteration loss = 0.0022867674

Training iteration loss = 0.0034725324

Training iteration loss = 0.0070118066

Training iteration loss = 0.004540231

Training iteration loss = 0.0036219747

Training iteration loss = 0.002876369

Training iteration loss = 0.0033954072

Training iteration loss = 0.002652054

Training iteration loss = 0.0032901575

Training iteration loss = 0.0020911435

Training iteration loss = 0.0025164324

Training iteration loss = 0.0025679548

Training iteration loss = 0.002399177

Training iteration loss = 0.0019483619

Training iteration loss = 0.0045300894

Training iteration loss = 0.0032258935

Training iteration loss = 0.0052445116

Training iteration loss = 0.003293216

Training iteration loss = 0.003161057

Training iteration loss = 0.003176879

Training iteration loss = 0.0062401667

Training iteration loss = 0.0038263341

Training iteration loss = 0.0033736706

Training iteration loss = 0.0025013902

Training iteration loss = 0.004455672

Training iteration loss = 0.0020970737

Training iteration loss = 0.0024705806

Training iteration loss = 0.0028772147

Training iteration loss = 0.0036494432

Training iteration loss = 0.0027973193

Training iteration loss = 0.0037413586

Training iteration loss = 0.0033691975

Training iteration loss = 0.0019492885

Training iteration loss = 0.002427851

Training iteration loss = 0.0019139837

Training iteration loss = 0.0024425269

Training iteration loss = 0.0020125469

Training iteration loss = 0.0024325333

Training iteration loss = 0.003313504

Training iteration loss = 0.0033542048

Training iteration loss = 0.004536873

Training iteration loss = 0.004087111

Training iteration loss = 0.0039643613

Training iteration loss = 0.0020836534

Training iteration loss = 0.002927865

Training iteration loss = 0.0021664004

Training iteration loss = 0.0060689356

Training iteration loss = 0.0035399802

Training iteration loss = 0.002932289

Training iteration loss = 0.0027704714

Training iteration loss = 0.0035496207

Training iteration loss = 0.0068886722

Training iteration loss = 0.0022829864

Training iteration loss = 0.0035139632

Training iteration loss = 0.003566378

Training iteration loss = 0.002272195

Training iteration loss = 0.0034541672

Training iteration loss = 0.0036993593

Training iteration loss = 0.0026195406

Training iteration loss = 0.0025073322

Training iteration loss = 0.0031426062

Training iteration loss = 0.0035529165

Training iteration loss = 0.0034864412

Training iteration loss = 0.004302446

Training iteration loss = 0.0046576587

Training iteration loss = 0.0031679468

Training iteration loss = 0.003578256

Training iteration loss = 0.0040958296

Training iteration loss = 0.00427583

Training iteration loss = 0.0027611156

Training iteration loss = 0.0035780438

Training iteration loss = 0.003907236

Training iteration loss = 0.0024776517

Training iteration loss = 0.002115867

Training iteration loss = 0.0035915636

Training iteration loss = 0.0023604142

Training iteration loss = 0.00202765

Training iteration loss = 0.0030727852

Training iteration loss = 0.0022452718

Training iteration loss = 0.001703217

Training iteration loss = 0.001844261

Training iteration loss = 0.0031578487

Training iteration loss = 0.0020216347

Training iteration loss = 0.0022460243

Training iteration loss = 0.0038182258

Training iteration loss = 0.0050237975

Training iteration loss = 0.002480634

Training iteration loss = 0.0026859508

Training iteration loss = 0.00236487

Training iteration loss = 0.002542976

Training iteration loss = 0.0022496986

Training iteration loss = 0.003929362

Training iteration loss = 0.0033092236

Training iteration loss = 0.0049009323

Training iteration loss = 0.0038503704

Training iteration loss = 0.0027674946

Training iteration loss = 0.0019084556

Training iteration loss = 0.0020612527

Training iteration loss = 0.008084828

Training iteration loss = 0.00289739

Training iteration loss = 0.0017010524

Training iteration loss = 0.0041972008

Training iteration loss = 0.003812242

Training iteration loss = 0.003365863

Training iteration loss = 0.0028449025

Training iteration loss = 0.0038722428

Training iteration loss = 0.0022008012

Training iteration loss = 0.006293693

Training iteration loss = 0.002570899

Training iteration loss = 0.0033930829

Training iteration loss = 0.0037976627

Training iteration loss = 0.0020621584

Training iteration loss = 0.002066164

Training iteration loss = 0.0025730762

Training iteration loss = 0.0015963353

Training iteration loss = 0.003226133

Training iteration loss = 0.0031615284

Training iteration loss = 0.0040212222

Training iteration loss = 0.003059158

Training iteration loss = 0.0027360804

Training iteration loss = 0.0023060564

Training iteration loss = 0.002186783

Training iteration loss = 0.0023337235

Training iteration loss = 0.0030503266

Training iteration loss = 0.00448491

Training iteration loss = 0.0017873911

Training iteration loss = 0.0029556805

Training iteration loss = 0.003045092

Training iteration loss = 0.0032841498

Training iteration loss = 0.0028287985

Training iteration loss = 0.0032434168

Training iteration loss = 0.0028194152

Training iteration loss = 0.0017463109

Training iteration loss = 0.005723674

Training iteration loss = 0.002950267

Training iteration loss = 0.002554991

Training iteration loss = 0.0017727857

Training iteration loss = 0.00314236

Training iteration loss = 0.0035586283

Training iteration loss = 0.0036135737

Training iteration loss = 0.0022756583

Training iteration loss = 0.005567921

Training iteration loss = 0.0030401486

Training iteration loss = 0.0022500406

Training iteration loss = 0.0020615913

Training iteration loss = 0.0024068654

Training iteration loss = 0.0019429335

Training iteration loss = 0.0028315748

Training iteration loss = 0.0017487011

Training iteration loss = 0.0019856328

Training iteration loss = 0.0036884334

Training iteration loss = 0.0026711847

Training iteration loss = 0.003255151

Training iteration loss = 0.0025439905

Training iteration loss = 0.003871679

Training iteration loss = 0.0041166623

Training iteration loss = 0.0039917743

Training iteration loss = 0.0019333786

Training iteration loss = 0.0027309908

Training iteration loss = 0.0023751077

Training iteration loss = 0.0036617105

Training iteration loss = 0.0032664007

Training iteration loss = 0.0044624438

Training iteration loss = 0.0028292963

Training iteration loss = 0.0023284175

Training iteration loss = 0.0031856035

Training iteration loss = 0.004675949

Training iteration loss = 0.0031576667

Training iteration loss = 0.0027503856

Training iteration loss = 0.0032216052

Training iteration loss = 0.0030928552

Training iteration loss = 0.002385584

Training iteration loss = 0.0024168533

Training iteration loss = 0.0036095558

Training iteration loss = 0.0029977125

Training iteration loss = 0.0030583625

Training iteration loss = 0.0028013585

Training iteration loss = 0.0022110923

Training iteration loss = 0.004345814

Training iteration loss = 0.0038685945

Training iteration loss = 0.0038395384

Training iteration loss = 0.0034447627

Training iteration loss = 0.0021716852

Training iteration loss = 0.0045282883

Training iteration loss = 0.005490905

Training iteration loss = 0.002260414

Training iteration loss = 0.0031604155

Training iteration loss = 0.0023096537

Training iteration loss = 0.0026396175

Training iteration loss = 0.0026237417

Training iteration loss = 0.0024552916

Training iteration loss = 0.004718133

Training iteration loss = 0.0052408613

Training iteration loss = 0.002429989

Training iteration loss = 0.0028655308

Training iteration loss = 0.0022087626

Training iteration loss = 0.0025111446

Training iteration loss = 0.0033492094

Training iteration loss = 0.0031867567

Training iteration loss = 0.0036229594

Training iteration loss = 0.0022824595

Training iteration loss = 0.0034731177

Training iteration loss = 0.00700423

Training iteration loss = 0.0045392266

Training iteration loss = 0.0036166005

Training iteration loss = 0.0028748699

Training iteration loss = 0.003395072

Training iteration loss = 0.0026555834

Training iteration loss = 0.0032947694

Training iteration loss = 0.0020931337

Training iteration loss = 0.0025205438

Training iteration loss = 0.002572723

Training iteration loss = 0.002408486

Training iteration loss = 0.0019508274

Training iteration loss = 0.0045314617

Training iteration loss = 0.003226081

Training iteration loss = 0.0052426676

Training iteration loss = 0.0032965578

Training iteration loss = 0.0031622986

Training iteration loss = 0.00319014

Training iteration loss = 0.0062293154

Training iteration loss = 0.0038223006

Training iteration loss = 0.0033727416

Training iteration loss = 0.0024948716

Training iteration loss = 0.0044344016

Training iteration loss = 0.0020955883

Training iteration loss = 0.0024699678

Training iteration loss = 0.0028843249

Training iteration loss = 0.0036524644

Training iteration loss = 0.0027914336

Training iteration loss = 0.0037390084

Training iteration loss = 0.0033648247

Training iteration loss = 0.0019476266

Training iteration loss = 0.0024270979

Training iteration loss = 0.001911526

Training iteration loss = 0.0024337696

Training iteration loss = 0.002002444

Training iteration loss = 0.0024270047

Training iteration loss = 0.003313031

Training iteration loss = 0.003348335

Training iteration loss = 0.0045329793

Training iteration loss = 0.0040888037

Training iteration loss = 0.0039521796

Training iteration loss = 0.0020828934

Training iteration loss = 0.0029288016

Training iteration loss = 0.0021687397

Training iteration loss = 0.006093144

Training iteration loss = 0.0035445418

Training iteration loss = 0.0029323148

Training iteration loss = 0.0027693866

Training iteration loss = 0.0035466852

Training iteration loss = 0.0068902546

Training iteration loss = 0.002279796

Training iteration loss = 0.0035159774

Training iteration loss = 0.003562754

Training iteration loss = 0.002276221

Training iteration loss = 0.0034617616

Training iteration loss = 0.0036947483

Training iteration loss = 0.0026154078

Training iteration loss = 0.0025064144

Training iteration loss = 0.0031482584

Training iteration loss = 0.0035643813

Training iteration loss = 0.003503815

Training iteration loss = 0.004303938

Training iteration loss = 0.004664682

Training iteration loss = 0.0031760999

Training iteration loss = 0.003554836

Training iteration loss = 0.0040899613

Training iteration loss = 0.0042793253

Training iteration loss = 0.0027755061

Training iteration loss = 0.0035765078

Training iteration loss = 0.0038899789

Training iteration loss = 0.0024727776

Training iteration loss = 0.0021178473

Training iteration loss = 0.0035947151

Training iteration loss = 0.0023726663

Training iteration loss = 0.0020265228

Training iteration loss = 0.003065273

Training iteration loss = 0.0022391635

Training iteration loss = 0.001701915

Training iteration loss = 0.0018475022

Training iteration loss = 0.0031674223

Training iteration loss = 0.0020226454

Training iteration loss = 0.002242802

Training iteration loss = 0.0038129555

Training iteration loss = 0.0050177136

Training iteration loss = 0.0024818454

Training iteration loss = 0.0026856328

Training iteration loss = 0.002366717

Training iteration loss = 0.0025381204

Training iteration loss = 0.0022463694

Training iteration loss = 0.0039244113

Training iteration loss = 0.003307685

Training iteration loss = 0.004901227

Training iteration loss = 0.0038423848

Training iteration loss = 0.0027685976

Training iteration loss = 0.00190984

Training iteration loss = 0.0020632474

Training iteration loss = 0.008074351

Training iteration loss = 0.0028957834

Training iteration loss = 0.0016958243

Training iteration loss = 0.0041975915

Training iteration loss = 0.0038163774

Training iteration loss = 0.00336459

Training iteration loss = 0.0028466696

Training iteration loss = 0.0038684558

Training iteration loss = 0.002197055

Training iteration loss = 0.006293222

Training iteration loss = 0.0025704766

Training iteration loss = 0.003388338

Training iteration loss = 0.003788425

Training iteration loss = 0.0020563789

Training iteration loss = 0.0020548345

Training iteration loss = 0.0025631536

Training iteration loss = 0.0015947161

Training iteration loss = 0.0032297552

Training iteration loss = 0.0031671738

Training iteration loss = 0.004024304

Training iteration loss = 0.003050548

Training iteration loss = 0.0027333742

Training iteration loss = 0.0023088404

Training iteration loss = 0.0021918498

Training iteration loss = 0.0023229707

Training iteration loss = 0.003038976

Training iteration loss = 0.004488913

Training iteration loss = 0.0017855741

Training iteration loss = 0.00295884

Training iteration loss = 0.003048057

Training iteration loss = 0.0032808462

Training iteration loss = 0.0028138962

Training iteration loss = 0.0032487188

Training iteration loss = 0.0028109539

Training iteration loss = 0.0017432179

Training iteration loss = 0.005703106

Training iteration loss = 0.0029551983

Training iteration loss = 0.002556529

Training iteration loss = 0.0017768029

Training iteration loss = 0.0031455783

Training iteration loss = 0.0035637503

Training iteration loss = 0.0036017431

Training iteration loss = 0.0022812209

Training iteration loss = 0.0055346526

Training iteration loss = 0.0030530265

Training iteration loss = 0.0022683234

Training iteration loss = 0.0020756812

Training iteration loss = 0.0024079054

Training iteration loss = 0.0019445455

Training iteration loss = 0.0028291529

Training iteration loss = 0.0017571374

Training iteration loss = 0.0019830493

Training iteration loss = 0.0036740697

Training iteration loss = 0.0026631216

Training iteration loss = 0.0032407064

Training iteration loss = 0.0025383227

Training iteration loss = 0.0038841506

Training iteration loss = 0.0041114986

Training iteration loss = 0.0039891773

Training iteration loss = 0.0019314255

Training iteration loss = 0.002719147

Training iteration loss = 0.0023657235

Training iteration loss = 0.0036540758

Training iteration loss = 0.003257721

Training iteration loss = 0.0044620163

Training iteration loss = 0.002834311

Training iteration loss = 0.0023403026

Training iteration loss = 0.0031910352

Training iteration loss = 0.004666806

Training iteration loss = 0.003161395

Training iteration loss = 0.0027529208

Training iteration loss = 0.0032119974

Training iteration loss = 0.003087545

Training iteration loss = 0.0023902983

Training iteration loss = 0.002402549

Training iteration loss = 0.0036194713

Training iteration loss = 0.0030038587

Training iteration loss = 0.003068597

Training iteration loss = 0.0028043545

Training iteration loss = 0.0022087174

Training iteration loss = 0.0043518804

Training iteration loss = 0.0038545523

Training iteration loss = 0.0038315153

Training iteration loss = 0.0034403342

Training iteration loss = 0.0021694135

Training iteration loss = 0.004523762

Training iteration loss = 0.0055061094

Training iteration loss = 0.0022603767

Training iteration loss = 0.0031457923

Training iteration loss = 0.0023079452

Training iteration loss = 0.0026496567

Training iteration loss = 0.002621222

Training iteration loss = 0.0024487784

Training iteration loss = 0.004716155

Training iteration loss = 0.005242272

Training iteration loss = 0.0024279573

Training iteration loss = 0.002867787

Training iteration loss = 0.0022068287

Training iteration loss = 0.0025082252

Training iteration loss = 0.003346362

Training iteration loss = 0.0031901048

Training iteration loss = 0.0036190555

Training iteration loss = 0.0022828423

Training iteration loss = 0.0034760768

Training iteration loss = 0.0070229373

Training iteration loss = 0.004532232

Training iteration loss = 0.0036115933

Training iteration loss = 0.002869703

Training iteration loss = 0.0033928666

Training iteration loss = 0.0026504658

Training iteration loss = 0.0032830127

Training iteration loss = 0.002087103

Training iteration loss = 0.0025129209

Training iteration loss = 0.0025630456

Training iteration loss = 0.0023945232

Training iteration loss = 0.0019446146

Training iteration loss = 0.004527896

Training iteration loss = 0.003231801

Training iteration loss = 0.005244745

Training iteration loss = 0.003293527

Training iteration loss = 0.0031587563

Training iteration loss = 0.0032083394

Training iteration loss = 0.0062174685

Training iteration loss = 0.0038147427

Training iteration loss = 0.0033727011

Training iteration loss = 0.0024856895

Training iteration loss = 0.004422783

Training iteration loss = 0.0020974653

Training iteration loss = 0.002461545

Training iteration loss = 0.0028800943

Training iteration loss = 0.003653937

Training iteration loss = 0.0027889907

Training iteration loss = 0.0037411926

Training iteration loss = 0.0033637416

Training iteration loss = 0.0019407724

Training iteration loss = 0.0024201956

Training iteration loss = 0.0018993764

Training iteration loss = 0.0024153655

Training iteration loss = 0.001988067

Training iteration loss = 0.0024229453

Training iteration loss = 0.0033044228

Training iteration loss = 0.0033324882

Training iteration loss = 0.0045213364

Training iteration loss = 0.004070483

Training iteration loss = 0.0039390842

Training iteration loss = 0.0020788137

Training iteration loss = 0.0029305771

Training iteration loss = 0.00217323

Training iteration loss = 0.006082228

Training iteration loss = 0.0035371094

Training iteration loss = 0.0029327355

Training iteration loss = 0.0027703678

Training iteration loss = 0.00355157

Training iteration loss = 0.006861485

Training iteration loss = 0.0022875476

Training iteration loss = 0.0035194654

Training iteration loss = 0.0035672511

Training iteration loss = 0.0022819766

Training iteration loss = 0.0034685375

Training iteration loss = 0.0036995234

Training iteration loss = 0.0026221203

Training iteration loss = 0.0025054596

Training iteration loss = 0.0031418677

Training iteration loss = 0.0035581195

Training iteration loss = 0.0034985214

Training iteration loss = 0.0043068114

Training iteration loss = 0.0046570865

Training iteration loss = 0.0031768887

Training iteration loss = 0.0035541758

Training iteration loss = 0.004083104

Training iteration loss = 0.004274016

Training iteration loss = 0.0027643938

Training iteration loss = 0.0035592914

Training iteration loss = 0.003886818

Training iteration loss = 0.002471639

Training iteration loss = 0.0021188797

Training iteration loss = 0.0035985345

Training iteration loss = 0.0023630897

Training iteration loss = 0.0020242904

Training iteration loss = 0.0030608422

Training iteration loss = 0.0022436385

Training iteration loss = 0.0017022091

Training iteration loss = 0.0018429686

Training iteration loss = 0.0031651834

Training iteration loss = 0.002019888

Training iteration loss = 0.0022463629

Training iteration loss = 0.0038090793

Training iteration loss = 0.0050071212

Training iteration loss = 0.0024851386

Training iteration loss = 0.0026903467

Training iteration loss = 0.0023672704

Training iteration loss = 0.0025297042

Training iteration loss = 0.0022488441

Training iteration loss = 0.0039235386

Training iteration loss = 0.0033048624

Training iteration loss = 0.0048977574

Training iteration loss = 0.0038430507

Training iteration loss = 0.0027670695

Training iteration loss = 0.0019100806

Training iteration loss = 0.0020627198

Training iteration loss = 0.008066029

Training iteration loss = 0.0028907012

Training iteration loss = 0.001693378

Training iteration loss = 0.004195735

Training iteration loss = 0.0038170775

Training iteration loss = 0.0033614195

Training iteration loss = 0.0028411502

Training iteration loss = 0.003867726

Training iteration loss = 0.0021960575

Training iteration loss = 0.0062869824

Training iteration loss = 0.002570668

Training iteration loss = 0.0033901262

Training iteration loss = 0.0037950324

Training iteration loss = 0.0020606779

Training iteration loss = 0.0020578045

Training iteration loss = 0.0025649457

Training iteration loss = 0.0015940607

Training iteration loss = 0.0032216718

Training iteration loss = 0.0031613728

Training iteration loss = 0.0040214374

Training iteration loss = 0.0030575742

Training iteration loss = 0.0027348876

Training iteration loss = 0.0023064103

Training iteration loss = 0.0021876032

Training iteration loss = 0.0023290138

Training iteration loss = 0.0030452593

Training iteration loss = 0.0044774697

Training iteration loss = 0.0017841744

Training iteration loss = 0.0029515259

Training iteration loss = 0.003042858

Training iteration loss = 0.0032814203

Training iteration loss = 0.0028229153

Training iteration loss = 0.0032461348

Training iteration loss = 0.0028137995

Training iteration loss = 0.0017430414

Training iteration loss = 0.005700855

Training iteration loss = 0.002947525

Training iteration loss = 0.002556936

Training iteration loss = 0.0017727768

Training iteration loss = 0.0031358323

Training iteration loss = 0.0035564948

Training iteration loss = 0.00360082

Training iteration loss = 0.0022743794

Training iteration loss = 0.0055417246

Training iteration loss = 0.0030413189

Training iteration loss = 0.0022587043

Training iteration loss = 0.002065928

Training iteration loss = 0.002406744

Training iteration loss = 0.0019423227

Training iteration loss = 0.0028224506

Training iteration loss = 0.0017509299

Training iteration loss = 0.0019810793

Training iteration loss = 0.003680962

Training iteration loss = 0.0026631234

Training iteration loss = 0.0032473214

Training iteration loss = 0.0025407486

Training iteration loss = 0.003875964

Training iteration loss = 0.00411015

Training iteration loss = 0.0039824843

Training iteration loss = 0.0019317771

Training iteration loss = 0.002724719

Training iteration loss = 0.0023674697

Training iteration loss = 0.0036553862

Training iteration loss = 0.0032595873

Training iteration loss = 0.004452644

Training iteration loss = 0.0028288665

Training iteration loss = 0.0023310508

Training iteration loss = 0.0031895556

Training iteration loss = 0.0046678297

Training iteration loss = 0.0031582303

Training iteration loss = 0.0027534144

Training iteration loss = 0.003212671

Training iteration loss = 0.0030925062

Training iteration loss = 0.0023893206

Training iteration loss = 0.0024117753

Training iteration loss = 0.0036129488

Training iteration loss = 0.003001296

Training iteration loss = 0.0030631348

Training iteration loss = 0.0028061175

Training iteration loss = 0.0022078287

Training iteration loss = 0.004345861

Training iteration loss = 0.0038527912

Training iteration loss = 0.00383602

Training iteration loss = 0.0034336324

Training iteration loss = 0.0021692212

Training iteration loss = 0.0045242277

Training iteration loss = 0.0054954416

Training iteration loss = 0.0022545485

Training iteration loss = 0.003148624

Training iteration loss = 0.0023045451

Training iteration loss = 0.0026428134

Training iteration loss = 0.00262025

Training iteration loss = 0.0024549265

Training iteration loss = 0.0047107446

Training iteration loss = 0.005224479

Training iteration loss = 0.0024240168

Training iteration loss = 0.0028674693

Training iteration loss = 0.002208625

Training iteration loss = 0.00250546

Training iteration loss = 0.0033501538

Training iteration loss = 0.0031903957

Training iteration loss = 0.0036181754

Training iteration loss = 0.002278204

Training iteration loss = 0.0034733058

Training iteration loss = 0.0070050736

Training iteration loss = 0.0045297253

Training iteration loss = 0.0036094475

Training iteration loss = 0.0028716603

Training iteration loss = 0.0033919949

Training iteration loss = 0.002654135

Training iteration loss = 0.0032905412

Training iteration loss = 0.0020918343

Training iteration loss = 0.0025160976

Training iteration loss = 0.0025693555

Training iteration loss = 0.0023970895

Training iteration loss = 0.0019450582

Training iteration loss = 0.004531233

Training iteration loss = 0.0032223966

Training iteration loss = 0.005242064

Training iteration loss = 0.0033029765

Training iteration loss = 0.0031625524

Training iteration loss = 0.0031755946

Training iteration loss = 0.0062140916

Training iteration loss = 0.0038204528

Training iteration loss = 0.0033737347

Training iteration loss = 0.00249247

Training iteration loss = 0.004424581

Training iteration loss = 0.0020933712

Training iteration loss = 0.002472866

Training iteration loss = 0.0028762834

Training iteration loss = 0.003649494

Training iteration loss = 0.0027928741

Training iteration loss = 0.0037396217

Training iteration loss = 0.0033690818

Training iteration loss = 0.0019486933

Training iteration loss = 0.002426728

Training iteration loss = 0.0019085108

Training iteration loss = 0.0024316453

Training iteration loss = 0.0020052118

Training iteration loss = 0.0024266278

Training iteration loss = 0.0033118941

Training iteration loss = 0.003340993

Training iteration loss = 0.0045328303

Training iteration loss = 0.0040810094

Training iteration loss = 0.0039516203

Training iteration loss = 0.0020777734

Training iteration loss = 0.0029289543

Training iteration loss = 0.0021651892

Training iteration loss = 0.006070439

Training iteration loss = 0.0035295878

Training iteration loss = 0.0029376952

Training iteration loss = 0.0027709734

Training iteration loss = 0.0035507483

Training iteration loss = 0.006860128

Training iteration loss = 0.0022834365

Training iteration loss = 0.0035110097

Training iteration loss = 0.0035713129

Training iteration loss = 0.0022788942

Training iteration loss = 0.0034613963

Training iteration loss = 0.003696765

Training iteration loss = 0.0026130602

Training iteration loss = 0.0024971354

Training iteration loss = 0.0031299368

Training iteration loss = 0.0035419522

Training iteration loss = 0.0034869816

Training iteration loss = 0.004321182

Training iteration loss = 0.0046526045

Training iteration loss = 0.0031711443

Training iteration loss = 0.0035555055

Training iteration loss = 0.0040837354

Training iteration loss = 0.0042565856

Training iteration loss = 0.0027497746

Training iteration loss = 0.0035701978

Training iteration loss = 0.0038986618

Training iteration loss = 0.0024775795

Training iteration loss = 0.0021210527

Training iteration loss = 0.0035892285

Training iteration loss = 0.0023529388

Training iteration loss = 0.0020191271

Training iteration loss = 0.0030735882

Training iteration loss = 0.0022461128

Training iteration loss = 0.0016982431

Training iteration loss = 0.0018450696

Training iteration loss = 0.0031673973

Training iteration loss = 0.0020167131

Training iteration loss = 0.002240769

Training iteration loss = 0.0038073352

Training iteration loss = 0.005019832

Training iteration loss = 0.0024779974

Training iteration loss = 0.0026843685

Training iteration loss = 0.002368571

Training iteration loss = 0.0025344312

Training iteration loss = 0.0022377057

Training iteration loss = 0.003919949

Training iteration loss = 0.0033092445

Training iteration loss = 0.0048910654

Training iteration loss = 0.0038425562

Training iteration loss = 0.0027598038

Training iteration loss = 0.0019058661

Training iteration loss = 0.002061886

Training iteration loss = 0.008060226

Training iteration loss = 0.0028839603

Training iteration loss = 0.0016962242

Training iteration loss = 0.004183993

Training iteration loss = 0.0038168498

Training iteration loss = 0.0033592538

Training iteration loss = 0.002838878

Training iteration loss = 0.003866965

Training iteration loss = 0.0021941757

Training iteration loss = 0.006279114

Training iteration loss = 0.0025694007

Training iteration loss = 0.0033909343

Training iteration loss = 0.0037970615

Training iteration loss = 0.0020612634

Training iteration loss = 0.0020600017

Training iteration loss = 0.0025704114

Training iteration loss = 0.0015949369

Training iteration loss = 0.0032176292

Training iteration loss = 0.0031611752

Training iteration loss = 0.0040171663

Training iteration loss = 0.0030582033

Training iteration loss = 0.0027339512

Training iteration loss = 0.002306295

Training iteration loss = 0.0021878507

Training iteration loss = 0.0023332897

Training iteration loss = 0.0030460104

Training iteration loss = 0.004476914

Training iteration loss = 0.0017832356

Training iteration loss = 0.002953279

Training iteration loss = 0.0030421596

Training iteration loss = 0.0032792697

Training iteration loss = 0.0028225735

Training iteration loss = 0.003247129

Training iteration loss = 0.0028178415

Training iteration loss = 0.0017418085

Training iteration loss = 0.0056984383

Training iteration loss = 0.0029453773

Training iteration loss = 0.0025573531

Training iteration loss = 0.0017716405

Training iteration loss = 0.00313198

Training iteration loss = 0.0035520347

Training iteration loss = 0.0036009995

Training iteration loss = 0.0022719342

Training iteration loss = 0.0055414694

Training iteration loss = 0.0030388494

Training iteration loss = 0.0022579925

Training iteration loss = 0.002063558

Training iteration loss = 0.0024054265

Training iteration loss = 0.0019395687

Training iteration loss = 0.0028175293

Training iteration loss = 0.0017498326

Training iteration loss = 0.001981085

Training iteration loss = 0.0036874858

Training iteration loss = 0.0026604012

Training iteration loss = 0.0032459644

Training iteration loss = 0.0025419763

Training iteration loss = 0.0038700318

Training iteration loss = 0.0041091987

Training iteration loss = 0.0039743357

Training iteration loss = 0.0019291391

Training iteration loss = 0.0027254866

Training iteration loss = 0.0023645584

Training iteration loss = 0.003650638

Training iteration loss = 0.0032592958

Training iteration loss = 0.004447157

Training iteration loss = 0.0028280022

Training iteration loss = 0.00232624

Training iteration loss = 0.003188981

Training iteration loss = 0.0046656528

Training iteration loss = 0.0031537404

Training iteration loss = 0.0027539798

Training iteration loss = 0.003213021

Training iteration loss = 0.0030942422

Training iteration loss = 0.002389264

Training iteration loss = 0.0024127124

Training iteration loss = 0.0036083653

Training iteration loss = 0.003000453

Training iteration loss = 0.003060975

Training iteration loss = 0.0028058777

Training iteration loss = 0.0022076876

Training iteration loss = 0.0043445835

Training iteration loss = 0.0038542887

Training iteration loss = 0.0038361175

Training iteration loss = 0.0034292073

Training iteration loss = 0.0021684177

Training iteration loss = 0.004525623

Training iteration loss = 0.0054914095

Training iteration loss = 0.002249643

Training iteration loss = 0.0031478547

Training iteration loss = 0.0023021323

Training iteration loss = 0.002638432

Training iteration loss = 0.0026195627

Training iteration loss = 0.0024560771

Training iteration loss = 0.0047076778

Training iteration loss = 0.005212721

Training iteration loss = 0.0024218706

Training iteration loss = 0.0028679527

Training iteration loss = 0.002207763

Training iteration loss = 0.0025028351

Training iteration loss = 0.003351762

Training iteration loss = 0.0031907167

Training iteration loss = 0.003615605

Training iteration loss = 0.0022753105

Training iteration loss = 0.0034733769

Training iteration loss = 0.006992902

Training iteration loss = 0.0045269644

Training iteration loss = 0.0036051346

Training iteration loss = 0.002871097

Training iteration loss = 0.0033904684

Training iteration loss = 0.0026570114

Training iteration loss = 0.003294275

Training iteration loss = 0.0020945016

Training iteration loss = 0.002520058

Training iteration loss = 0.0025735418

Training iteration loss = 0.0024023098

Training iteration loss = 0.0019461443

Training iteration loss = 0.004532237

Training iteration loss = 0.0032199824

Training iteration loss = 0.0052407025

Training iteration loss = 0.0033077418

Training iteration loss = 0.003163751

Training iteration loss = 0.0031780032

Training iteration loss = 0.0062049967

Training iteration loss = 0.003818053

Training iteration loss = 0.00337377

Training iteration loss = 0.0024886671

Training iteration loss = 0.0044084108

Training iteration loss = 0.0020916266

Training iteration loss = 0.0024740847

Training iteration loss = 0.0028810243

Training iteration loss = 0.0036502492

Training iteration loss = 0.0027897034

Training iteration loss = 0.0037381668

Training iteration loss = 0.003367602

Training iteration loss = 0.0019481098

Training iteration loss = 0.002426265

Training iteration loss = 0.0019092835

Training iteration loss = 0.002428904

Training iteration loss = 0.002000724

Training iteration loss = 0.0024226427

Training iteration loss = 0.0033135274

Training iteration loss = 0.0033391211

Training iteration loss = 0.004532093

Training iteration loss = 0.0040830374

Training iteration loss = 0.0039455257

Training iteration loss = 0.002077045

Training iteration loss = 0.0029292079

Training iteration loss = 0.0021654966

Training iteration loss = 0.0060839355

Training iteration loss = 0.0035289319

Training iteration loss = 0.002938697

Training iteration loss = 0.0027697885

Training iteration loss = 0.0035488966

Training iteration loss = 0.00685193

Training iteration loss = 0.0022811177

Training iteration loss = 0.0035099369

Training iteration loss = 0.0035715986

Training iteration loss = 0.0022833473

Training iteration loss = 0.0034680078

Training iteration loss = 0.0036934372

Training iteration loss = 0.0026097388

Training iteration loss = 0.0024947368

Training iteration loss = 0.0031296816

Training iteration loss = 0.0035464864

Training iteration loss = 0.0034966667

Training iteration loss = 0.0043250974

Training iteration loss = 0.004658571

Training iteration loss = 0.0031759494

Training iteration loss = 0.0035421345

Training iteration loss = 0.004081948

Training iteration loss = 0.004256955

Training iteration loss = 0.0027524417

Training iteration loss = 0.0035689801

Training iteration loss = 0.0038912653

Training iteration loss = 0.0024769166

Training iteration loss = 0.002123448

Training iteration loss = 0.0035882106

Training iteration loss = 0.0023583593

Training iteration loss = 0.0020164016

Training iteration loss = 0.0030705084

Training iteration loss = 0.0022432024

Training iteration loss = 0.0016970957

Training iteration loss = 0.0018465286

Training iteration loss = 0.0031740016

Training iteration loss = 0.0020151306

Training iteration loss = 0.0022375563

Training iteration loss = 0.00380401

Training iteration loss = 0.005015367

Training iteration loss = 0.002478825

Training iteration loss = 0.002683617

Training iteration loss = 0.0023698153

Training iteration loss = 0.0025301194

Training iteration loss = 0.0022349022

Training iteration loss = 0.0039176405

Training iteration loss = 0.0033081053

Training iteration loss = 0.0048903637

Training iteration loss = 0.003839301

Training iteration loss = 0.0027590028

Training iteration loss = 0.0019050296

Training iteration loss = 0.002062451

Training iteration loss = 0.008050794

Training iteration loss = 0.002882081

Training iteration loss = 0.0016942321

Training iteration loss = 0.004179193

Training iteration loss = 0.0038193865

Training iteration loss = 0.0033586088

Training iteration loss = 0.002839828

Training iteration loss = 0.0038651237

Training iteration loss = 0.002190543

Training iteration loss = 0.0062757805

Training iteration loss = 0.002566869

Training iteration loss = 0.0033887913

Training iteration loss = 0.0037943143

Training iteration loss = 0.0020619482

Training iteration loss = 0.0020566494

Training iteration loss = 0.0025696922

Training iteration loss = 0.001592235

Training iteration loss = 0.0032178166

Training iteration loss = 0.003166159

Training iteration loss = 0.0040208767

Training iteration loss = 0.0030562386

Training iteration loss = 0.0027339077

Training iteration loss = 0.0023052974

Training iteration loss = 0.0021932865

Training iteration loss = 0.00232557

Training iteration loss = 0.003037845

Training iteration loss = 0.0044735675

Training iteration loss = 0.0017823795

Training iteration loss = 0.0029565587

Training iteration loss = 0.0030418625

Training iteration loss = 0.0032763826

Training iteration loss = 0.0028148743

Training iteration loss = 0.0032505419

Training iteration loss = 0.0028140768

Training iteration loss = 0.0017384961

Training iteration loss = 0.005683691

Training iteration loss = 0.0029497591

Training iteration loss = 0.0025560122

Training iteration loss = 0.0017723511

Training iteration loss = 0.0031291961

Training iteration loss = 0.0035557663

Training iteration loss = 0.003598109

Training iteration loss = 0.0022705884

Training iteration loss = 0.0055197873

Training iteration loss = 0.003042395

Training iteration loss = 0.0022608652

Training iteration loss = 0.0020702838

Training iteration loss = 0.0024027938

Training iteration loss = 0.0019447155

Training iteration loss = 0.002815213

Training iteration loss = 0.0017541478

Training iteration loss = 0.0019802193

Training iteration loss = 0.0036918279

Training iteration loss = 0.0026548777

Training iteration loss = 0.003241076

Training iteration loss = 0.0025336833

Training iteration loss = 0.0038748905

Training iteration loss = 0.004106751

Training iteration loss = 0.0039653615

Training iteration loss = 0.0019313018

Training iteration loss = 0.0027150495

Training iteration loss = 0.0023663316

Training iteration loss = 0.0036581967

Training iteration loss = 0.0032473349

Training iteration loss = 0.0044507463

Training iteration loss = 0.002827176

Training iteration loss = 0.0023278533

Training iteration loss = 0.0031883493

Training iteration loss = 0.0046658074

Training iteration loss = 0.003154944

Training iteration loss = 0.0027544582

Training iteration loss = 0.0032079255

Training iteration loss = 0.0030864

Training iteration loss = 0.0023828542

Training iteration loss = 0.0024036923

Training iteration loss = 0.0036131723

Training iteration loss = 0.0030037293

Training iteration loss = 0.0030647675

Training iteration loss = 0.002810322

Training iteration loss = 0.0022031812

Training iteration loss = 0.0043434924

Training iteration loss = 0.0038330473

Training iteration loss = 0.0038355428

Training iteration loss = 0.0034184444

Training iteration loss = 0.0021661825

Training iteration loss = 0.004532848

Training iteration loss = 0.0054981844

Training iteration loss = 0.0022474132

Training iteration loss = 0.0031453008

Training iteration loss = 0.0023028038

Training iteration loss = 0.0026415708

Training iteration loss = 0.0026166614

Training iteration loss = 0.0024547395

Training iteration loss = 0.004704707

Training iteration loss = 0.005215341

Training iteration loss = 0.0024172177

Training iteration loss = 0.0028696686

Training iteration loss = 0.0022056187

Training iteration loss = 0.0025004589

Training iteration loss = 0.0033527315

Training iteration loss = 0.003190342

Training iteration loss = 0.0036099916

Training iteration loss = 0.0022796781

Training iteration loss = 0.0034721114

Training iteration loss = 0.0070037018

Training iteration loss = 0.004521844

Training iteration loss = 0.003603561

Training iteration loss = 0.0028676458

Training iteration loss = 0.0033908933

Training iteration loss = 0.002651512

Training iteration loss = 0.003284667

Training iteration loss = 0.0020899887

Training iteration loss = 0.002514757

Training iteration loss = 0.0025657944

Training iteration loss = 0.0023854717

Training iteration loss = 0.0019421169

Training iteration loss = 0.0045315004

Training iteration loss = 0.0032241603

Training iteration loss = 0.0052417344

Training iteration loss = 0.003299294

Training iteration loss = 0.0031569628

Training iteration loss = 0.0031850375

Training iteration loss = 0.0061939596

Training iteration loss = 0.0038089778

Training iteration loss = 0.0033702692

Training iteration loss = 0.002482416

Training iteration loss = 0.004405165

Training iteration loss = 0.00209461

Training iteration loss = 0.0024693976

Training iteration loss = 0.0028699443

Training iteration loss = 0.0036475472

Training iteration loss = 0.0027906958

Training iteration loss = 0.0037369821

Training iteration loss = 0.0033682808

Training iteration loss = 0.0019428702

Training iteration loss = 0.0024213775

Training iteration loss = 0.0018999927

Training iteration loss = 0.002421642

Training iteration loss = 0.001999371

Training iteration loss = 0.002421052

Training iteration loss = 0.0032999313

Training iteration loss = 0.0033348892

Training iteration loss = 0.004526219

Training iteration loss = 0.004069301

Training iteration loss = 0.003942164

Training iteration loss = 0.0020732686

Training iteration loss = 0.002927932

Training iteration loss = 0.0021635008

Training iteration loss = 0.006080041

Training iteration loss = 0.0035314572

Training iteration loss = 0.00293384

Training iteration loss = 0.0027553

Training iteration loss = 0.0035384893

Training iteration loss = 0.0068706167

Training iteration loss = 0.0022820926

Training iteration loss = 0.0035106838

Training iteration loss = 0.0035569966

Training iteration loss = 0.0022672208

Training iteration loss = 0.0034555888

Training iteration loss = 0.0036933909

Training iteration loss = 0.0026094134

Training iteration loss = 0.0025075767

Training iteration loss = 0.003150317

Training iteration loss = 0.0035508878

Training iteration loss = 0.003500619

Training iteration loss = 0.0042685983

Training iteration loss = 0.0046567447

Training iteration loss = 0.0031608709

Training iteration loss = 0.0035637086

Training iteration loss = 0.004073935

Training iteration loss = 0.0042722174

Training iteration loss = 0.0027562783

Training iteration loss = 0.00355905

Training iteration loss = 0.0038740486

Training iteration loss = 0.0024609326

Training iteration loss = 0.0021174739

Training iteration loss = 0.0035933934

Training iteration loss = 0.0023593549

Training iteration loss = 0.0020175383

Training iteration loss = 0.0030677256

Training iteration loss = 0.0022466965

Training iteration loss = 0.001696913

Training iteration loss = 0.0018398251

Training iteration loss = 0.0031661957

Training iteration loss = 0.0020116735

Training iteration loss = 0.0022452185

Training iteration loss = 0.003807227

Training iteration loss = 0.0050028064

Training iteration loss = 0.0024861672

Training iteration loss = 0.002690575

Training iteration loss = 0.0023645638

Training iteration loss = 0.0025225084

Training iteration loss = 0.002244438

Training iteration loss = 0.003915609

Training iteration loss = 0.003305963

Training iteration loss = 0.0048881834

Training iteration loss = 0.0038379475

Training iteration loss = 0.0027568415

Training iteration loss = 0.0019015921

Training iteration loss = 0.0020587326

Training iteration loss = 0.008040938

Training iteration loss = 0.0028789823

Training iteration loss = 0.0016834092

Training iteration loss = 0.004183861

Training iteration loss = 0.0038199443

Training iteration loss = 0.0033533613

Training iteration loss = 0.0028372838

Training iteration loss = 0.0038624408

Training iteration loss = 0.0021941727

Training iteration loss = 0.006268283

Training iteration loss = 0.002568732

Training iteration loss = 0.0033891562

Training iteration loss = 0.0037955728

Training iteration loss = 0.0020644937

Training iteration loss = 0.002055835

Training iteration loss = 0.0025649667

Training iteration loss = 0.0015925327

Training iteration loss = 0.0032146832

Training iteration loss = 0.003166207

Training iteration loss = 0.004021719

Training iteration loss = 0.0030574882

Training iteration loss = 0.0027356257

Training iteration loss = 0.0023019698

Training iteration loss = 0.0021904528

Training iteration loss = 0.0023286554

Training iteration loss = 0.0030410346

Training iteration loss = 0.0044615674

Training iteration loss = 0.0017809236

Training iteration loss = 0.0029503915

Training iteration loss = 0.003037069

Training iteration loss = 0.003275505

Training iteration loss = 0.0028201481

Training iteration loss = 0.0032485665

Training iteration loss = 0.002813219

Training iteration loss = 0.0017381272

Training iteration loss = 0.0056788772

Training iteration loss = 0.002943766

Training iteration loss = 0.002554378

Training iteration loss = 0.0017705689

Training iteration loss = 0.003120928

Training iteration loss = 0.0035465711

Training iteration loss = 0.0035992737

Training iteration loss = 0.0022644254

Training iteration loss = 0.005525543

Training iteration loss = 0.0030362804

Training iteration loss = 0.002254174

Training iteration loss = 0.0020662574

Training iteration loss = 0.0023986849

Training iteration loss = 0.0019436566

Training iteration loss = 0.0028085422

Training iteration loss = 0.0017503555

Training iteration loss = 0.0019817627

Training iteration loss = 0.003704533

Training iteration loss = 0.002654263

Training iteration loss = 0.0032407038

Training iteration loss = 0.0025334957

Training iteration loss = 0.0038722085

Training iteration loss = 0.004110523

Training iteration loss = 0.0039589223

Training iteration loss = 0.0019265403

Training iteration loss = 0.0027130435

Training iteration loss = 0.002367537

Training iteration loss = 0.0036560579

Training iteration loss = 0.0032452326

Training iteration loss = 0.004447726

Training iteration loss = 0.0028271368

Training iteration loss = 0.0023194442

Training iteration loss = 0.00318757

Training iteration loss = 0.004663027

Training iteration loss = 0.0031490438

Training iteration loss = 0.002758416

Training iteration loss = 0.003207463

Training iteration loss = 0.003084591

Training iteration loss = 0.0023856151

Training iteration loss = 0.002406762

Training iteration loss = 0.003609281

Training iteration loss = 0.003006607

Training iteration loss = 0.0030626736

Training iteration loss = 0.0028115187

Training iteration loss = 0.0022034112

Training iteration loss = 0.0043419865

Training iteration loss = 0.0038355186

Training iteration loss = 0.003835803

Training iteration loss = 0.0034119645

Training iteration loss = 0.0021661913

Training iteration loss = 0.0045309477

Training iteration loss = 0.0054900753

Training iteration loss = 0.002242264

Training iteration loss = 0.003143725

Training iteration loss = 0.0023010925

Training iteration loss = 0.0026386622

Training iteration loss = 0.002615928

Training iteration loss = 0.0024605615

Training iteration loss = 0.004701544

Training iteration loss = 0.0051986077

Training iteration loss = 0.0024137853

Training iteration loss = 0.0028692568

Training iteration loss = 0.0022079106

Training iteration loss = 0.0024992172

Training iteration loss = 0.0033550344

Training iteration loss = 0.0031907603

Training iteration loss = 0.003609684

Training iteration loss = 0.002274967

Training iteration loss = 0.0034713976

Training iteration loss = 0.0069931503

Training iteration loss = 0.0045199688

Training iteration loss = 0.0036013275

Training iteration loss = 0.0028690684

Training iteration loss = 0.0033909364

Training iteration loss = 0.002655104

Training iteration loss = 0.0032909934

Training iteration loss = 0.002093268

Training iteration loss = 0.002517976

Training iteration loss = 0.002571156

Training iteration loss = 0.0023897067

Training iteration loss = 0.0019433714

Training iteration loss = 0.0045345635

Training iteration loss = 0.0032184531

Training iteration loss = 0.0052397237

Training iteration loss = 0.0033069316

Training iteration loss = 0.003160613

Training iteration loss = 0.0031684134

Training iteration loss = 0.0061883815

Training iteration loss = 0.003812601

Training iteration loss = 0.0033696985

Training iteration loss = 0.002486163

Training iteration loss = 0.004399118

Training iteration loss = 0.002092614

Training iteration loss = 0.0024774165

Training iteration loss = 0.0028699425

Training iteration loss = 0.0036456028

Training iteration loss = 0.002791426

Training iteration loss = 0.0037359644

Training iteration loss = 0.003371678

Training iteration loss = 0.0019501351

Training iteration loss = 0.0024245437

Training iteration loss = 0.0019051615

Training iteration loss = 0.0024348695

Training iteration loss = 0.0020118845

Training iteration loss = 0.002422865

Training iteration loss = 0.0033036547

Training iteration loss = 0.003340805

Training iteration loss = 0.0045338953

Training iteration loss = 0.004076064

Training iteration loss = 0.0039502117

Training iteration loss = 0.0020737487

Training iteration loss = 0.0029267576

Training iteration loss = 0.0021593657

Training iteration loss = 0.0060773506

Training iteration loss = 0.0035239048

Training iteration loss = 0.0029388021

Training iteration loss = 0.002758243

Training iteration loss = 0.0035419746

Training iteration loss = 0.00686661

Training iteration loss = 0.0022785787

Training iteration loss = 0.0035033126

Training iteration loss = 0.0035620388

Training iteration loss = 0.002268071

Training iteration loss = 0.0034547828

Training iteration loss = 0.003689821

Training iteration loss = 0.002603106

Training iteration loss = 0.0025000684

Training iteration loss = 0.0031419198

Training iteration loss = 0.0035397473

Training iteration loss = 0.0034958795

Training iteration loss = 0.004282668

Training iteration loss = 0.004654843

Training iteration loss = 0.0031609498

Training iteration loss = 0.0035583384

Training iteration loss = 0.004076584

Training iteration loss = 0.0042577414

Training iteration loss = 0.002744144

Training iteration loss = 0.0035595726

Training iteration loss = 0.003882387

Training iteration loss = 0.0024646511

Training iteration loss = 0.0021206432

Training iteration loss = 0.0035889957

Training iteration loss = 0.0023547458

Training iteration loss = 0.002013168

Training iteration loss = 0.003071036

Training iteration loss = 0.0022465016

Training iteration loss = 0.0016947496

Training iteration loss = 0.0018411438

Training iteration loss = 0.0031701003

Training iteration loss = 0.0020114414

Training iteration loss = 0.002243372

Training iteration loss = 0.0038037682

Training iteration loss = 0.0050080656

Training iteration loss = 0.0024823025

Training iteration loss = 0.0026835876

Training iteration loss = 0.0023648841

Training iteration loss = 0.0025220902

Training iteration loss = 0.002238132

Training iteration loss = 0.0039133914

Training iteration loss = 0.0033081882

Training iteration loss = 0.004883736

Training iteration loss = 0.00383603

Training iteration loss = 0.0027498982

Training iteration loss = 0.0018966623

Training iteration loss = 0.0020567637

Training iteration loss = 0.0080365455

Training iteration loss = 0.002875657

Training iteration loss = 0.0016801251

Training iteration loss = 0.004182767

Training iteration loss = 0.0038172987

Training iteration loss = 0.003348511

Training iteration loss = 0.0028348037

Training iteration loss = 0.00386098

Training iteration loss = 0.002194921

Training iteration loss = 0.0062630572

Training iteration loss = 0.002570127

Training iteration loss = 0.003387279

Training iteration loss = 0.0037937223

Training iteration loss = 0.0020623996

Training iteration loss = 0.0020547695

Training iteration loss = 0.0025654584

Training iteration loss = 0.0015910594

Training iteration loss = 0.0032083418

Training iteration loss = 0.003165626

Training iteration loss = 0.0040206634

Training iteration loss = 0.0030588442

Training iteration loss = 0.0027342904

Training iteration loss = 0.0023026636

Training iteration loss = 0.002192704

Training iteration loss = 0.0023307574

Training iteration loss = 0.0030404415

Training iteration loss = 0.0044601792

Training iteration loss = 0.0017790267

Training iteration loss = 0.0029508837

Training iteration loss = 0.0030371246

Training iteration loss = 0.0032726254

Training iteration loss = 0.0028182268

Training iteration loss = 0.003250925

Training iteration loss = 0.0028158457

Training iteration loss = 0.001736211

Training iteration loss = 0.0056759664

Training iteration loss = 0.0029420499

Training iteration loss = 0.0025589159

Training iteration loss = 0.0017719289

Training iteration loss = 0.003120455

Training iteration loss = 0.003540013

Training iteration loss = 0.0035958297

Training iteration loss = 0.002262628

Training iteration loss = 0.0055181407

Training iteration loss = 0.0030360727

Training iteration loss = 0.00225734

Training iteration loss = 0.0020659326

Training iteration loss = 0.002397232

Training iteration loss = 0.0019403766

Training iteration loss = 0.0028030376

Training iteration loss = 0.0017522139

Training iteration loss = 0.001986336

Training iteration loss = 0.0037116546

Training iteration loss = 0.0026540272

Training iteration loss = 0.0032379758

Training iteration loss = 0.0025348316

Training iteration loss = 0.0038750174

Training iteration loss = 0.0041117757

Training iteration loss = 0.0039496985

Training iteration loss = 0.0019201501

Training iteration loss = 0.0027116344

Training iteration loss = 0.002362572

Training iteration loss = 0.0036468182

Training iteration loss = 0.003244182

Training iteration loss = 0.0044455645

Training iteration loss = 0.002828901

Training iteration loss = 0.0023141417

Training iteration loss = 0.003188974

Training iteration loss = 0.004658783

Training iteration loss = 0.0031428114

Training iteration loss = 0.0027597735

Training iteration loss = 0.0032098992

Training iteration loss = 0.003086997

Training iteration loss = 0.0023915374

Training iteration loss = 0.0024105685

Training iteration loss = 0.0036042982

Training iteration loss = 0.0030099703

Training iteration loss = 0.0030612608

Training iteration loss = 0.0028096212

Training iteration loss = 0.002204613

Training iteration loss = 0.004344217

Training iteration loss = 0.0038497064

Training iteration loss = 0.003834607

Training iteration loss = 0.0034130644

Training iteration loss = 0.0021672426

Training iteration loss = 0.0045269732

Training iteration loss = 0.0054905475

Training iteration loss = 0.0022393584

Training iteration loss = 0.0031423217

Training iteration loss = 0.0022974669

Training iteration loss = 0.0026359076

Training iteration loss = 0.0026151107

Training iteration loss = 0.0024613305

Training iteration loss = 0.0047007464

Training iteration loss = 0.005186305

Training iteration loss = 0.0024126985

Training iteration loss = 0.002869142

Training iteration loss = 0.0022076524

Training iteration loss = 0.0024960227

Training iteration loss = 0.0033564556

Training iteration loss = 0.0031918732

Training iteration loss = 0.003606966

Training iteration loss = 0.002270314

Training iteration loss = 0.003473216

Training iteration loss = 0.0069764275

Training iteration loss = 0.0045171697

Training iteration loss = 0.003596116

Training iteration loss = 0.0028686693

Training iteration loss = 0.0033895245

Training iteration loss = 0.0026593208

Training iteration loss = 0.0032955536

Training iteration loss = 0.0020966197

Training iteration loss = 0.002522054

Training iteration loss = 0.0025770096

Training iteration loss = 0.0023989747

Training iteration loss = 0.0019447124

Training iteration loss = 0.004535211

Training iteration loss = 0.003215449

Training iteration loss = 0.0052386317

Training iteration loss = 0.003313606

Training iteration loss = 0.0031623421

Training iteration loss = 0.0031679804

Training iteration loss = 0.0061807134

Training iteration loss = 0.0038115056

Training iteration loss = 0.0033713775

Training iteration loss = 0.0024829921

Training iteration loss = 0.0043878686

Training iteration loss = 0.0020907363

Training iteration loss = 0.0024792606

Training iteration loss = 0.002875895

Training iteration loss = 0.0036465542

Training iteration loss = 0.002788584

Training iteration loss = 0.0037349404

Training iteration loss = 0.0033701344

Training iteration loss = 0.0019499076

Training iteration loss = 0.0024244064

Training iteration loss = 0.0019065227

Training iteration loss = 0.0024301093

Training iteration loss = 0.002006015

Training iteration loss = 0.002418789

Training iteration loss = 0.0033075958

Training iteration loss = 0.0033387877

Training iteration loss = 0.0045336154

Training iteration loss = 0.004078641

Training iteration loss = 0.003943246

Training iteration loss = 0.0020729387

Training iteration loss = 0.0029275268

Training iteration loss = 0.0021599275

Training iteration loss = 0.00608925

Training iteration loss = 0.0035223383

Training iteration loss = 0.0029398839

Training iteration loss = 0.0027576496

Training iteration loss = 0.0035392179

Training iteration loss = 0.006851295

Training iteration loss = 0.0022767943

Training iteration loss = 0.0035042923

Training iteration loss = 0.0035648819

Training iteration loss = 0.0022754315

Training iteration loss = 0.0034640043

Training iteration loss = 0.0036883748

Training iteration loss = 0.0026010184

Training iteration loss = 0.0024958516

Training iteration loss = 0.0031400062

Training iteration loss = 0.003547064

Training iteration loss = 0.0035065748

Training iteration loss = 0.0042898483

Training iteration loss = 0.0046599414

Training iteration loss = 0.0031645976

Training iteration loss = 0.0035376207

Training iteration loss = 0.0040724957

Training iteration loss = 0.0042569917

Training iteration loss = 0.0027493688

Training iteration loss = 0.0035611093

Training iteration loss = 0.003873985

Training iteration loss = 0.0024618001

Training iteration loss = 0.0021204248

Training iteration loss = 0.0035900057

Training iteration loss = 0.0023582263

Training iteration loss = 0.0020127716

Training iteration loss = 0.0030673963

Training iteration loss = 0.0022421293

Training iteration loss = 0.0016935043

Training iteration loss = 0.0018425294

Training iteration loss = 0.0031749848

Training iteration loss = 0.0020090332

Training iteration loss = 0.0022385316

Training iteration loss = 0.0038007672

Training iteration loss = 0.0050043263

Training iteration loss = 0.0024830212

Training iteration loss = 0.0026840458

Training iteration loss = 0.002365682

Training iteration loss = 0.0025182469

Training iteration loss = 0.0022337215

Training iteration loss = 0.0039098617

Training iteration loss = 0.0033064317

Training iteration loss = 0.0048820875

Training iteration loss = 0.0038308364

Training iteration loss = 0.0027503918

Training iteration loss = 0.0018972304

Training iteration loss = 0.0020588

Training iteration loss = 0.008030054

Training iteration loss = 0.0028728328

Training iteration loss = 0.0016801924

Training iteration loss = 0.004172161

Training iteration loss = 0.0038210498

Training iteration loss = 0.003349176

Training iteration loss = 0.002834118

Training iteration loss = 0.003859264

Training iteration loss = 0.002188342

Training iteration loss = 0.006257579

Training iteration loss = 0.0025658798

Training iteration loss = 0.0033862672

Training iteration loss = 0.0037942438

Training iteration loss = 0.002066247

Training iteration loss = 0.0020537695

Training iteration loss = 0.0025677716

Training iteration loss = 0.0015892284

Training iteration loss = 0.003207081

Training iteration loss = 0.0031647312

Training iteration loss = 0.0040188446

Training iteration loss = 0.0030593246

Training iteration loss = 0.002735681

Training iteration loss = 0.0022994943

Training iteration loss = 0.002193154

Training iteration loss = 0.0023281074

Training iteration loss = 0.003038521

Training iteration loss = 0.004452502

Training iteration loss = 0.0017781197

Training iteration loss = 0.0029492227

Training iteration loss = 0.003034005

Training iteration loss = 0.0032704156

Training iteration loss = 0.0028173123

Training iteration loss = 0.0032522932

Training iteration loss = 0.0028142256

Training iteration loss = 0.0017343191

Training iteration loss = 0.0056643574

Training iteration loss = 0.0029433195

Training iteration loss = 0.0025556616

Training iteration loss = 0.0017690173

Training iteration loss = 0.0031113115

Training iteration loss = 0.003542709

Training iteration loss = 0.0035937105

Training iteration loss = 0.0022601401

Training iteration loss = 0.0055063237

Training iteration loss = 0.003030836

Training iteration loss = 0.0022511089

Training iteration loss = 0.0020627899

Training iteration loss = 0.0023943495

Training iteration loss = 0.001943838

Training iteration loss = 0.002800734

Training iteration loss = 0.0017522207

Training iteration loss = 0.0019801129

Training iteration loss = 0.0037139182

Training iteration loss = 0.0026506104

Training iteration loss = 0.0032422042

Training iteration loss = 0.002530697

Training iteration loss = 0.0038703417

Training iteration loss = 0.004106401

Training iteration loss = 0.0039407336

Training iteration loss = 0.0019254847

Training iteration loss = 0.0027124316

Training iteration loss = 0.0023660585

Training iteration loss = 0.0036563848

Training iteration loss = 0.0032403574

Training iteration loss = 0.00444359

Training iteration loss = 0.0028232054

Training iteration loss = 0.0023129352

Training iteration loss = 0.0031862364

Training iteration loss = 0.0046628495

Training iteration loss = 0.0031436302

Training iteration loss = 0.00275658

Training iteration loss = 0.003208163

Training iteration loss = 0.003085725

Training iteration loss = 0.0023836493

Training iteration loss = 0.002408024

Training iteration loss = 0.0036023492

Training iteration loss = 0.003007448

Training iteration loss = 0.0030582694

Training iteration loss = 0.0028130517

Training iteration loss = 0.0022005003

Training iteration loss = 0.0043387283

Training iteration loss = 0.0038378264

Training iteration loss = 0.0038355878

Training iteration loss = 0.003408092

Training iteration loss = 0.0021627669

Training iteration loss = 0.004538408

Training iteration loss = 0.0054907617

Training iteration loss = 0.002236291

Training iteration loss = 0.003142969

Training iteration loss = 0.002295512

Training iteration loss = 0.00263532

Training iteration loss = 0.00261256

Training iteration loss = 0.0024591356

Training iteration loss = 0.004700032

Training iteration loss = 0.0051881485

Training iteration loss = 0.0024079694

Training iteration loss = 0.002870801

Training iteration loss = 0.0022027001

Training iteration loss = 0.0024929857

Training iteration loss = 0.003359705

Training iteration loss = 0.0031910718

Training iteration loss = 0.0036002889

Training iteration loss = 0.0022733016

Training iteration loss = 0.003469251

Training iteration loss = 0.0069856024

Training iteration loss = 0.0045122434

Training iteration loss = 0.0035925598

Training iteration loss = 0.0028663815

Training iteration loss = 0.003388204

Training iteration loss = 0.0026550805

Training iteration loss = 0.003288538

Training iteration loss = 0.0020947608

Training iteration loss = 0.0025204367

Training iteration loss = 0.0025718294

Training iteration loss = 0.002387998

Training iteration loss = 0.0019408244

Training iteration loss = 0.0045350716

Training iteration loss = 0.0032172215

Training iteration loss = 0.005238415

Training iteration loss = 0.0033071686

Training iteration loss = 0.0031567656

Training iteration loss = 0.0031782978

Training iteration loss = 0.0061695348

Training iteration loss = 0.0038019903

Training iteration loss = 0.0033691407

Training iteration loss = 0.0024761958

Training iteration loss = 0.0043739625

Training iteration loss = 0.002091159

Training iteration loss = 0.0024764594

Training iteration loss = 0.0028707122

Training iteration loss = 0.0036465793

Training iteration loss = 0.0027880676

Training iteration loss = 0.0037345903

Training iteration loss = 0.003368633

Training iteration loss = 0.0019444322

Training iteration loss = 0.002420582

Training iteration loss = 0.0019012643

Training iteration loss = 0.002423133

Training iteration loss = 0.002001547

Training iteration loss = 0.0024143944

Training iteration loss = 0.0032975562

Training iteration loss = 0.003333804

Training iteration loss = 0.0045290827

Training iteration loss = 0.004071412

Training iteration loss = 0.0039375625

Training iteration loss = 0.002070602

Training iteration loss = 0.0029277662

Training iteration loss = 0.0021591631

Training iteration loss = 0.006098001

Training iteration loss = 0.003528147

Training iteration loss = 0.0029356892

Training iteration loss = 0.0027466414

Training iteration loss = 0.0035313393

Training iteration loss = 0.006880649

Training iteration loss = 0.002274783

Training iteration loss = 0.0035023943

Training iteration loss = 0.0035483774

Training iteration loss = 0.0022590184

Training iteration loss = 0.0034491157

Training iteration loss = 0.003681267

Training iteration loss = 0.0025954293

Training iteration loss = 0.002506219

Training iteration loss = 0.0031542087

Training iteration loss = 0.0035522731

Training iteration loss = 0.0035180748

Training iteration loss = 0.0042544757

Training iteration loss = 0.0046574883

Training iteration loss = 0.0031519232

Training iteration loss = 0.0035537158

Training iteration loss = 0.004071045

Training iteration loss = 0.004270848

Training iteration loss = 0.0027509548

Training iteration loss = 0.0035558038

Training iteration loss = 0.0038610052

Training iteration loss = 0.0024520743

Training iteration loss = 0.0021191873

Training iteration loss = 0.003589672

Training iteration loss = 0.0023650152

Training iteration loss = 0.0020103217

Training iteration loss = 0.003066237

Training iteration loss = 0.0022456262

Training iteration loss = 0.0016929494

Training iteration loss = 0.0018366348

Training iteration loss = 0.0031730172

Training iteration loss = 0.002006348

Training iteration loss = 0.002244686

Training iteration loss = 0.0038028753

Training iteration loss = 0.0049969093

Training iteration loss = 0.002487484

Training iteration loss = 0.0026860917

Training iteration loss = 0.0023619707

Training iteration loss = 0.002513102

Training iteration loss = 0.0022397372

Training iteration loss = 0.0039085983

Training iteration loss = 0.0033070745

Training iteration loss = 0.0048799966

Training iteration loss = 0.0038293067

Training iteration loss = 0.002747476

Training iteration loss = 0.0018933607

Training iteration loss = 0.0020558324

Training iteration loss = 0.008023811

Training iteration loss = 0.0028698593

Training iteration loss = 0.0016705503

Training iteration loss = 0.0041784444

Training iteration loss = 0.0038215574

Training iteration loss = 0.0033422373

Training iteration loss = 0.0028320819

Training iteration loss = 0.0038563155

Training iteration loss = 0.00219169

Training iteration loss = 0.0062503796

Training iteration loss = 0.002568167

Training iteration loss = 0.0033846053

Training iteration loss = 0.0037918559

Training iteration loss = 0.0020649885

Training iteration loss = 0.0020498575

Training iteration loss = 0.002561568

Training iteration loss = 0.0015903967

Training iteration loss = 0.0032052582

Training iteration loss = 0.003166424

Training iteration loss = 0.004019543

Training iteration loss = 0.003056977

Training iteration loss = 0.0027359575

Training iteration loss = 0.002297036

Training iteration loss = 0.002193304

Training iteration loss = 0.0023292343

Training iteration loss = 0.0030392818

Training iteration loss = 0.0044450434

Training iteration loss = 0.0017765557

Training iteration loss = 0.0029462466

Training iteration loss = 0.003031078

Training iteration loss = 0.0032684219

Training iteration loss = 0.002817094

Training iteration loss = 0.0032525922

Training iteration loss = 0.0028127667

Training iteration loss = 0.001733669

Training iteration loss = 0.00565091

Training iteration loss = 0.0029397504

Training iteration loss = 0.0025535815

Training iteration loss = 0.0017693258

Training iteration loss = 0.0031062511

Training iteration loss = 0.0035379648

Training iteration loss = 0.0035942143

Training iteration loss = 0.0022585073

Training iteration loss = 0.005507421

Training iteration loss = 0.0030298617

Training iteration loss = 0.0022526036

Training iteration loss = 0.0020639587

Training iteration loss = 0.0023921658

Training iteration loss = 0.0019433746

Training iteration loss = 0.0027962476

Training iteration loss = 0.0017509294

Training iteration loss = 0.0019767783

Training iteration loss = 0.0037103265

Training iteration loss = 0.002647192

Training iteration loss = 0.0032381422

Training iteration loss = 0.0025313518

Training iteration loss = 0.003867633

Training iteration loss = 0.004106887

Training iteration loss = 0.0039399965

Training iteration loss = 0.0019228909

Training iteration loss = 0.0027092465

Training iteration loss = 0.0023590983

Training iteration loss = 0.003650864

Training iteration loss = 0.0032357965

Training iteration loss = 0.004437451

Training iteration loss = 0.0028220855

Training iteration loss = 0.002312852

Training iteration loss = 0.0031875006

Training iteration loss = 0.0046583395

Training iteration loss = 0.003142908

Training iteration loss = 0.0027586408

Training iteration loss = 0.0032022959

Training iteration loss = 0.0030815557

Training iteration loss = 0.002385087

Training iteration loss = 0.0024046379

Training iteration loss = 0.003603529

Training iteration loss = 0.0030089226

Training iteration loss = 0.003062823

Training iteration loss = 0.0028147332

Training iteration loss = 0.0021995916

Training iteration loss = 0.0043402547

Training iteration loss = 0.0038308233

Training iteration loss = 0.0038334227

Training iteration loss = 0.003401452

Training iteration loss = 0.0021617685

Training iteration loss = 0.004536242

Training iteration loss = 0.005491627

Training iteration loss = 0.0022314994

Training iteration loss = 0.003137667

Training iteration loss = 0.0022948517

Training iteration loss = 0.0026386792

Training iteration loss = 0.0026112236

Training iteration loss = 0.0024626583

Training iteration loss = 0.004694468

Training iteration loss = 0.0051753125

Training iteration loss = 0.0024058633

Training iteration loss = 0.0028705664

Training iteration loss = 0.002204706

Training iteration loss = 0.0024906187

Training iteration loss = 0.0033593841

Training iteration loss = 0.0031922136

Training iteration loss = 0.0035993021

Training iteration loss = 0.0022697446

Training iteration loss = 0.0034700802

Training iteration loss = 0.006976252

Training iteration loss = 0.0045081065

Training iteration loss = 0.003591081

Training iteration loss = 0.002866681

Training iteration loss = 0.0033883562

Training iteration loss = 0.0026556402

Training iteration loss = 0.0032917291

Training iteration loss = 0.0020965855

Training iteration loss = 0.0025204741

Training iteration loss = 0.0025737283

Training iteration loss = 0.0023840326

Training iteration loss = 0.0019392808

Training iteration loss = 0.004536523

Training iteration loss = 0.003211908

Training iteration loss = 0.0052371044

Training iteration loss = 0.0033128948

Training iteration loss = 0.003157776

Training iteration loss = 0.0031551293

Training iteration loss = 0.0061647757

Training iteration loss = 0.003805971

Training iteration loss = 0.0033681372

Training iteration loss = 0.0024810394

Training iteration loss = 0.0043799356

Training iteration loss = 0.0020903016

Training iteration loss = 0.0024822683

Training iteration loss = 0.0028641324

Training iteration loss = 0.0036409646

Training iteration loss = 0.002792476

Training iteration loss = 0.0037328193

Training iteration loss = 0.0033755128

Training iteration loss = 0.0019488017

Training iteration loss = 0.0024221966

Training iteration loss = 0.0019044454

Training iteration loss = 0.0024365261

Training iteration loss = 0.00201708

Training iteration loss = 0.0024176894

Training iteration loss = 0.0032985948

Training iteration loss = 0.003341242

Training iteration loss = 0.0045368727

Training iteration loss = 0.004073852

Training iteration loss = 0.003949162

Training iteration loss = 0.0020701664

Training iteration loss = 0.0029256272

Training iteration loss = 0.002153884

Training iteration loss = 0.006081046

Training iteration loss = 0.0035161164

Training iteration loss = 0.002939707

Training iteration loss = 0.0027452533

Training iteration loss = 0.0035315894

Training iteration loss = 0.0068665654

Training iteration loss = 0.0022743682

Training iteration loss = 0.00349655

Training iteration loss = 0.0035543516

Training iteration loss = 0.0022573103

Training iteration loss = 0.0034454176

Training iteration loss = 0.0036809398

Training iteration loss = 0.0025922407

Training iteration loss = 0.0025017455

Training iteration loss = 0.003149164

Training iteration loss = 0.0035403657

Training iteration loss = 0.0035093327

Training iteration loss = 0.004252466

Training iteration loss = 0.0046551195

Training iteration loss = 0.00314717

Training iteration loss = 0.0035564832

Training iteration loss = 0.004069214

Training iteration loss = 0.0042613386

Training iteration loss = 0.0027384004

Training iteration loss = 0.0035525768

Training iteration loss = 0.0038634231

Training iteration loss = 0.002451807

Training iteration loss = 0.0021183302

Training iteration loss = 0.0035874338

Training iteration loss = 0.00235465

Training iteration loss = 0.0020077405

Training iteration loss = 0.003069576

Training iteration loss = 0.0022496704

Training iteration loss = 0.0016933699

Training iteration loss = 0.0018356581

Training iteration loss = 0.003169133

Training iteration loss = 0.0020007726

Training iteration loss = 0.0022445053

Training iteration loss = 0.0038012948

Training iteration loss = 0.0049931374

Training iteration loss = 0.0024879572

Training iteration loss = 0.0026878205

Training iteration loss = 0.002363934

Training iteration loss = 0.0025097227

Training iteration loss = 0.0022374538

Training iteration loss = 0.003908489

Training iteration loss = 0.0033085064

Training iteration loss = 0.0048754215

Training iteration loss = 0.0038280946

Training iteration loss = 0.0027433664

Training iteration loss = 0.001889876

Training iteration loss = 0.0020539754

Training iteration loss = 0.008016861

Training iteration loss = 0.0028643832

Training iteration loss = 0.0016690805

Training iteration loss = 0.0041728853

Training iteration loss = 0.0038203334

Training iteration loss = 0.0033377276

Training iteration loss = 0.0028281326

Training iteration loss = 0.0038545597

Training iteration loss = 0.0021910267

Training iteration loss = 0.006246608

Training iteration loss = 0.0025693746

Training iteration loss = 0.0033851883

Training iteration loss = 0.0037938522

Training iteration loss = 0.0020667764

Training iteration loss = 0.0020504864

Training iteration loss = 0.0025619897

Training iteration loss = 0.0015889443

Training iteration loss = 0.0031985368

Training iteration loss = 0.0031691815

Training iteration loss = 0.0040252632

Training iteration loss = 0.003059677

Training iteration loss = 0.0027347805

Training iteration loss = 0.0022985174

Training iteration loss = 0.002197433

Training iteration loss = 0.0023288843

Training iteration loss = 0.003036653

Training iteration loss = 0.0044403938

Training iteration loss = 0.0017750337

Training iteration loss = 0.002948312

Training iteration loss = 0.003031277

Training iteration loss = 0.0032646237

Training iteration loss = 0.0028141811

Training iteration loss = 0.0032543421

Training iteration loss = 0.0028139167

Training iteration loss = 0.0017313218

Training iteration loss = 0.005654465

Training iteration loss = 0.0029385227

Training iteration loss = 0.0025591871

Training iteration loss = 0.0017716793

Training iteration loss = 0.0031054765

Training iteration loss = 0.0035307992

Training iteration loss = 0.0035895493

Training iteration loss = 0.002256545

Training iteration loss = 0.005493991

Training iteration loss = 0.0030331959

Training iteration loss = 0.0022582274

Training iteration loss = 0.002066726

Training iteration loss = 0.0023906229

Training iteration loss = 0.0019402517

Training iteration loss = 0.002787903

Training iteration loss = 0.0017530853

Training iteration loss = 0.0019856058

Training iteration loss = 0.0037219692

Training iteration loss = 0.0026441207

Training iteration loss = 0.0032317934

Training iteration loss = 0.0025303557

Training iteration loss = 0.0038759105

Training iteration loss = 0.0041106897

Training iteration loss = 0.0039327764

Training iteration loss = 0.0019152365

Training iteration loss = 0.0027047035

Training iteration loss = 0.0023559537

Training iteration loss = 0.0036390296

Training iteration loss = 0.0032328928

Training iteration loss = 0.004435927

Training iteration loss = 0.0028268846

Training iteration loss = 0.0023094385

Training iteration loss = 0.0031894892

Training iteration loss = 0.0046532676

Training iteration loss = 0.0031390062

Training iteration loss = 0.0027622965

Training iteration loss = 0.0032021434

Training iteration loss = 0.0030835755

Training iteration loss = 0.0023934345

Training iteration loss = 0.002402852

Training iteration loss = 0.0036013455

Training iteration loss = 0.003013686

Training iteration loss = 0.0030648627

Training iteration loss = 0.0028150512

Training iteration loss = 0.00219878

Training iteration loss = 0.0043436037

Training iteration loss = 0.0038363887

Training iteration loss = 0.0038307786

Training iteration loss = 0.003396854

Training iteration loss = 0.0021621026

Training iteration loss = 0.004530363

Training iteration loss = 0.0054946207

Training iteration loss = 0.002230114

Training iteration loss = 0.0031327773

Training iteration loss = 0.002292603

Training iteration loss = 0.002638878

Training iteration loss = 0.0026101766

Training iteration loss = 0.0024613563

Training iteration loss = 0.004694466

Training iteration loss = 0.005167281

Training iteration loss = 0.002404379

Training iteration loss = 0.0028700351

Training iteration loss = 0.0022027895

Training iteration loss = 0.0024876622

Training iteration loss = 0.003359039

Training iteration loss = 0.0031952087

Training iteration loss = 0.003596223

Training iteration loss = 0.0022652282

Training iteration loss = 0.0034725685

Training iteration loss = 0.006972617

Training iteration loss = 0.0045058993

Training iteration loss = 0.0035856373

Training iteration loss = 0.002863838

Training iteration loss = 0.003386519

Training iteration loss = 0.0026568829

Training iteration loss = 0.0032911024

Training iteration loss = 0.0020953768

Training iteration loss = 0.0025184408

Training iteration loss = 0.0025738447

Training iteration loss = 0.0023900743

Training iteration loss = 0.001938752

Training iteration loss = 0.0045363796

Training iteration loss = 0.0032129232

Training iteration loss = 0.005237454

Training iteration loss = 0.003320305

Training iteration loss = 0.0031604941

Training iteration loss = 0.0031659615

Training iteration loss = 0.0061574453

Training iteration loss = 0.003804866

Training iteration loss = 0.0033714243

Training iteration loss = 0.0024747746

Training iteration loss = 0.0043676165

Training iteration loss = 0.0020889924

Training iteration loss = 0.0024808329

Training iteration loss = 0.002871357

Training iteration loss = 0.0036461486

Training iteration loss = 0.0027878538

Training iteration loss = 0.00373412

Training iteration loss = 0.0033707386

Training iteration loss = 0.0019499365

Training iteration loss = 0.002420002

Training iteration loss = 0.0018980916

Training iteration loss = 0.002421912

Training iteration loss = 0.002002947

Training iteration loss = 0.0024142365

Training iteration loss = 0.0033048454

Training iteration loss = 0.0033265383

Training iteration loss = 0.0045323684

Training iteration loss = 0.004065939

Training iteration loss = 0.0039312323

Training iteration loss = 0.0020673953

Training iteration loss = 0.0029291818

Training iteration loss = 0.0021582188

Training iteration loss = 0.0060686707

Training iteration loss = 0.0034975244

Training iteration loss = 0.0029492166

Training iteration loss = 0.0027639342

Training iteration loss = 0.0035457276

Training iteration loss = 0.00678421

Training iteration loss = 0.0022833652

Training iteration loss = 0.0035052306

Training iteration loss = 0.0035797453

Training iteration loss = 0.0022895075

Training iteration loss = 0.0034780458

Training iteration loss = 0.0036902605

Training iteration loss = 0.002602191

Training iteration loss = 0.0024830936

Training iteration loss = 0.0031229856

Training iteration loss = 0.0035310003

Training iteration loss = 0.0035038749

Training iteration loss = 0.0043154447

Training iteration loss = 0.004662829

Training iteration loss = 0.0031728141

Training iteration loss = 0.0035064183

Training iteration loss = 0.004051655

Training iteration loss = 0.004235839

Training iteration loss = 0.0027407545

Training iteration loss = 0.0035396882

Training iteration loss = 0.0038639114

Training iteration loss = 0.0024606318

Training iteration loss = 0.0021244928

Training iteration loss = 0.0035898972

Training iteration loss = 0.0023484027

Training iteration loss = 0.0020049305

Training iteration loss = 0.0030606783

Training iteration loss = 0.0022433156

Training iteration loss = 0.0016916004

Training iteration loss = 0.0018452819

Training iteration loss = 0.003182277

Training iteration loss = 0.0020021778

Training iteration loss = 0.0022324699

Training iteration loss = 0.0037873841

Training iteration loss = 0.004994257

Training iteration loss = 0.0024817882

Training iteration loss = 0.0026872244

Training iteration loss = 0.0023715994

Training iteration loss = 0.0025032815

Training iteration loss = 0.0022228982

Training iteration loss = 0.0039017405

Training iteration loss = 0.0033039935

Training iteration loss = 0.004877168

Training iteration loss = 0.0038222736

Training iteration loss = 0.0027443052

Training iteration loss = 0.0018964872

Training iteration loss = 0.0020618

Training iteration loss = 0.008001978

Training iteration loss = 0.0028603899

Training iteration loss = 0.0016740701

Training iteration loss = 0.0041607455

Training iteration loss = 0.0038258887

Training iteration loss = 0.0033395428

Training iteration loss = 0.0028288637

Training iteration loss = 0.003855189

Training iteration loss = 0.0021792774

Training iteration loss = 0.00624229

Training iteration loss = 0.0025634898

Training iteration loss = 0.00338447

Training iteration loss = 0.0037923523

Training iteration loss = 0.0020657594

Training iteration loss = 0.0020465737

Training iteration loss = 0.0025623098

Training iteration loss = 0.0015866077

Training iteration loss = 0.0031969827

Training iteration loss = 0.003166193

Training iteration loss = 0.0040227366

Training iteration loss = 0.0030599174

Training iteration loss = 0.002734095

Training iteration loss = 0.0023001868

Training iteration loss = 0.0021998126

Training iteration loss = 0.0023239988

Training iteration loss = 0.0030285055

Training iteration loss = 0.004447666

Training iteration loss = 0.0017735293

Training iteration loss = 0.0029470322

Training iteration loss = 0.0030327188

Training iteration loss = 0.0032636898

Training iteration loss = 0.0028067979

Training iteration loss = 0.003258696

Training iteration loss = 0.0028100845

Training iteration loss = 0.001729413

Training iteration loss = 0.0056477482

Training iteration loss = 0.0029409009

Training iteration loss = 0.0025594856

Training iteration loss = 0.0017665554

Training iteration loss = 0.00310037

Training iteration loss = 0.0035391012

Training iteration loss = 0.0035794983

Training iteration loss = 0.0022592016

Training iteration loss = 0.005471712

Training iteration loss = 0.0030333924

Training iteration loss = 0.0022631527

Training iteration loss = 0.0020666341

Training iteration loss = 0.0023916007

Training iteration loss = 0.0019394007

Training iteration loss = 0.0027853155

Training iteration loss = 0.0017540195

Training iteration loss = 0.0019782137

Training iteration loss = 0.0037191578

Training iteration loss = 0.002634868

Training iteration loss = 0.0032313534

Training iteration loss = 0.00252507

Training iteration loss = 0.0038711436

Training iteration loss = 0.0040975544

Training iteration loss = 0.003920296

Training iteration loss = 0.0019214827

Training iteration loss = 0.002706089

Training iteration loss = 0.0023565174

Training iteration loss = 0.0036461893

Training iteration loss = 0.0032309964

Training iteration loss = 0.004435224

Training iteration loss = 0.0028221316

Training iteration loss = 0.0023092625

Training iteration loss = 0.0031867733

Training iteration loss = 0.0046506594

Training iteration loss = 0.0031393066

Training iteration loss = 0.0027587453

Training iteration loss = 0.0031983526

Training iteration loss = 0.0030846598

Training iteration loss = 0.002385026

Training iteration loss = 0.0024043336

Training iteration loss = 0.0036026186

Training iteration loss = 0.003010757

Training iteration loss = 0.003063481

Training iteration loss = 0.0028168678

Training iteration loss = 0.0021960794

Training iteration loss = 0.0043380014

Training iteration loss = 0.0038172547

Training iteration loss = 0.0038326841

Training iteration loss = 0.0033908116

Training iteration loss = 0.002157889

Training iteration loss = 0.004537959

Training iteration loss = 0.00549734

Training iteration loss = 0.0022265194

Training iteration loss = 0.0031345997

Training iteration loss = 0.0022899942

Training iteration loss = 0.002634859

Training iteration loss = 0.002608763

Training iteration loss = 0.002460872

Training iteration loss = 0.0046880604

Training iteration loss = 0.005165127

Training iteration loss = 0.0024009922

Training iteration loss = 0.0028715953

Training iteration loss = 0.0021993222

Training iteration loss = 0.0024851712

Training iteration loss = 0.003361781

Training iteration loss = 0.0031955785

Training iteration loss = 0.0035921421

Training iteration loss = 0.0022651425

Training iteration loss = 0.003468833

Training iteration loss = 0.0069688573

Training iteration loss = 0.0045006513

Training iteration loss = 0.0035831628

Training iteration loss = 0.002863315

Training iteration loss = 0.0033823403

Training iteration loss = 0.0026542211

Training iteration loss = 0.0032880919

Training iteration loss = 0.0020961878

Training iteration loss = 0.002519152

Training iteration loss = 0.0025718047

Training iteration loss = 0.0023828822

Training iteration loss = 0.0019363338

Training iteration loss = 0.0045376113

Training iteration loss = 0.003211759

Training iteration loss = 0.0052346922

Training iteration loss = 0.0033172027

Training iteration loss = 0.0031547796

Training iteration loss = 0.0031643112

Training iteration loss = 0.0061481423

Training iteration loss = 0.0038010955

Training iteration loss = 0.0033692122

Training iteration loss = 0.0024708528

Training iteration loss = 0.0043587782

Training iteration loss = 0.0020880548

Training iteration loss = 0.002481099

Training iteration loss = 0.0028663578

Training iteration loss = 0.0036426845

Training iteration loss = 0.0027882245

Training iteration loss = 0.003732174

Training iteration loss = 0.0033715942

Training iteration loss = 0.0019470764

Training iteration loss = 0.0024179153

Training iteration loss = 0.0018967428

Training iteration loss = 0.0024216298

Training iteration loss = 0.0020046283

Training iteration loss = 0.0024117657

Training iteration loss = 0.0032976817

Training iteration loss = 0.0033278551

Training iteration loss = 0.0045302026

Training iteration loss = 0.0040620943

Training iteration loss = 0.0039307666

Training iteration loss = 0.0020653082

Training iteration loss = 0.0029280337

Training iteration loss = 0.0021549421

Training iteration loss = 0.006077362

Training iteration loss = 0.003502286

Training iteration loss = 0.0029430382

Training iteration loss = 0.0027480861

Training iteration loss = 0.003535726

Training iteration loss = 0.006813565

Training iteration loss = 0.0022799198

Training iteration loss = 0.003498029

Training iteration loss = 0.0035638625

Training iteration loss = 0.0022752055

Training iteration loss = 0.0034664888

Training iteration loss = 0.00368073

Training iteration loss = 0.0025959837

Training iteration loss = 0.0024933508

Training iteration loss = 0.0031388446

Training iteration loss = 0.0035373184

Training iteration loss = 0.003508901

Training iteration loss = 0.004274528

Training iteration loss = 0.0046614497

Training iteration loss = 0.0031627303

Training iteration loss = 0.0035240839

Training iteration loss = 0.004052381

Training iteration loss = 0.0042491565

Training iteration loss = 0.002740909

Training iteration loss = 0.0035327754

Training iteration loss = 0.003852969

Training iteration loss = 0.0024496976

Training iteration loss = 0.002124145

Training iteration loss = 0.003593384

Training iteration loss = 0.0023538957

Training iteration loss = 0.002001385

Training iteration loss = 0.0030583283

Training iteration loss = 0.0022457212

Training iteration loss = 0.001691144

Training iteration loss = 0.0018394705

Training iteration loss = 0.003179808

Training iteration loss = 0.0020012083

Training iteration loss = 0.0022389991

Training iteration loss = 0.0037889353

Training iteration loss = 0.0049882717

Training iteration loss = 0.0024863041

Training iteration loss = 0.0026868135

Training iteration loss = 0.0023647568

Training iteration loss = 0.0024971256

Training iteration loss = 0.0022290107

Training iteration loss = 0.0038998162

Training iteration loss = 0.0033023015

Training iteration loss = 0.004875893

Training iteration loss = 0.003819851

Training iteration loss = 0.0027400989

Training iteration loss = 0.0018910378

Training iteration loss = 0.0020576299

Training iteration loss = 0.007993297

Training iteration loss = 0.0028588374

Training iteration loss = 0.0016617447

Training iteration loss = 0.00416761

Training iteration loss = 0.0038233108

Training iteration loss = 0.0033317292

Training iteration loss = 0.002829791

Training iteration loss = 0.0038520775

Training iteration loss = 0.0021843805

Training iteration loss = 0.0062350384

Training iteration loss = 0.002563206

Training iteration loss = 0.0033805913

Training iteration loss = 0.003787507

Training iteration loss = 0.0020642912

Training iteration loss = 0.0020425394

Training iteration loss = 0.0025572823

Training iteration loss = 0.0015872149

Training iteration loss = 0.0031955054

Training iteration loss = 0.0031676756

Training iteration loss = 0.0040239394

Training iteration loss = 0.0030593742

Training iteration loss = 0.0027332455

Training iteration loss = 0.002297187

Training iteration loss = 0.0021996964

Training iteration loss = 0.0023231735

Training iteration loss = 0.0030269849

Training iteration loss = 0.0044356524

Training iteration loss = 0.0017719591

Training iteration loss = 0.002945137

Training iteration loss = 0.003029844

Training iteration loss = 0.0032598886

Training iteration loss = 0.0028061084

Training iteration loss = 0.0032581475

Training iteration loss = 0.0028062097

Training iteration loss = 0.0017290353

Training iteration loss = 0.0056432784

Training iteration loss = 0.0029362384

Training iteration loss = 0.0025611224

Training iteration loss = 0.0017692285

Training iteration loss = 0.0030961798

Training iteration loss = 0.0035304858

Training iteration loss = 0.0035780503

Training iteration loss = 0.0022546782

Training iteration loss = 0.0054648607

Training iteration loss = 0.0030319307

Training iteration loss = 0.0022633092

Training iteration loss = 0.0020702959

Training iteration loss = 0.0023897283

Training iteration loss = 0.00194116

Training iteration loss = 0.0027806747

Training iteration loss = 0.0017556647

Training iteration loss = 0.0019805194

Training iteration loss = 0.0037227648

Training iteration loss = 0.0026334466

Training iteration loss = 0.0032282397

Training iteration loss = 0.0025223147

Training iteration loss = 0.003876103

Training iteration loss = 0.0041018864

Training iteration loss = 0.0039182515

Training iteration loss = 0.0019160431

Training iteration loss = 0.0027009153

Training iteration loss = 0.0023546817

Training iteration loss = 0.0036415525

Training iteration loss = 0.003226163

Training iteration loss = 0.0044337087

Training iteration loss = 0.0028235924

Training iteration loss = 0.0023067857

Training iteration loss = 0.0031879174

Training iteration loss = 0.0046473965

Training iteration loss = 0.0031364148

Training iteration loss = 0.002762647

Training iteration loss = 0.0031962737

Training iteration loss = 0.003082895

Training iteration loss = 0.0023881525

Training iteration loss = 0.0024021447

Training iteration loss = 0.0036022805

Training iteration loss = 0.0030134905

Training iteration loss = 0.0030658168

Training iteration loss = 0.0028187057

Training iteration loss = 0.0021942656

Training iteration loss = 0.004338536

Training iteration loss = 0.003814907

Training iteration loss = 0.0038301433

Training iteration loss = 0.0033846626

Training iteration loss = 0.0021578784

Training iteration loss = 0.004535482

Training iteration loss = 0.0054977085

Training iteration loss = 0.0022244642

Training iteration loss = 0.0031299004

Training iteration loss = 0.0022890246

Training iteration loss = 0.0026355444

Training iteration loss = 0.002607656

Training iteration loss = 0.0024612828

Training iteration loss = 0.0046861996

Training iteration loss = 0.0051574255

Training iteration loss = 0.0023974103

Training iteration loss = 0.002871699

Training iteration loss = 0.002198183

Training iteration loss = 0.002484512

Training iteration loss = 0.0033629488

Training iteration loss = 0.0031978562

Training iteration loss = 0.0035895985

Training iteration loss = 0.0022631157

Training iteration loss = 0.003469664

Training iteration loss = 0.0069715106

Training iteration loss = 0.0044968287

Training iteration loss = 0.003581415

Training iteration loss = 0.002862143

Training iteration loss = 0.0033813657

Training iteration loss = 0.002654846

Training iteration loss = 0.0032861305

Training iteration loss = 0.0020962197

Training iteration loss = 0.0025181207

Training iteration loss = 0.0025703276

Training iteration loss = 0.0023786882

Training iteration loss = 0.0019349073

Training iteration loss = 0.0045380164

Training iteration loss = 0.003211071

Training iteration loss = 0.0052344184

Training iteration loss = 0.003318987

Training iteration loss = 0.0031537705

Training iteration loss = 0.0031611265

Training iteration loss = 0.0061404817

Training iteration loss = 0.0037991647

Training iteration loss = 0.0033697106

Training iteration loss = 0.0024684416

Training iteration loss = 0.0043532383

Training iteration loss = 0.0020875838

Training iteration loss = 0.0024838466

Training iteration loss = 0.0028647368

Training iteration loss = 0.0036421055

Training iteration loss = 0.002788109

Training iteration loss = 0.0037329616

Training iteration loss = 0.0033710226

Training iteration loss = 0.001947348

Training iteration loss = 0.002416671

Training iteration loss = 0.0018943279

Training iteration loss = 0.00241979

Training iteration loss = 0.0020044434

Training iteration loss = 0.0024101292

Training iteration loss = 0.0032954433

Training iteration loss = 0.0033245832

Training iteration loss = 0.004529813

Training iteration loss = 0.0040596058

Training iteration loss = 0.0039259135

Training iteration loss = 0.0020636402

Training iteration loss = 0.002929182

Training iteration loss = 0.0021545382

Training iteration loss = 0.0060697948

Training iteration loss = 0.0034957526

Training iteration loss = 0.0029453018

Training iteration loss = 0.0027482358

Training iteration loss = 0.0035371736

Training iteration loss = 0.0068003945

Training iteration loss = 0.002280798

Training iteration loss = 0.0034973517

Training iteration loss = 0.003568165

Training iteration loss = 0.0022770409

Training iteration loss = 0.003467545

Training iteration loss = 0.0036797952

Training iteration loss = 0.0025954728

Training iteration loss = 0.0024889747

Training iteration loss = 0.0031318972

Training iteration loss = 0.0035305284

Training iteration loss = 0.0035077312

Training iteration loss = 0.004280727

Training iteration loss = 0.004659815

Training iteration loss = 0.0031614455

Training iteration loss = 0.0035200615

Training iteration loss = 0.0040488592

Training iteration loss = 0.004238097

Training iteration loss = 0.0027318944

Training iteration loss = 0.003533834

Training iteration loss = 0.0038583602

Training iteration loss = 0.0024524713

Training iteration loss = 0.0021272285

Training iteration loss = 0.0035900641

Training iteration loss = 0.002347894

Training iteration loss = 0.0019982166

Training iteration loss = 0.0030623125

Training iteration loss = 0.0022467023

Training iteration loss = 0.0016880883

Training iteration loss = 0.0018400991

Training iteration loss = 0.0031830305

Training iteration loss = 0.0020005936

Training iteration loss = 0.0022347274

Training iteration loss = 0.00378663

Training iteration loss = 0.0049920105

Training iteration loss = 0.002481738

Training iteration loss = 0.002683389

Training iteration loss = 0.0023662446

Training iteration loss = 0.0024969617

Training iteration loss = 0.00222151

Training iteration loss = 0.0038979594

Training iteration loss = 0.0033038927

Training iteration loss = 0.004873201

Training iteration loss = 0.003819165

Training iteration loss = 0.0027352653

Training iteration loss = 0.0018896568

Training iteration loss = 0.00205836

Training iteration loss = 0.007985064

Training iteration loss = 0.0028540392

Training iteration loss = 0.0016635996

Training iteration loss = 0.0041549504

Training iteration loss = 0.003824293

Training iteration loss = 0.0033288877

Training iteration loss = 0.002828405

Training iteration loss = 0.0038521735

Training iteration loss = 0.0021803621

Training iteration loss = 0.006225376

Training iteration loss = 0.0025603427

Training iteration loss = 0.0033818546

Training iteration loss = 0.0037902298

Training iteration loss = 0.0020673228

Training iteration loss = 0.0020448037

Training iteration loss = 0.0025617837

Training iteration loss = 0.00158686

Training iteration loss = 0.003192664

Training iteration loss = 0.003167199

Training iteration loss = 0.004021419

Training iteration loss = 0.0030603108

Training iteration loss = 0.0027349938

Training iteration loss = 0.00229399

Training iteration loss = 0.0022002468

Training iteration loss = 0.0023247243

Training iteration loss = 0.0030268559

Training iteration loss = 0.004428864

Training iteration loss = 0.001770095

Training iteration loss = 0.0029443444

Training iteration loss = 0.0030270077

Training iteration loss = 0.003258261

Training iteration loss = 0.0028053538

Training iteration loss = 0.0032592162

Training iteration loss = 0.002807106

Training iteration loss = 0.0017264117

Training iteration loss = 0.0056317435

Training iteration loss = 0.0029355914

Training iteration loss = 0.002556794

Training iteration loss = 0.0017678376

Training iteration loss = 0.0030899586

Training iteration loss = 0.0035302462

Training iteration loss = 0.0035790612

Training iteration loss = 0.0022515839

Training iteration loss = 0.0054620546

Training iteration loss = 0.0030275108

Training iteration loss = 0.0022596961

Training iteration loss = 0.0020670972

Training iteration loss = 0.0023849993

Training iteration loss = 0.0019418523

Training iteration loss = 0.0027775783

Training iteration loss = 0.0017541217

Training iteration loss = 0.0019748618

Training iteration loss = 0.0037264142

Training iteration loss = 0.0026310345

Training iteration loss = 0.00322807

Training iteration loss = 0.0025197822

Training iteration loss = 0.00387172

Training iteration loss = 0.004098847

Training iteration loss = 0.0039100875

Training iteration loss = 0.001915946

Training iteration loss = 0.0026990531

Training iteration loss = 0.0023527325

Training iteration loss = 0.003642766

Training iteration loss = 0.0032215577

Training iteration loss = 0.004432197

Training iteration loss = 0.0028215924

Training iteration loss = 0.0023042087

Training iteration loss = 0.0031851686

Training iteration loss = 0.0046472703

Training iteration loss = 0.0031351189

Training iteration loss = 0.0027634667

Training iteration loss = 0.0031933582

Training iteration loss = 0.0030797867

Training iteration loss = 0.00238604

Training iteration loss = 0.0024012027

Training iteration loss = 0.003600493

Training iteration loss = 0.0030160295

Training iteration loss = 0.0030666823

Training iteration loss = 0.002820247

Training iteration loss = 0.00219281

Training iteration loss = 0.0043385513

Training iteration loss = 0.0038097631

Training iteration loss = 0.0038311195

Training iteration loss = 0.0033809107

Training iteration loss = 0.0021544076

Training iteration loss = 0.004537313

Training iteration loss = 0.0054975078

Training iteration loss = 0.0022187151

Training iteration loss = 0.0031309568

Training iteration loss = 0.00228672

Training iteration loss = 0.0026341535

Training iteration loss = 0.0026062916

Training iteration loss = 0.0024649333

Training iteration loss = 0.004681733

Training iteration loss = 0.005145591

Training iteration loss = 0.0023946234

Training iteration loss = 0.0028715935

Training iteration loss = 0.0021987522

Training iteration loss = 0.0024823204

Training iteration loss = 0.0033625867

Training iteration loss = 0.0031960597

Training iteration loss = 0.0035870408

Training iteration loss = 0.0022604263

Training iteration loss = 0.0034667458

Training iteration loss = 0.006956763

Training iteration loss = 0.0044931327

Training iteration loss = 0.0035794408

Training iteration loss = 0.0028638784

Training iteration loss = 0.003379505

Training iteration loss = 0.0026559876

Training iteration loss = 0.0032894744

Training iteration loss = 0.002099531

Training iteration loss = 0.002521888

Training iteration loss = 0.002573873

Training iteration loss = 0.0023784477

Training iteration loss = 0.0019342457

Training iteration loss = 0.004539974

Training iteration loss = 0.003204991

Training iteration loss = 0.0052324426

Training iteration loss = 0.0033223778

Training iteration loss = 0.0031530894

Training iteration loss = 0.0031442132

Training iteration loss = 0.006134042

Training iteration loss = 0.003799905

Training iteration loss = 0.0033683963

Training iteration loss = 0.002471587

Training iteration loss = 0.004351034

Training iteration loss = 0.002086605

Training iteration loss = 0.0024908534

Training iteration loss = 0.0028618493

Training iteration loss = 0.0036365483

Training iteration loss = 0.0027897737

Training iteration loss = 0.0037302782

Training iteration loss = 0.00337458

Training iteration loss = 0.0019500306

Training iteration loss = 0.0024196901

Training iteration loss = 0.0018993075

Training iteration loss = 0.0024327605

Training iteration loss = 0.0020178126

Training iteration loss = 0.0024112163

Training iteration loss = 0.00329151

Training iteration loss = 0.0033340657

Training iteration loss = 0.0045357826

Training iteration loss = 0.0040659807

Training iteration loss = 0.003933629

Training iteration loss = 0.0020651002

Training iteration loss = 0.0029264651

Training iteration loss = 0.0021508727

Training iteration loss = 0.006079912

Training iteration loss = 0.0034964497

Training iteration loss = 0.0029427537

Training iteration loss = 0.0027376416

Training iteration loss = 0.0035306339

Training iteration loss = 0.0068302024

Training iteration loss = 0.0022746052

Training iteration loss = 0.003487808

Training iteration loss = 0.0035568385

Training iteration loss = 0.0022606477

Training iteration loss = 0.0034526123

Training iteration loss = 0.0036688633

Training iteration loss = 0.0025855694

Training iteration loss = 0.0024978688

Training iteration loss = 0.0031434612

Training iteration loss = 0.0035355266

Training iteration loss = 0.0035158684

Training iteration loss = 0.004255776

Training iteration loss = 0.0046595535

Training iteration loss = 0.0031490729

Training iteration loss = 0.003540067

Training iteration loss = 0.004057448

Training iteration loss = 0.004251445

Training iteration loss = 0.002725506

Training iteration loss = 0.003532036

Training iteration loss = 0.003854316

Training iteration loss = 0.0024458023

Training iteration loss = 0.002127587

Training iteration loss = 0.0035893004

Training iteration loss = 0.0023524843

Training iteration loss = 0.0019944094

Training iteration loss = 0.0030623593

Training iteration loss = 0.0022495047

Training iteration loss = 0.001688471

Training iteration loss = 0.0018337318

Training iteration loss = 0.0031798882

Training iteration loss = 0.001998147

Training iteration loss = 0.0022427384

Training iteration loss = 0.003790621

Training iteration loss = 0.004985275

Training iteration loss = 0.002486895

Training iteration loss = 0.0026812695

Training iteration loss = 0.0023607246

Training iteration loss = 0.0024929221

Training iteration loss = 0.0022290966

Training iteration loss = 0.0038995754

Training iteration loss = 0.0033046575

Training iteration loss = 0.004869688

Training iteration loss = 0.0038187664

Training iteration loss = 0.002731472

Training iteration loss = 0.0018827524

Training iteration loss = 0.002053111

Training iteration loss = 0.0079854615

Training iteration loss = 0.0028518122

Training iteration loss = 0.0016524422

Training iteration loss = 0.004161104

Training iteration loss = 0.0038205788

Training iteration loss = 0.0033212684

Training iteration loss = 0.002825986

Training iteration loss = 0.0038490181

Training iteration loss = 0.00218565

Training iteration loss = 0.006217606

Training iteration loss = 0.0025621261

Training iteration loss = 0.0033800357

Training iteration loss = 0.0037901213

Training iteration loss = 0.002069384

Training iteration loss = 0.0020455772

Training iteration loss = 0.0025620495

Training iteration loss = 0.0015876369

Training iteration loss = 0.003187295

Training iteration loss = 0.0031658243

Training iteration loss = 0.0040199873

Training iteration loss = 0.0030629116

Training iteration loss = 0.0027360672

Training iteration loss = 0.0022906337

Training iteration loss = 0.0021985967

Training iteration loss = 0.0023293316

Training iteration loss = 0.003032904

Training iteration loss = 0.0044137635

Training iteration loss = 0.0017686874

Training iteration loss = 0.0029417512

Training iteration loss = 0.0030233313

Training iteration loss = 0.003255384

Training iteration loss = 0.0028116452

Training iteration loss = 0.0032581643

Training iteration loss = 0.0028081767

Training iteration loss = 0.0017256383

Training iteration loss = 0.005630279

Training iteration loss = 0.0029310882

Training iteration loss = 0.0025590986

Training iteration loss = 0.0017699726

Training iteration loss = 0.003084422

Training iteration loss = 0.0035209127

Training iteration loss = 0.0035804736

Training iteration loss = 0.002245797

Training iteration loss = 0.0054641496

Training iteration loss = 0.0030203892

Training iteration loss = 0.0022539955

Training iteration loss = 0.0020636467

Training iteration loss = 0.0023829665

Training iteration loss = 0.0019412278

Training iteration loss = 0.0027704632

Training iteration loss = 0.0017528041

Training iteration loss = 0.0019765147

Training iteration loss = 0.003730025

Training iteration loss = 0.0026318964

Training iteration loss = 0.003231423

Training iteration loss = 0.0025213466

Training iteration loss = 0.0038723683

Training iteration loss = 0.004103102

Training iteration loss = 0.0039056314

Training iteration loss = 0.0019133346

Training iteration loss = 0.0027043473

Training iteration loss = 0.0023505334

Training iteration loss = 0.0036372945

Training iteration loss = 0.003222878

Training iteration loss = 0.0044250223

Training iteration loss = 0.0028194885

Training iteration loss = 0.0023005747

Training iteration loss = 0.0031860347

Training iteration loss = 0.0046508736

Training iteration loss = 0.0031318571

Training iteration loss = 0.0027620497

Training iteration loss = 0.0031964008

Training iteration loss = 0.0030835893

Training iteration loss = 0.0023878638

Training iteration loss = 0.0024025405

Training iteration loss = 0.003592816

Training iteration loss = 0.003012236

Training iteration loss = 0.003061894

Training iteration loss = 0.0028209744

Training iteration loss = 0.002190836

Training iteration loss = 0.004335237

Training iteration loss = 0.0038190011

Training iteration loss = 0.0038301467

Training iteration loss = 0.0033806516

Training iteration loss = 0.0021524937

Training iteration loss = 0.004541078

Training iteration loss = 0.005495528

Training iteration loss = 0.002218012

Training iteration loss = 0.0031302178

Training iteration loss = 0.0022831273

Training iteration loss = 0.0026330908

Training iteration loss = 0.0026042068

Training iteration loss = 0.0024609705

Training iteration loss = 0.0046862005

Training iteration loss = 0.005145171

Training iteration loss = 0.0023911672

Training iteration loss = 0.0028718577

Training iteration loss = 0.0021906567

Training iteration loss = 0.002478977

Training iteration loss = 0.003365983

Training iteration loss = 0.0031976579

Training iteration loss = 0.0035809083

Training iteration loss = 0.0022597003

Training iteration loss = 0.0034662348

Training iteration loss = 0.0069697425

Training iteration loss = 0.0044901506

Training iteration loss = 0.003574381

Training iteration loss = 0.002859596

Training iteration loss = 0.0033786537

Training iteration loss = 0.0026535017

Training iteration loss = 0.0032835025

Training iteration loss = 0.0020968749

Training iteration loss = 0.0025186616

Training iteration loss = 0.0025681949

Training iteration loss = 0.0023761091

Training iteration loss = 0.0019318621

Training iteration loss = 0.0045396597

Training iteration loss = 0.0032103749

Training iteration loss = 0.0052317977

Training iteration loss = 0.0033187598

Training iteration loss = 0.0031489397

Training iteration loss = 0.0031694397

Training iteration loss = 0.0061237365

Training iteration loss = 0.0037902659

Training iteration loss = 0.003368468

Training iteration loss = 0.0024598187

Training iteration loss = 0.004335948

Training iteration loss = 0.0020865388

Training iteration loss = 0.0024825195

Training iteration loss = 0.002863582

Training iteration loss = 0.0036444839

Training iteration loss = 0.0027854994

Training iteration loss = 0.0037324645

Training iteration loss = 0.0033670657

Training iteration loss = 0.0019419693

Training iteration loss = 0.002411029

Training iteration loss = 0.0018875203

Training iteration loss = 0.0024063282

Training iteration loss = 0.0019924298

Training iteration loss = 0.0024018928

Training iteration loss = 0.003291764

Training iteration loss = 0.0033153507

Training iteration loss = 0.004524308

Training iteration loss = 0.004052035

Training iteration loss = 0.0039162147

Training iteration loss = 0.002060542

Training iteration loss = 0.0029340966

Training iteration loss = 0.002154116

Training iteration loss = 0.006074205

Training iteration loss = 0.0034944334

Training iteration loss = 0.0029460348

Training iteration loss = 0.0027417855

Training iteration loss = 0.0035315019

Training iteration loss = 0.006791509

Training iteration loss = 0.002278492

Training iteration loss = 0.0034995116

Training iteration loss = 0.003567879

Training iteration loss = 0.0022768925

Training iteration loss = 0.003464083

Training iteration loss = 0.0036761353

Training iteration loss = 0.00259408

Training iteration loss = 0.0024830466

Training iteration loss = 0.0031292401

Training iteration loss = 0.003531305

Training iteration loss = 0.0035184317

Training iteration loss = 0.0042779264

Training iteration loss = 0.00465148

Training iteration loss = 0.0031557607

Training iteration loss = 0.0035061508

Training iteration loss = 0.004044199

Training iteration loss = 0.004231022

Training iteration loss = 0.0027267488

Training iteration loss = 0.0035262667

Training iteration loss = 0.003846174

Training iteration loss = 0.0024441273

Training iteration loss = 0.0021246027

Training iteration loss = 0.0035909389

Training iteration loss = 0.0023438428

Training iteration loss = 0.0019952408

Training iteration loss = 0.003056326

Training iteration loss = 0.0022478197

Training iteration loss = 0.0016870899

Training iteration loss = 0.0018364527

Training iteration loss = 0.0031829209

Training iteration loss = 0.001993281

Training iteration loss = 0.0022341742

Training iteration loss = 0.0037847825

Training iteration loss = 0.0049861516

Training iteration loss = 0.002482383

Training iteration loss = 0.002686974

Training iteration loss = 0.0023665978

Training iteration loss = 0.0024892983

Training iteration loss = 0.002217128

Training iteration loss = 0.0038927235

Training iteration loss = 0.0033036845

Training iteration loss = 0.0048663854

Training iteration loss = 0.0038089098

Training iteration loss = 0.0027314706

Training iteration loss = 0.0018881528

Training iteration loss = 0.0020589156

Training iteration loss = 0.007977736

Training iteration loss = 0.0028445746

Training iteration loss = 0.0016581531

Training iteration loss = 0.00414368

Training iteration loss = 0.0038256615

Training iteration loss = 0.003319758

Training iteration loss = 0.0028214215

Training iteration loss = 0.0038480957

Training iteration loss = 0.0021739316

Training iteration loss = 0.0062070726

Training iteration loss = 0.0025588525

Training iteration loss = 0.0033806814

Training iteration loss = 0.003791332

Training iteration loss = 0.0020697194

Training iteration loss = 0.0020409548

Training iteration loss = 0.0025595282

Training iteration loss = 0.0015870174

Training iteration loss = 0.003184552

Training iteration loss = 0.0031650392

Training iteration loss = 0.0040203417

Training iteration loss = 0.0030616906

Training iteration loss = 0.002735501

Training iteration loss = 0.0022910032

Training iteration loss = 0.002199456

Training iteration loss = 0.002327598

Training iteration loss = 0.003029309

Training iteration loss = 0.0044176946

Training iteration loss = 0.0017654469

Training iteration loss = 0.002938905

Training iteration loss = 0.0030226053

Training iteration loss = 0.003252643

Training iteration loss = 0.0028052514

Training iteration loss = 0.0032606432

Training iteration loss = 0.0028066149

Training iteration loss = 0.001723918

Training iteration loss = 0.005612536

Training iteration loss = 0.0029295913

Training iteration loss = 0.0025575536

Training iteration loss = 0.0017684327

Training iteration loss = 0.0030786006

Training iteration loss = 0.003522844

Training iteration loss = 0.0035718952

Training iteration loss = 0.0022515089

Training iteration loss = 0.005447484

Training iteration loss = 0.0030237231

Training iteration loss = 0.002262811

Training iteration loss = 0.0020644574

Training iteration loss = 0.0023811974

Training iteration loss = 0.0019375436

Training iteration loss = 0.0027673468

Training iteration loss = 0.0017536362

Training iteration loss = 0.0019695614

Training iteration loss = 0.0037187506

Training iteration loss = 0.0026252428

Training iteration loss = 0.0032234273

Training iteration loss = 0.002520407

Training iteration loss = 0.003873444

Training iteration loss = 0.004095108

Training iteration loss = 0.003902945

Training iteration loss = 0.0019106154

Training iteration loss = 0.0026999048

Training iteration loss = 0.0023407978

Training iteration loss = 0.0036256511

Training iteration loss = 0.0032198213

Training iteration loss = 0.0044194805

Training iteration loss = 0.002821962

Training iteration loss = 0.0023078988

Training iteration loss = 0.0031876087

Training iteration loss = 0.00464119

Training iteration loss = 0.0031362593

Training iteration loss = 0.00276459

Training iteration loss = 0.0031858124

Training iteration loss = 0.0030813543

Training iteration loss = 0.0023944841

Training iteration loss = 0.002396242

Training iteration loss = 0.0035989198

Training iteration loss = 0.003016508

Training iteration loss = 0.0030715012

Training iteration loss = 0.0028226543

Training iteration loss = 0.0021908844

Training iteration loss = 0.004341278

Training iteration loss = 0.0038108497

Training iteration loss = 0.0038255684

Training iteration loss = 0.0033767892

Training iteration loss = 0.002149544

Training iteration loss = 0.004530775

Training iteration loss = 0.005500987

Training iteration loss = 0.0022120562

Training iteration loss = 0.003120689

Training iteration loss = 0.0022812297

Training iteration loss = 0.0026394827

Training iteration loss = 0.0026035865

Training iteration loss = 0.0024631992

Training iteration loss = 0.0046777874

Training iteration loss = 0.005129146

Training iteration loss = 0.0023904801

Training iteration loss = 0.0028714754

Training iteration loss = 0.0021941995

Training iteration loss = 0.0024757842

Training iteration loss = 0.0033622414

Training iteration loss = 0.0031987217

Training iteration loss = 0.0035802182

Training iteration loss = 0.0022543909

Training iteration loss = 0.0034659666

Training iteration loss = 0.0069564246

Training iteration loss = 0.004485931

Training iteration loss = 0.0035709403

Training iteration loss = 0.0028606418

Training iteration loss = 0.0033761503

Training iteration loss = 0.002654446

Training iteration loss = 0.0032870378

Training iteration loss = 0.0020982365

Training iteration loss = 0.0025197354

Training iteration loss = 0.0025712892

Training iteration loss = 0.00237883

Training iteration loss = 0.0019313017

Training iteration loss = 0.0045404905

Training iteration loss = 0.0032043115

Training iteration loss = 0.005230192

Training iteration loss = 0.003328738

Training iteration loss = 0.0031519865

Training iteration loss = 0.0031509001

Training iteration loss = 0.0061190096

Training iteration loss = 0.0037954843

Training iteration loss = 0.0033691966

Training iteration loss = 0.002463821

Training iteration loss = 0.0043371157

Training iteration loss = 0.002084375

Training iteration loss = 0.0024901575

Training iteration loss = 0.002864268

Training iteration loss = 0.0036380498

Training iteration loss = 0.0027868703

Training iteration loss = 0.003730321

Training iteration loss = 0.0033721242

Training iteration loss = 0.0019498472

Training iteration loss = 0.0024141066

Training iteration loss = 0.0018929929

Training iteration loss = 0.0024219074

Training iteration loss = 0.002009815

Training iteration loss = 0.0024045606

Training iteration loss = 0.0032909473

Training iteration loss = 0.0033241666

Training iteration loss = 0.004532698

Training iteration loss = 0.004058141

Training iteration loss = 0.0039211367

Training iteration loss = 0.0020607866

Training iteration loss = 0.00292948

Training iteration loss = 0.0021507265

Training iteration loss = 0.0060706795

Training iteration loss = 0.0034814405

Training iteration loss = 0.0029473824

Training iteration loss = 0.002742505

Training iteration loss = 0.0035345608

Training iteration loss = 0.0067797625

Training iteration loss = 0.002277368

Training iteration loss = 0.0034884468

Training iteration loss = 0.0035689266

Training iteration loss = 0.0022745116

Training iteration loss = 0.0034662022

Training iteration loss = 0.0036686526

Training iteration loss = 0.002590105

Training iteration loss = 0.0024872925

Training iteration loss = 0.0031329505

Training iteration loss = 0.0035340537

Training iteration loss = 0.0035195022

Training iteration loss = 0.0042696795

Training iteration loss = 0.004655968

Training iteration loss = 0.0031552024

Training iteration loss = 0.0035048986

Training iteration loss = 0.0040407726

Training iteration loss = 0.004235671

Training iteration loss = 0.0027250855

Training iteration loss = 0.0035120165

Training iteration loss = 0.003844331

Training iteration loss = 0.0024392728

Training iteration loss = 0.0021275866

Training iteration loss = 0.003596196

Training iteration loss = 0.0023489601

Training iteration loss = 0.001993109

Training iteration loss = 0.0030484411

Training iteration loss = 0.00224518

Training iteration loss = 0.0016880481

Training iteration loss = 0.0018363221

Training iteration loss = 0.0031841758

Training iteration loss = 0.0019979894

Training iteration loss = 0.0022389116

Training iteration loss = 0.003776367

Training iteration loss = 0.004973156

Training iteration loss = 0.0024876993

Training iteration loss = 0.0026836793

Training iteration loss = 0.0023643721

Training iteration loss = 0.002480034

Training iteration loss = 0.0022233063

Training iteration loss = 0.0038940518

Training iteration loss = 0.003302645

Training iteration loss = 0.004869293

Training iteration loss = 0.0038093263

Training iteration loss = 0.0027274853

Training iteration loss = 0.0018846095

Training iteration loss = 0.0020560126

Training iteration loss = 0.007968245

Training iteration loss = 0.0028452713

Training iteration loss = 0.001644759

Single layer neural network training data error = 0.001644759

Single layer neural network test data error = 0.002885855
