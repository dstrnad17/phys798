Training iteration loss = 0.031281326

Training iteration loss = 0.01859282

Training iteration loss = 0.015579056

Training iteration loss = 0.014953315

Training iteration loss = 0.015062224

Training iteration loss = 0.010924825

Training iteration loss = 0.020799842

Training iteration loss = 0.01052063

Training iteration loss = 0.008888174

Training iteration loss = 0.006283906

Training iteration loss = 0.004639695

Training iteration loss = 0.005279113

Training iteration loss = 0.0054600146

Training iteration loss = 0.00627297

Training iteration loss = 0.0061891163

Training iteration loss = 0.007121475

Training iteration loss = 0.0067382082

Training iteration loss = 0.0061429883

Training iteration loss = 0.004967987

Training iteration loss = 0.004267891

Training iteration loss = 0.006390287

Training iteration loss = 0.0044443267

Training iteration loss = 0.005781944

Training iteration loss = 0.013043006

Training iteration loss = 0.0061165486

Training iteration loss = 0.0055043525

Training iteration loss = 0.0067377905

Training iteration loss = 0.008725107

Training iteration loss = 0.005587214

Training iteration loss = 0.006484814

Training iteration loss = 0.0051453817

Training iteration loss = 0.0036923501

Training iteration loss = 0.005403653

Training iteration loss = 0.0037408671

Training iteration loss = 0.00562329

Training iteration loss = 0.004990875

Training iteration loss = 0.008702446

Training iteration loss = 0.004512756

Training iteration loss = 0.0065850094

Training iteration loss = 0.007220392

Training iteration loss = 0.009438121

Training iteration loss = 0.007813398

Training iteration loss = 0.0065865996

Training iteration loss = 0.0034986646

Training iteration loss = 0.004192916

Training iteration loss = 0.0042253747

Training iteration loss = 0.005729362

Training iteration loss = 0.0032022665

Training iteration loss = 0.004133885

Training iteration loss = 0.003958438

Training iteration loss = 0.005350631

Training iteration loss = 0.004267008

Training iteration loss = 0.0055080843

Training iteration loss = 0.0074141673

Training iteration loss = 0.004414033

Training iteration loss = 0.009980595

Training iteration loss = 0.0068356865

Training iteration loss = 0.0067147403

Training iteration loss = 0.004605393

Training iteration loss = 0.007315781

Training iteration loss = 0.005759375

Training iteration loss = 0.00929678

Training iteration loss = 0.0067676487

Training iteration loss = 0.0059838896

Training iteration loss = 0.0033162106

Training iteration loss = 0.0065574516

Training iteration loss = 0.005535278

Training iteration loss = 0.007356312

Training iteration loss = 0.006662503

Training iteration loss = 0.006555158

Training iteration loss = 0.0058166045

Training iteration loss = 0.0100698685

Training iteration loss = 0.00426309

Training iteration loss = 0.0046589947

Training iteration loss = 0.0059480267

Training iteration loss = 0.0045731734

Training iteration loss = 0.004634097

Training iteration loss = 0.0075317994

Training iteration loss = 0.011822426

Training iteration loss = 0.0057378695

Training iteration loss = 0.0071057044

Training iteration loss = 0.0038562596

Training iteration loss = 0.007529323

Training iteration loss = 0.0141605195

Training iteration loss = 0.0058450606

Training iteration loss = 0.00690201

Training iteration loss = 0.0064325063

Training iteration loss = 0.008484122

Training iteration loss = 0.0047890185

Training iteration loss = 0.005296588

Training iteration loss = 0.00741091

Training iteration loss = 0.012229383

Training iteration loss = 0.0049010543

Training iteration loss = 0.005481545

Training iteration loss = 0.0045126877

Training iteration loss = 0.006794749

Training iteration loss = 0.0048848465

Training iteration loss = 0.0054168976

Training iteration loss = 0.0065558953

Training iteration loss = 0.0038880939

Training iteration loss = 0.008162622

Training iteration loss = 0.012003471

Training iteration loss = 0.0067642634

Training iteration loss = 0.005306108

Training iteration loss = 0.0047913375

Training iteration loss = 0.0074846814

Training iteration loss = 0.0054951366

Training iteration loss = 0.0065993094

Training iteration loss = 0.0036003548

Training iteration loss = 0.0041906806

Training iteration loss = 0.004433567

Training iteration loss = 0.007994885

Training iteration loss = 0.0050255936

Training iteration loss = 0.0058307033

Training iteration loss = 0.0054319054

Training iteration loss = 0.008084147

Training iteration loss = 0.0042183297

Training iteration loss = 0.007717802

Training iteration loss = 0.008221583

Training iteration loss = 0.01488782

Training iteration loss = 0.010577344

Training iteration loss = 0.006003172

Training iteration loss = 0.004710147

Training iteration loss = 0.010925381

Training iteration loss = 0.005260658

Training iteration loss = 0.0046706107

Training iteration loss = 0.0049363915

Training iteration loss = 0.0058284746

Training iteration loss = 0.005534161

Training iteration loss = 0.007787875

Training iteration loss = 0.004716897

Training iteration loss = 0.004096017

Training iteration loss = 0.006430885

Training iteration loss = 0.0033614375

Training iteration loss = 0.0056546195

Training iteration loss = 0.003466624

Training iteration loss = 0.004643799

Training iteration loss = 0.005212578

Training iteration loss = 0.00559479

Training iteration loss = 0.006687346

Training iteration loss = 0.005150342

Training iteration loss = 0.009725761

Training iteration loss = 0.0035206855

Training iteration loss = 0.007361359

Training iteration loss = 0.0026778847

Training iteration loss = 0.009707354

Training iteration loss = 0.01343596

Training iteration loss = 0.00384338

Training iteration loss = 0.0039948896

Training iteration loss = 0.0059343353

Training iteration loss = 0.014526235

Training iteration loss = 0.0075035873

Training iteration loss = 0.004390654

Training iteration loss = 0.004812085

Training iteration loss = 0.0048836474

Training iteration loss = 0.0041419086

Training iteration loss = 0.0040292633

Training iteration loss = 0.0044745323

Training iteration loss = 0.003914076

Training iteration loss = 0.0046947747

Training iteration loss = 0.007838635

Training iteration loss = 0.0058858446

Training iteration loss = 0.012487971

Training iteration loss = 0.0104682045

Training iteration loss = 0.0052641737

Training iteration loss = 0.005935351

Training iteration loss = 0.0083853565

Training iteration loss = 0.008170068

Training iteration loss = 0.0051388526

Training iteration loss = 0.008038395

Training iteration loss = 0.0068037356

Training iteration loss = 0.0069762673

Training iteration loss = 0.006978035

Training iteration loss = 0.0062946593

Training iteration loss = 0.00731978

Training iteration loss = 0.005394536

Training iteration loss = 0.005107037

Training iteration loss = 0.0033536018

Training iteration loss = 0.003218768

Training iteration loss = 0.0033521305

Training iteration loss = 0.0037227909

Training iteration loss = 0.003369597

Training iteration loss = 0.004261304

Training iteration loss = 0.006498555

Training iteration loss = 0.014750692

Training iteration loss = 0.003440487

Training iteration loss = 0.0053498903

Training iteration loss = 0.00418761

Training iteration loss = 0.0066597587

Training iteration loss = 0.004605841

Training iteration loss = 0.0055307164

Training iteration loss = 0.006416727

Training iteration loss = 0.0038674604

Training iteration loss = 0.008960295

Training iteration loss = 0.008351933

Training iteration loss = 0.0032885848

Training iteration loss = 0.0041716276

Training iteration loss = 0.0091433395

Training iteration loss = 0.009670981

Training iteration loss = 0.0050760936

Training iteration loss = 0.009620437

Training iteration loss = 0.0039870967

Training iteration loss = 0.005180816

Training iteration loss = 0.004302751

Training iteration loss = 0.005608229

Training iteration loss = 0.0041173813

Training iteration loss = 0.011404019

Training iteration loss = 0.0055087754

Training iteration loss = 0.005493195

Training iteration loss = 0.0052466374

Training iteration loss = 0.003077633

Training iteration loss = 0.0044265636

Training iteration loss = 0.004173396

Training iteration loss = 0.00509756

Training iteration loss = 0.0046402654

Training iteration loss = 0.006342683

Training iteration loss = 0.0051759155

Training iteration loss = 0.0053061536

Training iteration loss = 0.0034194577

Training iteration loss = 0.002660878

Training iteration loss = 0.004822827

Training iteration loss = 0.0030769554

Training iteration loss = 0.0040657376

Training iteration loss = 0.011099696

Training iteration loss = 0.004361202

Training iteration loss = 0.0037120054

Training iteration loss = 0.004963174

Training iteration loss = 0.0074952715

Training iteration loss = 0.004316404

Training iteration loss = 0.0051717423

Training iteration loss = 0.0045520207

Training iteration loss = 0.003030447

Training iteration loss = 0.0047199707

Training iteration loss = 0.002811489

Training iteration loss = 0.004590088

Training iteration loss = 0.004104914

Training iteration loss = 0.007920224

Training iteration loss = 0.004000367

Training iteration loss = 0.005441787

Training iteration loss = 0.0062668035

Training iteration loss = 0.008689891

Training iteration loss = 0.0069025666

Training iteration loss = 0.005670332

Training iteration loss = 0.002933784

Training iteration loss = 0.0037018757

Training iteration loss = 0.0035608858

Training iteration loss = 0.0048987484

Training iteration loss = 0.002567926

Training iteration loss = 0.003372462

Training iteration loss = 0.0033042158

Training iteration loss = 0.0047046645

Training iteration loss = 0.003865478

Training iteration loss = 0.0045347596

Training iteration loss = 0.0063040564

Training iteration loss = 0.0039510205

Training iteration loss = 0.009056019

Training iteration loss = 0.0061319475

Training iteration loss = 0.0059250845

Training iteration loss = 0.0038574582

Training iteration loss = 0.0064720353

Training iteration loss = 0.0051555154

Training iteration loss = 0.008696091

Training iteration loss = 0.0060186

Training iteration loss = 0.005244649

Training iteration loss = 0.0027265511

Training iteration loss = 0.0059669726

Training iteration loss = 0.004743446

Training iteration loss = 0.006403208

Training iteration loss = 0.0057460843

Training iteration loss = 0.0056355256

Training iteration loss = 0.0047838576

Training iteration loss = 0.009305057

Training iteration loss = 0.0036311087

Training iteration loss = 0.0038334564

Training iteration loss = 0.005183073

Training iteration loss = 0.003753881

Training iteration loss = 0.004036407

Training iteration loss = 0.0071193455

Training iteration loss = 0.011011684

Training iteration loss = 0.005066056

Training iteration loss = 0.006345786

Training iteration loss = 0.0033874763

Training iteration loss = 0.006675592

Training iteration loss = 0.013088211

Training iteration loss = 0.0052106013

Training iteration loss = 0.006240476

Training iteration loss = 0.0057389904

Training iteration loss = 0.007455964

Training iteration loss = 0.004192669

Training iteration loss = 0.0045460616

Training iteration loss = 0.0066582877

Training iteration loss = 0.011439942

Training iteration loss = 0.004254236

Training iteration loss = 0.004782145

Training iteration loss = 0.0037524628

Training iteration loss = 0.005837264

Training iteration loss = 0.0043892306

Training iteration loss = 0.00464746

Training iteration loss = 0.0056625484

Training iteration loss = 0.0031701387

Training iteration loss = 0.0072451644

Training iteration loss = 0.011129635

Training iteration loss = 0.006115809

Training iteration loss = 0.0045689563

Training iteration loss = 0.0039616274

Training iteration loss = 0.0068404037

Training iteration loss = 0.00466502

Training iteration loss = 0.0059241364

Training iteration loss = 0.0028686083

Training iteration loss = 0.0036957199

Training iteration loss = 0.00379507

Training iteration loss = 0.007053307

Training iteration loss = 0.0043381234

Training iteration loss = 0.0049726237

Training iteration loss = 0.0047003906

Training iteration loss = 0.0077094217

Training iteration loss = 0.0037749228

Training iteration loss = 0.006919954

Training iteration loss = 0.0071878554

Training iteration loss = 0.014057539

Training iteration loss = 0.009870402

Training iteration loss = 0.0054897983

Training iteration loss = 0.004146891

Training iteration loss = 0.009844423

Training iteration loss = 0.004427123

Training iteration loss = 0.0041209217

Training iteration loss = 0.004648679

Training iteration loss = 0.0055480916

Training iteration loss = 0.0047294726

Training iteration loss = 0.007118973

Training iteration loss = 0.0042565013

Training iteration loss = 0.0037565415

Training iteration loss = 0.0061541363

Training iteration loss = 0.0030273367

Training iteration loss = 0.0047781817

Training iteration loss = 0.0027873015

Training iteration loss = 0.0041492507

Training iteration loss = 0.004820817

Training iteration loss = 0.005194071

Training iteration loss = 0.0062616398

Training iteration loss = 0.0043959157

Training iteration loss = 0.008972336

Training iteration loss = 0.0030374965

Training iteration loss = 0.0063998504

Training iteration loss = 0.002035288

Training iteration loss = 0.008926239

Training iteration loss = 0.012442894

Training iteration loss = 0.0033857883

Training iteration loss = 0.0032008397

Training iteration loss = 0.004952624

Training iteration loss = 0.0134471925

Training iteration loss = 0.006582989

Training iteration loss = 0.0038848987

Training iteration loss = 0.004195476

Training iteration loss = 0.0043805433

Training iteration loss = 0.0033135307

Training iteration loss = 0.003469879

Training iteration loss = 0.0037719633

Training iteration loss = 0.0033256705

Training iteration loss = 0.0040616477

Training iteration loss = 0.006921932

Training iteration loss = 0.005428492

Training iteration loss = 0.011535678

Training iteration loss = 0.009724755

Training iteration loss = 0.004796496

Training iteration loss = 0.005192531

Training iteration loss = 0.007557871

Training iteration loss = 0.007496242

Training iteration loss = 0.0045075333

Training iteration loss = 0.007124252

Training iteration loss = 0.006339219

Training iteration loss = 0.0062621897

Training iteration loss = 0.006214021

Training iteration loss = 0.0055327606

Training iteration loss = 0.0065660696

Training iteration loss = 0.0050188787

Training iteration loss = 0.0046103643

Training iteration loss = 0.0028371327

Training iteration loss = 0.0027330848

Training iteration loss = 0.0027979666

Training iteration loss = 0.0031853549

Training iteration loss = 0.0029479936

Training iteration loss = 0.0038182552

Training iteration loss = 0.0061889775

Training iteration loss = 0.013988301

Training iteration loss = 0.0030038152

Training iteration loss = 0.004797299

Training iteration loss = 0.0035496054

Training iteration loss = 0.006043128

Training iteration loss = 0.0039495397

Training iteration loss = 0.004938336

Training iteration loss = 0.0059103174

Training iteration loss = 0.003393397

Training iteration loss = 0.00822855

Training iteration loss = 0.0078041963

Training iteration loss = 0.0027258832

Training iteration loss = 0.0037397214

Training iteration loss = 0.008786877

Training iteration loss = 0.008889159

Training iteration loss = 0.004198788

Training iteration loss = 0.00884613

Training iteration loss = 0.0033376066

Training iteration loss = 0.004369146

Training iteration loss = 0.0036951064

Training iteration loss = 0.00492568

Training iteration loss = 0.0035983701

Training iteration loss = 0.010589633

Training iteration loss = 0.0048471885

Training iteration loss = 0.004838557

Training iteration loss = 0.0046692686

Training iteration loss = 0.0025752215

Training iteration loss = 0.0040271375

Training iteration loss = 0.003543892

Training iteration loss = 0.004399212

Training iteration loss = 0.004199919

Training iteration loss = 0.005734153

Training iteration loss = 0.0047064372

Training iteration loss = 0.004661488

Training iteration loss = 0.003030146

Training iteration loss = 0.0022209391

Training iteration loss = 0.0043562097

Training iteration loss = 0.002667667

Training iteration loss = 0.0035279286

Training iteration loss = 0.010268233

Training iteration loss = 0.003640412

Training iteration loss = 0.0031271023

Training iteration loss = 0.004206486

Training iteration loss = 0.006692263

Training iteration loss = 0.0038660297

Training iteration loss = 0.004690341

Training iteration loss = 0.00410213

Training iteration loss = 0.0026408192

Training iteration loss = 0.004117056

Training iteration loss = 0.0022190728

Training iteration loss = 0.003990615

Training iteration loss = 0.0034867884

Training iteration loss = 0.007486117

Training iteration loss = 0.0034744402

Training iteration loss = 0.004759132

Training iteration loss = 0.0052880687

Training iteration loss = 0.008098457

Training iteration loss = 0.006109944

Training iteration loss = 0.005034113

Training iteration loss = 0.0024310711

Training iteration loss = 0.0032575133

Training iteration loss = 0.0030560675

Training iteration loss = 0.0044955844

Training iteration loss = 0.002244311

Training iteration loss = 0.0027585395

Training iteration loss = 0.002839999

Training iteration loss = 0.0042585833

Training iteration loss = 0.0035776885

Training iteration loss = 0.0039676577

Training iteration loss = 0.005495903

Training iteration loss = 0.0035112093

Training iteration loss = 0.008210432

Training iteration loss = 0.0054379385

Training iteration loss = 0.00515775

Training iteration loss = 0.0033003127

Training iteration loss = 0.0058025005

Training iteration loss = 0.0048088827

Training iteration loss = 0.008284453

Training iteration loss = 0.0053142603

Training iteration loss = 0.00457605

Training iteration loss = 0.002392436

Training iteration loss = 0.0055052065

Training iteration loss = 0.0041238214

Training iteration loss = 0.0056917383

Training iteration loss = 0.0050384197

Training iteration loss = 0.00480415

Training iteration loss = 0.0040419535

Training iteration loss = 0.008651022

Training iteration loss = 0.0031655051

Training iteration loss = 0.0032340533

Training iteration loss = 0.004598588

Training iteration loss = 0.0031959964

Training iteration loss = 0.0036866553

Training iteration loss = 0.0067332285

Training iteration loss = 0.010110753

Training iteration loss = 0.004593532

Training iteration loss = 0.0057435967

Training iteration loss = 0.002975991

Training iteration loss = 0.0062064384

Training iteration loss = 0.012143858

Training iteration loss = 0.0047447933

Training iteration loss = 0.005678663

Training iteration loss = 0.0052114944

Training iteration loss = 0.006485313

Training iteration loss = 0.0036596113

Training iteration loss = 0.0040271115

Training iteration loss = 0.0060458686

Training iteration loss = 0.010644153

Training iteration loss = 0.0038223148

Training iteration loss = 0.0041591143

Training iteration loss = 0.0031164424

Training iteration loss = 0.0050979825

Training iteration loss = 0.003919954

Training iteration loss = 0.004001597

Training iteration loss = 0.004989831

Training iteration loss = 0.0026830148

Training iteration loss = 0.006497113

Training iteration loss = 0.010397927

Training iteration loss = 0.0055784294

Training iteration loss = 0.00408328

Training iteration loss = 0.0032978677

Training iteration loss = 0.0062192623

Training iteration loss = 0.0040186234

Training iteration loss = 0.005401649

Training iteration loss = 0.0023693042

Training iteration loss = 0.0032675224

Training iteration loss = 0.0033143994

Training iteration loss = 0.006280716

Training iteration loss = 0.0039042463

Training iteration loss = 0.0043247025

Training iteration loss = 0.0040437696

Training iteration loss = 0.007304147

Training iteration loss = 0.003367221

Training iteration loss = 0.006191763

Training iteration loss = 0.0063982466

Training iteration loss = 0.013384984

Training iteration loss = 0.009181075

Training iteration loss = 0.0049443603

Training iteration loss = 0.0036036791

Training iteration loss = 0.008876177

Training iteration loss = 0.0037620785

Training iteration loss = 0.003783142

Training iteration loss = 0.0042489464

Training iteration loss = 0.0050185807

Training iteration loss = 0.0041421987

Training iteration loss = 0.006651821

Training iteration loss = 0.004177253

Training iteration loss = 0.003597979

Training iteration loss = 0.005789407

Training iteration loss = 0.0025811105

Training iteration loss = 0.0038869183

Training iteration loss = 0.0025104834

Training iteration loss = 0.0038510414

Training iteration loss = 0.004543538

Training iteration loss = 0.004601675

Training iteration loss = 0.0055925176

Training iteration loss = 0.003939513

Training iteration loss = 0.008661604

Training iteration loss = 0.0029336102

Training iteration loss = 0.0057387464

Training iteration loss = 0.0017796353

Training iteration loss = 0.008216377

Training iteration loss = 0.011354903

Training iteration loss = 0.0032420643

Training iteration loss = 0.0027352488

Training iteration loss = 0.004337128

Training iteration loss = 0.012541877

Training iteration loss = 0.005931028

Training iteration loss = 0.0033572842

Training iteration loss = 0.0037721596

Training iteration loss = 0.0040145363

Training iteration loss = 0.0028156806

Training iteration loss = 0.0031141865

Training iteration loss = 0.0032363855

Training iteration loss = 0.0028716426

Training iteration loss = 0.0036343616

Training iteration loss = 0.006213521

Training iteration loss = 0.0050515444

Training iteration loss = 0.010745158

Training iteration loss = 0.008915097

Training iteration loss = 0.004383835

Training iteration loss = 0.0045281197

Training iteration loss = 0.007029888

Training iteration loss = 0.0069939373

Training iteration loss = 0.004119546

Training iteration loss = 0.006307509

Training iteration loss = 0.006063656

Training iteration loss = 0.005529473

Training iteration loss = 0.005535055

Training iteration loss = 0.004887529

Training iteration loss = 0.0059919907

Training iteration loss = 0.004482299

Training iteration loss = 0.004159405

Training iteration loss = 0.0024881193

Training iteration loss = 0.0024433054

Training iteration loss = 0.0024804578

Training iteration loss = 0.0026909183

Training iteration loss = 0.002403041

Training iteration loss = 0.003405511

Training iteration loss = 0.0060228813

Training iteration loss = 0.013293215

Training iteration loss = 0.0026926915

Training iteration loss = 0.0044244053

Training iteration loss = 0.0030954517

Training iteration loss = 0.0057019438

Training iteration loss = 0.0035074851

Training iteration loss = 0.0044139596

Training iteration loss = 0.005521695

Training iteration loss = 0.0030810637

Training iteration loss = 0.0075002084

Training iteration loss = 0.0074739708

Training iteration loss = 0.0023901062

Training iteration loss = 0.0033528435

Training iteration loss = 0.008482524

Training iteration loss = 0.008198062

Training iteration loss = 0.0036344596

Training iteration loss = 0.008307168

Training iteration loss = 0.002738588

Training iteration loss = 0.0037801086

Training iteration loss = 0.003264889

Training iteration loss = 0.004397054

Training iteration loss = 0.0032678521

Training iteration loss = 0.009698903

Training iteration loss = 0.004401252

Training iteration loss = 0.0043904753

Training iteration loss = 0.0041594305

Training iteration loss = 0.002253022

Training iteration loss = 0.0037334757

Training iteration loss = 0.0030961216

Training iteration loss = 0.0040106373

Training iteration loss = 0.0038594664

Training iteration loss = 0.0052510235

Training iteration loss = 0.0044737067

Training iteration loss = 0.004199849

Training iteration loss = 0.0027481525

Training iteration loss = 0.0019275903

Training iteration loss = 0.003990822

Training iteration loss = 0.0024728142

Training iteration loss = 0.003161572

Training iteration loss = 0.009707907

Training iteration loss = 0.0030978946

Training iteration loss = 0.0027044802

Training iteration loss = 0.00362242

Training iteration loss = 0.0061315307

Training iteration loss = 0.0036065953

Training iteration loss = 0.004330506

Training iteration loss = 0.0037781363

Training iteration loss = 0.0023549297

Training iteration loss = 0.003710366

Training iteration loss = 0.0018549456

Training iteration loss = 0.0035319354

Training iteration loss = 0.0030851397

Training iteration loss = 0.0072307787

Training iteration loss = 0.0031380402

Training iteration loss = 0.004281486

Training iteration loss = 0.0045467135

Training iteration loss = 0.0076444233

Training iteration loss = 0.005435636

Training iteration loss = 0.0045712152

Training iteration loss = 0.002059654

Training iteration loss = 0.0029711914

Training iteration loss = 0.0026865131

Training iteration loss = 0.004265722

Training iteration loss = 0.0020492158

Training iteration loss = 0.0022968955

Training iteration loss = 0.0025599406

Training iteration loss = 0.0039559305

Training iteration loss = 0.0034264198

Training iteration loss = 0.0035934749

Training iteration loss = 0.0049281153

Training iteration loss = 0.003145757

Training iteration loss = 0.0074832905

Training iteration loss = 0.0048766825

Training iteration loss = 0.0045342557

Training iteration loss = 0.0029841822

Training iteration loss = 0.0052815815

Training iteration loss = 0.0045784474

Training iteration loss = 0.007999886

Training iteration loss = 0.004772549

Training iteration loss = 0.00414144

Training iteration loss = 0.0021470773

Training iteration loss = 0.0052277767

Training iteration loss = 0.003647175

Training iteration loss = 0.0052287793

Training iteration loss = 0.004535411

Training iteration loss = 0.0042561647

Training iteration loss = 0.003541342

Training iteration loss = 0.008124726

Training iteration loss = 0.0028894846

Training iteration loss = 0.0028068984

Training iteration loss = 0.004226724

Training iteration loss = 0.0028523672

Training iteration loss = 0.0034243206

Training iteration loss = 0.0065473104

Training iteration loss = 0.009402475

Training iteration loss = 0.0042522717

Training iteration loss = 0.005331058

Training iteration loss = 0.0027214214

Training iteration loss = 0.0058650756

Training iteration loss = 0.011364489

Training iteration loss = 0.0045160665

Training iteration loss = 0.0052499147

Training iteration loss = 0.0048568677

Training iteration loss = 0.005667682

Training iteration loss = 0.0032922756

Training iteration loss = 0.0036324281

Training iteration loss = 0.005533358

Training iteration loss = 0.00998898

Training iteration loss = 0.0035936194

Training iteration loss = 0.0036094466

Training iteration loss = 0.0027141273

Training iteration loss = 0.004591631

Training iteration loss = 0.00356228

Training iteration loss = 0.0035647014

Training iteration loss = 0.0045392136

Training iteration loss = 0.0024158473

Training iteration loss = 0.0059629665

Training iteration loss = 0.009784486

Training iteration loss = 0.0052531646

Training iteration loss = 0.0037461151

Training iteration loss = 0.0028169823

Training iteration loss = 0.0055990107

Training iteration loss = 0.0036361031

Training iteration loss = 0.0050232215

Training iteration loss = 0.002139486

Training iteration loss = 0.0029266742

Training iteration loss = 0.0030005942

Training iteration loss = 0.005726057

Training iteration loss = 0.0037070333

Training iteration loss = 0.0038240314

Training iteration loss = 0.0034780195

Training iteration loss = 0.006913606

Training iteration loss = 0.0030206353

Training iteration loss = 0.0057302676

Training iteration loss = 0.0058056843

Training iteration loss = 0.012776156

Training iteration loss = 0.0085404925

Training iteration loss = 0.004466816

Training iteration loss = 0.0032405823

Training iteration loss = 0.008202015

Training iteration loss = 0.0033540193

Training iteration loss = 0.0035505777

Training iteration loss = 0.003909393

Training iteration loss = 0.004454085

Training iteration loss = 0.0037167817

Training iteration loss = 0.006310433

Training iteration loss = 0.004160789

Training iteration loss = 0.0035039263

Training iteration loss = 0.005442876

Training iteration loss = 0.002265454

Training iteration loss = 0.0033108923

Training iteration loss = 0.0025046847

Training iteration loss = 0.0035922984

Training iteration loss = 0.0042768577

Training iteration loss = 0.003980544

Training iteration loss = 0.005065947

Training iteration loss = 0.0037417328

Training iteration loss = 0.008472241

Training iteration loss = 0.0029062217

Training iteration loss = 0.00516639

Training iteration loss = 0.0017009694

Training iteration loss = 0.007727611

Training iteration loss = 0.010582632

Training iteration loss = 0.0031179814

Training iteration loss = 0.002421511

Training iteration loss = 0.0038638762

Training iteration loss = 0.011798668

Training iteration loss = 0.005596079

Training iteration loss = 0.003028964

Training iteration loss = 0.0035573323

Training iteration loss = 0.003618931

Training iteration loss = 0.002424031

Training iteration loss = 0.0029056047

Training iteration loss = 0.0028951357

Training iteration loss = 0.0026637232

Training iteration loss = 0.00331726

Training iteration loss = 0.0058514588

Training iteration loss = 0.004700635

Training iteration loss = 0.01013582

Training iteration loss = 0.008180964

Training iteration loss = 0.0041385763

Training iteration loss = 0.004142021

Training iteration loss = 0.0065398514

Training iteration loss = 0.0065763174

Training iteration loss = 0.0038794177

Training iteration loss = 0.005647233

Training iteration loss = 0.0058115176

Training iteration loss = 0.004997317

Training iteration loss = 0.005098323

Training iteration loss = 0.0043985434

Training iteration loss = 0.00558135

Training iteration loss = 0.00409862

Training iteration loss = 0.0039010742

Training iteration loss = 0.0023571101

Training iteration loss = 0.0022566027

Training iteration loss = 0.0022891278

Training iteration loss = 0.0023289728

Training iteration loss = 0.0021219146

Training iteration loss = 0.0031735813

Training iteration loss = 0.005805345

Training iteration loss = 0.012632014

Training iteration loss = 0.0025075928

Training iteration loss = 0.0042585917

Training iteration loss = 0.002808242

Training iteration loss = 0.0054583712

Training iteration loss = 0.0032871084

Training iteration loss = 0.004010889

Training iteration loss = 0.005255444

Training iteration loss = 0.0028803977

Training iteration loss = 0.0069895387

Training iteration loss = 0.0072044153

Training iteration loss = 0.0022327763

Training iteration loss = 0.0030364592

Training iteration loss = 0.008208023

Training iteration loss = 0.0076220324

Training iteration loss = 0.0031625368

Training iteration loss = 0.007842269

Training iteration loss = 0.0023918813

Training iteration loss = 0.0033904011

Training iteration loss = 0.002985899

Training iteration loss = 0.00404794

Training iteration loss = 0.0030425317

Training iteration loss = 0.009059408

Training iteration loss = 0.0041358355

Training iteration loss = 0.00409131

Training iteration loss = 0.0037235557

Training iteration loss = 0.0021119653

Training iteration loss = 0.0035341554

Training iteration loss = 0.0028108133

Training iteration loss = 0.0037765014

Training iteration loss = 0.0036056968

Training iteration loss = 0.004913389

Training iteration loss = 0.004375475

Training iteration loss = 0.003968318

Training iteration loss = 0.002519372

Training iteration loss = 0.0017466955

Training iteration loss = 0.0037343507

Training iteration loss = 0.0024383005

Training iteration loss = 0.0029382766

Training iteration loss = 0.009287052

Training iteration loss = 0.0026868607

Training iteration loss = 0.002429578

Training iteration loss = 0.0032372843

Training iteration loss = 0.0057990435

Training iteration loss = 0.0034586708

Training iteration loss = 0.0040015243

Training iteration loss = 0.0035355543

Training iteration loss = 0.002178628

Training iteration loss = 0.003491211

Training iteration loss = 0.0016740828

Training iteration loss = 0.0031949396

Training iteration loss = 0.002833297

Training iteration loss = 0.007129409

Training iteration loss = 0.0029871128

Training iteration loss = 0.0039837286

Training iteration loss = 0.004050576

Training iteration loss = 0.0073128655

Training iteration loss = 0.0049437513

Training iteration loss = 0.004291804

Training iteration loss = 0.001816757

Training iteration loss = 0.0028306588

Training iteration loss = 0.0024121879

Training iteration loss = 0.004161258

Training iteration loss = 0.0019354278

Training iteration loss = 0.0019975281

Training iteration loss = 0.0024211432

Training iteration loss = 0.0037718979

Training iteration loss = 0.0033560928

Training iteration loss = 0.0033756788

Training iteration loss = 0.0045731384

Training iteration loss = 0.0028880031

Training iteration loss = 0.006923153

Training iteration loss = 0.0044693886

Training iteration loss = 0.0040627276

Training iteration loss = 0.0028222862

Training iteration loss = 0.004897344

Training iteration loss = 0.004440205

Training iteration loss = 0.007854185

Training iteration loss = 0.004428941

Training iteration loss = 0.0038758384

Training iteration loss = 0.0019698143

Training iteration loss = 0.0050855274

Training iteration loss = 0.0033409395

Training iteration loss = 0.004957121

Training iteration loss = 0.0042183865

Training iteration loss = 0.003967325

Training iteration loss = 0.003230142

Training iteration loss = 0.007744757

Training iteration loss = 0.0027503546

Training iteration loss = 0.0025313275

Training iteration loss = 0.0040510073

Training iteration loss = 0.002668453

Training iteration loss = 0.0032432512

Training iteration loss = 0.0064790603

Training iteration loss = 0.008850397

Training iteration loss = 0.0040496634

Training iteration loss = 0.0051034554

Training iteration loss = 0.00258156

Training iteration loss = 0.0056585865

Training iteration loss = 0.0108113885

Training iteration loss = 0.0044207443

Training iteration loss = 0.0049551493

Training iteration loss = 0.0046493714

Training iteration loss = 0.0050626495

Training iteration loss = 0.0030691694

Training iteration loss = 0.0033557094

Training iteration loss = 0.0051693004

Training iteration loss = 0.009488116

Training iteration loss = 0.0035125632

Training iteration loss = 0.0031932048

Training iteration loss = 0.0024788408

Training iteration loss = 0.0043472615

Training iteration loss = 0.0033330282

Training iteration loss = 0.003293158

Training iteration loss = 0.004290577

Training iteration loss = 0.0023148311

Training iteration loss = 0.0055867154

Training iteration loss = 0.009339784

Training iteration loss = 0.0050706146

Training iteration loss = 0.0035520946

Training iteration loss = 0.0025252807

Training iteration loss = 0.005088242

Training iteration loss = 0.0034560487

Training iteration loss = 0.0047982456

Training iteration loss = 0.0021079737

Training iteration loss = 0.0027496344

Training iteration loss = 0.0028411956

Training iteration loss = 0.005400342

Training iteration loss = 0.003675523

Training iteration loss = 0.0034699247

Training iteration loss = 0.0030627542

Training iteration loss = 0.006636249

Training iteration loss = 0.0027856496

Training iteration loss = 0.0054784864

Training iteration loss = 0.005389573

Training iteration loss = 0.012279934

Training iteration loss = 0.008054141

Training iteration loss = 0.004151997

Training iteration loss = 0.0030732304

Training iteration loss = 0.007801162

Training iteration loss = 0.0031503718

Training iteration loss = 0.0034067472

Training iteration loss = 0.003711881

Training iteration loss = 0.0039996672

Training iteration loss = 0.0034376266

Training iteration loss = 0.0060766786

Training iteration loss = 0.0041374858

Training iteration loss = 0.003469618

Training iteration loss = 0.005222802

Training iteration loss = 0.002114522

Training iteration loss = 0.0030314522

Training iteration loss = 0.0026023989

Training iteration loss = 0.0033916943

Training iteration loss = 0.0041036773

Training iteration loss = 0.0035099294

Training iteration loss = 0.0047562453

Training iteration loss = 0.0036695865

Training iteration loss = 0.008307549

Training iteration loss = 0.0029008638

Training iteration loss = 0.004756188

Training iteration loss = 0.00177078

Training iteration loss = 0.0074421586

Training iteration loss = 0.010088441

Training iteration loss = 0.0029481172

Training iteration loss = 0.0022252216

Training iteration loss = 0.0035351682

Training iteration loss = 0.011280513

Training iteration loss = 0.005452142

Training iteration loss = 0.0028298288

Training iteration loss = 0.0034633204

Training iteration loss = 0.003304413

Training iteration loss = 0.0021888104

Training iteration loss = 0.0028438002

Training iteration loss = 0.002712001

Training iteration loss = 0.0025787824

Training iteration loss = 0.0030750392

Training iteration loss = 0.005712741

Training iteration loss = 0.004495685

Training iteration loss = 0.009737966

Training iteration loss = 0.007639793

Training iteration loss = 0.0040264535

Training iteration loss = 0.0039479486

Training iteration loss = 0.0061755846

Training iteration loss = 0.0063128117

Training iteration loss = 0.003774371

Training iteration loss = 0.0052061332

Training iteration loss = 0.0055786544

Training iteration loss = 0.0046439767

Training iteration loss = 0.0048495084

Training iteration loss = 0.0041203545

Training iteration loss = 0.0053038807

Training iteration loss = 0.0038990474

Training iteration loss = 0.003761541

Training iteration loss = 0.0023392162

Training iteration loss = 0.0022070175

Training iteration loss = 0.0022121253

Training iteration loss = 0.0021679061

Training iteration loss = 0.0020697718

Training iteration loss = 0.0030897246

Training iteration loss = 0.005625509

Training iteration loss = 0.012154979

Training iteration loss = 0.0024481844

Training iteration loss = 0.0042431387

Training iteration loss = 0.0026646429

Training iteration loss = 0.0052847727

Training iteration loss = 0.0032220825

Training iteration loss = 0.0037803827

Training iteration loss = 0.0051229456

Training iteration loss = 0.0027936504

Training iteration loss = 0.0067013507

Training iteration loss = 0.007020445

Training iteration loss = 0.0022144432

Training iteration loss = 0.0028506978

Training iteration loss = 0.0080426

Training iteration loss = 0.0072135488

Training iteration loss = 0.0028617883

Training iteration loss = 0.00751922

Training iteration loss = 0.0022162986

Training iteration loss = 0.0031763148

Training iteration loss = 0.0028317636

Training iteration loss = 0.0038530522

Training iteration loss = 0.002927305

Training iteration loss = 0.008636762

Training iteration loss = 0.004030317

Training iteration loss = 0.0039393515

Training iteration loss = 0.003450055

Training iteration loss = 0.0020897042

Training iteration loss = 0.0034507257

Training iteration loss = 0.0026685589

Training iteration loss = 0.0036803207

Training iteration loss = 0.0034463739

Training iteration loss = 0.0047257454

Training iteration loss = 0.0043410454

Training iteration loss = 0.0038998756

Training iteration loss = 0.0024022893

Training iteration loss = 0.0017102011

Training iteration loss = 0.0036253822

Training iteration loss = 0.0024698055

Training iteration loss = 0.0028296905

Training iteration loss = 0.009025599

Training iteration loss = 0.0024350076

Training iteration loss = 0.0023093321

Training iteration loss = 0.0030385323

Training iteration loss = 0.0056221196

Training iteration loss = 0.0033957916

Training iteration loss = 0.0037850062

Training iteration loss = 0.0034176884

Training iteration loss = 0.0021202194

Training iteration loss = 0.0033845322

Training iteration loss = 0.0016044499

Training iteration loss = 0.0029881254

Training iteration loss = 0.0027076479

Training iteration loss = 0.0071173566

Training iteration loss = 0.0029650067

Training iteration loss = 0.0038175937

Training iteration loss = 0.0037613676

Training iteration loss = 0.0071242074

Training iteration loss = 0.004667727

Training iteration loss = 0.004163192

Training iteration loss = 0.0016924037

Training iteration loss = 0.0027913898

Training iteration loss = 0.0022443952

Training iteration loss = 0.0041494262

Training iteration loss = 0.0019030196

Training iteration loss = 0.0018504383

Training iteration loss = 0.0023834917

Training iteration loss = 0.0036972936

Training iteration loss = 0.0033501445

Training iteration loss = 0.003279962

Training iteration loss = 0.0043771095

Training iteration loss = 0.0027483974

Training iteration loss = 0.0065560816

Training iteration loss = 0.004212179

Training iteration loss = 0.0037531834

Training iteration loss = 0.0027761047

Training iteration loss = 0.004658072

Training iteration loss = 0.0043934723

Training iteration loss = 0.0078191925

Training iteration loss = 0.004250838

Training iteration loss = 0.0037233378

Training iteration loss = 0.001891952

Training iteration loss = 0.005049679

Training iteration loss = 0.003191889

Training iteration loss = 0.0048130765

Training iteration loss = 0.00405425

Training iteration loss = 0.0038541607

Training iteration loss = 0.003072298

Training iteration loss = 0.007512327

Training iteration loss = 0.0027054127

Training iteration loss = 0.0023876717

Training iteration loss = 0.0040088766

Training iteration loss = 0.002598205

Training iteration loss = 0.0031515053

Training iteration loss = 0.006478598

Training iteration loss = 0.008481816

Training iteration loss = 0.0039544576

Training iteration loss = 0.005009223

Training iteration loss = 0.002523019

Training iteration loss = 0.005557181

Training iteration loss = 0.010470519

Training iteration loss = 0.004408164

Training iteration loss = 0.0048124935

Training iteration loss = 0.004560136

Training iteration loss = 0.004676357

Training iteration loss = 0.0029502253

Training iteration loss = 0.0032052095

Training iteration loss = 0.0049652965

Training iteration loss = 0.009183114

Training iteration loss = 0.0035239137

Training iteration loss = 0.002941655

Training iteration loss = 0.0023636073

Training iteration loss = 0.0042854794

Training iteration loss = 0.0032272313

Training iteration loss = 0.0031665624

Training iteration loss = 0.0041704387

Training iteration loss = 0.002313111

Training iteration loss = 0.0053545283

Training iteration loss = 0.009078654

Training iteration loss = 0.0049946364

Training iteration loss = 0.0034588668

Training iteration loss = 0.0023729468

Training iteration loss = 0.0047647962

Training iteration loss = 0.0033885809

Training iteration loss = 0.004696963

Training iteration loss = 0.0021529142

Training iteration loss = 0.0027158477

Training iteration loss = 0.0027895665

Training iteration loss = 0.0052497997

Training iteration loss = 0.0037312137

Training iteration loss = 0.003270859

Training iteration loss = 0.0028103944

Training iteration loss = 0.006493618

Training iteration loss = 0.00268421

Training iteration loss = 0.0053648655

Training iteration loss = 0.005140845

Training iteration loss = 0.011954127

Training iteration loss = 0.0077333087

Training iteration loss = 0.0039952206

Training iteration loss = 0.0030333058

Training iteration loss = 0.0075996867

Training iteration loss = 0.003075747

Training iteration loss = 0.0033374578

Training iteration loss = 0.0036353504

Training iteration loss = 0.0037267294

Training iteration loss = 0.0032950859

Training iteration loss = 0.0059478004

Training iteration loss = 0.0041306

Training iteration loss = 0.0034644916

Training iteration loss = 0.005123535

Training iteration loss = 0.0020766933

Training iteration loss = 0.0029302503

Training iteration loss = 0.0027152817

Training iteration loss = 0.003261243

Training iteration loss = 0.004043673

Training iteration loss = 0.0032395078

Training iteration loss = 0.004614741

Training iteration loss = 0.0036499598

Training iteration loss = 0.008192719

Training iteration loss = 0.0029300347

Training iteration loss = 0.0045237346

Training iteration loss = 0.0018959122

Training iteration loss = 0.0072950153

Training iteration loss = 0.00979095

Training iteration loss = 0.002815437

Training iteration loss = 0.0021465109

Training iteration loss = 0.003349695

Training iteration loss = 0.010965948

Training iteration loss = 0.0053834687

Training iteration loss = 0.0027331791

Training iteration loss = 0.0034484388

Training iteration loss = 0.0031301219

Training iteration loss = 0.002096417

Training iteration loss = 0.0028621843

Training iteration loss = 0.0026263322

Training iteration loss = 0.0025562553

Training iteration loss = 0.002936789

Training iteration loss = 0.005690785

Training iteration loss = 0.004414388

Training iteration loss = 0.009510535

Training iteration loss = 0.007307798

Training iteration loss = 0.0040048985

Training iteration loss = 0.0038775078

Training iteration loss = 0.0059718895

Training iteration loss = 0.006185392

Training iteration loss = 0.0037529347

Training iteration loss = 0.0049646255

Training iteration loss = 0.0054346686

Training iteration loss = 0.004441841

Training iteration loss = 0.0047211973

Training iteration loss = 0.0039896765

Training iteration loss = 0.005133255

Training iteration loss = 0.0038285172

Training iteration loss = 0.0037056012

Training iteration loss = 0.002371448

Training iteration loss = 0.0022380124

Training iteration loss = 0.0022031225

Training iteration loss = 0.0021275128

Training iteration loss = 0.00210405

Training iteration loss = 0.0030843483

Training iteration loss = 0.005533717

Training iteration loss = 0.011873048

Training iteration loss = 0.0024564196

Training iteration loss = 0.004280238

Training iteration loss = 0.0026257627

Training iteration loss = 0.005200248

Training iteration loss = 0.0032320884

Training iteration loss = 0.0036824958

Training iteration loss = 0.0050782715

Training iteration loss = 0.002785958

Training iteration loss = 0.0065569435

Training iteration loss = 0.0069305566

Training iteration loss = 0.0022562977

Training iteration loss = 0.002768361

Training iteration loss = 0.0079635605

Training iteration loss = 0.0069794166

Training iteration loss = 0.0027280531

Training iteration loss = 0.0073513016

Training iteration loss = 0.0021569575

Training iteration loss = 0.0030795392

Training iteration loss = 0.0027624771

Training iteration loss = 0.0037574738

Training iteration loss = 0.002899963

Training iteration loss = 0.0083821

Training iteration loss = 0.0040193396

Training iteration loss = 0.0038862375

Training iteration loss = 0.0033071013

Training iteration loss = 0.0021211924

Training iteration loss = 0.0034443464

Training iteration loss = 0.0026210267

Training iteration loss = 0.0036539445

Training iteration loss = 0.0033722334

Training iteration loss = 0.0046319203

Training iteration loss = 0.0043523163

Training iteration loss = 0.00390749

Training iteration loss = 0.0023764463

Training iteration loss = 0.0017492219

Training iteration loss = 0.0035993923

Training iteration loss = 0.0025145672

Training iteration loss = 0.002802287

Training iteration loss = 0.00889813

Training iteration loss = 0.0023068343

Training iteration loss = 0.0022795112

Training iteration loss = 0.002954213

Training iteration loss = 0.005537506

Training iteration loss = 0.0033934792

Training iteration loss = 0.0036835354

Training iteration loss = 0.0033805617

Training iteration loss = 0.0021194778

Training iteration loss = 0.003350235

Training iteration loss = 0.0015968853

Training iteration loss = 0.0028850192

Training iteration loss = 0.002659866

Training iteration loss = 0.0071353805

Training iteration loss = 0.0029885396

Training iteration loss = 0.0037418187

Training iteration loss = 0.0036105728

Training iteration loss = 0.0070404736

Training iteration loss = 0.004543618

Training iteration loss = 0.004110331

Training iteration loss = 0.0016399027

Training iteration loss = 0.0027958797

Training iteration loss = 0.0021653788

Training iteration loss = 0.0041743633

Training iteration loss = 0.0019125359

Training iteration loss = 0.0017959506

Training iteration loss = 0.0023938415

Training iteration loss = 0.0036836576

Training iteration loss = 0.0033767214

Training iteration loss = 0.0032464513

Training iteration loss = 0.004281034

Training iteration loss = 0.0026851222

Training iteration loss = 0.006352279

Training iteration loss = 0.004072581

Training iteration loss = 0.0035775863

Training iteration loss = 0.002786986

Training iteration loss = 0.0045258175

Training iteration loss = 0.0043924158

Training iteration loss = 0.00783025

Training iteration loss = 0.004171347

Training iteration loss = 0.003642792

Training iteration loss = 0.0018802466

Training iteration loss = 0.0050615217

Training iteration loss = 0.003132397

Training iteration loss = 0.0047480776

Training iteration loss = 0.003984767

Training iteration loss = 0.0038212002

Training iteration loss = 0.0030028604

Training iteration loss = 0.0073867617

Training iteration loss = 0.00270636

Training iteration loss = 0.0023269805

Training iteration loss = 0.004023179

Training iteration loss = 0.0025835002

Training iteration loss = 0.0031141436

Training iteration loss = 0.0065033473

Training iteration loss = 0.008274963

Training iteration loss = 0.0039199414

Training iteration loss = 0.004980692

Training iteration loss = 0.0025116252

Training iteration loss = 0.0055126664

Training iteration loss = 0.010278195

Training iteration loss = 0.0044284198

Training iteration loss = 0.004761284

Training iteration loss = 0.0045290953

Training iteration loss = 0.0044593755

Training iteration loss = 0.0028940241

Training iteration loss = 0.003137598

Training iteration loss = 0.0048677116

Training iteration loss = 0.009021519

Training iteration loss = 0.00356085

Training iteration loss = 0.002813493

Training iteration loss = 0.0023193583

Training iteration loss = 0.004288399

Training iteration loss = 0.003184198

Training iteration loss = 0.0031220498

Training iteration loss = 0.004114658

Training iteration loss = 0.0023411138

Training iteration loss = 0.005230786

Training iteration loss = 0.008944627

Training iteration loss = 0.0049721943

Training iteration loss = 0.0034186887

Training iteration loss = 0.002301517

Training iteration loss = 0.00459884

Training iteration loss = 0.0033695651

Training iteration loss = 0.0046547973

Training iteration loss = 0.0021972698

Training iteration loss = 0.0027385922

Training iteration loss = 0.0027816175

Training iteration loss = 0.0051891813

Training iteration loss = 0.0037965812

Training iteration loss = 0.0031723208

Training iteration loss = 0.0026795536

Training iteration loss = 0.0064383415

Training iteration loss = 0.0026600547

Training iteration loss = 0.0053195646

Training iteration loss = 0.005004516

Training iteration loss = 0.011767012

Training iteration loss = 0.0075413547

Training iteration loss = 0.003931419

Training iteration loss = 0.0030383822

Training iteration loss = 0.0075048744

Training iteration loss = 0.0030559704

Training iteration loss = 0.0033130443

Training iteration loss = 0.0036250507

Training iteration loss = 0.0035946248

Training iteration loss = 0.0032302365

Training iteration loss = 0.005877416

Training iteration loss = 0.004134784

Training iteration loss = 0.00346908

Training iteration loss = 0.005088925

Training iteration loss = 0.0020801574

Training iteration loss = 0.002901945

Training iteration loss = 0.002799768

Training iteration loss = 0.0031878569

Training iteration loss = 0.004043071

Training iteration loss = 0.003107537

Training iteration loss = 0.004557278

Training iteration loss = 0.0036432534

Training iteration loss = 0.0081266

Training iteration loss = 0.0029685493

Training iteration loss = 0.004405715

Training iteration loss = 0.0019930834

Training iteration loss = 0.007217647

Training iteration loss = 0.009617346

Training iteration loss = 0.0027390756

Training iteration loss = 0.0021307268

Training iteration loss = 0.0032539656

Training iteration loss = 0.010785794

Training iteration loss = 0.005341581

Training iteration loss = 0.0026948978

Training iteration loss = 0.0034604173

Training iteration loss = 0.0030488712

Training iteration loss = 0.0020692316

Training iteration loss = 0.0028929682

Training iteration loss = 0.0025889436

Training iteration loss = 0.0025572572

Training iteration loss = 0.0028695152

Training iteration loss = 0.0056976965

Training iteration loss = 0.0043869866

Training iteration loss = 0.009389672

Training iteration loss = 0.007125479

Training iteration loss = 0.004015325

Training iteration loss = 0.0038546706

Training iteration loss = 0.005868565

Training iteration loss = 0.006127568

Training iteration loss = 0.0037583637

Training iteration loss = 0.004843183

Training iteration loss = 0.005364867

Training iteration loss = 0.0043309126

Training iteration loss = 0.0046530706

Training iteration loss = 0.0039311415

Training iteration loss = 0.0050358432

Training iteration loss = 0.0038126651

Training iteration loss = 0.0036872262

Training iteration loss = 0.0024023

Training iteration loss = 0.0022777792

Training iteration loss = 0.002210106

Training iteration loss = 0.0021263252

Training iteration loss = 0.0021408964

Training iteration loss = 0.003094445

Training iteration loss = 0.0054931105

Training iteration loss = 0.011716602

Training iteration loss = 0.0024780354

Training iteration loss = 0.004312656

Training iteration loss = 0.0026243124

Training iteration loss = 0.0051663397

Training iteration loss = 0.0032523575

Training iteration loss = 0.003644875

Training iteration loss = 0.00507131

Training iteration loss = 0.002799632

Training iteration loss = 0.006483018

Training iteration loss = 0.0068891896

Training iteration loss = 0.002297124

Training iteration loss = 0.0027366073

Training iteration loss = 0.007921755

Training iteration loss = 0.0068543255

Training iteration loss = 0.0026734842

Training iteration loss = 0.0072753094

Training iteration loss = 0.0021467267

Training iteration loss = 0.0030364974

Training iteration loss = 0.0027322948

Training iteration loss = 0.0037081868

Training iteration loss = 0.0029042054

Training iteration loss = 0.008238761

Training iteration loss = 0.0040321024

Training iteration loss = 0.0038720965

Training iteration loss = 0.0032335257

Training iteration loss = 0.0021555247

Training iteration loss = 0.0034569795

Training iteration loss = 0.0026093414

Training iteration loss = 0.00364382

Training iteration loss = 0.0033404366

Training iteration loss = 0.0045858887

Training iteration loss = 0.0043722684

Training iteration loss = 0.0039296616

Training iteration loss = 0.002379888

Training iteration loss = 0.0017937201

Training iteration loss = 0.003596827

Training iteration loss = 0.002544523

Training iteration loss = 0.0028049832

Training iteration loss = 0.008836938

Training iteration loss = 0.0022425235

Training iteration loss = 0.0022775773

Training iteration loss = 0.002918973

Training iteration loss = 0.0054961466

Training iteration loss = 0.0034074476

Training iteration loss = 0.0036372633

Training iteration loss = 0.0033715495

Training iteration loss = 0.0021295547

Training iteration loss = 0.0033427903

Training iteration loss = 0.0016053772

Training iteration loss = 0.0028355634

Training iteration loss = 0.0026414744

Training iteration loss = 0.0071502314

Training iteration loss = 0.0030098176

Training iteration loss = 0.0037051644

Training iteration loss = 0.0035320427

Training iteration loss = 0.0070022047

Training iteration loss = 0.0044895113

Training iteration loss = 0.004084425

Training iteration loss = 0.0016171922

Training iteration loss = 0.0028056635

Training iteration loss = 0.0021292176

Training iteration loss = 0.004198196

Training iteration loss = 0.001926548

Training iteration loss = 0.0017773209

Training iteration loss = 0.0024093965

Training iteration loss = 0.0036843016

Training iteration loss = 0.003404035

Training iteration loss = 0.0032323038

Training iteration loss = 0.004233139

Training iteration loss = 0.0026559352

Training iteration loss = 0.0062434375

Training iteration loss = 0.003999823

Training iteration loss = 0.003482606

Training iteration loss = 0.0028074735

Training iteration loss = 0.0044523613

Training iteration loss = 0.004400253

Training iteration loss = 0.007846649

Training iteration loss = 0.0041332836

Training iteration loss = 0.0035977294

Training iteration loss = 0.0018887903

Training iteration loss = 0.0050785732

Training iteration loss = 0.0031072416

Training iteration loss = 0.0047195666

Training iteration loss = 0.003955005

Training iteration loss = 0.0038103017

Training iteration loss = 0.0029702622

Training iteration loss = 0.007319165

Training iteration loss = 0.0027162682

Training iteration loss = 0.0022997377

Training iteration loss = 0.0040439386

Training iteration loss = 0.002583482

Training iteration loss = 0.0030965973

Training iteration loss = 0.0065253535

Training iteration loss = 0.00816334

Training iteration loss = 0.0039088894

Training iteration loss = 0.0049735717

Training iteration loss = 0.0025143623

Training iteration loss = 0.005492808

Training iteration loss = 0.01017059

Training iteration loss = 0.0044490993

Training iteration loss = 0.004742248

Training iteration loss = 0.0045150267

Training iteration loss = 0.004340675

Training iteration loss = 0.002866854

Training iteration loss = 0.0031056895

Training iteration loss = 0.0048201014

Training iteration loss = 0.008935487

Training iteration loss = 0.0035901386

Training iteration loss = 0.0027485937

Training iteration loss = 0.0023028967

Training iteration loss = 0.0042952434

Training iteration loss = 0.0031613493

Training iteration loss = 0.0031085121

Training iteration loss = 0.0040857545

Training iteration loss = 0.0023645407

Training iteration loss = 0.005164919

Training iteration loss = 0.008874956

Training iteration loss = 0.004966913

Training iteration loss = 0.0033991544

Training iteration loss = 0.0022682012

Training iteration loss = 0.0045164404

Training iteration loss = 0.0033667702

Training iteration loss = 0.0046317945

Training iteration loss = 0.0022225743

Training iteration loss = 0.0027641824

Training iteration loss = 0.0027797536

Training iteration loss = 0.00516228

Training iteration loss = 0.0038420698

Training iteration loss = 0.0031212044

Training iteration loss = 0.002614576

Training iteration loss = 0.006419029

Training iteration loss = 0.0026591215

Training iteration loss = 0.0052981596

Training iteration loss = 0.0049272757

Training iteration loss = 0.011661499

Training iteration loss = 0.007428049

Training iteration loss = 0.0039048672

Training iteration loss = 0.0030483706

Training iteration loss = 0.0074545904

Training iteration loss = 0.0030515234

Training iteration loss = 0.0033069456

Training iteration loss = 0.0036362917

Training iteration loss = 0.0035320716

Training iteration loss = 0.0031975433

Training iteration loss = 0.005833442

Training iteration loss = 0.004137591

Training iteration loss = 0.0034741003

Training iteration loss = 0.00507486

Training iteration loss = 0.002086084

Training iteration loss = 0.0028945347

Training iteration loss = 0.0028509444

Training iteration loss = 0.0031472929

Training iteration loss = 0.0040578526

Training iteration loss = 0.0030428807

Training iteration loss = 0.0045312517

Training iteration loss = 0.0036358193

Training iteration loss = 0.008089885

Training iteration loss = 0.0029974775

Training iteration loss = 0.0043438883

Training iteration loss = 0.0020469045

Training iteration loss = 0.007170496

Training iteration loss = 0.00951416

Training iteration loss = 0.002696624

Training iteration loss = 0.002133066

Training iteration loss = 0.0032014973

Training iteration loss = 0.010679769

Training iteration loss = 0.0053103007

Training iteration loss = 0.0026790025

Training iteration loss = 0.0034718602

Training iteration loss = 0.003010308

Training iteration loss = 0.0020610373

Training iteration loss = 0.0029118366

Training iteration loss = 0.0025710596

Training iteration loss = 0.0025622293

Training iteration loss = 0.002835611

Training iteration loss = 0.00570157

Training iteration loss = 0.0043742657

Training iteration loss = 0.009323607

Training iteration loss = 0.0070259175

Training iteration loss = 0.0040268693

Training iteration loss = 0.0038426796

Training iteration loss = 0.005813914

Training iteration loss = 0.0060973

Training iteration loss = 0.0037654145

Training iteration loss = 0.0047790273

Training iteration loss = 0.005331134

Training iteration loss = 0.0042654583

Training iteration loss = 0.0046132114

Training iteration loss = 0.0039030914

Training iteration loss = 0.0049793627

Training iteration loss = 0.003809825

Training iteration loss = 0.0036786161

Training iteration loss = 0.0024173178

Training iteration loss = 0.0023042343

Training iteration loss = 0.0022137654

Training iteration loss = 0.0021312332

Training iteration loss = 0.0021605438

Training iteration loss = 0.003099446

Training iteration loss = 0.0054695345

Training iteration loss = 0.011625558

Training iteration loss = 0.0024916313

Training iteration loss = 0.004329516

Training iteration loss = 0.0026264486

Training iteration loss = 0.0051515

Training iteration loss = 0.0032640798

Training iteration loss = 0.0036276188

Training iteration loss = 0.0050736694

Training iteration loss = 0.0028096205

Training iteration loss = 0.0064409254

Training iteration loss = 0.0068652746

Training iteration loss = 0.0023226906

Training iteration loss = 0.0027232738

Training iteration loss = 0.007892341

Training iteration loss = 0.00678338

Training iteration loss = 0.002645813

Training iteration loss = 0.007241937

Training iteration loss = 0.0021475123

Training iteration loss = 0.003013423

Training iteration loss = 0.0027167355

Training iteration loss = 0.0036780138

Training iteration loss = 0.0029121514

Training iteration loss = 0.008156872

Training iteration loss = 0.004042386

Training iteration loss = 0.00386874

Training iteration loss = 0.003191779

Training iteration loss = 0.0021775865

Training iteration loss = 0.0034653198

Training iteration loss = 0.0026055824

Training iteration loss = 0.0036342412

Training iteration loss = 0.0033220032

Training iteration loss = 0.004561494

Training iteration loss = 0.0043843077

Training iteration loss = 0.0039465674

Training iteration loss = 0.0023853902

Training iteration loss = 0.0018234939

Training iteration loss = 0.0035967561

Training iteration loss = 0.002556358

Training iteration loss = 0.0028111495

Training iteration loss = 0.008804329

Training iteration loss = 0.0022072438

Training iteration loss = 0.0022781673

Training iteration loss = 0.0029003243

Training iteration loss = 0.005473478

Training iteration loss = 0.0034192102

Training iteration loss = 0.003612095

Training iteration loss = 0.0033693933

Training iteration loss = 0.0021362607

Training iteration loss = 0.0033394347

Training iteration loss = 0.0016129581

Training iteration loss = 0.0028099136

Training iteration loss = 0.0026321854

Training iteration loss = 0.007153955

Training iteration loss = 0.0030183517

Training iteration loss = 0.0036816322

Training iteration loss = 0.0034874924

Training iteration loss = 0.0069794925

Training iteration loss = 0.0044609183

Training iteration loss = 0.004067899

Training iteration loss = 0.0016051143

Training iteration loss = 0.002809693

Training iteration loss = 0.0021094605

Training iteration loss = 0.004212721

Training iteration loss = 0.0019339896

Training iteration loss = 0.0017690249

Training iteration loss = 0.0024173642

Training iteration loss = 0.0036839806

Training iteration loss = 0.003422364

Training iteration loss = 0.0032222997

Training iteration loss = 0.0042051836

Training iteration loss = 0.0026399218

Training iteration loss = 0.0061811297

Training iteration loss = 0.003958932

Training iteration loss = 0.003429825

Training iteration loss = 0.002822724

Training iteration loss = 0.004408117

Training iteration loss = 0.0044062864

Training iteration loss = 0.007858468

Training iteration loss = 0.004109869

Training iteration loss = 0.0035684537

Training iteration loss = 0.0018987159

Training iteration loss = 0.005089645

Training iteration loss = 0.0030928638

Training iteration loss = 0.0047053928

Training iteration loss = 0.0039385445

Training iteration loss = 0.0038028418

Training iteration loss = 0.0029514665

Training iteration loss = 0.0072793984

Training iteration loss = 0.0027235674

Training iteration loss = 0.0022833718

Training iteration loss = 0.00405759

Training iteration loss = 0.0025844774

Training iteration loss = 0.003084485

Training iteration loss = 0.006538989

Training iteration loss = 0.008098802

Training iteration loss = 0.0039046444

Training iteration loss = 0.004971163

Training iteration loss = 0.0025176962

Training iteration loss = 0.0054827267

Training iteration loss = 0.010107217

Training iteration loss = 0.0044627576

Training iteration loss = 0.004731356

Training iteration loss = 0.00450455

Training iteration loss = 0.0042716498

Training iteration loss = 0.0028517717

Training iteration loss = 0.003087012

Training iteration loss = 0.0047932337

Training iteration loss = 0.008885799

Training iteration loss = 0.003607404

Training iteration loss = 0.0027117452

Training iteration loss = 0.002294843

Training iteration loss = 0.004293952

Training iteration loss = 0.0031443033

Training iteration loss = 0.0031042665

Training iteration loss = 0.0040679495

Training iteration loss = 0.002378029

Training iteration loss = 0.0051253415

Training iteration loss = 0.008834329

Training iteration loss = 0.0049655093

Training iteration loss = 0.0033863392

Training iteration loss = 0.0022513983

Training iteration loss = 0.004472332

Training iteration loss = 0.003368691

Training iteration loss = 0.004614526

Training iteration loss = 0.0022330617

Training iteration loss = 0.002780531

Training iteration loss = 0.0027748889

Training iteration loss = 0.005147159

Training iteration loss = 0.0038689317

Training iteration loss = 0.0030906224

Training iteration loss = 0.0025804043

Training iteration loss = 0.0064122565

Training iteration loss = 0.0026610862

Training iteration loss = 0.0052844863

Training iteration loss = 0.004879294

Training iteration loss = 0.011598642

Training iteration loss = 0.0073575396

Training iteration loss = 0.0038909568

Training iteration loss = 0.0030544945

Training iteration loss = 0.0074220914

Training iteration loss = 0.0030498991

Training iteration loss = 0.0033070701

Training iteration loss = 0.0036513314

Training iteration loss = 0.0034990583

Training iteration loss = 0.0031775725

Training iteration loss = 0.005802354

Training iteration loss = 0.004135919

Training iteration loss = 0.0034774686

Training iteration loss = 0.0050651818

Training iteration loss = 0.0020864145

Training iteration loss = 0.002891787

Training iteration loss = 0.0028791614

Training iteration loss = 0.0031227034

Training iteration loss = 0.004073064

Training iteration loss = 0.0030080602

Training iteration loss = 0.004516721

Training iteration loss = 0.003625752

Training iteration loss = 0.008068041

Training iteration loss = 0.0030156206

Training iteration loss = 0.004308697

Training iteration loss = 0.0020710249

Training iteration loss = 0.0071367393

Training iteration loss = 0.009449158

Training iteration loss = 0.0026703002

Training iteration loss = 0.002137418

Training iteration loss = 0.0031685822

Training iteration loss = 0.010612294

Training iteration loss = 0.005284092

Training iteration loss = 0.002670657

Training iteration loss = 0.00347777

Training iteration loss = 0.0029900228

Training iteration loss = 0.0020570187

Training iteration loss = 0.002918722

Training iteration loss = 0.0025605415

Training iteration loss = 0.0025659027

Training iteration loss = 0.0028164661

Training iteration loss = 0.005698809

Training iteration loss = 0.0043642716

Training iteration loss = 0.009283708

Training iteration loss = 0.006968066

Training iteration loss = 0.00403349

Training iteration loss = 0.00383233

Training iteration loss = 0.0057824077

Training iteration loss = 0.0060774493

Training iteration loss = 0.0037690338

Training iteration loss = 0.004740934

Training iteration loss = 0.005312229

Training iteration loss = 0.0042219223

Training iteration loss = 0.0045869406

Training iteration loss = 0.0038880128

Training iteration loss = 0.0049443226

Training iteration loss = 0.0038081286

Training iteration loss = 0.0036713486

Training iteration loss = 0.0024200454

Training iteration loss = 0.002319128

Training iteration loss = 0.002212584

Training iteration loss = 0.0021352596

Training iteration loss = 0.0021671294

Training iteration loss = 0.0030987249

Training iteration loss = 0.0054503405

Training iteration loss = 0.0115672415

Training iteration loss = 0.0024964558

Training iteration loss = 0.004336056

Training iteration loss = 0.002625184

Training iteration loss = 0.0051431954

Training iteration loss = 0.0032683734

Training iteration loss = 0.0036173102

Training iteration loss = 0.0050762924

Training iteration loss = 0.0028134077

Training iteration loss = 0.0064141443

Training iteration loss = 0.006847631

Training iteration loss = 0.0023371023

Training iteration loss = 0.0027163245

Training iteration loss = 0.007867896

Training iteration loss = 0.006738797

Training iteration loss = 0.0026270912

Training iteration loss = 0.0072275414

Training iteration loss = 0.0021481868

Training iteration loss = 0.0029980252

Training iteration loss = 0.0027069375

Training iteration loss = 0.003656698

Training iteration loss = 0.0029178904

Training iteration loss = 0.00810703

Training iteration loss = 0.0040475717

Training iteration loss = 0.0038679373

Training iteration loss = 0.0031648064

Training iteration loss = 0.0021892223

Training iteration loss = 0.0034672325

Training iteration loss = 0.0026024983

Training iteration loss = 0.0036236136

Training iteration loss = 0.0033067756

Training iteration loss = 0.004546719

Training iteration loss = 0.004388351

Training iteration loss = 0.003956982

Training iteration loss = 0.002388216

Training iteration loss = 0.0018406926

Training iteration loss = 0.0035957256

Training iteration loss = 0.0025564637

Training iteration loss = 0.002814404

Training iteration loss = 0.00878497

Training iteration loss = 0.0021856881

Training iteration loss = 0.0022764513

Training iteration loss = 0.002887405

Training iteration loss = 0.0054598586

Training iteration loss = 0.0034263409

Training iteration loss = 0.003595631

Training iteration loss = 0.0033687023

Training iteration loss = 0.002138936

Training iteration loss = 0.0033346782

Training iteration loss = 0.0016175986

Training iteration loss = 0.0027950662

Training iteration loss = 0.0026261134

Training iteration loss = 0.007149442

Training iteration loss = 0.0030176141

Training iteration loss = 0.0036630179

Training iteration loss = 0.0034594059

Training iteration loss = 0.006962342

Training iteration loss = 0.0044412804

Training iteration loss = 0.0040556523

Training iteration loss = 0.0015973394

Training iteration loss = 0.0028084791

Training iteration loss = 0.0020963235

Training iteration loss = 0.004220297

Training iteration loss = 0.0019357383

Training iteration loss = 0.0017634947

Training iteration loss = 0.002418814

Training iteration loss = 0.0036814376

Training iteration loss = 0.0034330857

Training iteration loss = 0.0032132172

Training iteration loss = 0.0041856132

Training iteration loss = 0.0026293867

Training iteration loss = 0.006141284

Training iteration loss = 0.003932847

Training iteration loss = 0.0033987248

Training iteration loss = 0.0028323333

Training iteration loss = 0.0043786527

Training iteration loss = 0.0044099167

Training iteration loss = 0.007866224

Training iteration loss = 0.004092053

Training iteration loss = 0.0035468908

Training iteration loss = 0.0019063032

Training iteration loss = 0.0050955308

Training iteration loss = 0.0030820002

Training iteration loss = 0.0046968036

Training iteration loss = 0.003926519

Training iteration loss = 0.0037957737

Training iteration loss = 0.0029384932

Training iteration loss = 0.007253034

Training iteration loss = 0.00272758

Training iteration loss = 0.0022708478

Training iteration loss = 0.00406478

Training iteration loss = 0.0025842697

Training iteration loss = 0.0030739396

Training iteration loss = 0.0065465197

Training iteration loss = 0.008057052

Training iteration loss = 0.003902101

Training iteration loss = 0.0049692206

Training iteration loss = 0.0025192238

Training iteration loss = 0.005476539

Training iteration loss = 0.010066593

Training iteration loss = 0.004470782

Training iteration loss = 0.0047221845

Training iteration loss = 0.0044952235

Training iteration loss = 0.0042272434

Training iteration loss = 0.0028420978

Training iteration loss = 0.003073669

Training iteration loss = 0.0047752704

Training iteration loss = 0.0088540865

Training iteration loss = 0.0036164909

Training iteration loss = 0.0026874943

Training iteration loss = 0.0022891469

Training iteration loss = 0.0042869756

Training iteration loss = 0.003129604

Training iteration loss = 0.003102556

Training iteration loss = 0.0040552546

Training iteration loss = 0.0023845995

Training iteration loss = 0.005097715

Training iteration loss = 0.0088070715

Training iteration loss = 0.0049645416

Training iteration loss = 0.003375814

Training iteration loss = 0.0022418958

Training iteration loss = 0.0044461996

Training iteration loss = 0.0033720143

Training iteration loss = 0.0045996015

Training iteration loss = 0.002235238

Training iteration loss = 0.002789508

Training iteration loss = 0.0027676048

Training iteration loss = 0.005136776

Training iteration loss = 0.0038843027

Training iteration loss = 0.0030694846

Training iteration loss = 0.0025605098

Training iteration loss = 0.0064100074

Training iteration loss = 0.002661727

Training iteration loss = 0.005274208

Training iteration loss = 0.004846476

Training iteration loss = 0.011557862

Training iteration loss = 0.007309959

Training iteration loss = 0.003881566

Training iteration loss = 0.0030571197

Training iteration loss = 0.007397588

Training iteration loss = 0.0030483794

Training iteration loss = 0.0033094182

Training iteration loss = 0.0036656905

Training iteration loss = 0.0034790263

Training iteration loss = 0.003163299

Training iteration loss = 0.0057785115

Training iteration loss = 0.0041311234

Training iteration loss = 0.0034796477

Training iteration loss = 0.005056293

Training iteration loss = 0.002082652

Training iteration loss = 0.0028899782

Training iteration loss = 0.002894406

Training iteration loss = 0.003105939

Training iteration loss = 0.0040860428

Training iteration loss = 0.002987038

Training iteration loss = 0.0045070774

Training iteration loss = 0.0036140725

Training iteration loss = 0.008053617

Training iteration loss = 0.0030268554

Training iteration loss = 0.0042869295

Training iteration loss = 0.0020789832

Training iteration loss = 0.007109582

Training iteration loss = 0.0094048

Training iteration loss = 0.0026518768

Training iteration loss = 0.002140704

Training iteration loss = 0.00314492

Training iteration loss = 0.010565003

Training iteration loss = 0.0052610114

Training iteration loss = 0.0026651742

Training iteration loss = 0.0034797827

Training iteration loss = 0.0029781074

Training iteration loss = 0.002053709

Training iteration loss = 0.002918254

Training iteration loss = 0.0025530956

Training iteration loss = 0.0025680594

Training iteration loss = 0.0028044595

Training iteration loss = 0.005691639

Training iteration loss = 0.0043546488

Training iteration loss = 0.009256545

Training iteration loss = 0.006931185

Training iteration loss = 0.004036327

Training iteration loss = 0.0038223467

Training iteration loss = 0.005762422

Training iteration loss = 0.0060619507

Training iteration loss = 0.0037699705

Training iteration loss = 0.004715195

Training iteration loss = 0.0052996594

Training iteration loss = 0.0041894233

Training iteration loss = 0.0045675347

Training iteration loss = 0.003878953

Training iteration loss = 0.004920791

Training iteration loss = 0.0038056867

Training iteration loss = 0.0036640265

Training iteration loss = 0.0024159849

Training iteration loss = 0.0023272545

Training iteration loss = 0.0022087255

Training iteration loss = 0.0021379786

Training iteration loss = 0.0021667944

Training iteration loss = 0.0030948939

Training iteration loss = 0.0054326374

Training iteration loss = 0.011525877

Training iteration loss = 0.0024960216

Training iteration loss = 0.0043376

Training iteration loss = 0.0026211333

Training iteration loss = 0.00513734

Training iteration loss = 0.0032688132

Training iteration loss = 0.0036101209

Training iteration loss = 0.0050776796

Training iteration loss = 0.0028134293

Training iteration loss = 0.0063953577

Training iteration loss = 0.0068329107

Training iteration loss = 0.0023455983

Training iteration loss = 0.0027120158

Training iteration loss = 0.007846558

Training iteration loss = 0.006707823

Training iteration loss = 0.002612068

Single layer neural network training data error = 0.002612068

Single layer neural network test data error = 0.0022195214
